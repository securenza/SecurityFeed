{"id":"2bP4pJr4wVimh6yine63HqNeafoyheTFz1gqCrQ4h7Z","title":"AlgoMaster Newsletter","displayTitle":"Dev - Algomaster","url":"https://blog.algomaster.io/feed","feedLink":"https://blog.algomaster.io/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":10,"items":[{"title":"Top 15 Database Scaling Techniques","url":"https://blog.algomaster.io/p/top-15-database-scaling-techniques","date":1742100801,"author":"Ashish Pratap Singh","guid":483,"unread":true,"content":"<p>When your application is small, with just a few hundred users, a  is usually enough to handle all the reads, writes, and transactions.</p><p>But as your , so does the volume of data and database operations. More users mean more queries per second, more concurrent connections, and larger datasets.</p><p>If you don't scale your database to handle the increased load, it can  your app and cause problems.</p><p>In this article we will explore the <strong>15 Database Scaling Techniques</strong> to ensure your application keeps operating at optimal performance without the database becoming a bottleneck.</p><p>, also known as , is the process of increasing the capacity of a single database server by adding more resources—CPU, RAM, disk storage, or network bandwidth.</p><ol><li><p> – You replace the existing machine with a higher-capacity one. This might involve switching to a server with more CPU cores, higher memory, or better disk performance (e.g., moving from HDDs to NVMe SSDs).</p></li><li><p><strong>Increasing Resource Allocations</strong> – If you're using a cloud provider (AWS, GCP, Azure), you can resize instances dynamically. For example, upgrading from an AWS RDS  instance to a  instance.</p></li><li><p><strong>Database Engine Optimizations</strong> – Tuning configurations such as increasing buffer pool size in MySQL () or allocating more shared memory in PostgreSQL ().</p></li><li><p> – Moving from traditional HDDs to SSDs or leveraging NVMe storage to reduce disk I/O bottlenecks.</p></li></ol><h3><strong>When Should You Consider Using Vertical Scaling?</strong></h3><ul><li><p>When your workload fits within the limits of a single machine and you want  without introducing the complexity of distributed databases.</p></li><li><p>When , and distributing queries across multiple nodes introduces unwanted overhead.</p></li><li><p>When your application is still , and horizontal scaling (sharding or replication) is unnecessary.</p></li><li><p>When you need a <strong>quick and cost-effective solution</strong> in the short term without redesigning the system architecture.</p></li></ul><h3><strong>Limitations of Vertical Scaling</strong></h3><ol><li><p> – There's a ceiling to how much you can scale a single machine. Even the largest cloud instance has limits.</p></li><li><p> – A vertically scaled database is a single machine. If it crashes, everything goes down unless there's a failover mechanism.</p></li><li><p><strong>Expensive Beyond a Certain Point</strong> – The cost of high-end machines grows exponentially. A top-tier AWS RDS instance can cost thousands of dollars per month.</p></li><li><p> – Increasing CPU, memory, or disk space often requires downtime, especially in on-premise setups.</p></li></ol><blockquote><p>Vertical scaling is <strong>simple, effective, and easy to implement</strong>, making it a great first step for scaling a database. However, as traffic grows, a single machine will eventually hit a hard limit, forcing a move toward <strong>horizontal scaling techniques</strong> like sharding or replication.</p></blockquote><p> is a technique used to <strong>speed up database queries</strong> by creating a data structure that allows for faster lookups. Instead of scanning the entire table to find relevant rows, an index acts like a  in a book—helping the database locate data quickly.</p><p>Imagine searching for a word in a dictionary. Without an index, you’d have to read every page. But with an alphabetically sorted index, you can jump directly to the correct section. That’s exactly how a database index works.</p><p>Creating an index on a single column that is frequently used in  clauses. Example:</p><pre><code>CREATE INDEX idx_users_email ON users(email);</code></pre><p>An index on multiple columns, useful when queries filter by multiple conditions. Example:</p><pre><code>CREATE INDEX idx_orders_customer_date ON orders(customer_id, order_date);</code></pre><h3><strong>When Should You Consider Using Indexing?</strong></h3><ul><li><p>When queries frequently  by a specific column (, , ).</p></li><li><p>When performing  on large tables.</p></li><li><p>When optimizing , where fast lookups are more critical than fast writes.</p></li></ul><ol><li><p> – Every , , or  operation must also update the index, increasing overhead.</p></li><li><p> – Indexes consume additional disk space, sometimes larger than the actual table.</p></li><li><p><strong>Not Useful for Every Query</strong> – If a query retrieves a large portion of the table, an index may not help and could even slow it down.</p></li><li><p> – Too many indexes can slow down performance instead of improving it. Choosing the right indexes is key.</p></li></ol><blockquote><p>Indexing is one of the most powerful ways to scale a database <strong>without adding more hardware</strong>. However, it requires careful planning. The  can improve query performance by orders of magnitude, while  can slow down writes and waste storage.</p></blockquote><p> is the process of storing frequently accessed data in a  to reduce database load and improve response times. Instead of repeatedly querying the database for the same data, applications can retrieve it from a , which is significantly faster.</p><p>There are multiple <a href=\"https://blog.algomaster.io/p/top-5-caching-strategies-explained\">caching strategies</a> (read through, cache aside, write back etc.,) each suited for different use cases.</p><p>The  pattern is widely used because it gives the application full control over caching logic.</p><ul><li><p>When a client requests data, the application first checks the cache.</p></li><li><p>If the data exists in cache (), it is returned instantly.</p></li><li><p>If data is not found (), it is fetched from the database, stored in the cache for future requests, and returned to the client.</p></li></ul><h4><strong>Content Delivery Network (CDN) Caching</strong></h4><p>For web applications, static content (images, videos, scripts) is cached at CDN edge servers, reducing database and server load.</p><h3><strong>When Should You Consider Using Caching?</strong></h3><ul><li><p>When the <strong>same data is frequently accessed</strong>, such as user profiles, product catalogs, or search results.</p></li><li><p>When you need , especially for real-time applications.</p></li><li><p>When your database is experiencing  and you want to reduce direct database queries.</p></li><li><p>When serving  like images, CSS, and JavaScript in web applications.</p></li></ul><ol><li><p> – If the cache is not updated when the database changes, users might see outdated information.</p></li><li><p><strong>Cache Invalidation Complexity</strong> – Deciding when to refresh or expire cached data is challenging.</p></li><li><p> – Caching requires additional memory (RAM), which can be expensive at scale.</p></li><li><p><strong>Not Ideal for Write-Heavy Applications</strong> – Since caches mainly optimize read performance, write-heavy applications don’t benefit as much.</p></li></ol><blockquote><p>Caching is one of the most effective database scaling techniques because it <strong>reduces query load and improves response times</strong>. However, it requires <strong>careful cache invalidation strategies</strong> to ensure data consistency.</p></blockquote>","contentLength":6084,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/42a63987-4801-4374-81ca-d8453943b6c7_1238x874.png","enclosureMime":"","commentsUrl":null},{"title":"REST vs GraphQL","url":"https://blog.algomaster.io/p/rest-vs-graphql","date":1741668622,"author":"Ashish Pratap Singh","guid":482,"unread":true,"content":"<p> are the backbone of modern applications, acting as the bridge between <strong>client applications and backend servers</strong>.</p><p>Among the many API design choices,  and  have emerged as two dominant approaches.</p><p>Both offer powerful ways to retrieve and manipulate data, but they are built on fundamentally different philosophies.</p><p>REST, a time-tested architectural style, structures APIs around <strong>fixed endpoints and HTTP methods</strong>, making it intuitive and widely adopted. </p><p>On the other hand, GraphQL, a newer query language developed by Facebook, takes a more <strong>flexible and efficient approach</strong>, allowing clients to request exactly the data they need in a single request.</p><p>In this article, we’ll break down REST and GraphQL, compare their differences, and help you decide which one is best suited for your use case.</p><p> emerged in the early 2000s as a set of architectural principles for designing networked applications.</p><p>REST is not a protocol or standard but rather a <strong>set of guiding principles</strong> that leverage the existing  to enable communication between clients and servers.</p><p>At its core, REST is built around . Each resource (such as a user, order, or product) is uniquely identified by a Uniform Resource Locator, and clients interact with these resources using a <strong>fixed set of HTTP methods</strong>.</p><ul><li><p> → Retrieve a resource (e.g.,  to fetch user data).</p></li><li><p> → Create a new resource (e.g.,  to add a new user).</p></li><li><p> → Update an existing resource (e.g.,  to update user details).</p></li><li><p> → Remove a resource (e.g.,  to delete a user).</p></li></ul><p>For example, let’s say a client needs information about a specific user with .</p><ul><li><p>The client makes a request</p></li><li><p>The server responds with a JSON representation of the user</p></li></ul><p>REST APIs typically  and use  to communicate the outcome of the request:</p><ul><li><p> → Resource successfully created</p></li><li><p> → Client error (e.g., missing required fields)</p></li><li><p> → Requested resource does not exist</p></li><li><p><strong>500 Internal Server Error</strong> → Unexpected server issue</p></li></ul><ul><li><p><strong>Simplicity and Intuitive Design</strong>: The resource-based model aligns well with most business domains, making REST intuitive for developers.</p></li><li><p>: Each request contains all the information needed to complete it, making REST scalable across distributed systems.</p></li><li><p>: HTTP's caching mechanisms can be leveraged to improve performance.</p></li><li><p>REST APIs can be easily scaled using load balancers and CDNs.</p></li><li><p>: With nearly two decades of widespread use, REST enjoys robust tooling, documentation, and developer familiarity.</p></li></ul><ul><li><p>REST endpoints often return , leading to inefficient network usage. For example, if a mobile app only needs a user’s name and email, but the API response includes additional fields like address, phone number, and metadata, it results in .</p></li><li><p>: If an API doesn’t return related data, the client may need to  to retrieve all required information. For example, to get user details and their posts, a client might have to make:</p><ol><li><p> (fetch user)</p></li><li><p> (fetch user’s posts)</p></li></ol></li><li><p>: When APIs evolve, maintaining backward compatibility becomes difficult. REST APIs often require  (, ), adding maintenance overhead.</p></li><li><p><strong>Rigid Response Structure:</strong> The server defines how data is returned, and clients must adapt to it—even if they only need a subset of the data.</p></li></ul><p>For years,  was the de facto standard for building APIs. However, as applications grew more complex, REST began to show limitations—especially in scenarios where clients needed fine-grained control over the data they fetched.</p><p>To address these challenges, <strong>Facebook introduced GraphQL in 2015</strong>, offering a more flexible and efficient approach to data retrieval.</p><p>Unlike REST, which organizes APIs around <strong>fixed endpoints and HTTP methods</strong>, GraphQL is a  that allows clients to request exactly the data they need—nothing more, nothing less.</p><blockquote><p>A  () replaces multiple REST endpoints, allowing clients to structure their own queries instead of relying on predefined responses.</p></blockquote><p>Here, the query asks for a <strong>specific user's firstName, email, profileUrl and posts</strong>, all within a </p><p>GraphQL aggregates the data from multiple services and returns precisely the requested data.</p><p>It solves the problems of  (getting unnecessary data) and  (requiring multiple requests to retrieve related data).</p><p>Unlike REST, where API responses are  and may vary across versions, <strong>GraphQL enforces a strict schema</strong> that defines the shape of the data.</p><p>A simple GraphQL schema for the above example might look like this:</p><pre><code>type User {\n  id: ID!\n  firstName: String!\n  lastName: String!\n  email: String!\n  profile: Profile!\n  posts: [Post!]\n}\n\ntype Profile {\n  id: ID!\n  url: String!\n}\n\ntype Post {\n  id: ID!\n  title: String!\n  publishedDate: String!\n  content: String!\n  author: User!\n}\n\ntype Query {\n  user(id: ID!): User\n  posts: [Post!]!\n}</code></pre><h3>Three Core Functionalities of GraphQL</h3><p>GraphQL provides three core functionalities:</p><p>Similar to GET requests in REST, GraphQL queries allow clients to request specific fields of data.</p><p>Clients have full control over what they retrieve, avoiding unnecessary data fetching.</p><p><strong>Example: Fetching specific user and post details in a single request</strong></p><pre><code>query {\n  user(id: 123) {\n    name\n    email\n    posts {\n      title\n      content\n    }\n  }\n}</code></pre><p>Equivalent to <strong>POST, PUT, PATCH, or DELETE</strong> in REST. Used to <strong>create, update, or delete</strong> resources in the API.</p><p><strong>Example: Creating a new post</strong></p><pre><code>mutation {\n  createPost(title: \"GraphQL vs REST\", content: \"GraphQL solves many of REST's limitations...\", publishedDate: \"2025-03-10\") {\n    id\n    title\n    content\n  }\n}</code></pre><p>The response will contain the newly created post with its .</p><h4>3.  → Real-Time Updates</h4><p>Unlike REST, which requires polling or WebSockets for real-time updates, GraphQL subscriptions enable clients to listen for changes and receive updates automatically when data is modified.</p><p>Ideal for chat applications, live feeds, stock market updates, and notifications.</p><p><strong>Example: Listening for new posts</strong></p><pre><code>subscription {\n  newPost {\n    title\n    content\n    author {\n      name\n    }\n  }\n}</code></pre><p>Whenever a , all subscribed clients will .</p><h3><strong>How GraphQL Differs from REST</strong></h3><p>Both GraphQL and REST rely on <strong>HTTP requests and responses</strong>, but they differ in how they structure and deliver data.</p><ul><li><p>REST centers around resources (each identified by a URL).</p></li><li><p>GraphQL centers around a schema that defines the types of data available.</p></li></ul><p>In REST, the  decides which data is included in a response. If a client requests a blog post, the API might also return related , even if they aren’t needed.</p><p>With GraphQL, the  what to fetch. This makes GraphQL more flexible but also introduces challenges in <strong>caching and performance optimization</strong>.</p><ol><li><p>: Clients can request only the fields they need, reducing over-fetching and under-fetching.</p></li><li><p><strong>Single Request for Multiple Resources</strong>: Related data can be retrieved in one request, solving REST’s  query problem.</p></li><li><p>: GraphQL APIs use a schema to define available data, making them easier to explore and document.</p></li><li><p><strong>Real-time Data with Subscriptions:</strong> GraphQL natively supports real-time data updates through subscriptions, enabling clients to receive automatic notifications whenever data changes on the server.</p></li><li><p><strong>API Evolution Without Versioning</strong>: New fields can be added without breaking existing queries, avoiding REST-style ,  versioning issues.</p></li></ol><ol><li><p>: Unlike REST, which can be used with basic HTTP clients (cURL, browsers), GraphQL requires a GraphQL server, schema, and resolvers.</p></li><li><p>: REST APIs leverage HTTP caching (e.g., browser caching, CDNs), but GraphQL queries use POST requests, making caching trickier.</p></li><li><p> Since clients can request arbitrary amounts of data, GraphQL APIs must be carefully optimized to prevent performance issues.</p></li><li><p> Unoptimized queries (e.g., deeply nested requests) can lead to costly database scans, increasing the risk of denial-of-service (DoS) attacks.</p></li></ol><h3>Performance Risks with GraphQL</h3><p>Imagine a mobile app introduces a  that unexpectedly triggers a  on a critical database table.</p><p>With REST, this scenario is less likely because API endpoints are predefined, and developers control how data is exposed.</p><p>With GraphQL, the client , which could inadvertently request massive amounts of data. If a poorly designed query is executed on a high-traffic service, it could <strong>bring down the entire database</strong>.</p><p>To mitigate this, GraphQL APIs require <strong>strict query rate limiting, depth restrictions, and cost analysis mechanisms</strong>—adding additional complexity to the implementation.</p><p>There is no  answer.  remains a great choice for simple APIs, while  is powerful for complex applications with varying data needs.</p><p>Ultimately, it’s not about which is better, but which is better for your specific needs.</p><ul><li><p>Your API is simple and doesn’t require flexible queries.</p></li><li><p>You need caching benefits from HTTP. </p></li><li><p>You need a standardized, well-established API  approach.</p></li><li><p>You’re integrating with third-party services.</p></li><li><p>Your team is already familiar with REST and need faster implementation.</p></li></ul><ul><li><p>You need flexible and efficient data fetching.</p></li><li><p>Your API serves multiple clients (mobile, web, IoT) with different data needs.</p></li><li><p>Real-time updates are required (GraphQL subscriptions). </p></li><li><p>You want to avoid API versioning issues.</p></li><li><p>Your application requires deeply nested data</p></li></ul><h4><strong>Can You Use Both REST and GraphQL?</strong></h4><p>Absolutely! REST and GraphQL are , and many organizations implement a  to get the best of both worlds:</p><ul><li><p>GraphQL for client-facing applications where flexibility, performance, and dynamic querying are essential.</p></li><li><p>REST for admin interfaces, third-party integrations, and internal microservices where statelessness, caching, and simplicity are beneficial.</p></li></ul><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&amp;token=eyJ1c2VyX2lkIjo4MzYwMjc0MywicG9zdF9pZCI6MTQ1NjU1MjUyLCJpYXQiOjE3MjE1MjE3MzEsImV4cCI6MTcyNDExMzczMSwiaXNzIjoicHViLTIyMDIyNjgiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.2cNY811YEugd5iH9XJQhakBzyahGqF7PcATBlFj5J2w&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re enjoying this newsletter and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":9590,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d86506-cb5f-4c9f-a56a-257439ec46eb_1666x1210.png","enclosureMime":"","commentsUrl":null},{"title":"I created a FREE Low Level Design (LLD) Interview Resource","url":"https://blog.algomaster.io/p/low-level-design-interview-resource","date":1741525361,"author":"Ashish Pratap Singh","guid":481,"unread":true,"content":"<p>I’m excited to share that you can now prepare for <strong>Low-Level Design (LLD) Interviews </strong>for FREE at .</p><p>It includes structured resources to help you study:</p><ul><li><p><strong>Object-Oriented Programming (OOP)</strong></p></li><li><p>, categorized by difficulty</p></li></ul><ul><li><p> through topics</p></li><li><p> by marking topics as complete</p></li><li><p>Experience resources based on your preferred programming language—supports Java, Python, C++, C#, and Go</p></li></ul><p>Previously, I shared LLD learning resources in a , which many found valuable. However, it had limitations—no filtering, no language-based experience, and no progress tracking.</p><p>I've added it to AlgoMaster.io to solve these issues and provide a <strong>better learning experience</strong>.</p><p>I plan to <strong>keep improving the platform</strong>—adding UML diagrams, real-world use cases, and much more to make it <strong>the best resource for mastering LLD interviews</strong>.</p>","contentLength":787,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/b2821a47-6e44-4562-affb-279801c7f276_1364x1038.png","enclosureMime":"","commentsUrl":null},{"title":"15 Data Structures that Power Distributed Databases","url":"https://blog.algomaster.io/p/15-data-structures-that-power-distributed-databases","date":1741239691,"author":"Ashish Pratap Singh","guid":480,"unread":true,"content":"<p> are the backbone of modern large-scale applications, powering everything from real-time analytics to global e-commerce platforms.</p><p>Behind the scenes, these systems rely on specialized data structures to enable fast lookups, efficient storage, and high-throughput operations, even when managing .</p><p>In this article, we'll explore  that power modern distributed databases.</p><p>A  is a data structure that efficiently maps keys to values using a .</p><p>The hash function converts a given key into an integer, which is used as an index in a  to store and retrieve values.</p><p>This indexing technique is optimized for <strong>fast lookups and insertions</strong>, making it ideal for operations like:</p><ul><li><p>Inserting or finding a record with </p></li></ul><p>In most cases, hash indexes provide an <strong>O(1) average-time complexity</strong> for insertions, deletions, and lookups.</p><blockquote><p>Hash Indexes are commonly used in  (e.g., ) and  (e.g., ) where quick access to data is crucial.</p></blockquote><p>A  is a <strong>space-efficient, probabilistic data structure</strong> used to test . </p><p>It answers the question: <strong>\"Does this element exist in a set?\"</strong></p><p>Unlike traditional data structures, a Bloom filter does not store actual elements, making it extremely .</p><p>It starts as a  of size m, initialized with  and relies on  independent , each of which maps an element to one of the  positions in the bit array.</p><ul><li><p>: When an element is added, it is passed through the  hash functions, each mapping it to an index in the bit array. The bits at these positions are set to .</p></li><li><p>: To check if an element is present, it is again passed through the same  functions.</p><ul><li><p>If  corresponding bits are , the element is  in the set (though false positives can occur).</p></li><li><p>If  bit is , the element is  in the set.</p></li></ul></li></ul><blockquote><p>Bloom filters allow databases to efficiently check whether a key might exist in a dataset, helping to <strong>avoid unnecessary disk lookups</strong> in places where the key is guaranteed to be absent. They are widely used in systems like SSTables in LSM trees (e.g., Apache Cassandra) and database partitions for fast key lookups.</p></blockquote><p>A <strong>Log-Structured Merge (LSM) Tree</strong> is a  data structure designed to handle high-throughput workloads efficiently. </p><p>Unlike , which modify disk pages directly, LSM Trees sequentially in memory and periodically , reducing . </p><p>This makes them ideal for write-heavy workloads.</p><h4><strong>Writes (Inserts, Updates, Deletes)</strong></h4><ul><li><p>New writes are first stored in an in-memory structure called a  (typically a Red-Black Tree or Skip List).</p></li><li><p>Once the MemTable reaches a certain size, it is flushed to disk as an immutable <strong>SSTable (Sorted String Table)</strong>.</p></li><li><p>This sequential write pattern ensures fast insertions while avoiding costly disk seeks.</p></li></ul><ul><li><p>Reads first check the MemTable (fast in-memory lookups).</p></li><li><p>If not found, the search moves to recent SSTables.</p></li><li><p>A  is often used to quickly determine whether a key exists in an SSTable.</p></li><li><p>If found, the key is retrieved via .</p></li></ul><h4><strong>Compaction (Merging SSTables)</strong></h4><ul><li><p>Over time, multiple SSTables accumulate, increasing read overhead.</p></li><li><p>To optimize storage and retrieval, the system <strong>merges smaller SSTables into larger ones</strong>.</p></li><li><p>Compaction removes duplicate, obsolete, or deleted records, reducing disk space.</p></li></ul><blockquote><p>LSM Trees are widely used in high-scale NoSQL databases like: Apache Cassandra, Google Bigtable and RocksDB.</p></blockquote>","contentLength":3149,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09adab5c-4345-43bc-93ec-be37191f781a_1870x1212.png","enclosureMime":"","commentsUrl":null},{"title":"What is a Content Delivery Network?","url":"https://blog.algomaster.io/p/content-delivery-networks","date":1741063083,"author":"Ashish Pratap Singh","guid":479,"unread":true,"content":"<p>Imagine you've built an app that serves  to millions of users worldwide.</p><p>To keep things simple, you host all your videos in <strong>one geographical location</strong>.</p><p>At first, everything seems to work fine—users located  enjoy smooth playback with minimal buffering.</p><p>But as your audience grows globally, you start noticing a problem. </p><p>Users in distant regions experience <strong>significant latency, slow load times, and frustrating buffering issues.</strong> The farther they are from your server, the longer it takes for data to travel across the network, degrading their experience.</p><p>To fix this, you need a way to <strong>bring your content physically closer to your users, </strong>reducing the distance data must travel.</p><p>This is exactly what a <strong>Content Delivery Network (CDN)</strong> does.</p><p>In this article, we will explore what a CDN is, how it works, its benefits, different use-cases, and popular CDN providers.</p><p>A CDN is a geographically distributed network of servers that work together to deliver  (like HTML pages, JavaScript files, stylesheets, images, and videos) to users based on their .</p><p>The primary purpose of a CDN is to deliver content to end-users with  and  by reducing the physical distance between the server and the user.</p><p>When a user requests content from a website, the CDN redirects the request to the nearest server in its network,  and </p><p>A  operates using three key components:</p><ul><li><p> – The primary servers where the original content is stored.</p></li><li><p> – Directs user requests to the nearest edge server instead of the origin server.</p></li></ul><p>By leveraging edge servers distributed across multiple geographical regions, CDNs minimize latency and accelerate content delivery.</p><p> Here’s a step-by-step breakdown of how a CDN works:</p><ol><li><p> – A user visits a website and requests content, such as an image, a webpage, or a video. This request must be  that can serve the content.</p></li><li><p> – The browser  to resolve the web content address (e.g., <code>https://cdn.example.com/images/logo.png</code>) into an IP address. The DNS return the <strong>nearest CDN edge server’s IP address</strong> rather than the origin server.</p></li><li><ul><li><p>If the content is  at the edge server, it is served immediately to the user.</p></li><li><p>If not, the edge server forwards the request to the origin server. The origin server processes the request and  to the edge server. The edge server caches the content it retrieved from the origin server.</p></li></ul></li><li><p> – Once cached, future requests for the same content are served <strong>directly from the edge server</strong>, reducing load on the origin and improving speed.</p></li></ol><blockquote><p>CDNs use a <strong>Time-to-Live (TTL) mechanism</strong> to determine how long content remains cached before expiring. To ensure users always receive the latest version, <strong>CDNs periodically refresh and update cached content</strong> from the origin server.</p></blockquote><ul><li><p> – By serving content from the nearest edge server, CDNs reduce latency and improve page load speed.</p></li><li><p> – CDNs offload traffic from the origin server by caching static assets, reducing resource consumption.</p></li><li><p><strong>Improved Availability and Reliability</strong> – With multiple servers in different locations, CDNs prevent single points of failure.</p></li><li><p>: CDNs can handle traffic spikes more efficiently than traditional hosting, making them ideal for websites with fluctuating traffic patterns.</p></li><li><p>: CDNs make it easier to deliver content to users worldwide, regardless of their location.</p></li><li><p> – Many CDNs offer DDoS protection, Web Application Firewalls (WAFs), and bot mitigation to secure applications.</p></li></ul><p>While CDNs offer many benefits, it’s important to note that they also introduce some challenges like:</p><ul><li><p> Integrating a CDN requires proper DNS configuration, cache rules, and content invalidation policies.</p></li><li><p>Many CDN providers charge based on bandwidth usage and request volume. For high-traffic websites, CDN costs , especially for video streaming, gaming, and software distribution.</p></li></ul><ul><li><p><strong>Accelerating Website Performance</strong></p><ul><li><p>Websites with  use CDNs to ensure  for users regardless of location.</p></li><li><p> (images, CSS, JavaScript) at , reducing the time required to fetch them from the origin.</p></li></ul></li><li><p><strong>Video Streaming &amp; OTT Platforms</strong></p><ul><li><p><strong>CDNs optimize video content delivery</strong> by caching video files closer to users, minimizing buffering and latency.</p></li><li><p>Supports <strong>adaptive bitrate streaming</strong> (ABR) to serve video based on the user’s internet speed.</p></li><li><p>Netflix, YouTube, and Spotify use CDNs to serve videos and music in real-time to user.</p></li></ul></li><li><ul><li><p>Multiplayer  require  content delivery to ensure a smooth gaming experience.</p></li><li><p>CDNs help distribute game updates, patches, and downloadable content (DLCs) faster.</p></li></ul></li><li><p><strong>Content &amp; Media Distribution</strong></p><ul><li><p>News websites and content platforms <strong>deliver images, articles, and videos</strong> through a CDN to handle large traffic spikes.</p></li></ul></li><li><p><strong>Software Distribution &amp; Updates</strong></p><ul><li><p>Operating system and software vendors use CDNs to <strong>distribute large files, updates, and patches</strong> quickly.</p></li><li><p>Accelerates the distribution of software updates and applications to users worldwide.</p></li><li><p> Microsoft, Apple, and Google use CDNs for distributing Windows updates, macOS updates, and Android app downloads.</p></li></ul></li></ul><p>Here are some of the most widely used CDN providers:</p><ul><li><p>: One of the oldest and largest CDN providers, known for its extensive global network and robust security features.</p></li><li><p>: Offers a comprehensive suite of performance and security services, including a free tier for smaller websites.</p></li><li><p>: Known for its real-time content delivery and edge computing capabilities.</p></li><li><p>: Integrated with AWS, provides seamless scalability and extensive integration with other AWS services.</p></li><li><p>: Leverages Google’s global network infrastructure to ensure high performance and low-latency content delivery.</p></li><li><p> – Designed for applications hosted on Microsoft Azure, providing seamless integration with other Azure services.</p></li></ul><p>Selecting the best CDN depends on your , , and <strong>platform integration requirements</strong>. </p><p>Cloudflare and Fastly are great for performance and security, while CloudFront, Google Cloud CDN, and Azure CDN offer seamless cloud integration. </p><p>Akamai is a preferred choice for high-scale enterprise applications requiring a robust global network.</p><p>A Content Delivery Network is an essential tool for any online service aiming to deliver content quickly and reliably to a global audience.</p><p>By understanding how CDNs work, the benefits they offer, and how to choose and implement the right one, you can significantly enhance the performance, security, and scalability of your web applications.</p><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&amp;token=eyJ1c2VyX2lkIjo4MzYwMjc0MywicG9zdF9pZCI6MTQ1NjU1MjUyLCJpYXQiOjE3MjE1MjE3MzEsImV4cCI6MTcyNDExMzczMSwiaXNzIjoicHViLTIyMDIyNjgiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.2cNY811YEugd5iH9XJQhakBzyahGqF7PcATBlFj5J2w&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re enjoying this newsletter and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":6497,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1ef9c83-5fd9-46e3-8469-c2a43f8b7dd2_1670x1046.png","enclosureMime":"","commentsUrl":null},{"title":"Design Uber - System Design Interview","url":"https://blog.algomaster.io/p/design-uber-system-design-interview","date":1740668558,"author":"Ashish Pratap Singh","guid":478,"unread":true,"content":"<p>The concept of  has transformed how we travel. Platforms like , , and  seamlessly connect riders with drivers through intuitive smartphone apps.</p><p>By simply entering a destination and tapping a button, users can summon a nearby vehicle and monitor its arrival in real time.</p><p>However, building such a service at scale involves more than just connecting drivers and riders. Behind every “Request Ride” tap lies a sophisticated system coordinating <strong>real-time driver matching</strong>, , <strong>high-throughput data processing</strong>, , and .</p><p>In this article, we will explore how to <strong>design an Uber-like system </strong>that can handle millions of rides every day</p><p>We’ll walk through every step of the design—from  and  to  and . Finally, we'll take a deep dive into  like how to efficiently find nearby drivers.</p><p>Before diving into the design, lets outline the functional and non-functional requirements.</p><ol><li><p>Riders should be able to input their pickup and destination locations and request a ride.</p></li><li><p>The system should provide an estimated time of arrival (ETA) and estimated fare to riders before they confirm the booking.</p></li><li><p>The system should match riders with available drivers who are in close proximity.</p></li><li><p>: Drivers should be able to accept or decline incoming ride requests.</p></li><li><p>: Once a rider is matched with a driver, the rider should be able to track the driver’s location and view the estimated time of arrival (ETA).</p></li><li><p>: Both riders and drivers should have the ability to rate each other after a ride is completed.</p></li><li><p>: The user should be able to complete the payment after the ride is completed.</p></li></ol><h3><strong>Non-Functional Requirements</strong>:</h3><ol><li><p>: The system should provide real-time location updates and fast driver-rider matching.</p></li><li><p>: The system should be up 24/7 with minimal downtime.</p></li><li><p>: The system must handle peak loads (e.g., New Year’s Eve, sporting events).</p></li></ol><ul><li><p>50 million riders, 5 million drivers</p></li><li><p><strong>Daily Active Users (DAU): </strong>10 million riders, 1 million drivers</p></li><li><p>: 1 million riders,  ~100,000 drivers (assuming 10% of DAUs are active at peak hours)</p></li><li><p><strong>Average Daily Ride Requests:</strong> 10 million globally</p></li><li><p><strong>Peak rides per second (RPS): </strong>~5,000</p></li></ul><ul><li><p>A driver sends a location update  while active.</p></li><li><p>Assuming  at peak time:</p><ul><li><p><strong>Location updates per second</strong>: 100,000 / 3 ≈ 33,333 updates/sec</p></li></ul></li></ul><ul><li><p>: ~2 KB per user (name, email, phone, payment method, preferences)</p></li><li><p>: ~5 KB per driver (vehicle details, license, payment details, ratings)</p></li><li><p><strong>Total storage for 50M users</strong>: (50M × 2 KB) + (5M × 5 KB) = (</p></li></ul><ul><li><p>Ride ID (UUID) → 16 bytes</p></li><li><p>Rider ID, Driver ID → 8 bytes each</p></li><li><p>Start &amp; end location (lat/lon) → 16 bytes</p></li><li><p>Fare, pickup/dropoff time → 24 bytes</p></li></ul><p> ~80 bytes</p><ul><li><p> 10M × 80 Bytes = </p></li><li><p><strong>Storage per year (365 days):</strong></p></li></ul><h3>Network Bandwidth Estimation</h3><p>Each API call (ride request, driver update, fare estimation, etc.) contributes to network usage.</p><ul><li><p>: ~5,000 RPS</p></li><li><p><strong>Driver location updates per second</strong>: ~33,333 RPS</p></li><li><p>: ~40,000 RPS</p></li></ul><p>Assuming an  of , network bandwidth usage at peak:</p><ul><li><p><strong>40,000 RPS × 5 KB = 200 MB/sec</strong></p></li></ul>","contentLength":2863,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27a8ca99-a288-41b1-98bc-cd7ecdec889f_2322x2302.png","enclosureMime":"","commentsUrl":null},{"title":"5 Books Every Software Engineer Should Read (at least once)","url":"https://blog.algomaster.io/p/5-best-software-engineering-books","date":1740457955,"author":"Ashish Pratap Singh","guid":477,"unread":true,"content":"<p>During my Software Engineering career, I have come across and read many  and  books, but there are a few that I keep coming back to and try to re-read them every year.</p><p>In this article, I will share <strong>5 of the best Software Engineering books</strong> I’ve read. These book are not tied to any specific library, tool or framework; instead, they focus on  that can be applied to any tech stack.</p><p>They cover multiple aspects of building software, from coding and design patterns to distributed systems, microservices, and designing good APIs. I also found most of them very helpful when preparing for .</p><p> is all about writing high-quality, maintainable code. The author, Robert C. Martin (also known as Uncle Bob), provides guidelines and best practices for structuring your code, naming variables, handling errors, and more.</p><p>You’ll learn how to make your code more readable and easier to understand, not just for yourself but for any developer who might read it later. It also covers principles like the Single Responsibility Principle, DRY (Don’t Repeat Yourself), and how to effectively refactor your code when it starts to get messy.</p><h4>How it can help your career:</h4><p>Writing clean code is one of the most important skills for a Software Engineer. By applying the principles in this book, you’ll be able to deliver features faster, avoid technical debt, and stand out as someone who values code quality. This can open up opportunities for leadership roles and help you perform better in coding interviews.</p><p><strong>Head First Design Patterns</strong> uses a fun, engaging style to teach you the core design patterns you’ll encounter in everyday software development. The book breaks down each pattern in a visually-rich format, making it easier to understand why and when to use them.</p><p>You’ll learn how to recognize common problems in code and how to solve them using design patterns like the Strategy Pattern, Observer Pattern, Singleton Pattern, and more. This book makes heavy use of code examples and diagrams, so it’s great for visual learners.</p><h4><strong>How it can help your career:</strong></h4><p>Design patterns are frequently asked about in technical interviews, and they also come up a lot when you’re collaborating with other engineers. Having a solid understanding of design patterns will help you write flexible, scalable solutions and communicate better with your peers about how to structure your code.</p><p>This book focuses on how to build systems that handle large amounts of data reliably, efficiently, and securely. It covers topics like data modeling, database internals, distributed systems, transactions, and scalability.</p><p>You’ll gain a deep understanding of how different storage systems work (SQL, NoSQL, etc.) and how to handle big data challenges. Martin Kleppmann explains concepts like replication, partitioning, and consistency in a way that is easy to grasp, even if you’re new to distributed systems.</p><h4><strong>How it can help your career:</strong></h4><p>As data volumes grow in almost every company, understanding how to design data-intensive systems is a crucial skill. This knowledge is also extremely valuable in System Design Interviews, where you’re often asked about scalability, reliability, and performance.</p><p> gives a detailed look at how to design and implement microservice-based systems. Sam Newman walks through the fundamentals of what microservices are, why they’re useful, and how to manage the challenges that come with them.</p><p>You’ll learn about service boundaries, communication patterns (like synchronous vs. asynchronous), testing strategies for microservices, and how to deploy and monitor distributed systems. The book also covers organizational aspects—such as team structures—that can support a microservices architecture.</p><h4><strong>How it can help your career:</strong></h4><p>Microservices are widely adopted in modern tech companies, and many architectural interviews will delve into your understanding of them. Knowing how to break a monolith into microservices and handle issues like service discovery, API gateways, and observability can make you a stronger candidate for senior engineering roles.</p><p> focuses on the practical aspects of creating robust, well-documented, and user-friendly APIs. It covers the entire process—from planning and design to documentation and versioning. It includes expert advice, worksheets, checklists, and case studies from companies including Slack, Stripe, Facebook, and GitHub.</p><p>You’ll discover how to define API requirements, choose the right data formats (like JSON, XML), and handle authentication and rate-limiting. The book also addresses collaboration between teams and how to involve stakeholders in the API design process.</p><h4><strong>How it can help your career:</strong></h4><p>APIs are at the heart of modern software systems. Whether you’re building internal services or public APIs, understanding how to design them effectively makes you more valuable to your team. It also comes up in interviews if you’re applying for roles where you need to talk about RESTful or GraphQL APIs, integration points, and best practices for scaling APIs, handling security and managing changes.</p><p>There are other great books that I haven’t mentioned in this article.</p><p>Do let me know your favorite Software Engineering books in the comments. I’m always looking to add new ones to my reading list!</p><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&amp;token=eyJ1c2VyX2lkIjo4MzYwMjc0MywicG9zdF9pZCI6MTQ1NjU1MjUyLCJpYXQiOjE3MjE1MjE3MzEsImV4cCI6MTcyNDExMzczMSwiaXNzIjoicHViLTIyMDIyNjgiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.2cNY811YEugd5iH9XJQhakBzyahGqF7PcATBlFj5J2w&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re enjoying this newsletter and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":5517,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/75c4b37d-8b9b-494c-8bde-75faf2468b9b_1080x720.jpeg","enclosureMime":"","commentsUrl":null},{"title":"Top 10 Redis Use Cases","url":"https://blog.algomaster.io/p/top-10-redis-use-cases","date":1740030347,"author":"Ashish Pratap Singh","guid":476,"unread":true,"content":"<p><strong>Redis (Remote Dictionary Server)</strong> is an open source, <strong>in-memory key-value data store</strong> that provides , making it an excellent choice for  applications.</p><p>Its versatility and speed allow it to solve complex scalability challenges, making it a popular choice in design discussions and a valuable topic for .</p><p>Redis supports a rich set of, including <strong>strings, hashes, lists, sets, and sorted sets</strong>. These structures, combined with powerful  like , , and enable Redis to handle many use cases requiring  and .</p><p>In this article, we will explore the <strong>Top 10 Use Cases of Redis</strong> with real-world examples and code implementation.</p><p>Caching is the most common use case of Redis. </p><p>Since web applications frequently rely on databases, querying a database on every request can be slow and inefficient, leading to high response times and increased server load.</p><p> solves this problem by <strong>storing frequently accessed data</strong> in memory, significantly reducing latency and offloading queries from the database.</p><p>There are multiple caching strategies (read through, cache aside, write back etc.,) each suited for different use cases.</p><p>The  pattern is widely used because it gives the application full control over caching logic.</p><ul><li><p>When a client requests data, the application first checks Redis.</p></li><li><p>If the data exists in Redis (), it is returned instantly.</p></li><li><p>If data is not found (), it is fetched from the database, stored in Redis for future requests, and returned to the client.</p></li></ul><h4><strong>Code Example: Caching API Responses</strong></h4><p>To prevent stale or outdated data, Redis allows setting  (), ensuring automatic eviction of cached entries.</p><p>Most modern web applications are , meaning they don’t store session information directly on the server. However, to keep users logged in, maintain shopping carts, or track user preferences, web applications need a reliable <strong>session management system</strong>.</p><p>Since Redis is andprovide  options, it’s a great choice for storing session data.</p><ul><li><p>The application generates a unique session ID for the user.</p></li><li><p>It stores session data in Redis, using the session ID as the key.</p></li><li><p>The session ID is sent to the user's browser as a .</p></li></ul><ul><li><p>The application retrieves the session ID from the user's cookie.</p></li><li><p>It fetches user data from Redis using the session ID.</p></li></ul><ul><li><p>If a user is inactive for too long, Redis automatically deletes the session after a set expiration time ().</p></li><li><p>This prevents stale session accumulation, optimizing memory usage.</p></li></ul><h4><strong>Code Example: Storing and Retrieving Sessions</strong></h4><p>Since Redis is an in-memory database, all session data is lost if the server restarts.</p><ul><li><ul><li><p>Redis allows saving session data to disk using snapshots () or AOF logging.</p></li><li><p>However, reloading session data after a crash may take too long, causing delays.</p></li></ul></li><li><p><strong>Using Redis Replication for High Availability</strong> (Recommended for Production)</p><ul><li><p>Sessions are replicated to a backup Redis instance.</p></li><li><p>If the primary Redis server fails, the backup is promoted to take over.</p></li><li><p>This ensures minimal downtime for user sessions.</p></li></ul></li></ul>","contentLength":2895,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/50f500e0-7b74-425b-b93e-68b8efbe86ae_1492x996.png","enclosureMime":"","commentsUrl":null},{"title":"Consistent Hashing Explained","url":"https://blog.algomaster.io/p/consistent-hashing-explained","date":1739853043,"author":"Ashish Pratap Singh","guid":475,"unread":true,"content":"<p>In a  where nodes (servers) are frequently , efficiently routing requests becomes challenging.</p><p>A common approach is to use  and assign it to a server using , where N is the number of servers. </p><p>However, this method is highly dependent on the number of servers, and any change in N can lead to , causing a major redistribution of keys (requests).</p><p> addresses this issue by ensuring that only a small subset of keys need to be reassigned when nodes are added or removed.</p><p>Popularized by , it has now become a fundamental technique in distributed databases like DynamoDB, Cassandra and ScyllaDB.</p><p>In this article, we’ll explore what consistent hashing is, why it’s needed, how it works, and how to implement it in code.</p><p>Imagine you're building a <strong>high-traffic web application</strong> that serves millions of users daily. To handle the load efficiently, you distribute incoming requests across multiple backend servers using a .</p><p>Your system consists of  (), and requests are assigned using a hash function that maps each user's <strong>IP address to a specific server</strong>.</p><p>The process works like this:</p><ol><li><p>The load balancer takes a user’s IP address (or session ID).</p></li><li><p>A  maps the IP to one of the backend servers by taking the <strong>sum of bytes in the IP address</strong> and computing  (since we have 5 servers).</p></li><li><p>The request is <strong>routed to the assigned server</strong>, ensuring that the same user is always directed to the same server for session consistency.</p></li></ol><h3><strong>Everything Works Fine… Until You Scale</strong></h3><p>This approach works <strong>as long as the number of servers remains constant</strong>. But what happens when you ?</p><h4><strong>Scenario 1: Adding a New Server (S5)</strong></h4><p>As traffic increases, you decide to  by adding a new backend server (). Now, the hash function must be modified to use  instead of since we have 6 servers now.</p><p>This seemingly simple change <strong>completely disrupts the existing mapping</strong>, causing <strong>most users to be reassigned to different servers</strong>.</p><p>This results into , leading to <strong>high overhead, and potential downtime</strong>.</p><h4><strong>Scenario 2: Removing a Server (S4)</strong></h4><p>Now, let’s say one of the servers () fails or is removed. The number of servers drops to 4, forcing the hash function to switch from  to .</p><p>Even though only  server was removed, <strong>most users are reassigned to different servers</strong>. This can cause:</p><ul><li><p>Active users may be logged out or disconnected.</p></li><li><p>Cached data becomes irrelevant, increasing database load.</p></li><li><p><strong>Severe performance degradation: </strong>The system may struggle to run efficiently.</p></li></ul><h3><strong>The Solution: Consistent Hashing</strong></h3><p> offers a more scalable and efficient solution by ensuring that only a  are reassigned when scaling up or down.</p><p>It performs really well when operated in dynamic environments, where the system scales up and down frequently.</p><p>Consistent hashing is a <strong>distributed hashing technique</strong> used to efficiently distribute data across multiple nodes (servers, caches, etc.).</p><p>It uses a  (hash ring) with a large and constant hash space.</p><p>Both nodes (servers, caches, or databases) and keys (data items) are mapped to positions on this hash ring using a .</p><p>Unlike modulo-based hashing, where changes in the number of nodes cause large-scale remapping, consistent hashing ensures that only a small fraction of keys are reassigned when a node is added or removed, making it highly scalable and efficient.</p><blockquote><p>In consistent hashing, when the number of nodes changes, only keys need to be reassigned, where  is the total number of keys and  is the total number of nodes.</p></blockquote><h2><strong>2.1 Constructing the Hash Ring</strong></h2><p>Instead of distributing keys based on , consistent hashing places both servers and keys on a circular hash ring.</p><ul><li><p>We use a large, fixed hash space ranging from  to  (assuming a 32-bit hash function).</p></li><li><p>This creates a circular structure, where values wrap around after reaching the maximum limit.</p></li></ul><h4><strong>Placing Servers on the Ring</strong></h4><ul><li><p>Each  is assigned a position on the hash ring by computing .</p></li><li><p>Using the above example with , the hash function distributes them at different positions around the ring.</p></li></ul><ul><li><p>When a key is added, its position is determined by computing .</p><ul><li><p>Example: a user’s request is assigned a position on the ring based on the hash of their IP address: </p></li></ul></li><li><p>We then move clockwise around the ring until we find the next available server.</p></li><li><p>The key (or request) is assigned to this server for storage or retrieval.</p></li></ul><blockquote><p> In case a key’s hash falls directly on a node’s position, it belongs to that node.</p></blockquote><p>Suppose we add a to the system.</p><ul><li><p>The position of  falls between  and  in the hash ring.</p></li><li><p> takes over all keys (requests) that fall between  and , which were previously handled by .</p><ul><li><p>requests which were originally assigned to  will now be redirected to </p></li></ul></li></ul><p>This demonstrates how consistent hashing efficiently redistributes keys with minimal disruption, ensuring that only a small subset of keys are reassigned when new servers are added.</p><p>When a server, such as , fails or is removed from the system:</p><ul><li><p>All keys previously assigned to  are reassigned to the next available server in the ring ().</p></li><li><p>Only the keys (requests) that were mapped to  need to move, while all other keys remain unaffected.</p></li></ul><p>This results in , unlike traditional hashing where removing a node would require reassigning most keys.</p><p>In , each server is assigned  on the hash ring. However, this can lead to , especially when:</p><ul><li><p>The number of servers is small.</p></li><li><p>Some servers accidentally get clustered together, creating .</p></li><li><p>A server is , causing a sudden load shift to its immediate neighbor.</p></li></ul><p> are a technique used in consistent hashing to improve  and  by distributing data more evenly across servers.</p><p>Instead of assigning one position per server, each physical server is assigned  (virtual nodes) on the hash ring.</p><ul><li><p>Each server is hashed multiple times to different locations on the ring.</p></li><li><p>When a request (key) is hashed, it is assigned to the next virtual node in a clockwise direction.</p></li><li><p>The request is then routed to the actual server associated with the virtual node.</p></li></ul><p>Assume we have <strong>three physical servers (S1, S2, S3)</strong>. Without virtual nodes, their positions might be:</p><pre><code>S1 → Position 10\nS2 → Position 50\nS3 → Position 90</code></pre><p>If , all its keys must be reassigned to , which can create an overload.</p><p>With , each server is hashed multiple times:</p><pre><code>S1-1 → Position 10\nS1-2 → Position 70\nS1-3 → Position 120\nS2-1 → Position 50\nS2-2 → Position 80\nS2-3 → Position 160\nS3-1 → Position 30\nS3-2 → Position 90\nS3-3 → Position 140</code></pre><p>Now, instead of just one point,  is represented at , making the distribution .</p><p>If , its keys are more evenly redistributed among , rather than all going to .</p><ol><li><ul><li><p>Stores hash values → server mappings. Uses  (replicas) for better load balancing.</p></li><li><p>Maintains a  of hash values for efficient lookups.</p></li><li><p>Tracks active physical servers.</p></li></ul></li><li><ul><li><p>Calls  for each server, hashing it multiple times (based on ) to ensure even distribution.</p></li></ul></li><li><ul><li><p>Uses  to convert strings into large integers for consistent placement on the hash ring.</p></li></ul></li><li><ul><li><p>Generates multiple hash values for each server (, , etc.).</p></li><li><p>Stores these in  and maintains a sorted order in  for fast lookup.</p></li></ul></li><li><ul><li><p>Deletes the server’s hash values and its virtual nodes from  and .</p></li></ul></li><li><ul><li><p>Hashes the input key and finds the closest  server using . Wraps around to the first node if necessary.</p></li></ul></li></ol><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><p>If you have any questions or suggestions, leave a comment.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&amp;token=eyJ1c2VyX2lkIjo4MzYwMjc0MywicG9zdF9pZCI6MTQ1NjU1MjUyLCJpYXQiOjE3MjE1MjE3MzEsImV4cCI6MTcyNDExMzczMSwiaXNzIjoicHViLTIyMDIyNjgiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.2cNY811YEugd5iH9XJQhakBzyahGqF7PcATBlFj5J2w&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re enjoying this newsletter and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":7350,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/9d4c8499-0733-43fa-95f8-c3370c0ad2ea_1984x1462.png","enclosureMime":"","commentsUrl":null},{"title":"Speedrunning Guide: Junior to Staff Engineer in 3 years","url":"https://blog.algomaster.io/p/speedrunning-guide-junior-to-staff","date":1739680258,"author":"Ashish Pratap Singh","guid":474,"unread":true,"content":"<p>Today’s newsletter features a special guest, , who was promoted from Junior to Staff Engineer at Meta in just 3 years.</p><p>In this article, Ryan will share his insights on how to fast track your career growth and get promoted faster.</p><p>Once you land that first software engineering job, the next big question becomes: how do you get promoted? Many engineers fall into the day-to-day routine of writing code without a clear idea of how to grow their careers.</p><p>This happened to me. At my first job at Amazon, I landed code without knowing what I could do to grow my skills. I left that job within eight months because I felt I wasn’t growing as an engineer. Three years later, I made it to Staff Software Engineer at Instagram after tons of mentorship. Early on, I learned that being good at coding wasn’t enough to get promoted; you have to think strategically about your career and often need to develop new behaviors to move up.</p><p>In this article, I’ll share everything that helped me fast-track my way up the ladder, from developing the right mindset to making key moves that many overlook. Even if rapid growth isn’t your goal, this guide has learnings for all tech career paths.</p><ul><li><p>Software Engineering Levels</p></li><li><p>An Algorithm for Promotion</p></li><li><p>Junior (IC3) → Mid-level (IC4)</p></li><li><p>Mid-level (IC4) → Senior (IC5)</p></li><li><p>Senior (IC5) → Staff (IC6)</p></li></ul><h2>Software Engineering Levels</h2><p><em>Note: “IC” = “Individual Contributor”</em></p><p>In software engineering, companies measure career progression by levels that measure both behaviors and impact within the company. While the exact titles and structure can vary between companies, most tech companies follow a similar system:</p><ul><li><p> - Early in your career, working on smaller, well-defined tasks with guidance from more experienced engineers.</p></li><li><p> - More autonomous, handling moderately complex projects, and beginning to take initiative in improving the codebase and what they build.</p></li><li><p> - Leading larger projects with team-level influence. You’ll mentor and guide the team while having a broad impact on the codebase.</p></li><li><p>: Focusing on cross-team collaboration and solving org-wide challenges. Staff engineers are strategic thinkers who influence the technical direction of their organization.</p></li><li><p><strong>Senior Staff Engineer and Beyond (IC7+): </strong>Senior staff engineers and up operate with top technical expertise, driving large-scale initiatives that have a broad impact on the company. Senior staff engineers mentor staff engineers and work closely with executive leadership to meet business objectives.</p></li></ul><p>Your impact and compensation increase as you progress, which is a lot more satisfying in my experience. Not to mention that the skills that get you promoted also let you control what you and the company work on.</p><p>Also, many companies consider only senior engineers (IC5) and higher to be “terminal levels.” You must eventually get promoted to IC5, or you’ll be managed out. Most engineers are promoted in time, so it’s not meant to scare you but to encourage you to grow.</p><h2>An Algorithm For Promotion</h2><p>There’s a common set of steps across all promotions that will get you to Staff:</p><p><strong>1) Exceed expectations at your current level</strong> - Your manager will be hesitant to find you opportunities at the next level if they have concerns about your performance at the current level. Also, when your manager puts together a promotion packet, it’ll contain a history of your past ratings. The promotion committee will have concerns about your packet if you have a history of only meeting expectations for your level. Work with your manager to understand the expectations for your level and how to exceed them.</p><p><strong>2) Be direct with your manager about promotion </strong>- Once you know you’re exceeding expectations for your level, ask your manager what next-level performance looks like. Your manager plays a huge role in your promotion. They build your case and advocate for it, so they have a lot of influence on this process. Also, the lower the level, the more control your manager has. IC3 -&gt; IC4 promotions are straightforward, so your manager’s perspective is usually what happens. For IC5 -&gt; IC6, there is a lot more ambiguity, so <a href=\"https://www.developing.dev/p/how-promotions-and-ratings-work\">your manager serves more as a middleman between you and the promotion committee</a>. Your manager still plays a significant role in writing your packet and delivering feedback.</p><p><strong>3) Find next-level scope - </strong>If you only work on projects that fit your level’s behaviors, you won’t get any closer to promotion, no matter how good your work is. One simple pattern for finding next-level scope is brainstorming projects with engineers who are 1-2 levels higher than you are. Often, they will have a lot of projects sitting in their backlog that are big enough to help you get promoted. If you take on one of their projects, they’ll often help mentor you, review your designs and code, and give you strong peer feedback for your future promotion packet. I wrote <a href=\"https://www.developing.dev/p/a-simple-pattern-for-finding-next\">more on this here</a>. Make sure to confirm with your manager that they agree that what you’re working on fits the behaviors of the next level.<strong>4) Maintain next-level behaviors and impact </strong>- The duration you need to perform at the next level varies depending on your level and your company. At minimum though, you need to maintain that performance for 6-12 months. This is because promotions are “lagging” in tech. You must prove that you’re already operating at the next level before getting promoted. This reduces the risk of failing to meet expectations at the new level.</p><p>Getting promoted faster is a matter of doing steps (1), (2) and (3) as fast as possible. The best you can do is immediately start exceeding expectations in your first half and working with your manager on the next level.</p><p>Almost every team has scope for more Senior Engineers (IC5). You can get promoted up to that level if you have the skills and behaviors. Past that, situation and business scope play a much larger role. <a href=\"https://www.developing.dev/p/staff-career-growth-product-or-infra\">Many teams don’t need someone who has Staff-level leadership and technical skills</a>. If you find yourself stuck at any point due to your situation, you’ll likely have to switch teams to continue growing your career.</p><p>Now that you have the algorithm that applies at any of these levels let’s get into the level-specific strategies. I’ll share what got me promoted and what I would change if I did it again.</p><h2>Junior (IC3) → Mid-level (IC4)</h2>","contentLength":6298,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0173844b-0e38-4ca8-b779-b34f7f778872_1600x413.png","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}