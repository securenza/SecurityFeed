{"id":"82kPqoBYiySD8ih7nAXkFuDhjyLjtPi8jr6gSpxV4VMW","title":"The Go Blog","displayTitle":"Dev - Golang Blog","url":"http://blog.golang.org/feed.atom","feedLink":"http://blog.golang.org/feed.atom","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":4,"items":[{"title":"Traversal-resistant file APIs","url":"https://go.dev/blog/osroot","date":1741737600,"author":"Damien Neil","guid":84,"unread":true,"content":"<p>A <em>path traversal vulnerability</em> arises when an attacker can trick a program\ninto opening a file other than the one it intended.\nThis post explains this class of vulnerability,\nsome existing defenses against it, and describes how the new\n<a href=\"https://go.dev/pkg/os#Root\"></a> API added in Go 1.24 provides\na simple and robust defense against unintentional path traversal.</p><p>“Path traversal” covers a number of related attacks following a common pattern:\nA program attempts to open a file in some known location, but an attacker causes\nit to open a file in a different location.</p><p>If the attacker controls part of the filename, they may be able to use relative\ndirectory components (\"..\") to escape the intended location:</p><pre><code>f, err := os.Open(filepath.Join(trustedLocation, \"../../../../etc/passwd\"))\n</code></pre><p>On Windows systems, some names have special meaning:</p><pre><code>// f will print to the console.\nf, err := os.Create(filepath.Join(trustedLocation, \"CONOUT$\"))\n</code></pre><p>If the attacker controls part of the local filesystem, they may be able to use\nsymbolic links to cause a program to access the wrong file:</p><pre><code>// Attacker links /home/user/.config to /home/otheruser/.config:\nerr := os.WriteFile(\"/home/user/.config/foo\", config, 0o666)\n</code></pre><p>If the program defends against symlink traversal by first verifying that the intended file\ndoes not contain any symlinks, it may still be vulnerable to\n<a href=\"https://en.wikipedia.org/wiki/Time-of-check_to_time-of-use\" rel=\"noreferrer\" target=\"_blank\">time-of-check/time-of-use (TOCTOU) races</a>,\nwhere the attacker creates a symlink after the program’s check:</p><pre><code>// Validate the path before use.\ncleaned, err := filepath.EvalSymlinks(unsafePath)\nif err != nil {\n  return err\n}\nif !filepath.IsLocal(cleaned) {\n  return errors.New(\"unsafe path\")\n}\n\n// Attacker replaces part of the path with a symlink.\n// The Open call follows the symlink:\nf, err := os.Open(cleaned)\n</code></pre><p>Another variety of TOCTOU race involves moving a directory that forms part of a path\nmid-traversal. For example, the attacker provides a path such as “a/b/c/../../etc/passwd”,\nand renames “a/b/c” to “a/b” while the open operation is in progress.</p><p>Before we tackle path traversal attacks in general, let’s start with path sanitization.\nWhen a program’s threat model does not include attackers with access to the local file system,\nit can be sufficient to validate untrusted input paths before use.</p><p>Unfortunately, sanitizing paths can be surprisingly tricky,\nespecially for portable programs that must handle both Unix and Windows paths.\nFor example, on Windows  reports ,\nbecause the path “\\foo” is relative to the current drive.</p><p>In Go 1.20, we added the <a href=\"https://go.dev/pkg/path/filepath#IsLocal\"></a>\nfunction, which reports whether a path is “local”. A “local” path is one which:</p><ul><li>does not escape the directory in which it is evaluated (\"../etc/passwd\" is not allowed);</li><li>is not an absolute path (\"/etc/passwd\" is not allowed);</li><li>is not empty (\"\" is not allowed);</li><li>on Windows, is not a reserved name (“COM1” is not allowed).</li></ul><p>In Go 1.23, we added the <a href=\"https://go.dev/pkg/path/filepath#Localize\"></a>\nfunction, which converts a /-separated path into a local operating system path.</p><p>Programs that accept and operate on potentially attacker-controlled paths should almost\nalways use  or  to validate or sanitize those paths.</p><p>Path sanitization is not sufficient when attackers may have access to part of\nthe local filesystem.</p><p>Multi-user systems are uncommon these days, but attacker access to the filesystem\ncan still occur in a variety of ways.\nAn unarchiving utility that extracts a tar or zip file may be induced\nto extract a symbolic link and then extract a file name that traverses that link.\nA container runtime may give untrusted code access to a portion of the local filesystem.</p><p>Programs may defend against unintended symlink traversal by using the\n<a href=\"https://go.dev/pkg/path/filepath#EvalSymlinks\"><code>path/filepath.EvalSymlinks</code></a>\nfunction to resolve links in untrusted names before validation, but as described\nabove this two-step process is vulnerable to TOCTOU races.</p><p>Before Go 1.24, the safer option was to use a package such as\n<a href=\"https://go.dev/pkg/github.com/google/safeopen\">github.com/google/safeopen</a>,\nthat provides path traversal-resistant functions for opening a potentially-untrusted\nfilename within a specific directory.</p><p>In Go 1.24, we are introducing new APIs in the  package to safely open\na file in a location in a traversal-resistent fashion.</p><p>The new <a href=\"https://go.dev/pkg/os#Root\"></a> type represents a directory somewhere\nin the local filesystem. Open a root with the <a href=\"https://go.dev/pkg/os#OpenRoot\"></a>\nfunction:</p><pre><code>root, err := os.OpenRoot(\"/some/root/directory\")\nif err != nil {\n  return err\n}\ndefer root.Close()\n</code></pre><p> provides methods to operate on files within the root.\nThese methods all accept filenames relative to the root,\nand disallow any operations that would escape from the root either\nusing relative path components (\"..\") or symlinks.</p><pre><code>f, err := root.Open(\"path/to/file\")\n</code></pre><p> permits relative path components and symlinks that do not escape the root.\nFor example,  is permitted. Filenames are resolved using the\nsemantics of the local platform: On Unix systems, this will follow\nany symlink in “a” (so long as that link does not escape the root);\nwhile on Windows systems this will open “b” (even if “a” does not exist).</p><p> currently provides the following set of operations:</p><pre><code>func (*Root) Create(string) (*File, error)\nfunc (*Root) Lstat(string) (fs.FileInfo, error)\nfunc (*Root) Mkdir(string, fs.FileMode) error\nfunc (*Root) Open(string) (*File, error)\nfunc (*Root) OpenFile(string, int, fs.FileMode) (*File, error)\nfunc (*Root) OpenRoot(string) (*Root, error)\nfunc (*Root) Remove(string) error\nfunc (*Root) Stat(string) (fs.FileInfo, error)\n</code></pre><p>In addition to the  type, the new\n<a href=\"https://go.dev/pkg/os#OpenInRoot\"></a> function\nprovides a simple way to open a potentially-untrusted filename within a\nspecific directory:</p><pre><code>f, err := os.OpenInRoot(\"/some/root/directory\", untrustedFilename)\n</code></pre><p>The  type provides a simple, safe, portable API for operating with untrusted filenames.</p><h2>Caveats and considerations</h2><p>On Unix systems,  is implemented using the  family of system calls.\nA  contains a file descriptor referencing its root directory and will track that\ndirectory across renames or deletion.</p><p> defends against symlink traversal but does not limit traversal\nof mount points. For example,  does not prevent traversal of\nLinux bind mounts. Our threat model is that  defends against\nfilesystem constructs that may be created by ordinary users (such\nas symlinks), but does not handle ones that require root privileges\nto create (such as bind mounts).</p><p>On Windows,  opens a handle referencing its root directory.\nThe open handle prevents that directory from being renamed or deleted until the  is closed.</p><p> prevents access to reserved Windows device names such as  and .</p><p>On WASI, the  package uses the WASI preview 1 filesystem API,\nwhich are intended to provide traversal-resistent filesystem access.\nNot all WASI implementations fully support filesystem sandboxing,\nhowever, and ’s defense against traversal is limited to that provided\nby the WASI impementation.</p><p>When GOOS=js, the  package uses the Node.js file system API.\nThis API does not include the openat family of functions,\nand so  is vulnerable to TOCTOU (time-of-check-time-of-use) races in symlink\nvalidation on this platform.</p><p>When GOOS=js, a  references a directory name rather than a file descriptor,\nand does not track directories across renames.</p><p>Plan 9 does not have symlinks.\nOn Plan 9, a  references a directory name and performs lexical sanitization of\nfilenames.</p><p> operations on filenames containing many directory components can be much more expensive\nthan the equivalent non- operation. Resolving “..” components can also be expensive.\nPrograms that want to limit the cost of filesystem operations can use  to\nremove “..” components from input filenames, and may want to limit the number of\ndirectory components.</p><p>You should use  or  if:</p><ul><li>you are opening a file in a directory; AND</li><li>the operation should not access a file outside that directory.</li></ul><p>For example, an archive extractor writing files to an output directory should use\n, because the filenames are potentially untrusted and it would be incorrect\nto write a file outside the output directory.</p><p>However, a command-line program that writes output to a user-specified location\nshould not use , because the filename is not untrusted and may\nrefer to anywhere on the filesystem.</p><p>As a good rule of thumb, code which calls  to combine a fixed directory\nand an externally-provided filename should probably use  instead.</p><pre><code>// This might open a file not located in baseDirectory.\nf, err := os.Open(filepath.Join(baseDirectory, filename))\n\n// This will only open files under baseDirectory.\nf, err := os.OpenInRoot(baseDirectory, filename)\n</code></pre><p>The  API is new in Go 1.24.\nWe expect to make additions and refinements to it in future releases.</p><p>The current implementation prioritizes correctness and safety over performance.\nFuture versions will take advantage of platform-specific APIs, such as\nLinux’s , to improve performance where possible.</p><p>There are a number of filesystem operations which  does not support yet, such as\ncreating symbolic links and renaming files. Where possible, we will add support for these\noperations. A list of additional functions in progress is in\n<a href=\"https://go.dev/issue/67002\">go.dev/issue/67002</a>.</p>","contentLength":8941,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"From unique to cleanups and weak: new low-level tools for efficiency","url":"https://go.dev/blog/cleanups-and-weak","date":1741219200,"author":"Michael Knyszek","guid":83,"unread":true,"content":"<p>\n      Michael Knyszek\n      6 March 2025\n      </p><p>In <a href=\"https://go.dev/blog/unique\">last year’s blog post</a> about the  package, we alluded\nto some new features then in proposal review, and we’re excited to share that as\nof Go 1.24 they are now available to all Go developers.\nThese new features are <a href=\"https://pkg.go.dev/runtime#AddCleanup\" rel=\"noreferrer\" target=\"_blank\">the \nfunction</a>, which queues up a function to\nrun when an object is no longer reachable, and <a href=\"https://pkg.go.dev/weak#Pointer\" rel=\"noreferrer\" target=\"_blank\">the \ntype</a>, which safely points to an object without\npreventing it from being garbage collected.\nTogether, these two features are powerful enough to build your own \npackage!\nLet’s dig into what makes these features useful, and when to use them.</p><p>Note: these new features are advanced features of the garbage collector.\nIf you’re not already familiar with basic garbage collection concepts, we\nstrongly recommend reading the introduction of our <a href=\"https://go.dev/doc/gc-guide#Introduction\">garbage collector\nguide</a>.</p><p>If you’ve ever used a finalizer, then the concept of a cleanup will be\nfamiliar.\nA finalizer is a function, associated with an allocated object by <a href=\"https://pkg.go.dev/runtime#SetFinalizer\" rel=\"noreferrer\" target=\"_blank\">calling\n</a>, that is later\ncalled by the garbage collector some time after the object becomes unreachable.\nAt a high level, cleanups work the same way.</p><p>Let’s consider an application that makes use of a memory-mapped file, and see\nhow cleanups can help.</p><pre><code>//go:build unix\n\ntype MemoryMappedFile struct {\n    data []byte\n}\n\nfunc NewMemoryMappedFile(filename string) (*MemoryMappedFile, error) {\n    f, err := os.Open(filename)\n    if err != nil {\n        return nil, err\n    }\n    defer f.Close()\n\n    // Get the file's info; we need its size.\n    fi, err := f.Stat()\n    if err != nil {\n        return nil, err\n    }\n\n    // Extract the file descriptor.\n    conn, err := f.SyscallConn()\n    if err != nil {\n        return nil, err\n    }\n    var data []byte\n    connErr := conn.Control(func(fd uintptr) {\n        // Create a memory mapping backed by this file.\n        data, err = syscall.Mmap(int(fd), 0, int(fi.Size()), syscall.PROT_READ, syscall.MAP_SHARED)\n    })\n    if connErr != nil {\n        return nil, connErr\n    }\n    if err != nil {\n        return nil, err\n    }\n    mf := &amp;MemoryMappedFile{data: data}\n    cleanup := func(data []byte) {\n        syscall.Munmap(data) // ignore error\n    }\n    runtime.AddCleanup(mf, cleanup, data)\n    return mf, nil\n}\n</code></pre><p>A memory-mapped file has its contents mapped to memory, in this case, the\nunderlying data of a byte slice.\nThanks to operating-system magic, reads and writes to the byte slice directly\naccess the contents of the file.\nWith this code, we can pass around a , and when it’s\nno longer referenced, the memory mapping we created will get cleaned up.</p><p>Notice that  takes three arguments: the address of a\nvariable to attach the cleanup to, the cleanup function itself, and an argument\nto the cleanup function.\nA key difference between this function and  is that the\ncleanup function takes a different argument than the object we’re attaching the\ncleanup to.\nThis change fixes some problems with finalizers.</p><p>It’s no secret that <a href=\"https://go.dev/doc/gc-guide#Common_finalizer_issues\">finalizers\nare difficult to use correctly</a>.\nFor example, objects to which finalizers are attached must not be involved\nin any reference cycles (even a pointer to itself is too much!), otherwise the\nobject will never be reclaimed and the finalizer will never run, causing a\nleak.\nFinalizers also significantly delay reclamation of memory.\nIt takes at a minumum two full garbage collection cycles to reclaim the\nmemory for a finalized object: one to determine that it’s unreachable, and\nanother to determine that it’s still unreachable after the finalizer\nexecutes.</p><p>The problem is that finalizers <a href=\"https://en.wikipedia.org/wiki/Object_resurrection\" rel=\"noreferrer\" target=\"_blank\">resurrect the objects they’re attached\nto</a>.\nThe finalizer doesn’t run until the object is unreachable, at which point it is\nconsidered “dead.”\nBut since the finalizer is called with a pointer to the object, the garbage\ncollector must prevent the reclamation of that object’s memory, and instead must\ngenerate a new reference for the finalizer, making it reachable, or “live,” once\nmore.\nThat reference may even remain after the finalizer returns, for example if the\nfinalizer writes it to a global variable or sends it across a channel.\nObject resurrection is problematic because it means the object, and everything\nit points to, and everything those objects point to, and so on, is reachable,\neven if it would otherwise have been collected as garbage.</p><p>We solve both of these problems by not passing the original object to the\ncleanup function.\nFirst, the values the object refers to don’t need to be kept specially\nreachable by the garbage collector, so the object can still be reclaimed even\nif it’s involved in a cycle.\nSecond, since the object is not needed for the cleanup, its memory can be\nreclaimed immediately.</p><p>Returning to our memory-mapped file example, suppose we notice that our program\nfrequently maps the same files over and over, from different goroutines that are\nunaware of each other.\nThis is fine from a memory perspective, since all these mappings will share\nphysical memory, but it results in lots of unnecessary system calls to map and\nunmap the file.\nThis is especially bad if each goroutine reads only a small section of each\nfile.</p><p>So, let’s deduplicate the mappings by filename.\n(Let’s assume that our program only reads from the mappings, and the files\nthemselves are never modified or renamed once created.\nSuch assumptions are reasonable for system font files, for example.)</p><p>We could maintain a map from filename to memory mapping, but then it becomes\nunclear when it’s safe to remove entries from that map.\nWe could  use a cleanup, if it weren’t for the fact that the map entry\nitself will keep the memory-mapped file object alive.</p><p>Weak pointers solve this problem.\nA weak pointer is a special kind of pointer that the garbage collector ignores\nwhen deciding whether an object is reachable.\nGo 1.24’s <a href=\"https://pkg.go.dev/weak#Pointer\" rel=\"noreferrer\" target=\"_blank\">new weak pointer type,\n</a>, has a  method that\nreturns either a real pointer if the object is still reachable, or  if it\nis not.</p><p>If we instead maintain a map that only  points to the memory-mapped\nfile, we can clean up the map entry when nobody’s using it anymore!\nLet’s see what this looks like.</p><pre><code>var cache sync.Map // map[string]weak.Pointer[MemoryMappedFile]\n\nfunc NewCachedMemoryMappedFile(filename string) (*MemoryMappedFile, error) {\n    var newFile *MemoryMappedFile\n    for {\n        // Try to load an existing value out of the cache.\n        value, ok := cache.Load(filename)\n        if !ok {\n            // No value found. Create a new mapped file if needed.\n            if newFile == nil {\n                var err error\n                newFile, err = NewMemoryMappedFile(filename)\n                if err != nil {\n                    return nil, err\n                }\n            }\n\n            // Try to install the new mapped file.\n            wp := weak.Make(newFile)\n            var loaded bool\n            value, loaded = cache.LoadOrStore(filename, wp)\n            if !loaded {\n                runtime.AddCleanup(newFile, func(filename string) {\n                    // Only delete if the weak pointer is equal. If it's not, someone\n                    // else already deleted the entry and installed a new mapped file.\n                    cache.CompareAndDelete(filename, wp)\n                }, filename)\n                return newFile, nil\n            }\n            // Someone got to installing the file before us.\n            //\n            // If it's still there when we check in a moment, we'll discard newFile\n            // and it'll get cleaned up by garbage collector.\n        }\n\n        // See if our cache entry is valid.\n        if mf := value.(weak.Pointer[MemoryMappedFile]).Value(); mf != nil {\n            return mf, nil\n        }\n\n        // Discovered a nil entry awaiting cleanup. Eagerly delete it.\n        cache.CompareAndDelete(filename, value)\n    }\n}\n</code></pre><p>This example is a little complicated, but the gist is simple.\nWe start with a global concurrent map of all the mapped files we made.\n<code>NewCachedMemoryMappedFile</code> consults this map for an existing mapped\nfile, and if that fails, creates and tries to insert a new mapped file.\nThis could of course fail as well since we’re racing with other insertions, so\nwe need to be careful about that too, and retry.\n(This design has a flaw in that we might wastefully map the same file multiple\ntimes in a race, and we’ll have to throw it away via the cleanup added by\n.\nThis is probably not a big deal most of the time.\nFixing it is left as an exercise for the reader.)</p><p>Let’s look at some useful properties of weak pointers and cleanups exploited by\nthis code.</p><p>Firstly, notice that weak pointers are comparable.\nNot only that, weak pointers have a stable and independent identity, which\nremains even after the objects they point to are long gone.\nThis is why it is safe for the cleanup function to call ’s\n, which compares the , and a crucial reason\nthis code works at all.</p><p>Secondly, observe that we can add multiple independent cleanups to a single\n object.\nThis allows us to use cleanups in a composable way and use them to build\ngeneric data structures.\nIn this particular example, it might be more efficient to combine\n<code>NewCachedMemoryMappedFile</code> with  and\nhave them share a cleanup.\nHowever, the advantage of the code we wrote above is that it can be rewritten\nin a generic way!</p><pre><code>type Cache[K comparable, V any] struct {\n    create func(K) (*V, error)\n    m     sync.Map\n}\n\nfunc NewCache[K comparable, V any](create func(K) (*V, error)) *Cache[K, V] {\n    return &amp;Cache[K, V]{create: create}\n}\n\nfunc (c *Cache[K, V]) Get(key K) (*V, error) {\n    var newValue *V\n    for {\n        // Try to load an existing value out of the cache.\n        value, ok := cache.Load(key)\n        if !ok {\n            // No value found. Create a new mapped file if needed.\n            if newValue == nil {\n                var err error\n                newValue, err = c.create(key)\n                if err != nil {\n                    return nil, err\n                }\n            }\n\n            // Try to install the new mapped file.\n            wp := weak.Make(newValue)\n            var loaded bool\n            value, loaded = cache.LoadOrStore(key, wp)\n            if !loaded {\n                runtime.AddCleanup(newValue, func(key K) {\n                    // Only delete if the weak pointer is equal. If it's not, someone\n                    // else already deleted the entry and installed a new mapped file.\n                    cache.CompareAndDelete(key, wp)\n                }, key)\n                return newValue, nil\n            }\n        }\n\n        // See if our cache entry is valid.\n        if mf := value.(weak.Pointer[V]).Value(); mf != nil {\n            return mf, nil\n        }\n\n        // Discovered a nil entry awaiting cleanup. Eagerly delete it.\n        cache.CompareAndDelete(key, value)\n    }\n}\n</code></pre><p>Despite our best efforts, cleanups and weak pointers can still be error-prone.\nTo guide those considering using finalizers, cleanups, and weak pointers, we\nrecently updated the <a href=\"https://go.dev/doc/gc-guide#Finalizers_cleanups_and_weak_pointers\">guide to the garbage\ncollector</a> with some advice\nabout using these features.\nTake a look next time you reach for them, but also carefully consider whether\nyou need to use them at all.\nThese are advanced tools with subtle semantics and, as the guide says, most\nGo code benefits from these features indirectly, not from using them directly.\nStick to the use-cases where these features shine, and you’ll be alright.</p><p>For now, we’ll call out some of the issues that you are more likely to run into.</p><p>First, the object the cleanup is attached to must be reachable from neither\nthe cleanup function (as a captured variable) nor the argument to the cleanup\nfunction.\nBoth of these situations result in the cleanup never executing.\n(In the special case of the cleanup argument being exactly the pointer passed\nto ,  will panic, as a signal to the\ncaller that they should not use cleanups the same way as finalizers.)</p><p>Second, when weak pointers are used as map keys, the weakly referenced object\nmust not be reachable from the corresponding map value, otherwise the object\nwill continue to remain live.\nThis may seem obvious when deep inside of a blog post about weak pointers, but\nit’s an easy subtlety to miss.\nThis problem inspired the entire concept of an\n<a href=\"https://en.wikipedia.org/wiki/Ephemeron\" rel=\"noreferrer\" target=\"_blank\">ephemeron</a> to resolve it, which is a\npotential future direction.</p><p>Thirdly, a common pattern with cleanups is that a wrapper object is needed, like\nwe see here with our  example.\nIn this particular case, you could imagine the garbage collector directly\ntracking the mapped memory region and passing around the inner .\nSuch functionality is possible future work, and an API for it has been recently\n<a href=\"https://go.dev/issue/70224\">proposed</a>.</p><p>Lastly, both weak pointers and cleanups are inherently non-deterministic, their\nbehavior depending intimately on the design and dynamics of the garbage\ncollector.\nThe documentation for cleanups even permits the garbage collector never to run\ncleanups at all.\nEffectively testing code that uses them can be tricky, but <a href=\"https://go.dev/doc/gc-guide#Testing_object_death\">it is\npossible</a>.</p><p>Weak pointers have been brought up as a feature for Go since nearly the\nbeginning, but for years were not prioritized by the Go team.\nOne reason for that is that they are subtle, and the design space of weak\npointers is a minefield of decisions that can make them even harder to use.\nAnother is that weak pointers are a niche tool, while simultaneously adding\ncomplexity to the language.\nWe already had experience with how painful  could be to use.\nBut there are some useful programs that are not expressible without them, and\nthe  package and the reasons for its existence really emphasized that.</p><p>With generics, the hindsight of finalizers, and insights from all the great work\nsince done by teams in other languages like C# and Java, the designs for weak\npointers and cleanups came together quickly.\nThe desire to use weak pointers with finalizers raised additional questions,\nand so the design for  quickly came together as well.</p><p>I want to thank everyone in the community who contributed feedback on the\nproposal issues and filed bugs when the features became available.\nI also want to thank David Chase for thoroughly thinking through weak\npointer semantics with me, and I want to thank him, Russ Cox, and Austin\nClements for their help with the design of .\nI want to thank Carlos Amedee for his work on getting \nimplemented, polished, landed for Go 1.24.\nAnd finally I want to thank Carlos Amedee and Ian Lance Taylor for their work\nreplacing  with  throughout the\nstandard library for Go 1.25.</p>","contentLength":14444,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Faster Go maps with Swiss Tables","url":"https://go.dev/blog/swisstable","date":1740528000,"author":"Michael Pratt","guid":82,"unread":true,"content":"<p>\n      Michael Pratt\n      26 February 2025\n      </p><p>The hash table is a central data structure in computer science, and it provides the implementation for the map type in many languages, including Go.</p><p>The concept of a hash table was <a href=\"https://spectrum.ieee.org/hans-peter-luhn-and-the-birth-of-the-hashing-algorithm\" rel=\"noreferrer\" target=\"_blank\">first described</a> by Hans Peter Luhn in 1953 in an internal IBM memo that suggested speeding up search by placing items into “buckets” and using a linked list for overflow when buckets already contain an item.\nToday we would call this a <a href=\"https://en.wikipedia.org/wiki/Hash_table#Separate_chaining\" rel=\"noreferrer\" target=\"_blank\">hash table using chaining</a>.</p><p>With data structures that have been around this long, it’s easy to think that they must be “done”; that we know everything there is to know about them and they can’t be improved anymore.\nThat’s not true!\nComputer science research continues to make advancements in fundamental algorithms, both in terms of algorithmic complexity and taking advantage of modern CPU hardware.\nFor example, Go 1.19 <a href=\"https://go.dev/doc/go1.19#sortpkgsort\">switched the  package</a> from a traditional quicksort, to <a href=\"https://arxiv.org/pdf/2106.05123.pdf\" rel=\"noreferrer\" target=\"_blank\">pattern-defeating quicksort</a>, a novel sorting algorithm from Orson R. L. Peters, first described in 2015.</p><p>Go 1.24 includes a completely new implementation of the built-in map type, based on the Swiss Table design.\nIn this blog post we’ll look at how Swiss Tables improve upon traditional hash tables, and at some of the unique challenges in bringing the Swiss Table design to Go’s maps.</p><h2>Open-addressed hash table</h2><p>Swiss Tables are a form of open-addressed hash table, so let’s do a quick overview of how a basic open-addressed hash table works.</p><p>In an open-addressed hash table, all items are stored in a single backing array.\nWe’ll call each location in the array a .\nThe slot to which a key belongs is primarily determined by the , .\nThe hash function maps each key to an integer, where the same key always maps to the same integer, and different keys ideally follow a uniform random distribution of integers.\nThe defining feature of open-addressed hash tables is that they resolve collisions by storing the key elsewhere in the backing array.\nSo, if the slot is already full (a ), then a  is used to consider other slots until an empty slot is found.\nLet’s take a look at a sample hash table to see how this works.</p><p>Below you can see a 16-slot backing array for a hash table, and the key (if any) stored in each slot.\nThe values are not shown, as they are not relevant to this example.</p><div><table><thead><tr></tr></thead></table></div><p>To insert a new key, we use the hash function to select a slot.\nSince there are only 16 slots, we need to restrict to this range, so we’ll use  as the target slot.\nSuppose we want to insert key  and .\nSlot 7 is empty, so we simply insert 98 there.\nOn the other hand, suppose we want to insert key  and .\nSlot 3 is a collision because it already contains key 56.\nThus we cannot insert here.</p><p>We use a probe sequence to find another slot.\nThere are a variety of well-known probe sequences.\nThe original and most straightforward probe sequence is , which simply tries successive slots in order.</p><p>So, in the  example, since slot 3 is in use, we would consider slot 4 next, which is also in use.\nSo too is slot 5.\nFinally, we’d get to empty slot 6, where we’d store key 25.</p><p>Lookup follows the same approach.\nA lookup of key 25 would start at slot 3, check whether it contains key 25 (it does not), and then continue linear probing until it finds key 25 in slot 6.</p><p>This example uses a backing array with 16 slots.\nWhat happens if we insert more than 16 elements?\nIf the hash table runs out of space, it will grow, usually by doubling the size of the backing array.\nAll existing entries are reinserted into the new backing array.</p><p>Open-addressed hash tables don’t actually wait until the backing array is completely full to grow because as the array gets more full, the average length of each probe sequence increases.\nIn the example above using key 25, we must probe 4 different slots to find an empty slot.\nIf the array had only one empty slot, the worst case probe length would be O(n).\nThat is, you may need to scan the entire array.\nThe proportion of used slots is called the , and most hash tables define a  (typically 70-90%) at which point they will grow to avoid the extremely long probe sequences of very full hash tables.</p><p>The Swiss Table <a href=\"https://abseil.io/about/design/swisstables\" rel=\"noreferrer\" target=\"_blank\">design</a> is also a form of open-addressed hash table.\nLet’s see how it improves over a traditional open-addressed hash table.\nWe still have a single backing array for storage, but we will break the array into logical  of 8 slots each.\n(Larger group sizes are possible as well. More on that below.)</p><p>In addition, each group has a 64-bit  for metadata.\nEach of the 8 bytes in the control word corresponds to one of the slots in the group.\nThe value of each byte denotes whether that slot is empty, deleted, or in use.\nIf it is in use, the byte contains the lower 7 bits of the hash for that slot’s key (called ).</p><div><table><thead></thead></table><table><thead><tr></tr></thead></table></div><p>Insertion works as follows:</p><ol><li>Compute  and break the hash into two parts: the upper 57-bits (called ) and the lower 7 bits (called ).</li><li>The upper bits () are used to select the first group to consider:  in this case, as there are only 2 groups.</li><li>Within a group, all slots are equally eligible to hold the key. We must first determine whether any slot already contains this key, in which case this is an update rather than a new insertion.</li><li>If no slot contains the key, then we look for an empty slot to place this key</li><li>If no slot is empty, then we continue the probe sequence by searching the next group.</li></ol><p>Lookup follows the same basic process.\nIf we find an empty slot in step 4, then we know an insertion would have used this slot and can stop the search.</p><p>Step 3 is where the Swiss Table magic happens.\nWe need to check whether any slot in a group contains the desired key.\nNaively, we could just do a linear scan and compare all 8 keys.\nHowever, the control word lets us do this more efficiently.\nEach byte contains the lower 7 bits of the hash () for that slot.\nIf we determine which bytes of the control word contain the  we are looking for, we’ll have a set of candidate matches.</p><p>In other words, we want to do a byte-by-byte equality comparison within the control word.\nFor example, if we are looking for key 32, where , the operation we want looks like so.</p><div><table><tbody><tr></tr><tr></tr></tbody></table></div><p>This is an operation supported by <a href=\"https://en.wikipedia.org/wiki/Single_instruction,_multiple_data\" rel=\"noreferrer\" target=\"_blank\">SIMD</a> hardware, where a single instruction performs parallel operations on independent values within a larger value (). In this case, we <a href=\"https://cs.opensource.google/go/go/+/master:src/internal/runtime/maps/group.go;drc=a08984bc8f2acacebeeadf7445ecfb67b7e7d7b1;l=155?ss=go\" rel=\"noreferrer\" target=\"_blank\">can implement this operation</a> using a set of standard arithmetic and bitwise operations when special SIMD hardware is not available.</p><p>The result is a set of candidate slots.\nSlots where  does not match do not have a matching key, so they can be skipped.\nSlots where  does match are potential matches, but we must still check the entire key, as there is potential for collisions (1/128 probability of collision with a 7-bit hash, so still quite low).</p><p>This operation is very powerful, as we have effectively performed 8 steps of a probe sequence at once, in parallel.\nThis speeds up lookup and insertion by reducing the average number of comparisons we need to perform.\nThis improvement to probing behavior allowed both the Abseil and Go implementations to increase the maximum load factor of Swiss Table maps compared to prior maps, which lowers the average memory footprint.</p><p>Go’s built-in map type has some unusual properties that pose additional challenges to adopting a new map design.\nTwo were particularly tricky to deal with.</p><p>When a hash table reaches its maximum load factor, it needs to grow the backing array.\nTypically this means the next insertion doubles the size of the array, and copies all entries to the new array.\nImagine inserting into a map with 1GB of entries.\nMost insertions are very fast, but the one insertion that needs to grow the map from 1GB to 2GB will need to copy 1GB of entries, which will take a long time.</p><p>Go is frequently used for latency-sensitive servers, so we don’t want operations on built-in types that can have arbitrarily large impact on tail latency.\nInstead, Go maps grow incrementally, so that each insertion has an upper bound on the amount of growth work it must do.\nThis bounds the latency impact of a single map insertion.</p><p>Unfortunately, the Abseil (C++) Swiss Table design assumes all at once growth, and the probe sequence depends on the total group count, making it difficult to break up.</p><p>Go’s built-in map addresses this with another layer of indirection by splitting each map into multiple Swiss Tables.\nRather than a single Swiss Table implementing the entire map, each map consists of one or more independent tables that cover a subset of the key space.\nAn individual table stores a maximum of 1024 entries.\nA variable number of upper bits in the hash are used to select which table a key belongs to.\nThis is a form of <a href=\"https://en.wikipedia.org/wiki/Extendible_hashing\" rel=\"noreferrer\" target=\"_blank\"></a>, where the number of bits used increases as needed to differentiate the total number of tables.</p><p>During insertion, if an individual table needs to grow, it will do so all at once, but other tables are unaffected.\nThus the upper bound for a single insertion is the latency of growing a 1024-entry table into two 1024-entry tables, copying 1024 entries.</p><h3>Modification during iteration</h3><p>Many hash table designs, including Abseil’s Swiss Tables, forbid modifying the map during iteration.\nThe Go language spec <a href=\"https://go.dev/ref/spec#For_statements:~:text=The%20iteration%20order,iterations%20is%200.\">explicitly allows</a> modifications during iteration, with the following semantics:</p><ul><li>If an entry is deleted before it is reached, it will not be produced.</li><li>If an entry is updated before it is reached, the updated value will be produced.</li><li>If a new entry is added, it may or may not be produced.</li></ul><p>A typical approach to hash table iteration is to simply walk through the backing array and produce values in the order they are laid out in memory.\nThis approach runs afoul of the above semantics, most notably because insertions may grow the map, which would shuffle the memory layout.</p><p>We can avoid the impact of shuffle during growth by having the iterator keep a reference to the table it is currently iterating over.\nIf that table grows during iteration, we keep using the old version of the table and thus continue to deliver keys in the order of the old memory layout.</p><p>Does this work with the above semantics?\nNew entries added after growth will be missed entirely, as they are only added to the grown table, not the old table.\nThat’s fine, as the semantics allow new entries not to be produced.\nUpdates and deletions are a problem, though: using the old table could produce stale or deleted entries.</p><p>This edge case is addressed by using the old table only to determine the iteration order.\nBefore actually returning the entry, we consult the grown table to determine whether the entry still exists, and to retrieve the latest value.</p><p>This covers all the core semantics, though there are even more small edge cases not covered here.\nUltimately, the permissiveness of Go maps with iteration results in iteration being the most complex part of Go’s map implementation.</p><p>In <a href=\"https://go.dev/issue/54766#issuecomment-2542444404\">microbenchmarks</a>, map operations are up to 60% faster than in Go 1.23.\nExact performance improvement varies quite a bit due to the wide variety of operations and uses of maps, and some edge cases do regress compared to Go 1.23.\nOverall, in full application benchmarks, we found a geometric mean CPU time improvement of around 1.5%.</p><p>There are more map improvements we want to investigate for future Go releases.\nFor example, we may be able to <a href=\"https://go.dev/issue/70835\">increase the locality of</a> operations on maps that are not in the CPU cache.</p><p>We could also further improve the control word comparisons.\nAs described above, we have a portable implementation using standard arithmetic and bitwise operations.\nHowever, some architectures have SIMD instructions that perform this sort of comparison directly.\nGo 1.24 already uses 8-byte SIMD instructions for amd64, but we could extend support to other architectures.\nMore importantly, while standard instructions operate on up to 8-byte words, SIMD instructions nearly always support at least 16-byte words.\nThis means we could increase the group size to 16 slots, and perform 16 hash comparisons in parallel instead of 8.\nThis would further decrease the average number of probes required for lookups.</p><p>A Swiss Table-based Go map implementation has been a long time coming, and involved many contributors.\nI want to thank YunHao Zhang (<a href=\"https://github.com/zhangyunhao116\" rel=\"noreferrer\" target=\"_blank\">@zhangyunhao116</a>), PJ Malloy (<a href=\"https://github.com/thepudds\" rel=\"noreferrer\" target=\"_blank\">@thepudds</a>), and <a href=\"https://github.com/andy-wm-arthur\" rel=\"noreferrer\" target=\"_blank\">@andy-wm-arthur</a> for building initial versions of a Go Swiss Table implementation.\nPeter Mattis (<a href=\"https://github.com/petermattis\" rel=\"noreferrer\" target=\"_blank\">@petermattis</a>) combined these ideas with solutions to the Go challenges above to build <a href=\"https://pkg.go.dev/github.com/cockroachdb/swiss\" rel=\"noreferrer\" target=\"_blank\"><code>github.com/cockroachdb/swiss</code></a>, a Go-spec compliant Swiss Table implementation.\nThe Go 1.24 built-in map implementation is heavily based on Peter’s work.\nThank you to everyone in the community that contributed!</p>","contentLength":12633,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Testing concurrent code with testing/synctest","url":"https://go.dev/blog/synctest","date":1739923200,"author":"Damien Neil","guid":81,"unread":true,"content":"<p>\n      Damien Neil\n      19 February 2025\n      </p><p>One of Go’s signature features is built-in support for concurrency.\nGoroutines and channels are simple and effective primitives for\nwriting concurrent programs.</p><p>However, testing concurrent programs can be difficult and error prone.</p><p>In Go 1.24, we are introducing a new, experimental\n<a href=\"https://go.dev/pkg/testing/synctest\"></a> package\nto support testing concurrent code. This post will explain the motivation behind\nthis experiment, demonstrate how to use the synctest package, and discuss its potential future.</p><p>In Go 1.24, the  package is experimental and\nnot subject to the Go compatibility promise.\nIt is not visible by default.\nTo use it, compile your code with  set in your environment.</p><h2>Testing concurrent programs is difficult</h2><p>To begin with, let us consider a simple example.</p><p>The <a href=\"https://go.dev/pkg/context#AfterFunc\"></a> function\narranges for a function to be called in its own goroutine after a context is canceled.\nHere is a possible test for :</p><pre><code>func TestAfterFunc(t *testing.T) {\n    ctx, cancel := context.WithCancel(context.Background())\n\n    calledCh := make(chan struct{}) // closed when AfterFunc is called\n    context.AfterFunc(ctx, func() {\n        close(calledCh)\n    })\n\n    // TODO: Assert that the AfterFunc has not been called.\n\n    cancel()\n\n    // TODO: Assert that the AfterFunc has been called.\n}\n</code></pre><p>We want to check two conditions in this test:\nThe function is not called before the context is canceled,\nand the function  called after the context is canceled.</p><p>Checking a negative in a concurrent system is difficult.\nWe can easily test that the function has not been called ,\nbut how do we check that it  be called?</p><p>A common approach is to wait for some amount of time before\nconcluding that an event will not happen.\nLet’s try introducing a helper function to our test which does this.</p><pre><code>// funcCalled reports whether the function was called.\nfuncCalled := func() bool {\n    select {\n    case &lt;-calledCh:\n        return true\n    case &lt;-time.After(10 * time.Millisecond):\n        return false\n    }\n}\n\nif funcCalled() {\n    t.Fatalf(\"AfterFunc function called before context is canceled\")\n}\n\ncancel()\n\nif !funcCalled() {\n    t.Fatalf(\"AfterFunc function not called after context is canceled\")\n}\n</code></pre><p>This test is slow:\n10 milliseconds isn’t a lot of time, but it adds up over many tests.</p><p>This test is also flaky:\n10 milliseconds is a long time on a fast computer,\nbut it isn’t unusual to see pauses lasting several seconds\non shared and overloaded\n<a href=\"https://en.wikipedia.org/wiki/Continuous_integration\" rel=\"noreferrer\" target=\"_blank\">CI</a>\nsystems.</p><p>We can make the test less flaky at the expense of making it slower,\nand we can make it less slow at the expense of making it flakier,\nbut we can’t make it both fast and reliable.</p><h2>Introducing the testing/synctest package</h2><p>The  package solves this problem.\nIt allows us to rewrite this test to be simple, fast, and reliable,\nwithout any changes to the code being tested.</p><p>The package contains only two functions:  and .</p><p> calls a function in a new goroutine.\nThis goroutine and any goroutines started by it\nexist in an isolated environment which we call a .\n waits for every goroutine in the current goroutine’s bubble\nto block on another goroutine in the bubble.</p><p>Let’s rewrite our test above using the  package.</p><pre><code>func TestAfterFunc(t *testing.T) {\n    synctest.Run(func() {\n        ctx, cancel := context.WithCancel(context.Background())\n\n        funcCalled := false\n        context.AfterFunc(ctx, func() {\n            funcCalled = true\n        })\n\n        synctest.Wait()\n        if funcCalled {\n            t.Fatalf(\"AfterFunc function called before context is canceled\")\n        }\n\n        cancel()\n\n        synctest.Wait()\n        if !funcCalled {\n            t.Fatalf(\"AfterFunc function not called after context is canceled\")\n        }\n    })\n}\n</code></pre><p>This is almost identical to our original test,\nbut we have wrapped the test in a  call\nand we call  before asserting that the function has been called or not.</p><p>The  function waits for every goroutine in the caller’s bubble to block.\nWhen it returns, we know that the context package has either called the function,\nor will not call it until we take some further action.</p><p>This test is now both fast and reliable.</p><p>The test is simpler, too:\nwe have replaced the  channel with a boolean.\nPreviously we needed to use a channel to avoid a data race between\nthe test goroutine and the  goroutine,\nbut the  function now provides that synchronization.</p><p>The race detector understands  calls,\nand this test passes when run with .\nIf we remove the second  call,\nthe race detector will correctly report a data race in the test.</p><p>Concurrent code often deals with time.</p><p>Testing code that works with time can be difficult.\nUsing real time in tests causes slow and flaky tests,\nas we have seen above.\nUsing fake time requires avoiding  package functions,\nand designing the code under test to work with\nan optional fake clock.</p><p>The  package makes it simpler to test code that uses time.</p><p>Goroutines in the bubble started by  use a fake clock.\nWithin the bubble, functions in the  package operate on the\nfake clock. Time advances in the bubble when all goroutines are\nblocked.</p><p>To demonstrate, let’s write a test for the\n<a href=\"https://go.dev/pkg/context#WithTimeout\"></a> function.\n creates a child of a context,\nwhich expires after a given timeout.</p><pre><code>func TestWithTimeout(t *testing.T) {\n    synctest.Run(func() {\n        const timeout = 5 * time.Second\n        ctx, cancel := context.WithTimeout(context.Background(), timeout)\n        defer cancel()\n\n        // Wait just less than the timeout.\n        time.Sleep(timeout - time.Nanosecond)\n        synctest.Wait()\n        if err := ctx.Err(); err != nil {\n            t.Fatalf(\"before timeout, ctx.Err() = %v; want nil\", err)\n        }\n\n        // Wait the rest of the way until the timeout.\n        time.Sleep(time.Nanosecond)\n        synctest.Wait()\n        if err := ctx.Err(); err != context.DeadlineExceeded {\n            t.Fatalf(\"after timeout, ctx.Err() = %v; want DeadlineExceeded\", err)\n        }\n    })\n}\n</code></pre><p>We write this test just as if we were working with real time.\nThe only difference is that we wrap the test function in ,\nand call  after each  call to wait for the context\npackage’s timers to finish running.</p><p>A key concept in  is the bubble becoming .\nThis happens when every goroutine in the bubble is blocked,\nand can only be unblocked by another goroutine in the bubble.</p><p>When a bubble is durably blocked:</p><ul><li>If there is an outstanding  call, it returns.</li><li>Otherwise, time advances to the next time that could unblock a goroutine, if any.</li><li>Otherwise, the bubble is deadlocked and  panics.</li></ul><p>A bubble is not durably blocked if any goroutine is blocked\nbut might be woken by some event from outside the bubble.</p><p>The complete list of operations which durably block a goroutine is:</p><ul><li>a send or receive on a nil channel</li><li>a send or receive blocked on a channel created within the same bubble</li><li>a select statement where every case is durably blocking</li></ul><p>Operations on a  are not durably blocking.</p><p>It is common for functions to acquire a global mutex.\nFor example, a number of functions in the reflect package\nuse a global cache guarded by a mutex.\nIf a goroutine in a synctest bubble blocks while acquiring\na mutex held by a goroutine outside the bubble,\nit is not durably blocked—it is blocked, but will be unblocked\nby a goroutine from outside its bubble.</p><p>Since mutexes are usually not held for long periods of time,\nwe simply exclude them from ’s consideration.</p><p>Channels created within a bubble behave differently from ones created outside.</p><p>Channel operations are durably blocking only if the channel is bubbled\n(created in the bubble).\nOperating on a bubbled channel from outside the bubble panics.</p><p>These rules ensure that a goroutine is durably blocked only when\ncommunicating with goroutines within its bubble.</p><p>External I/O operations, such as reading from a network connection,\nare not durably blocking.</p><p>Network reads may be unblocked by writes from outside the bubble,\npossibly even from other processes.\nEven if the only writer to a network connection is also in the same bubble,\nthe runtime cannot distinguish between a connection waiting for more data to arrive\nand one where the kernel has received data and is in the process of delivering it.</p><p>Testing a network server or client with synctest will generally\nrequire supplying a fake network implementation.\nFor example, the <a href=\"https://go.dev/pkg/net#Pipe\"></a> function\ncreates a pair of s that use an in-memory network connection\nand can be used in synctest tests.</p><p>The  function starts a goroutine in a new bubble.\nIt returns when every goroutine in the bubble has exited.\nIt panics if the bubble is durably blocked\nand cannot be unblocked by advancing time.</p><p>The requirement that every goroutine in the bubble exit before Run returns\nmeans that tests must be careful to clean up any background goroutines\nbefore completing.</p><p>Let’s look at another example, this time using the \npackage to test a networked program.\nFor this example, we’ll test the  package’s handling of\nthe 100 Continue response.</p><p>An HTTP client sending a request can include an “Expect: 100-continue”\nheader to tell the server that the client has additional data to send.\nThe server may then respond with a 100 Continue informational response\nto request the rest of the request,\nor with some other status to tell the client that the content is not needed.\nFor example, a client uploading a large file might use this feature to\nconfirm that the server is willing to accept the file before sending it.</p><p>Our test will confirm that when sending an “Expect: 100-continue” header\nthe HTTP client does not send a request’s content before the server\nrequests it, and that it does send the content after receiving a\n100 Continue response.</p><p>Often tests of a communicating client and server can use a\nloopback network connection. When working with ,\nhowever, we will usually want to use a fake network connection\nto allow us to detect when all goroutines are blocked on the network.\nWe’ll start this test by creating an  (an HTTP client) that uses\nan in-memory network connection created by <a href=\"https://go.dev/pkg/net#Pipe\"></a>.</p><pre><code>func Test(t *testing.T) {\n    synctest.Run(func() {\n        srvConn, cliConn := net.Pipe()\n        defer srvConn.Close()\n        defer cliConn.Close()\n        tr := &amp;http.Transport{\n            DialContext: func(ctx context.Context, network, address string) (net.Conn, error) {\n                return cliConn, nil\n            },\n            // Setting a non-zero timeout enables \"Expect: 100-continue\" handling.\n            // Since the following test does not sleep,\n            // we will never encounter this timeout,\n            // even if the test takes a long time to run on a slow machine.\n            ExpectContinueTimeout: 5 * time.Second,\n        }\n</code></pre><p>We send a request on this transport with the “Expect: 100-continue” header set.\nThe request is sent in a new goroutine, since it won’t complete until the end of the test.</p><pre><code>        body := \"request body\"\n        go func() {\n            req, _ := http.NewRequest(\"PUT\", \"http://test.tld/\", strings.NewReader(body))\n            req.Header.Set(\"Expect\", \"100-continue\")\n            resp, err := tr.RoundTrip(req)\n            if err != nil {\n                t.Errorf(\"RoundTrip: unexpected error %v\", err)\n            } else {\n                resp.Body.Close()\n            }\n        }()\n</code></pre><p>We read the request headers sent by the client.</p><pre><code>        req, err := http.ReadRequest(bufio.NewReader(srvConn))\n        if err != nil {\n            t.Fatalf(\"ReadRequest: %v\", err)\n        }\n</code></pre><p>Now we come to the heart of the test.\nWe want to assert that the client will not send the request body yet.</p><p>We start a new goroutine copying the body sent to the server into a ,\nwait for all goroutines in the bubble to block, and verify that we haven’t read anything\nfrom the body yet.</p><p>If we forget the  call, the race detector will correctly complain\nabout a data race, but with the  this is safe.</p><pre><code>        var gotBody strings.Builder\n        go io.Copy(&amp;gotBody, req.Body)\n        synctest.Wait()\n        if got := gotBody.String(); got != \"\" {\n            t.Fatalf(\"before sending 100 Continue, unexpectedly read body: %q\", got)\n        }\n</code></pre><p>We write a “100 Continue” response to the client and verify that it now sends the\nrequest body.</p><pre><code>        srvConn.Write([]byte(\"HTTP/1.1 100 Continue\\r\\n\\r\\n\"))\n        synctest.Wait()\n        if got := gotBody.String(); got != body {\n            t.Fatalf(\"after sending 100 Continue, read body %q, want %q\", got, body)\n        }\n</code></pre><p>And finally, we finish up by sending the “200 OK” response to conclude the request.</p><p>We have started several goroutines during this test.\nThe  call will wait for all of them to exit before returning.</p><pre><code>        srvConn.Write([]byte(\"HTTP/1.1 200 OK\\r\\n\\r\\n\"))\n    })\n}\n</code></pre><p>This test can be easily extended to test other behaviors,\nsuch as verifying that the request body is not sent if the server does not ask for it,\nor that it is sent if the server does not respond within a timeout.</p><p>We are introducing <a href=\"https://go.dev/pkg/testing/synctest\"></a>\nin Go 1.24 as an  package.\nDepending on feedback and experience\nwe may release it with or without amendments,\ncontinue the experiment,\nor remove it in a future version of Go.</p><p>The package is not visible by default.\nTo use it, compile your code with  set in your environment.</p><p>We want to hear your feedback!\nIf you try out ,\nplease report your experiences, positive or negative,\non <a href=\"https://go.dev/issue/67434\">go.dev/issue/67434</a>.</p>","contentLength":13215,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["dev","go"]}