{"id":"4W3i2hyrJTVfcLq85rWgduVQ3y3BMzrSD4pVUCMqPpFhmXWpqxQ","title":"Hacker News: Front Page","displayTitle":"HN Front","url":"https://hnrss.org/frontpage?points=75","feedLink":"https://news.ycombinator.com/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":20,"items":[{"title":"Zlib-rs is faster than C","url":"https://trifectatech.org/blog/zlib-rs-is-faster-than-c/","date":1742153707,"author":"dochtman","guid":759,"unread":true,"content":"<p>We've released version <a href=\"https://crates.io/crates/libz-rs-sys\">0.4.2</a> of <a href=\"https://github.com/trifectatechfoundation/zlib-rs\">zlib-rs</a>, featuring a number of substantial performance improvements. We are now (to our knowledge) the fastest api-compatible zlib implementation for decompression, and beat the competition in the most important compression cases too.</p><p>We've built a <a href=\"https://trifectatechfoundation.github.io/zlib-rs-bench/\">dashboard</a> that shows the performance of the current main branch compared to other implementations, and tracks our performance over time to catch any regressions and visualize our progress.</p><p>This post compares zlib-rs to the latest <a href=\"https://github.com/zlib-ng/zlib-ng\">zlib-ng</a> and, for decompression, also to <a href=\"https://chromium.googlesource.com/chromium/src/third_party/zlib/\">zlib-chromium</a>. These are the leading C zlib implementations that focus on performance. We'll soon write a blog post with more technical details, and only cover the most impactful changes briefly.</p><p><a href=\"https://trifectatech.org/blog/current-zlib-rs-performance/\">Last time</a>, we benchmarked using the  flag. That gave the best results for our implementation, but was not entirely fair because our rust implementation could assume that certain SIMD capabilities would be available, while zlib-ng had to check for them at runtime.</p><p>We have now made some changes so that we can efficiently select the most optimal implementation at runtime too.</p><p>Picking the best version of a function is known as multiversioning. We have a baseline implementation that works on all CPUs, and then some number of specialized versions that use SIMD instructions or other features that may or may not be available on a particular CPU. The challenge is to always pick the optimal implementation, but with minimal runtime cost. That means we want to do the runtime check as few times as possible, and then perform a large chunk of work.</p><p>Today, multiversioning is not natively supported in rust. There are <a href=\"https://rust-lang.github.io/rust-project-goals/2025h1/simd-multiversioning.html\">proposals for adding it</a> (which we're very excited about!), but for now, we have to implement it manually which unfortunately involves some unsafe code. We'll write more about this soon (for the impatient, the relevant code is <a href=\"https://github.com/trifectatechfoundation/zlib-rs/blob/64d972982325626d8c8875e308846a53c7f0aa05/zlib-rs/src/inflate.rs#L1860-L1881\">here</a>).</p><p>The C code is able to use  implicit fallthroughs to generate very efficient code. Rust does not have an equivalent of this mechanism, and this really slowed us down when data comes in in small chunks.</p><p>Nikita Popov suggested we try the <code>-Cllvm-args=-enable-dfa-jump-thread</code> option, which recovers most of the performance here. It performs a kind of jump threading for deterministic finite automata, and our decompression logic matches this pattern.</p><p>LLVM does not currently enable this flag by default, but that is the plan eventually. We're also looking into supporting this optimization in rustc itself, and making it more fine-grained than just blindly applying it to a whole project and hoping for the best.</p><p>As far as we know, we're the fastest api-compatible zlib implementation today for decompression. Not only do we beat zlib-ng by a fair margin, we're also faster than the implementation used in chromium.</p><p>Like before, our benchmark is decompressing a compressed version of silesia-small.tar, feeding the state machine the input in power-of-2 sized chunks. Small chunk sizes simulate the streaming use case, larger chunk sizes model cases where the full input is availabe.</p><p>We're now significantly faster than zlib-ng for all but the smallest chunk size. A chunk size of  bytes is very unlikely to be relevant for performance in practice because the input can just be buffered and then decompressed in larger chunks.</p><p>We are however significantly faster than zlib-ng at the more relevant chunk sizes: well over 10% for inputs of 1kb, and over 6% for inputs of 65kb.</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>For decompression, the zlib implementation used in the chromium project (found <a href=\"https://chromium.googlesource.com/chromium/src/third_party/zlib/\">here</a>, which we use via <a href=\"https://github.com/folkertdev/libz-chromium-sys\">a modified version of </a>) is often faster than zlib-ng. However, we also beat it at this benchmark for the most relevant chunk sizes.</p><p>Interestingly, zlib-chromium is mostly faster for the smaller chunk sizes, while for larger chunk sizes performance is fairly comparable to zlib-ng.</p><table><thead><tr></tr></thead><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>We've been chipping away at compression too (shoutout to <a href=\"https://github.com/brian-pane\">Brian Pane</a>, who contributed numerous PRs in this area), but see more mixed results.</p><p>On x86_64 linux, we are faster for some of the compression levels that matter most, about 6% at the default level of 6, and over 10% at the \"best compression\" level 9. But we're still slightly slower for most of the other levels when comparing to zlib-ng.</p><table><tbody><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr><tr></tr></tbody></table><p>For most users, decompression is the most relevant operation, and even for compression we're a lot faster than stock zlib. Nevertheless, we'll continue to try and improve compression performance.</p><p>zlib-rs can be used both in C projects and as a rust crate in rust projects. For rust projects, we recommend using the  release of the <a href=\"https://crates.io/crates/flate2\">flate2</a> crate with the  feature flag. For use in C projects, zlib-rs can be built as a C dynamic library (see <a href=\"https://github.com/trifectatechfoundation/zlib-rs/tree/main/libz-rs-sys-cdylib\">instructions</a>) and used in any project that uses zlib today.</p><p>Our implementation is mostly done, and clearly performs extremely well. However, we're missing some <a href=\"https://github.com/trifectatechfoundation/zlib-rs/issues/49\">less commonly used API functions</a> related to gzip files that would make us a complete drop-in replacement in all cases.</p><p>To complete the work and improve performance and e.g. packaging, we're seeking funding for the amount of €95.000. See the <a href=\"https://trifectatech.org/initiatives/workplans/data-compression/#workplan-zlib-rs\">workplan</a> for details.</p><p>Please <a href=\"https://trifectatech.org/support\">contact us</a> if you are interested in financially supporting zlib-rs.</p>","contentLength":5160,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43381512"},{"title":"AI Is Making Developers Dumb","url":"https://eli.cx/blog/ai-is-making-developers-dumb","date":1742151118,"author":"chronicom","guid":746,"unread":true,"content":"<p>People often talk about the productivity gains that comes from LLMs, and it would be disingenuous of me to dismiss these. It’s true. You can be productive with an LLM-assisted workflow, but that same workflow could also be making you dumber.</p><p>There’s a reason behind why I say this. Over time, you develop a reliance on LLM tools. This is to the point where is starts to become hard for you to work without one.</p><p>I got into software engineering because I love building things and figuring out how stuff works. That means that I enjoy partaking in the laborious process of pressing buttons on my keyboard to form blocks of code.</p><p>LLM-assisted workflows take this away. Instead of the satisfaction of figuring out a problem by hand, one simply asks the LLM to take a guess.</p><p>Instead of understanding why things work in the way they do, you become dependent on an assistant to tell you what you should do.</p><p>Some people might not enjoy writing their own code. If that’s the case, as harsh as it may seem, I would say that they’re trying to work in a field that isn’t for them. Maybe you’re just here for the money? Fair enough. That happens with every profession, and it generally shows through one’s enthusiasm and demeanor.</p><p>The best engineers I’ve met are people who will spend hours at the weekend building their own version of a tool or software. Heck, that’s where you get innovation and advancements from. You can’t find performance improvements without a good understanding of how a system works, otherwise you’re just shooting in the dark.</p><p>There is a concept called “Copilot Lag”. It refers to a state where after each action, an engineer pauses, waiting for something to prompt them what to do next. There is no self-sufficiency, just the act of waiting for an AI to tell them what should come next. It’s akin to where a junior in the field might start - relying on their more senior colleagues to guide them and understand how to proceed.</p><p>Eons ago, I used to use GitHub Copilot in VS Code. When I look back on that time period now, I’m amazed I didn’t do more damage to knowledge retention.</p><p>Over time, I started to forget basic foundational elements of the languages I worked with. I started to forget parts of the syntax, how basic statements are used. It’s pretty embarrassing to look back and think about how I was eroding the knowledge I had gathered just because I wanted a short term speed increase.</p><p>That’s the reality of what happens when you use Copilot for a year. You start to forget things, because you are no longer having to think about what you’re doing in the same way that you would when you try to figure out how to solve a problem yourself.</p><p>It was actually a video by ThePrimeagen that made me realise this and confront reality. He had a clip from one of his streams where he was talking about Copilot lag. What a wake up call that was!</p><p>I stopped using LLM assistants for coding after that, and I’m glad I did.</p><p>To give an example, compilers are an area that I find super interesting. I had actually tried to work through Thorsten Ball’s <a href=\"https://interpreterbook.com\">Writing An Interpreter In Go</a> at the time. But it was completely pointless. Instead of learning about the topics and techniques in the book, Copilot was just outputting the code for me. Sure, it might feel cool that you just wrote a parser, but could you do it again if you turned Copilot off? Probably not. You also lose the chance to learn about concepts like memory management or data oriented design, because Copilot just gives you some code that it thinks might work, instead of you researching topics and understanding nuances.</p><p>That actually leads into another angle. Research. This time with a more positive spin on AI.</p><p>It’s true. LLMs are useful. They’re like a search engine. We used to use stack overflow to get help with a programming problem. Since LLMs are trained on all that data, they can be effective tools to learn more about a concept. But only if you use them with an inquisitive mindset and don’t trust their output.</p><p>As they’re notorious for making crap up because, well, that’s how LLMs work by design, it means that they’re probably making up nonsense half the time. It’s just about patterns and token sequences, not real statements by people that are insanely knowledgeable. It’s trained on content created by people who know what they’re talking about, but it regurgitates it in a manner that differs from the source material.</p><p>Anyway, interrogating responses and trying to figure out why it's recommending certain approaches is the only real way to get benefits from an LLM. Treat it like a conversation with someone, where you’re trying to understand why they like a certain technique. If you don’t understand why something is being suggested, or what it’s actually doing under the hood, then you have failed.</p><p>And make notes! Lots of them! I recently started playing around with Zig, and I constantly make notes on things that I am learning about the language, especially considering that it’s my first time dealing with memory management. They can be a useful reference point and handy when you’re stuck, or maybe even something to share with others!</p><p>I wrote this post on my morning commute, and my Tube has arrived at its destination, so I’ll leave it here.</p>","contentLength":5293,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43381215"},{"title":"Our Interfaces Have Lost Their Senses","url":"https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses","date":1742148671,"author":"me_smith","guid":745,"unread":true,"content":"<a href=\"https://wattenberger.com/\"></a><p>Think about how you experience the world—</p><p>you touch, you hear, you move.</p><div>An interface is the bridge between\n\t</div><p>Computers used to be physical beasts.</p><p>We programmed them by punching cards, plugging in wires, and flipping switches. Programmers walked among banks of switches and cables, physically choreographing their logic. Being on a computer used to be a full-body experience.\n</p><p>We've been successfully removing all friction from our apps — think about how effortless it is to scroll\n\tthrough a social feed. But is that what we want? Compare the feeling of doomscrolling to kneading\n\tdough, playing an instrument, sketching... these take effort, but they're also deeply\n\tsatisfying. When you strip away too much friction, meaning and satisfaction go with it.\n</p><p>Think about how you use physical tools. Drawing isn't just moving your hand—it's the\n\tfeel of the pencil against paper, the tiny adjustments of pressure, the sound of graphite\n\tscratching. You shift your body to reach the other side of the canvas. You erase with your other\n\thand. You step back to see the whole picture.\n</p><p>We made painting feel like typing,</p><h2>Putting the you back in UI</h2><p>So how might our interfaces look if we shaped them to fit us?\n</p><p>We use our hands to sculpt, our eyes to scan, our ears to catch patterns.\n\t</p><p>Our computers can communicate to us in many different formats, each with their own strengths:</p><div><p>And what about the reverse! We can communicate to our computers in many different ways, each with their own strengths:\n</p></div><p>And the real magic happens when we combine different modalities. You can't read and listen and speak\n\tat the same time—try reading this excerpt while talking about your day:\n</p><div><p>If it had not rained on a certain May morning Valancy Stirling’s whole life would have been\n\t\tentirely different. She would have gone, with the rest of her clan, to Aunt Wellington’s\n\t\tengagement picnic and Dr. Trent would have gone to Montreal. But it did rain and you shall hear\n\t\twhat happened to her because of it.\n\t</p></div><p>Let's build interfaces that let us multitask across senses.</p><p>So, what might a richer interface look like? I have strong conviction that our future interfaces should:\n</p><ul><li>let us collaborate on , not just ephemeral chat logs.</li><li>support <strong>multiple concurrent modalities</strong>—voice, gestures,\n\t\tvisuals, spatial components.\n\t</li><li>respond to —detecting context, organizing information, helping\n\t\tus think better.\n\t</li></ul><p>Last year, I did a rough exploration of what this could look like for a thought organizing tool. One that listened as you talked or typed, and organized your rambling thoughts into cards.\n</p><p>This interface is very rough, but felt like a different way of working with technology. Especially how it let me bumble through rough ideas one second, then responded to commands like \"re-group my cards\" or \"add 3 cards about this\" the next.\n</p><p>I would love to see more explorations like this!\n</p><h2>Our interfaces have lost their senses</h2><p>All day, we poke, swipe, and scroll through flat, silent\n\tscreens. But we're more than just eyes and a pointer finger. We think with our hands, our ears,\n\tour bodies.\n</p><p>The future of computing is being designed right now. Can we build something richer—something that\n\tmoves with us, speaks our language, and molds to our bodies?\n</p><img src=\"https://wattenberger.com/thoughts/our-interfaces-have-lost-their-senses/footer.png\">","contentLength":3226,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43380930"},{"title":"\"Wait, not like that\": Free and open access in the age of generative AI","url":"https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/","date":1742145813,"author":"thinkingemote","guid":758,"unread":true,"content":"<div data-nosnippet=\"\">Listen to me read this post here (not an AI-generated voice!), <a href=\"https://www.citationneeded.news/podcast/\">subscribe</a> to the feed in your podcast app, or <a href=\"https://www.citationneeded.news/content/media/2025/03/2025-03-14-Wait-not-like-that.mp3\">download</a> the recording for later.</div><p>The visions of the open access movement have inspired countless people to contribute their work to the commons: a world where “every single human being can freely share in the sum of all knowledge” (Wikimedia), and where “education, culture, and science are equitably shared as a means to benefit humanity” (Creative Commons).</p><p>But there are scenarios that can introduce doubt for those who contribute to free and open projects like the Wikimedia projects, or who independently release their own works under free licenses. I call these “wait, no, not like that” moments.</p><p>When a passionate Wikipedian discovers their carefully researched article has been packaged into an e-book and sold on Amazon for someone else’s profit? .</p><p>When a developer of an open source software project sees a multi-billion dollar tech company rely on their work without contributing anything back? </p><p>When a nature photographer discovers their freely licensed wildlife photo was used in an NFT collection minted on an environmentally destructive blockchain? .</p><p>And perhaps most recently, when a person who publishes their work under a free license discovers that work has been used by tech mega-giants to train extractive, exploitative large language models? </p><p>These reactions are understandable. When we freely license our work, we do so in service of those goals: free and open access to knowledge and education. But when trillion dollar companies exploit that openness while giving nothing back, or when our work enables harmful or exploitative uses, it can feel like we've been naïve. The natural response is to try to regain control.</p><p>This is where many creators find themselves today, particularly in response to AI training. But the solutions they're reaching for — more restrictive licenses, paywalls, or not publishing at all — risk destroying the very commons they originally set out to build.</p><div><div> is an independent publication, entirely supported by readers like you. Consider <a href=\"https://www.citationneeded.news/signup\">signing up</a> for a free or pay-what-you-want subscription — it really helps me to keep doing this work.</div></div><p>The first impulse is often to try to tighten the licensing, maybe by switching away to something like the <a href=\"https://en.wikipedia.org/wiki/Creative_Commons_NonCommercial_license\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">Creative Commons’ non-commercial</a> (and thus, non-free) license. When NFTs enjoyed a moment of popularity in the early 2020s, some artists looked to Creative Commons in hopes that they might declare NFTs fundamentally incompatible with their free licenses (they didn’t). The same thing happened again with the explosion of generative AI companies training models on CC-licensed works, and some were disappointed to see the group take the stance that, not only do CC licenses not prohibit AI training wholesale, AI training should be considered non-infringing by default from a copyright perspective.</p><p>But the trouble with trying to continually narrow the definitions of “free” is that it is impossible to write a license that will perfectly prohibit each possibility that makes a person go “wait, no, not like that” while retaining the benefits of free and open access. If that is truly what a creator wants, then they are likely better served by a traditional, all rights reserved model in which any prospective reuser must individually negotiate terms with them; but this undermines the purpose of free, and restricts permitted reuse only to those with the time, means, and bargaining power to negotiate on a case by case basis.</p><p>Particularly with AI, there’s also no indication that tightening the license even . We already know that major AI companies have been training their models on all rights reserved works in their ongoing efforts to ingest as much data as possible. Such training may prove to have been permissible in US courts under fair use, and it’s probably best that it does.</p><p>There’s also been an impulse by creators concerned about AI to dramatically limit how people can access their work. Some artists have decided it’s simply not worthwhile to maintain an online gallery of their work when that makes it easily accessible for AI training. Many have implemented restrictive content gates — paywalls, registration-walls, “are you a human”-walls, and similar — to try to fend off scrapers. This too closes off the commons, making it more challenging or expensive for those “every single human beings” described in open access manifestos to access the material that was originally intended to be common goods.</p><p>Often by trying to wall off those considered to be bad actors, people wall off the very people they intended to give access to. People who gate their work behind paywalls likely didn’t set out to create works that only the wealthy could access. People who implement registration walls probably didn’t intend for their work to only be available to those willing to put up with the risk of incessant email spam after they relinquish their personal information. People who try to stave off bots with CAPTCHAs asking “are you a human?” probably didn’t mean to limit their material only to abled people who are willing to abide ever more protracted and irritating riddles. And people using any of these strategies likely didn’t want people to struggle to even find their work in the first place after the paywalls and regwalls and anti-bot mechanisms thwarted search engine indexers or social media previews.</p><p>And frankly, if we want to create a world in which every single human being can freely share in the sum of all knowledge, and where education, culture, and science are equitably shared as a means to benefit humanity, we should stop attempting to erect these walls. If a kid learns that carbon dioxide traps heat in Earth's atmosphere or how to calculate compound interest thanks to an editor’s work on a Wikipedia article, does it really matter if they learned it via ChatGPT or by asking Siri or from opening a browser and visiting Wikipedia.org?</p><p><strong>Instead of worrying about “wait, not like that”, I think we need to reframe the conversation to “wait, not  like that” or “wait, not in ways that threaten open access itself”.</strong> The true threat from AI models training on open access material is not that more people may access knowledge thanks to new modalities. It’s that those models may stifle Wikipedia and other free knowledge repositories, benefiting from the labor, money, and care that goes into supporting them while also bleeding them dry. It’s that trillion dollar companies become the sole arbiters of access to knowledge after subsuming the painstaking work of those who made knowledge free to all, killing those projects in the process.</p><p>Irresponsible AI companies are already imposing huge loads on Wikimedia infrastructure, which is costly both from a pure bandwidth perspective, but also because it requires dedicated engineers to maintain and improve systems to handle the massive automated traffic. And AI&nbsp;companies that do not attribute their responses or otherwise provide any pointers back to Wikipedia prevent users from knowing where that material came from, and do not encourage those users to go visit Wikipedia, where they might then sign up as an editor, or donate after seeing a request for support. (This is most AI companies, by the way. Many AI “visionaries” seem perfectly content to promise that artificial superintelligence is just around the corner, but claim that attribution is somehow a permanently unsolvable problem.)</p><p>And while I rely on Wikipedia as an example here, the same goes for any website containing freely licensed material, where scraping benefits AI companies at often extreme cost to the content hosts. This isn't just about strain on one individual project, it's about the systematic dismantling of the infrastructure that makes open knowledge possible.</p><p>Anyone at an AI company who stops to think for half a second should be able to recognize they have a vampiric relationship with the commons. While they rely on these repositories for their sustenance, their adversarial and disrespectful relationships with creators reduce the incentives for anyone to make their work publicly available going forward (freely licensed or otherwise). They drain resources from maintainers of those common repositories often without any compensation. They reduce the visibility of the original sources, leaving people unaware that they can or should contribute towards maintaining such valuable projects. AI companies should want a thriving open access ecosystem, ensuring that the models they trained on Wikipedia in 2020 can be continually expanded and updated. Even if AI companies don’t care about the benefit to the common good, it shouldn’t be hard for them to understand that by bleeding these projects dry, they are destroying their own food supply.</p><p>And yet many AI companies seem to give very little thought to this, seemingly looking only at the months in front of them rather than operating on years-long timescales. (Though perhaps anyone who has observed AI companies’ activities more generally will be unsurprised to see that they do not act as though they believe their businesses will be sustainable on the order of years.)</p><p>It would be very wise for these companies to immediately begin prioritizing the ongoing health of the commons, so that they do not wind up strangling their golden goose. It would also be very wise for the rest of us to not rely on AI companies to suddenly, miraculously come to their senses or develop a conscience en masse.</p><p>Instead, we must ensure that mechanisms are in place to  AI companies to engage with these repositories on their creators' terms.</p><p>There are ways to do it: models like Wikimedia Enterprise, which welcomes AI companies to use Wikimedia-hosted data, but requires them to do so using paid, high-volume pipes to ensure that they do not clog up the system for everyone else and to make them financially support the extra load they’re placing on the project’s infrastructure. Creative Commons is experimenting with the idea of “<a href=\"https://www.ietf.org/slides/slides-aicontrolws-creative-commons-position-paper-on-preference-signals-00.pdf\">preference signals</a>” — a non-copyright-based model by which to communicate to AI companies and other entities the terms on which they may or may not reuse CC licensed work. Everyday people need to be given the tools — both legal and technical — to enforce their own preferences around how their works are used.</p><p>Some might argue that if AI companies are already ignoring copyright and training on all-rights-reserved works, they'll simply ignore these mechanisms too. But there's a crucial difference: rather than relying on murky copyright claims or threatening to expand copyright in ways that would ultimately harm creators, we can establish clear legal frameworks around consent and compensation that build on existing labor and contract law. Just as unions have successfully negotiated terms of use, ethical engagement, and fair compensation in the past, collective bargaining can help establish enforceable agreements between AI companies, those freely licensing their works, and communities maintaining open knowledge repositories. These agreements would cover not just financial compensation for infrastructure costs, but also requirements around attribution, ethical use, and reinvestment in the commons.</p><p>The future of free and open access isn't about saying “wait, not like that” — it’s about saying \"yes, like that, but under fair terms”. With fair compensation for infrastructure costs. With attribution and avenues by which new people can discover and give back to the underlying commons. With deep respect for the communities that make the commons — and the tools that build off them —&nbsp;possible. Only then can we truly build that world where every single human being can freely share in the sum of all knowledge.</p><p>As I was writing this piece, I discovered that a SXSW panel featuring delegates from the Wikimedia Foundation and Creative Commons, titled “<a href=\"https://schedule.sxsw.com/2025/events/PP153044\">Openness Under Pressure: Navigating the Future of Open Access</a>”, discussed some of the same topics. (I was, sadly, scheduled to speak at the same time and so was unable to attend in person). The audio recording is available online, and I would highly recommend giving it a listen if this is a topic that interests you!</p>","contentLength":12336,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43380617"},{"title":"Big LLMs weights are a piece of history","url":"https://antirez.com/news/147","date":1742127204,"author":"freeatnet","guid":151,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43378401"},{"title":"Docs – Open source alternative to Notion or Outline","url":"https://github.com/suitenumerique/docs","date":1742125132,"author":"maelito","guid":150,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43378239"},{"title":"Show HN: My high school team’s space probe","url":"https://drive.google.com/file/d/1_9V6lBTIfDsPdKCohQBc5Ed5UzDbnsrI/view?usp=sharing","date":1742114889,"author":"JohnOfOsgiliath","guid":136,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43377690"},{"title":"Apple's long-lost hidden recovery partition from 1994 has been found","url":"https://www.downtowndougbrown.com/2025/03/apples-long-lost-hidden-recovery-partition-from-1994-has-been-found/","date":1742083623,"author":"chmaynard","guid":149,"unread":true,"content":"<p>In my <a href=\"https://www.downtowndougbrown.com/2025/03/the-gooey-rubber-thats-slowly-ruining-old-hard-drives/\" data-type=\"post\" data-id=\"10245\" target=\"_blank\" rel=\"noreferrer noopener\">last post about hard drives that go bad over time</a>, I hinted at having rescued a lost piece of obscure Apple software history from an old 160 MB Conner hard drive that had its head stuck in the parked position. This post is going to be all about it. It’s the tale of a tad bit of an obsession, what felt like a hopeless search, and how persistence eventually paid off. There’s still an unsolved mystery too, so I’m hoping others will see this and help to fill in the blanks!</p><blockquote><p><strong>The LC 550’s Secret Partition</strong></p><p>If Apple’s programmers, in creating the Performa series, were aiming to make idiot-proof computers, they were serious about it. The Performa 550 is an amazing case in point. When you run the included Apple Backup program (see Chapter 15), you get a little surprise that you didn’t count on: a  on your hard drive!</p><p>This invisible chunk of hard drive space contains a miniature, invisible System Folder. Apple’s internal memo explains it this way:</p><p>“When a system problem (one that prevents the Performa from booting) is detected, a [dialog box] informs the user of a system problem. The user can choose to fix the problem manually or to reinstall software from the backup partition’s Mini System Folder.”</p><p>If you choose to reinstall your System software, you get the wristwatch cursor for a moment while the miniature System Folder is silently copied to your main hard-drive partition. The Performa restarts from the restored hard drive, and the invisible system partition disappears once again.</p><p>We got a Performa team member to admit that this kind of sneaky save-the-users-from-themselves approach may well be adopted in other Performa models.</p><p>Who knows what goodness lurks in the hearts of men?</p></blockquote><p>Cool! Although I have owned my own copy of this book for decades, I had no recollection of ever reading this little blurb. The book, if you’re curious, is <a href=\"https://apple.fandom.com/wiki/Macworld_Mac_Secrets\" target=\"_blank\" rel=\"noreferrer noopener\">Macworld Mac Secrets</a> by David Pogue and Joseph Schorr. I found this whole functionality very intriguing, particularly because I had what felt like a very personal connection to it: the very first Mac that my family had when I was growing up was a Performa 550. I don’t think I have any pictures from back then, but in the meantime I’ve acquired one that looks exactly identical, so here’s a (slightly blurry) view of the type of machine I’m talking about in this post:</p><p>I know that many people think the LC/Performa 5xx case style is ugly, but I really like it! I’m definitely biased though.</p><p>This is an early model manufactured in September of 1993, which came with a caddy-loading CD-ROM drive (AppleCD 300i). Like other Macs from the same era, <a href=\"https://tidbits.com/1994/01/31/apple-improves-cd-drive/\" target=\"_blank\" rel=\"noreferrer noopener\">newer versions from 1994 came with a tray-loading drive instead</a> (AppleCD 300i Plus). For comparison, here’s a photo of a late-model Performa 550 with a manufacture date of March 1994 that <a href=\"https://bsky.app/profile/re4mat.bsky.social\" target=\"_blank\" rel=\"noreferrer noopener\">re4mat</a> kindly gave me permission to share here:</p><p>Pierre asked me if I had a copy of Apple’s software restoration CD for the Performa 550, and if I knew how to get it working in an emulator in order to try out this special functionality. I <a href=\"https://macintoshgarden.org/apps/macintosh-os-71x\" target=\"_blank\" rel=\"noreferrer noopener\">pointed him to a download link</a> for the Performa CD for the 500 Series, version 7.1P6:</p><p>If you weren’t using multimedia computers in the early 1990s, you might not recognize the weird rectangular container that this CD is enclosed inside of. It’s a CD caddy, and it’s what was used for inserting CDs into computers like the first one pictured above. You would open the caddy by squeezing the top right and bottom right ends toward each other, stick the disc into it, close it, and then push it into the slot in the computer, similarly to how you would insert a floppy disk. I really don’t miss these things one bit!</p><p>Back to the story, though. I also <a href=\"https://www.emaculation.com/forum/viewtopic.php?t=8031\" target=\"_blank\" rel=\"noreferrer noopener\">gave Pierre some tips for using the restore CD in an emulator</a>. Nowadays, my advice is outdated because it’s much easier to use Apple restore CDs in at least one emulator — <a href=\"https://www.mamedev.org/\" target=\"_blank\" rel=\"noreferrer noopener\">MAME</a> has come a long way in the last few years. He figured out a bunch more stuff on his own after that, including trying it in his own Performa 450 (not 550), but the bottom line was that the recovery partition was nowhere to be found.</p><p>Well, sort of. He found that the process of restoring from the CD actually did create a recovery partition. Here’s a screenshot of the partitioning from inside of Apple HD SC Setup while booted from the Performa CD, after formatting the hard drive by clicking the Initialize button in the main window:</p><p>As you can see, there’s a 2,560 KB partition of type Apple_Recovery almost at the end of the drive, just after the main partition named “Hard Disk”. This was promising at first glance, but the partition was empty! Further testing revealed that the custom Performa-specific version of Apple HD SC Setup (7.2.2P6) bundled on the CD was responsible for creating it, but didn’t actually populate it with any data. Apple Backup also didn’t put anything onto the partition, despite what the book said. I even looked through <a href=\"https://www.downtowndougbrown.com/2013/06/legacy-apple-backup-file-format-on-floppy-disks/\" data-type=\"post\" data-id=\"457\" target=\"_blank\" rel=\"noreferrer noopener\">my past disassemblies of the Apple Backup and Apple Restore code</a> and confirmed that there was nothing related to creating a recovery partition.</p><p>The conclusion at the time was that someone needed to get ahold of a Performa 550 that still had its original hard drive and had never been reformatted. That’s where this story sat for 3 years. </p><p>A few months ago, I remembered this whole situation and decided that I really wanted to try to find this partition. After all, the clock had always been ticking. The longer we waited, the fewer and fewer original Performa 550s would be out there in the wild. Not to mention that hard drives go bad and people throw them out without knowing that it’s usually possible to recover data from drives of this era. I confirmed all of Pierre’s findings in MAME. I even tried using Apple Backup in case I missed something, but no, it didn’t do anything with the hidden recovery partition. An easy way to look at it is to manually edit the partition table in a hex editor and change the type from Apple_Recovery to Apple_HFS.</p><p>After doing this and booting up, I found another hard drive icon on my desktop called Recovery Volume, but it was empty, just like Pierre said:</p><p>Taking it a bit further, I tried recreating the recovery functionality myself. I copied a minimal system folder to the Recovery Volume, and then changed its type back to Apple_Recovery. This made it invisible again. Then I screwed up my main system folder and rebooted. Sure enough, it automatically came up with the Recovery Volume as the main boot volume.</p><p>This proved that the mechanism for booting from the recovery partition worked; we were just missing the data that was supposed to be on it. I came to the same conclusion that Pierre had already reached: we needed to find a Performa 550 that had never been reformatted. In the meantime, I spent some time digging into archives of Apple’s old tech notes and found several more references to this functionality.</p><blockquote><p><em>Backup Partition Software-automatically detects corrupted system folders. When a bad System Folder is detected, the user is given the option to re-load another System Folder into their system.</em></p></blockquote><blockquote><p><em>The Apple Backup application creates a backup recovery partition that allows the Performa to boot even when the System Software on the main hard drive has been corrupted. The partition is invisible to the user.</em></p></blockquote><blockquote><p><em>There is no built-in limit to the number of times the backup partition can be used. However, the partition will be lost if the hard drive is re-formatted. At this time the backup partition is used only on the Performa 550.</em></p></blockquote><p><a href=\"https://ia600306.us.archive.org/view_archive.php?archive=/21/items/APPLE_TIL_ARTICLES/TIL00001_to_TIL60496.zip&amp;file=TIL16006-Performa_550-System_Folder_Created_w-Dinosaur_Safari_CD_8-94_%28TA32248%29.pdf\" target=\"_blank\" rel=\"noreferrer noopener\">Performa 550: System Folder Created w/ Dinosaur Safari CD (8/94)</a> — not that I needed any more proof of the recovery partition’s existence at this point, but I got a kick out of this one. It talks about how launching an educational game about dinosaurs accidentally caused the system to go into recovery mode. It provided a little more info about what would happen when the recovery dialog popped up:</p><blockquote><p><em>When I launch the Dinosaur Safari CD from Creative Multimedia, a dialog box appears telling me that my Performa computer is having trouble starting up. I only have two options Shutdown or Continue? Why?</em></p></blockquote><p>After reading these articles, I was very convinced that the recovery partition was a real thing that existed, but I was also pretty confident that Apple Backup wasn’t responsible for creating it, despite Apple claiming otherwise. I had already seen that the special build of Apple HD SC Setup was what actually created it, and plus, like I said earlier, I had looked closely into a disassembly of the version of Apple Backup supplied with the Performa 500 series restore CD. There was nothing that copied any files to another partition on the hard drive, at least not that I could see.</p><p>Really, the most important thing I gained from this exercise was that the second tech note confirmed the need to find a Performa 550 that had never been reformatted. Also, if the first tech note was to be believed, it needed to have come with System 7.1P6. This could narrow the search even further — <a href=\"https://groups.google.com/g/comp.sys.mac.system/c/Wj1dL2xW3XQ/m/rt7YC4t-YzsJ\" target=\"_blank\" rel=\"noreferrer noopener\">I know for a fact that earlier Performa 550 models came with 7.1P5</a>, including my childhood one. The same tech note also pointed out that 7.1P6 was the first version to support the “AppleCD 300+”, which is referring to the tray-loading CD-ROM drive. Based on this information, it’s reasonable to deduce that all Performa 550s with a tray-loading CD-ROM drive would probably have originally come with at least System 7.1P6.</p><p>There was only one thing left to try at this point: asking the Internet for help. I asked people everywhere I could think of: <a href=\"https://tinkerdifferent.com/threads/performa-550-unpreserved-recovery-partition.4048/\" target=\"_blank\" rel=\"noreferrer noopener\">Tinker Different</a>, <a href=\"https://68kmla.org/bb/index.php?threads/performa-550-and-recovery-partition.39815/#post-551319\" target=\"_blank\" rel=\"noreferrer noopener\">68kMLA</a> (where <a href=\"https://68kmla.org/bb/index.php?threads/performa-550-and-recovery-partition.39815/\" target=\"_blank\" rel=\"noreferrer noopener\">Pierre had already asked</a>), and <a href=\"https://www.reddit.com/r/VintageApple/comments/1i75ns6/anybody_have_a_performa_550_that_has_never_been/\" target=\"_blank\" rel=\"noreferrer noopener\">various</a> social media <a href=\"https://bsky.app/profile/downtowndougbrown.com/post/3lconemblks2q\" target=\"_blank\" rel=\"noreferrer noopener\">sites</a>. I searched Reddit and found people who had posted in the past about having a 550, asking if they still had the hard drive. I think I scared some of them — at least one person deleted their post after I asked! To be honest, I can’t blame them. I can imagine how freaky it would be to hear from someone begging to look at my hard drive’s contents. I’m sure some people might think of it as crossing a line, but it’s not as crazy of an ask if it’s a machine they’ve received second-hand from someone else. Plus, I was very clear about exactly what I was looking for (and why).</p><p>I asked a seller of a Performa 550 that had been sitting on eBay for a long time if they would be willing to sell me the hard drive separately. They weren’t interested. I even bought some random hard drives on eBay that definitely went with a 5xx-style case. These were easy to identify because this case style uses a unique adapter for plugging the drive into the chassis wiring harness when you slide it into place.</p><p>What do I have to show for all of these eBay purchases? Well, after dumping them all with my <a href=\"https://zuluscsi.com/\" target=\"_blank\" rel=\"noreferrer noopener\">ZuluSCSI</a> in initiator mode, I can say that the one pictured above came from a Macintosh TV. I also found another one from an LC 575. Lastly, I bought yet another drive that the seller said came from a Performa 577. The Performa 577 one was funny — it had all the Mac mounting hardware on it, but when I dumped it, it turned out to be from an Atari TT or Falcon (not sure which). I’d love to hear the story of how it ended up with an LC 5xx drive sled and adapter on it! Needless to say, none of them had the elusive recovery partition. One particularly friendly eBay seller was even nice enough to show me a preview of a drive’s contents in HFSExplorer, which helped me determine that it wasn’t from a Performa.</p><p>I almost began questioning my sanity at one point during this search. Multiple people initially told me that they thought I was confused about this whole thing. I pointed them toward Apple’s tech notes describing it. Were Pierre and I imagining this whole thing? Were Apple’s tech notes all a lie?</p><p>The thing is, this whole functionality was super obscure. It’s understandable that people weren’t familiar with it. Apple publicly stated it was only included with this one specific Performa model. Their own documentation also said that it would be lost if you reformatted the hard drive. It was hiding in the background, so nobody really knew it was there, let alone thought about saving it. Also, I can say that the first thing a lot of people do when they obtain a classic computer is erase it in order to restore it to the factory state. Little did anyone know, if they reformatted the hard drive on a Performa 550, they could have been wiping out rare data that hadn’t been preserved!</p><p>Someone who saw my post on Reddit mentioned that they had a Performa 550 and would check it out. It was a newer tray-loading model with a January 1994 manufacture date. Unfortunately, the Conner hard drive inside of it wouldn’t cooperate, and plus this person didn’t have anything capable of dumping the contents. Luckily for me though, they were totally comfortable with letting me borrow the drive and try to recover the data from it.</p><p>To tie everything together, we have now reached the point in this story that I covered in <a href=\"https://www.downtowndougbrown.com/2025/03/the-gooey-rubber-thats-slowly-ruining-old-hard-drives/\" data-type=\"post\" data-id=\"10245\" target=\"_blank\" rel=\"noreferrer noopener\">my last post about hard drives with stuck heads</a>. As I mentioned in that blog, I could not get this drive to do anything. It would just spin up, sit there for a while, spin down, and then make an annoying buzzing sound for a while, repeating that whole process over and over again.</p><p>I tried all kinds of things. I nudged the head while the platters were spinning, inspected it with my thermal camera to see if any components were getting hot, and tried it at different temperatures — cold shortly after it arrived, and at room temperature later. The only thing I noticed was that when it was making the buzzing sound, one of the IRFD123 MOSFETs would get much hotter than normal: up near 100 degrees Celsius.</p><p>I wasn’t really sure what to do with this information though. It just seemed wrong that the head wasn’t moving at all. That’s when I finally decided to inspect everything further inside the drive and noticed the head stack seemed like it was sticking to a rubber/plastic looking piece. The Kapton tape trick I figured out and showed off in the last post finally allowed me to dump the drive contents. If you didn’t catch it last time, here’s a video showing how it was stuck, along with a successful dump with the help of the tape:</p><p>As soon as the drive imaging process completed, I powered everything off and anxiously opened the hard drive image file with my favorite hex editor (<a href=\"https://mh-nexus.de/en/hxd/\" target=\"_blank\" rel=\"noreferrer noopener\">HxD</a>):</p><p>Boom! This drive had a recovery partition on it! Now, that didn’t necessarily mean anything. After all, I had already seen an empty partition created by Apple HD SC Setup on the Performa CD. Still, though, it was definitely promising. Here’s an interpretation of the data at the beginning of the entry in the partition table:</p><p>50 4D = PM = Signature00 00 = Padding<p>00 00 00 05 = 5 total partitions on the drive</p>00 04 E2 60 = starting physical block of the partition (0x4E260 blocks = 0x9C4C000 bytes)<p>00 00 14 00 = size of partition in blocks (0x1400 blocks = 0x280000 bytes = 2560 kilobytes)</p>name = MacOS</p><p>Also, just like in the partition table created by the Performa CD that I had inspected earlier, there were four bytes “msjy” at an offset of 0x9C bytes into the partition table entry. No other partitions had any data at 0x9C. I wonder if these are a couple of developers’ initials hiding in there or something? Is it an acronym? “Make Steve Jobs Yodel”? I even asked ChatGPT to come up with a playful interpretation in the context of Macs in the mid-1990s. It suggested “My System Jammed Yesterday”, explaining it as a playful nod to the “chaotic charm” of the era’s extension conflicts and Sad Mac screens. I didn’t even mention anything about it involving OS recovery. Tell me how you really feel about old Macs, ChatGPT!</p><p>Knowing that the partition was there, the next step was to look near the end of the dumped drive image in HxD. If the partition had any actual data stored, it would be very obvious because starting at 0x9C4C000 in the file, there would be actual data and not just a bunch of zeros.</p><p>This is where I started to actually get excited. The partition contained boot blocks! This was obvious because of the starting signature of LK and all of the various system file names plainly visible. On the other hand, the recovery partition created by the Performa CD during testing had zeros at this location — no boot blocks.</p><p>These boot blocks are identical to the main partition’s boot blocks, except for one very important difference: at 0x1A, the Pascal string containing the Finder name is “recovery” instead of “Finder” like you’d normally see. This means that if you boot from this partition, it will load a program named recovery instead of the usual Finder app you’d expect on most Mac OS installs.</p><p>This was definitely something special that the restore CD was not capable of recreating. As I scrolled further down through the partition, it quickly became obvious that it actually had some files!</p><p>Okay, now I was totally stoked! I booted up a copy of the imaged drive in MAME and immediately noticed that there was evidence that the recovery partition had definitely activated itself on this machine in the past: there was a folder named  on the desktop with a creation date in 2004, and the trash contained an app called Read Me Mini System Folder with the exact same date.</p><p>I wanted to experience the automatic OS recovery process for myself without any customizations from the original owner of the machine this hard drive came from, so I used HxD to copy the entire 2,560 KB recovery partition onto the fresh hard drive image I had created by restoring from the Performa CD. This was easy because the Performa version of Apple HD SC Setup had created an empty recovery partition with the exact same size. Then I booted it up in MAME and dragged the System file out of my System Folder in order to intentionally mess it up. I had to turn off System Folder Protection in the Performa control panel first:</p><p>This is the classic kind of mistake that would have normally left you with an unbootable system showing a floppy disk icon with a flashing question mark. Would Apple’s automatic Performa OS recovery save me from myself? I rebooted to see what would happen. Instead of seeing a flashing question mark, I saw a Happy Mac very briefly before the system rebooted itself again. Then another Happy Mac showed up, and this time, it looked like a normal boot, except no extension icons showed up at the bottom of the screen. It was definitely booting from the recovery partition. Eventually, I was greeted with this screen:</p><p>Hooray! This was exactly the dialog box that Macworld Mac Secrets and Apple’s tech note had referred to. The recovery partition had been successfully rescued!</p><p>Let’s walk through the rest of this feature. If you click Shut Down, obviously the machine turns itself off. But when it boots back up, the recovery partition doesn’t automatically kick in anymore. So you’re on your own to fix the problem by booting from the Performa CD or the Utilities floppy disk.</p><p>On the other hand, clicking OK does exactly what the tech note describes. You get the wristwatch cursor for a few seconds, the system reboots, and then you are greeted with this amazing screen, complete with an ugly yellow desktop pattern. Shall we call it the yellow screen of shame? Notice that the Mini System Folder on the desktop is the active System Folder, because it has the special icon.</p><p>Here are the rest of the pages in this Read Me Mini System Folder app:</p><p>Aha! So it’s not entirely automatic, since you still have to manually drag the System, Finder, and System Enablers from the Mini System Folder back to your original System Folder. Still though, it’s a very handy solution that gives you a bootable machine when something goes wrong with your OS.</p><p>If you just ignore these instructions and keep using the computer, you will be nagged with this Read Me on every boot because it lives inside the Startup Items folder of the Mini System Folder. The Read Me also appears on your desktop, but for some reason it doesn’t show up until you open the Hard Disk icon.</p><p>Let’s take a deeper look at how it all works by temporarily changing the partition type to Apple_HFS instead of Apple_Recovery and booting up again, so we can inspect the files. After a quick automatic rebuild of the desktop file, the Recovery Volume appears, with actual contents this time!</p><p>Inside of the System Folder, there are definitely some interesting things. As expected based on the earlier analysis of the boot blocks, there is an app named “recovery” that contains all of the interesting stuff. The icons are kind of arranged willy-nilly in here.</p><p>The creator code of the recovery app is msjy — the exact same magic value we saw in the partition table entry.</p><p>Scrolling further down, there is a System file and various enablers. Everything is marked as being part of System Software v7.1P6.</p><p>It’s interesting to me that although this recovery partition was only available on the 550, it still has a bunch of enablers for other Performa models: the 45x/46x, 47x/57x, and 600. I guess that’s not too crazy considering all of these exact same enablers are included with a fresh copy of System 7.1P6 installed using the Performa CD.</p><p>As a quick detour, System Enabler 316 is an interesting one that is hard to find info about on the Internet. I inspected its ‘gbly’ resource and determined that it’s for the Centris 610, Centris 650, and Quadra 800. It’s an older version of the enabler created before <a href=\"https://512pixels.net/2021/03/the-sad-story-of-the-centris/\" target=\"_blank\" rel=\"noreferrer noopener\">the speed-bumped Quadra 610 and Quadra 650 were a thing</a>. I wonder if there was a plan at some point to have a Performa model based on one of those machines? If I had to guess, maybe it would have been a 68040-based successor to the Performa 600, which uses the same case style as the Centris 650. The Performa 650?</p><p>Let’s not get too far off track. Back to the Recovery Volume’s System Folder — as expected, the Startup Items folder contains the Read Me application:</p><p>Everything started to become clear. The recovery app was marked as the startup application instead of the Finder. It displayed the dialog giving the user the option to recover. If they clicked OK, it would copy the entire System Folder from the Recovery Volume, omitting itself, to the Desktop Folder of the main hard drive partition. Then, it would “bless” the newly-copied mini System Folder and reboot.</p><p>How did all this stuff get into the partition? Did Apple Backup do it, or was it factory-programmed data? I tried to see if I could deduce anything from the dates of the files. In order to preserve the integrity of all of the displayed dates, I performed this analysis with a read-only copy of the original drive image in order to prevent any modification dates from being updated.</p><p>All of the files in the partition have a creation date of March 4, 1994 — over 31 years ago! Most of the files have a matching modification date, except for the System suitcase, which was last modified on September 26, 1994. I don’t know exactly what this all means, considering it came from a machine with a January 1994 manufacture date.</p><p>The Recovery Volume itself also has a creation date of March 4th, just five minutes before the creation date of all the files. Interestingly, the modification date of the volume is still shown as March 4th in the Get Info window, even though the System suitcase was modified later in September of that year.</p><p>The Master Directory Block of the Recovery Volume says the modification date (drLsMod) is September 26th, matching when the System file was changed. I’m not sure what causes this discrepancy. I guess the date displayed in the Get Info window isn’t simply the date stored in the Master Directory Block.</p><p>Similarly, although the main hard drive partition has a creation date of December 5, 1993 according to the Master Directory Block, the Get Info window says it was created on February 3, 1994. I’m not sure which one is more accurate. Either way, it’s pretty clear this drive had not been reformatted. I did find it curious that the recovery partition was created over a month later, though. When you reformat a hard drive using the special version of Apple HD SC Setup on the Performa CD, the recovery partition ends up with a creation date about a minute after the main partition.</p><p>The Finder and System Enablers in the recovery partition are identical to the same stock files from a 7.1P6 restore. The only difference I could find in the System file was that the recovery partition’s version was missing a single At Ease ‘INIT’ resource, but the At Ease Startup extension automatically adds it to the System file after you reboot. This leaves you with a System file totally identical to what is restored from the Performa CD. I find it odd that At Ease was stripped out, but the American Heritage Dictionary ‘FKEY’ resource was not.</p><p>The best theory that I can come up with is that Apple Backup really was responsible for creating this partition. After all, Apple went out of their way to specifically mention it in their tech note. Maybe March 4th, 1994 was the date when the original owner of the computer backed it up for the first time. September 26th could have been the last time that Apple Backup was run. Perhaps the owner completely uninstalled At Ease from the computer between March and September, so the System file had been changed and the recovery copy needed to be updated accordingly? Unfortunately, most of the Performa-specific software had been deleted from this computer. It was still running System 7.1P6, but Apple Backup was nowhere to be found. So I wasn’t able to confirm whether or not a mysterious, unpreserved newer version of Apple Backup was really responsible for populating the partition.</p><p>The other theory floating around in my head is that maybe it came from the factory like this. The March 1994 timeline is consistent with the date of the tech note describing the functionality, so maybe that’s when Apple created it and started bundling it. I don’t know how long the machines sat at Apple’s factory before they were actually sold — does a manufacture date of January 1994 also mean it was shipped to a store in January 1994? Either way, I definitely don’t know how to explain the September 26th, 1994 modification date. Maybe a third-party utility did something to the System file on the secondary partition? The first Apple Backup theory seems like the more likely explanation, especially given that Apple said that’s how it was created.</p><p>This whole question is the last piece of the puzzle that hasn’t been solved yet. If anyone else has a Performa 550 and would be willing to dump their hard drive or at least look at Apple Backup, I’d be very interested in finding out A) if it has the recovery partition and B) if there was a special newer version of Apple Backup that didn’t make its way onto the Performa CD. I searched for various strings that show up in the “recovery” and “Read Me Mini System Folder” apps, and they aren’t anywhere on the Performa CD. I guess they could be stored compressed somewhere, but I’m pretty confident based on the actual Apple Backup code that nothing is hiding in there. Here are the various versions (with their exact sizes and dates) of Apple Backup that I have seen on Performa 550 installations. None of these have the recovery partition creation built in:</p><p>I also found version 1.3 (June 15, 1994, 163,388 bytes used) by restoring from a Performa 636 restore CD. It, too, does not contain any recovery partition code.</p><p>For a demo, I thought it would be fun to replicate the problem that the Apple tech note mentioned about the Dinosaur Safari CD inadvertently activating the recovery partition, so I bought a copy to test it out. To make it even more interesting, I decided to run this test on real hardware. I’m leaning toward believing that a lot of the older caddy-loading models (possibly all of them) didn’t have this recovery partition, so just pretend it’s a newer model that came with System 7.1P6. I copied the recovery partition onto a real Apple-branded IBM 160 MB SCSI hard drive using ZuluSCSI’s USB MSC initiator mode, which allows it to act as a USB-to-SCSI bridge. Sorry about the flickery screen; I couldn’t get my phone camera’s shutter speed to sync up perfectly with the display’s refresh rate.</p><p>Sure enough, when I opened the game from the CD, the computer did exactly what Apple’s tech note said it would do. The workaround of copying the application to my hard drive worked just fine. If it’s not obvious, I sped up the process of copying it to the hard drive — it took a while! It might be interesting someday to look into why this game accidentally activated the OS recovery, but this blog is already getting way too long!</p><p>I want to talk a little more about the yellow screen of shame. When I first saw it, I wasn’t entirely sure if it was really part of the recovery functionality or if the original owner just had terrible taste.</p><p>Digging deeper, I found three clues that all made it clear it was an intentional choice by Apple to really make it obvious that something was wrong. First, the yellow pattern is stored as a ‘ppat’ resource in the recovery app.</p><p>Second, the System file in the recovery partition has the default blue-gray Performa background shown in the screenshots above. This makes sense, because it’s the pattern that showed up with the dialog about the Performa having trouble starting up.</p><p>And lastly, page 3 of the Read Me app implies that something may have changed your desktop pattern.</p><p>So clearly, the recovery process, by design, sets up the custom yellow background.</p><p>Why did I care so much about finding this lost partition? Well, there are a number of reasons. For one, this is exactly the kind of research project that’s perfect for me because I don’t know how to let things go. It’s also something that, quite frankly, needed to be preserved before it became extinct. The most important reason, though, is that this functionality is historically significant and deserves some attention. How many personal computers in 1994 still had the ability to boot after the OS was trashed? Isn’t this an extremely early example of this type of functionality? Did Windows have anything like this prior to Vista? Did the Mac have anything else like this prior to sometime in the OS X era? I would love to hear more comments about what you think on this. I admittedly don’t know a ton about older machines that weren’t Macs.</p><p>I’m not saying this feature is perfect. Since we’ve already seen that the Dinosaur Safari CD was able to accidentally activate it, I wouldn’t be surprised if there were other ways to inadvertently cause it to pop up too. It also required manual intervention after the recovery process, which meant that you needed a fair amount of computer knowledge to finish fixing your OS. The average Joe Schmoe would probably have trouble following these directions to fix the System Folder. But still, it leaves you with a bootable system instead of an unusable computer with a flashing question mark. It’s very cool, especially for 1994.</p><p>I wonder why Apple didn’t continue down this path with subsequent models? Or even retroactively adding the functionality to earlier ones after a fresh install of a newer OS. I’m not aware of any other Macs that have this partition. It doesn’t depend on any special ROM support or anything like that, at least as far as I can see. I tried out the recovery functionality on several other machines: a IIci, LC, LC 475, and an emulated Performa 600, and it works great on all of them. Heck, it even works on the Classic II/Performa 200!</p><p>It kind of looks like the window size of the Read Me app was a calculated decision to ensure it would fit on the 512×342 screen used in black-and-white compact Macs.</p><p>Thinking about later models, the Performa 630 series used an internal IDE hard drive instead of SCSI, so the custom version of Apple HD SC Setup was no longer used. I wonder if the Performa 57x series had this partition? You’d think they would have had the exact same software bundle as the tray-loading 550 models. If any readers have a Performa 57x machine, I’d greatly appreciate it if you could check!</p><p>How did this functionality actually work under the hood? I haven’t gone too deep into the code (maybe it can be a future post), but I have pieced together a few clues. The “msjy” magic number I talked about earlier definitely plays a part in everything. The special Performa version of Apple HD SC Setup also includes a custom version of Apple’s hard disk driver. This driver contains several references to msjy, so I’m pretty sure that’s what it uses to identify the recovery partition.</p><p>I also discovered that the 7.1P4 and 7.1P5 Utilities floppy disks, which were bundled with various Performas, have slightly older custom versions of Apple HD SC Setup: 7.2.1P and 7.2.2P respectively. They also create the recovery partition. The interesting thing about these versions is that it appears Apple accidentally forgot to strip out the debug function names, in both the utility itself and the bundled hard disk driver. They didn’t make this mistake in the original non-Performa 7.2.2 version, and they also didn’t make the mistake in the newer 7.2.2P6 version. Anyway, this is kind of cool, because it tells me the names of functions that look for “msjy” at an offset of 0x9C. Function names in that same area of the driver code include: , , , , and . So Apple definitely at least sort of released some of the recovery functionality to the public prior to 7.1P6, despite what their own version history says. And the disk driver is definitely involved in it.</p><p>Newer versions of Apple’s disk driver no longer contain the magic number, so at some point they must have abandoned this functionality. In my opinion, it’s a real shame that they ditched it — this could have been very useful going forward on all Macs. They could have even expanded on it and automated more of the recovery process. Sure, it used some of your hard drive space, but it could have been a good trade-off for better reliability.</p><p>That’s more than enough technical stuff for one post. I am sharing a download link where you can try this functionality out for yourself if you want. After all, the whole reason I did this was for software preservation purposes, so it makes sense to share it with the world. This is a small piece of Apple software history that, to my knowledge, has not been preserved until now. <a href=\"https://macintoshgarden.org/apps/system-71p6-performa-550-hidden-recovery-partition\" target=\"_blank\" rel=\"noreferrer noopener\">I uploaded a drive image to the Macintosh Garden.</a> Don’t worry, I didn’t include any of the original owner’s personal data. I started fresh with a blank hard drive image, restored it using the 7.1P6 Performa CD, and then only copied over the restore partition from the dumped hard drive. So this is a factory-fresh Performa 550 7.1P6 install with the recovery partition also present and populated.</p><p>The MAME command that I use to boot from this disk image is:</p><p>Of course, you can also test it out on a real machine by copying the hard drive image to a <a href=\"https://zuluscsi.com/\" target=\"_blank\" rel=\"noreferrer noopener\">ZuluSCSI</a> or <a href=\"https://bluescsi.com/\" target=\"_blank\" rel=\"noreferrer noopener\">BlueSCSI</a> and naming it something like HD00.hda.</p><p>Winding down this super long post now, the main lessons I learned from this research project are:</p><ol><li>If you get your hands on a vintage computer, strongly consider backing the hard drive up before erasing it. I know it might contain someone’s personal files, so be mindful of that, and of course respect their privacy. But there might still be something hiding in the background that has been lost to time. You never know — it happened here!</li><li>The fact that many hard drives go bad as they age might actually be a good thing for software preservation. If a vintage computer’s hard drive has a stuck head that can easily be bypassed, someone might sell it as non-working with data intact, rather than erasing it and selling it as “fully tested and wiped”.</li><li>There are some really awesome people out there in the world!</li></ol><p>Special thanks to <a href=\"https://www.journaldulapin.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Pierre</a> for discovering that this functionality even existed in the first place, and getting the word out so we could eventually preserve it. I also have to thank David Pogue and Joseph Schorr for writing about it in their book many decades ago. And of course, huge thanks to the amazing person from Reddit, who asked not to be credited, who gave me the opportunity to borrow and repair the drive that ended up containing the lost partition. You’re seriously the best!</p><p>I’m going to repeat this again in case anybody has scrolled all the way to the end. There are still missing pieces of knowledge about how exactly this recovery partition would have been originally created. If you happen to have a Performa 550 with its original hard drive and wouldn’t mind checking for the partition and/or a special version of Apple Backup, please let me know! I would be happy to walk anybody through the process of dumping the drive contents. I’ll send you something if you don’t have the equipment needed to dump a hard drive. Even if the machine has been upgraded to System 7.5 or Mac OS 7.6, it’s still fine — everything could very well still be there, lurking in the background.</p>","contentLength":37272,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43376033"},{"title":"ESP32 WiFi Superstitions","url":"https://supakeen.com/weblog/esp32-wifi-superstitions/","date":1742080328,"author":"supakeen","guid":148,"unread":true,"content":"<p>The <a href=\"https://www.espressif.com/en/products/socs/esp32\">ESP32</a> is a popular microcontroller to use for do-it-yourself home automation, sensors, and a variety of other bits and bobs that you might want to take care of around the house. It’s the successor to the venerable <a href=\"https://www.espressif.com/en/products/socs/esp8266\">ESP8266</a> which has found its way into many of our WiFi connected devices (seriously, open up a device and chances are relatively large that you’ll find one).</p><p>After having done quite a few projects based on the ESP32 in the <a href=\"https://www.arduino.cc/\">Arduino</a> and <a href=\"https://docs.espressif.com/projects/esp-idf/en/stable/esp32/get-started/index.html\">esp-idf</a> frameworks I did start to notice some pecularities with my deployed devices (fancy wording for the one in my electrical cabinet that’s  to send the electrical usage data somewhere and a hodgepodge of sensor boards around the house, mostly the <a href=\"https://revspace.nl/Snuffelaar\">Snuffelaar</a> by <a href=\"https://tweakers.net/reviews/8876/tweaker-sebastius-over-zijn-soldeerworkshops-en-reparatieprojecten.html\">Sebastius</a> with firmware written by <a href=\"https://github.com/juerd\">Juerd</a>).</p><p>It seemed some of my ESP32 based boards were regularly losing connectivity. Initially my thoughts went out to the terrible power supplies I was using to run them (the cheapest of the cheap USB power supplies that came with a variety of accessories around my house). After switching these out for some more accessible and probably better quality tested <a href=\"https://www.ikea.com/nl/en/p/smahagel-3-port-usb-charger-white-60539177/\">Ikea chargers</a> the problems, however, persisted.</p><p>Asking around for experience from others at <a href=\"https://revspace.nl/\">RevSpace</a>, my local hackerspace, seemed to indicate that people had seen similar things with their ESP32-based projects. But not everyone had these issues. Slowly I started gathering more and more “superstitions” around how to keep these microcontrollers connected to my internet. Here are my favorite ones, I have applied all of these and while I haven’t tested them one-by-one the combination of them has ensured steady connections on my SSIDs.</p><p>While these workarounds don’t quite come close to placing a hexagon of CR2023 batteries around your ESP32 while you chant the 802.11ax specification at it, they have no basis in any  research I did. Take these as anecdotal workarounds for ESP32’s losing connectivity to your WiFi.</p><h2>Turn off power saving on the ESP32</h2><p>The ESP8266 never had any power saving for its WiFi modem stack, however the ESP32 . To me this is the most likely culprit in that in some network configurations, perhaps in combination with some radios, the power saving does something that makes it stop interacting with the network.</p><p>In your personal handcrafted firmware you can <a href=\"https://docs.espressif.com/projects/esp-idf/en/stable/esp32/api-reference/network/esp_wifi.html#_CPPv415esp_wifi_set_ps14wifi_ps_type_t\">use the following</a>, which should work in esp-idf  Arduino (from what I’ve been told):</p><div><pre tabindex=\"0\"><code data-lang=\"c\"></code></pre></div><p>For <a href=\"https://esphome.io/\">ESPHome</a> based projects you can add:</p><div><pre tabindex=\"0\"><code data-lang=\"yaml\"></code></pre></div><h2>Set your APs to use 20 Mhz wide channels</h2><p>If you have fancy network hardware then you can likely configure the channel width for the network that serves your ESP32’s. From what people and the internet tell me you  set the band width on the 2.4 Ghz network that your boards use to , not 40, not 60, and definitely not automatic.</p><h2>Pin your ESP32’s to a single AP</h2><p>It seems that when an ESP32 connects it goes straight for the first access point it sees. No matter if that access point is not the one you’ve taped it to. This can lead to bad connectivity, especially since I’ve not really observed ESP32’s moving around to other access points. If your network hardware allows it, you should pin the device to the closest one.</p><p>These urban legends have so far made it seem that at least my problems are ghosts of the past. I haven’t had a device drop from the network in about a week or two now while they used to drop multiple times per day. I’m planning to drop my application level keep-alives (still a good idea, I’ll write about them another time) because they seem to not be necessary at all anymore.</p><p>I hope these are of help to anyone, and that the spirits of the ESP32 deem your network worthy too.</p>","contentLength":3640,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43375780"},{"title":"Sign in as anyone: Bypassing SAML SSO authentication with parser differentials","url":"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/","date":1742065561,"author":"campuscodi","guid":147,"unread":true,"content":"<blockquote><p>Critical authentication bypass vulnerabilities (CVE-2025-25291 + CVE-2025-25292) were discovered in ruby-saml up to version 1.17.0. Attackers who are in possession of a single valid signature that was created with the key used to validate SAML responses or assertions of the targeted organization can use it to construct SAML assertions themselves and are in turn able to log in as any user. In other words, it could be used for an account takeover attack. Users of ruby-saml should update to version 1.18.0. References to libraries making use of ruby-saml (such as omniauth-saml) need also be updated to a version that reference a fixed version of ruby-saml.</p></blockquote><p>In this blog post, we detail newly discovered authentication bypass vulnerabilities in the <a href=\"https://github.com/SAML-Toolkits/ruby-saml\">ruby-saml</a> library used for single sign-on (SSO) via SAML on the service provider (application) side. GitHub doesn’t currently use ruby-saml for authentication, but began evaluating the use of the library with the intention of using an open source library for SAML authentication once more. This library is, however, used in other popular projects and products. We discovered an exploitable instance of this vulnerability in GitLab, and have notified their security team so they can take necessary actions to protect their users against potential attacks.</p><p>GitHub previously used the ruby-saml library up to 2014, but moved to our own SAML implementation due to missing features in ruby-saml at that time. Following bug bounty reports around vulnerabilities in our own implementation (such as <a href=\"https://docs.github.com/en/enterprise-server@3.13/admin/release-notes#3.13.5-security-fixes\">CVE-2024-9487</a>, related to encrypted assertions), GitHub recently decided to explore the use of ruby-saml again. Then in October 2024, a blockbuster vulnerability dropped: an <a href=\"https://github.com/advisories/GHSA-jw9c-mfg7-9rx2\">authentication bypass</a> in ruby-saml (CVE-2024-45409) by <a href=\"https://hackerone.com/ahacker1\">ahacker1</a>. With tangible evidence of exploitable attack surface, GitHub’s switch to ruby-saml had to be evaluated more thoroughly now. As such, GitHub started a <a href=\"https://hackerone.com/github\">private bug bounty engagement</a> to evaluate the security of the ruby-saml library. We gave selected bug bounty researchers access to GitHub test environments using ruby-saml for SAML authentication. In tandem, the GitHub Security Lab also reviewed the attack surface of the ruby-saml library.</p><p>As is not uncommon when multiple researchers are looking at the same code, both ahacker1, a participant in the <a href=\"https://hackerone.com/github\">GitHub bug bounty program</a>, and I noticed the same thing during code review: ruby-saml was using two different XML parsers during the code path of signature verification. Namely, REXML and Nokogiri. While REXML is an XML parser implemented in pure Ruby, Nokogiri provides an easy-to-use wrapper API around different libraries like libxml2, libgumbo and Xerces (used for JRuby). Nokogiri supports parsing of XML and HTML. It looks like Nokogiri was added to ruby-saml to support <a href=\"https://en.wikipedia.org/wiki/Canonical_XML\">canonicalization</a> and potentially other things REXML didn’t support at that time.</p><p>We both inspected the same code path in the <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L268\"></a> of  and found that the signature element to be verified is first read via REXML, and then also with Nokogiri’s XML parser. So, if REXML and Nokogiri could be tricked into retrieving different signature elements for the same XPath query it might be possible to trick ruby-saml into verifying the wrong signature. It looked like there could be a potential authentication bypass due to a !</p><p>The reality was actually more complicated than this.</p><p>Roughly speaking, four stages were involved in the discovery of this authentication bypass:</p><ol><li>Discovering that two different XML parsers are used during code review.  </li><li>Establishing if and how a parser differential could be exploited.  </li><li>Finding an actual parser differential for the parsers in use.  </li><li>Leveraging the parser differential to create a full-blown exploit.</li></ol><p>To prove the security impact of this vulnerability, it was necessary to complete all four stages and create a full-blown authentication bypass exploit.</p><h2>Quick recap: how SAML responses are validated<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#quick-recap-how-saml-responses-are-validated\" aria-label=\"Quick recap: how SAML responses are validated\"></a></h2><p>Security assertion markup language (<a href=\"https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language\">SAML</a>) responses are used to transport information about a signed-in user from the identity provider (IdP) to the service provider (SP) in XML format. Often the only important information transported is a username or an email address. When the HTTP POST binding is used, the SAML response travels from the IdP to the SP via the browser of the end user. This makes it obvious why there has to be some sort of signature verification in play to prevent the user from tampering with the message.</p><p>Let’s have a quick look at what a simplified SAML response looks like:<img data-recalc-dims=\"1\" decoding=\"async\" loading=\"lazy\" src=\"https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?resize=1024%2C355\" alt=\"A diagram depicting a simplified SAML response on the left and the verification of the digest and the signature on the right.\" width=\"1024\" height=\"355\" srcset=\"https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=2632 2632w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=300 300w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=768 768w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=1024 1024w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=1536 1536w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=2048 2048w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"></p><p><em>Note: in the response above the XML namespaces were removed for better readability.</em></p><p>As you might have noticed: the main part of a simple SAML response is its assertion element (A), whereas the main information contained in the assertion is the information contained in the  element (B) (here the NameID containing the username: admin). A real assertion typically contains more information (e.g.  and  dates as part of a  element.)</p><p>Normally, the  (A) (without the whole  part) is <a href=\"https://en.wikipedia.org/wiki/Canonical_XML\">canonicalized</a> and then compared against the  (C) and the  (D) is canonicalized and verified against the  (E). In this sample, the assertion of the SAML response is signed, and in other cases the whole SAML response is signed.</p><h2>Searching for parser differentials<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#searching-for-parser-differentials\" aria-label=\"Searching for parser differentials\"></a></h2><p>We learned that ruby-saml used two different XML parsers (REXML and Nokogiri) for validating the SAML response. Now let’s have a look at the verification of the signature and the digest comparison.\nThe focus of the following explanation lies on the <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L268\"></a> method inside of .</p><p>Inside that method, there’s a broad XPath <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L278C1-L282C8\">query</a> with REXML for the first signature element inside the SAML document:</p><pre><code>sig_element = REXML::XPath.first(\n  @working_copy,\n  \"//ds:Signature\",\n  {\"ds\"=&gt;DSIG}\n)\n</code></pre><p><em>Hint: When reading the code snippets, you can tell the difference between queries for REXML and Nokogiri by looking at how they are called. REXML methods are prefixed with , whereas Nokogiri methods are called on .</em></p><p>Later, the actual  is <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L293C1-L298C92\">read</a> from this element:</p><pre><code>base64_signature = REXML::XPath.first(\n  sig_element,\n  \"./ds:SignatureValue\",\n  {\"ds\" =&gt; DSIG}\n)\nsignature = Base64.decode64(OneLogin::RubySaml::Utils.element_text(base64_signature))\n</code></pre><p>Note: the name of the  element might be a bit confusing. While it contains the actual signature in the  node it also contains the part that is actually signed in the  node. Most importantly the  element contains the digest (hash) of the assertion and information about the used key.</p><p>So, an actual  element could look like this (removed namespace information for better readability):</p><pre><code>&lt;Signature&gt;\n    &lt;SignedInfo&gt;\n        &lt;CanonicalizationMethod Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\" /&gt;\n        &lt;SignatureMethod Algorithm=\"http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\" /&gt;\n        &lt;Reference URI=\"#_SAMEID\"&gt;\n            &lt;Transforms&gt;&lt;Transform Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\" /&gt;&lt;/Transforms&gt;\n            &lt;DigestMethod Algorithm=\"http://www.w3.org/2001/04/xmlenc#sha256\" /&gt;\n            &lt;DigestValue&gt;Su4v[..]&lt;/DigestValue&gt;\n        &lt;/Reference&gt;\n    &lt;/SignedInfo&gt;\n    &lt;SignatureValue&gt;L8/i[..]&lt;/SignatureValue&gt;\n    &lt;KeyInfo&gt;\n        &lt;X509Data&gt;\n            &lt;X509Certificate&gt;MIID[..]&lt;/X509Certificate&gt;\n        &lt;/X509Data&gt;\n    &lt;/KeyInfo&gt;\n&lt;/Signature&gt;\n</code></pre><p>Later in the same method () there’s again a <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L307\">query for the Signature</a>(s)—but this time with Nokogiri.</p><pre><code>noko_sig_element = document.at_xpath('//ds:Signature', 'ds' =&gt; DSIG)\n</code></pre><p>Then the  element is taken from that signature and <a href=\"https://en.wikipedia.org/wiki/Canonical_XML\">canonicalized</a>:</p><pre><code>noko_signed_info_element = noko_sig_element.at_xpath('./ds:SignedInfo', 'ds' =&gt; DSIG)\n\ncanon_string = noko_signed_info_element.canonicalize(canon_algorithm)\n</code></pre><p>Let’s remember this  contains the canonicalized  element.</p><p>The  element is then also <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L314C6-L318C8\">extracted</a> with REXML:</p><pre><code> signed_info_element = REXML::XPath.first(\n        sig_element,\n        \"./ds:SignedInfo\",\n        { \"ds\" =&gt; DSIG }\n )\n</code></pre><p>From this  element the  node is <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L324\">read</a>:</p><pre><code>ref = REXML::XPath.first(signed_info_element, \"./ds:Reference\", {\"ds\"=&gt;DSIG})\n</code></pre><pre><code>reference_nodes = document.xpath(\"//*[@ID=$id]\", nil, { 'id' =&gt; extract_signed_element_id })\n</code></pre><p>The method <code>extract_signed_element_id</code><a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L406C9-L406C34\">extracts</a> the signed element id with help of REXML. From the previous authentication bypass (CVE-2024-45409), there’s now a <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L328\">check</a> that only one element with the same ID can exist.</p><p>The first of the  is taken and canonicalized:</p><pre><code>hashed_element = reference_nodes[0][..]canon_hashed_element = hashed_element.canonicalize(canon_algorithm, inclusive_namespaces)\n</code></pre><p>The  is then <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L349C7-L349C59\">hashed</a>:</p><pre><code>hash = digest_algorithm.digest(canon_hashed_element)\n</code></pre><p>The  to compare it against is then <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L350C7-L355C99\">extracted</a> with REXML:</p><pre><code>encoded_digest_value = REXML::XPath.first(\n        ref,\n        \"./ds:DigestValue\",\n        { \"ds\" =&gt; DSIG }\n      )\ndigest_value = Base64.decode64(OneLogin::RubySaml::Utils.element_text(encoded_digest_value))\n</code></pre><p>Finally, the  (built from the element extracted by Nokogiri) is <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L357\">compared</a> against the  (extracted with REXML):</p><pre><code>unless digests_match?(hash, digest_value)\n</code></pre><p>The  extracted some lines ago (a result of an extraction with Nokogiri) is later <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L366C7-L366C86\">verified against</a> (extracted with REXML).</p><pre><code>unless cert.public_key.verify(signature_algorithm.new, signature, canon_string)\n</code></pre><p>In the end, we have the following constellation:</p><ol><li>The assertion is extracted and canonicalized with Nokogiri, and then hashed. In contrast, the hash against which it will be compared is extracted with REXML.  </li><li>The SignedInfo element is extracted and canonicalized with Nokogiri - it is then verified against the SignatureValue, which was extracted with REXML.</li></ol><h2>Exploiting the parser differential<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#exploiting-the-parser-differential\" aria-label=\"Exploiting the parser differential\"></a></h2><p>The question is: is it possible to create an XML document where REXML sees one signature and Nokogiri sees another?</p><p>Ahacker1, participating in the bug bounty, was faster to produce a working exploit using a parser differential. Among other things, ahacker1 was inspired by the <a href=\"https://mattermost.com/blog/securing-xml-implementations-across-the-web/\">XML roundtrips vulnerabilities</a> published by Mattermost’s Juho Forsén in 2021.</p><p>Not much later, I produced an exploit using a different parser differential with the help of <a href=\"https://blog.trailofbits.com/2024/03/29/introducing-ruzzy-a-coverage-guided-ruby-fuzzer/\">Trail of Bits’ Ruby fuzzer</a> called ruzzy.</p><p>Both exploits result in an authentication bypass. Meaning that an attacker, who is in possession of a single valid signature that was created with the key used to validate SAML responses or assertions of the targeted organization, can use it to construct assertions for any users which will be accepted by ruby-saml. Such a signature can either come from a signed assertion or response from another (unprivileged) user or in certain cases, it can even come from signed metadata of a SAML identity provider (which can be publicly accessible).</p><p>An exploit could look like this. Here, an additional Signature was added as part of the  element that is only visible to Nokogiri:</p><p>The  element (A) from the signature that is visible to Nokogiri is canonicalized and verified against the  (B) that was extracted from the signature seen by REXML.</p><p>The assertion is retrieved via Nokogiri by looking for its ID. This assertion is then canonicalized and hashed (C). The hash is then compared to the hash contained in the  (D). This DigestValue was retrieved via REXML. This DigestValue has no corresponding signature.</p><p>So, two things take place:</p><ul><li>A valid SignedInfo with DigestValue is verified against a valid signature. (which checks out)  </li><li>A fabricated canonicalized assertion is compared against its calculated digest. (which checks out as well)</li></ul><p>This allows an attacker, who is in possession of a valid signed assertion for any (unprivileged) user, to fabricate assertions and as such impersonate any other user.</p><h3>Check for errors when using Nokogiri<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#check-for-errors-when-using-nokogiri\" aria-label=\"Check for errors when using Nokogiri\"></a></h3><p>Parts of the currently known, undisclosed exploits can be stopped by checking for Nokogiri parsing errors on SAML responses. Sadly, those errors do not result in exceptions, but need to be checked on the <a href=\"https://www.rubydoc.info/github/sparklemotion/nokogiri/Nokogiri%2FXML%2FDocument:errors\"></a> member of the parsed document:</p><pre><code>doc = Nokogiri::XML(xml) do |config|\n  config.options = Nokogiri::XML::ParseOptions::STRICT | Nokogiri::XML::ParseOptions::NONET\nend\n\nraise \"XML errors when parsing: \" + doc.errors.to_s if doc.errors.any?\n</code></pre><p>While this is far from a perfect fix for the issues at hand, it renders at least one exploit infeasible.</p><p>We are not aware of any reliable indicators of compromise. While we’ve found a potential indicator of compromise, it only works in debug-like environments and to publish it, we would have to reveal too many details about how to implement a working exploit so we’ve decided that it’s better not to publish it. Instead, our best recommendation is to look for suspicious logins via SAML on the service provider side from IP addresses that do not align with the user’s expected location.</p><h2>SAML and XML signatures:as confusing as it gets<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#saml-and-xml-signaturesas-confusing-as-it-gets\" aria-label=\"SAML and XML signatures:as confusing as it gets\"></a></h2><p>Some might say it’s hard to integrate systems with SAML. That might be true. However, it’s even harder to write implementations of SAML using XML signatures in a secure way. As others have stated before: it’s probably best to <a href=\"https://ssoready.com/blog/engineering/ruby-saml-pwned-by-xml-signature-wrapping-attacks/#how-to-fix-this-disregard-the-spec\">disregard the specifications</a>, as following them doesn’t help build secure implementations.\nTo rehash how the validation works if the SAML assertion is signed, let’s have a look at the graphic below,  depicting a simplified SAML response. The assertion, which transports the protected information, contains a signature. Confusing, right?</p><p>To complicate it even more: What is even signed here? The whole assertion? No!</p><p>What’s signed is the  element and the  element contains a . This  is the hash of the canonicalized assertion with the signature element removed before the canonicalization. This two-stage verification process can lead to implementations that have a disconnect between the verification of the hash and the verification of the signature. This is the case for these Ruby-SAML parser differentials: while the hash and the signature check out on their own, they have no connection. The hash is actually a hash of the assertion, but the signature is a signature of a different  element containing another hash. What you actually want is a direct connection between the hashed content, the hash, and the signature. (And once the verification is done you only want to retrieve information from the exact part that was actually verified.) Or, alternatively, use a less complicated standard to transport a cryptographically signed username between two systems - but here we are.</p><p>In this case, the library already extracted the  and used it to verify the signature of its canonicalized string,. However, it did not use it to obtain the digest value. If the library had used the content of the already extracted  to obtain the digest value, it would have been secure in this case even with two XML parsers in use.</p><p>As shown once again: relying on two different parsers in a security context can be tricky and error-prone. That being said: exploitability is not automatically guaranteed in such cases. As we have seen in this case, checking for Nokogiri errors could not have prevented the parser differential, but could have stopped at least one practical exploitation of it.</p><p>The initial fix for the authentication bypasses does not remove one of the XML parsers to prevent API compatibility problems. As noted, the more fundamental issue was the disconnect between verification of the hash and verification of the signature, which was exploitable via parser differentials. The <a href=\"https://github.com/SAML-Toolkits/ruby-saml/pull/736\">removal of one of the XML</a> parsers was already planned for other reasons, and will likely come as part of a major release in combination with additional improvements to strengthen the library. If your company relies on open source software for business-critical functionality, consider <a href=\"https://github.com/sponsors\">sponsoring</a> them to help fund their future development and bug fix releases.</p><p>If you’re a user of ruby-saml library, make sure to update to the latest version, 1.18.0, containing fixes for <a href=\"https://github.com/SAML-Toolkits/ruby-saml/security/advisories/GHSA-4vc4-m8qh-g8jm\">CVE-2025-25291</a> and <a href=\"https://github.com/SAML-Toolkits/ruby-saml/security/advisories/GHSA-754f-8gm6-c4r2\">CVE-2025-25292</a>. References to libraries making use of ruby-saml (such as <a href=\"https://github.com/omniauth/omniauth-saml\">omniauth-saml</a>) need also be updated to a version that reference a fixed version of ruby-saml. We will publish a proof of concept exploit at a later date in the <a href=\"https://github.com/github/securitylab\">GitHub Security Lab repository</a>.</p><p>Special thanks to Sixto Martín, maintainer of ruby-saml, and Jeff Guerra from the GitHub Bug Bounty program.\nSpecial thanks also to ahacker1 for giving inputs to this blog post.</p><ul><li>2024-11-04: Bug bounty report demonstrating an authentication bypass was reported against a GitHub test environment evaluating ruby-saml for SAML authentication.  </li><li>2024-11-04: Work started to identify and test potential mitigations.  </li><li>2024-11-12: A second authentication bypass was found by Peter that renders the planned mitigations for the first useless.  </li><li>2024-11-13: Initial contact with Sixto Martín, maintainer of ruby-saml.  </li><li>2024-11-14: Both parser differentials are reported to ruby-saml, the maintainer responds immediately.  </li><li>2024-11-14: The work on potential patches by the maintainer and ahacker1 begins. (One of the initial ideas was to remove one of the XML parsers, but this was not feasible without breaking backwards compatibility).  </li><li>2025-02-04: ahacker1 proposes a non-backwards compatible fix.  </li><li>2025-02-06: ahacker1 also proposes a backwards compatible fix.  </li><li>2025-02-12: The 90 days deadline of GitHub Security Lab advisories ends.  </li><li>2025-02-16: The maintainer starts working on a fix with the idea to be backwards-compatible and easier to understand.  </li><li>2025-02-17: Initial contact with GitLab to coordinate a release of their on-prem product with the release of the ruby-saml library.  </li><li>2025-03-12: A fixed version of ruby-saml was released.</li></ul><div><article><div><div><p>Security Researcher at GitHub Security Lab</p></div></div></article></div>","contentLength":17509,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43374519"},{"title":"That Time I Recreated Photoshop in C++","url":"https://f055.net/technology/that-time-i/that-time-i-recreated-photoshop-in-c/","date":1742062935,"author":"f055","guid":744,"unread":true,"content":"<div><div><p>As I’m getting older I look back on all the things I’ve done as a creative developer, and I see so many cool projects! But I never wrote down any development stories, and most of these projects, even as successful when released, got lost in time as years go by. That’s why I’m starting my new posts series „That time I” where I look back on my most interesting projects.</p></div></div><p>The first one is about that time I recreated Photoshop in C++ and Windows API! I invite you to read my story and leave a comment with feedback, it’s hard to go on without your input 🙂</p><p>Everything started in early summer of 2006. I was reading *a lot* of manga back then. But all the image reading apps sucked. Specifically, none of the apps allowed me to control my reading using just the mouse, and reaching my keyboard all the time was distracting. Since I just finished the C++/Windows API course at the uni, I spent the summer break coding my perfect manga reader. And I named it <a href=\"https://github.com/f055/fiew-image-viewer\" target=\"_blank\" rel=\"noopener\">Fiew</a>.</p><p>Early autumn 2006 we returned to uni and had to decide on our final thesis for the degree. Writing the image viewer went smooth enough that I got the idea I could create an image editor as well. I was a heavy Adobe Photoshop user back then, so that became my goal. I mean, how hard can it be? Turns out, very.</p><p>Over the course of the next several months, I wrote Advanced Image Editor named Fedit in C++ using Windows API and GDI+ graphic libraries. It followed a set of five rules to benefit the end user: no installers, no archives, no registry keys, no additional runtimes and a single executable file. The result was a program that was ready to work without the need of installation, could be run on systems with limited privileges (or straight from a thumb drive) and consumed small amounts of resources.</p><p>I was very careful to make the interface look like classic Photoshop, and include all my most used features. So you had all the free floating windows with tools. The excellent colour picker. Easy layer management. Step-by-step reversible history. Several image filters, plus a matrix interface to encode your own pixel shifting filters too.</p><p>Straight from my previous project named Fiew I added a massive image library viewer. It really could quickly and easily scroll through massive amounts of pictures.</p><p>I had a lot of fun coding Fedit. And a lot of issues along the way. I spent a ton of time on MSDN and Stack Overflow, however that didn’t help that much since most of the issues were so specific I had to analyse and debug them on my own. But I worked like crazy on it, my motivation was immense. I had to make the bachelor thesis deadline, so for the final two-month stint I worked 14 hours a day.</p><p>User interface was the most tricky bit. I wanted the workflow to resemble Photoshop as much as possible. The freely snapping-unsnapping of the tool settings pane was particularly hard. But no less than recreating the colour picker or the tool selector.</p><p>By the time I finished I was pretty exhausted and kind of resenting WinAPI. But the thesis was a success and I received my Bachelor of Science in Engineering from the Warsaw University of Technology. Fedit received several positive reviews online but I didn’t promote it. Instead I took a well deserved holiday. A few months later thanks to the impression Fiew and Fedit made on the CTO of GoldenLine (Polish LinkedIn, market leader in its time, but now defunct), I landed a C++ job with a task to create extremely efficient WinAPI app to handle massive image uploading for a clone of Flickr. So in the end all that effort paid off.</p><p>Fedit (and Fiew) source code is available on <a href=\"https://github.com/f055/fedit-image-editor\" target=\"_blank\" rel=\"noopener\">GitHub</a>. The thesis documentation is available as <a href=\"https://f055.net/wp-content/uploads/files/Thesis-Fedit.pdf\">PDF</a>. The original website for these apps is still up on the <a href=\"https://web.archive.org/web/20140517125711/http://fapplication.org/\" target=\"_blank\" rel=\"noopener\">Web Archive</a>!</p>","contentLength":3735,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43374278"},{"title":"How many artists' careers did the Beatles kill?","url":"https://www.cantgetmuchhigher.com/p/how-many-artists-did-the-beatles","date":1742058307,"author":"dwighttk","guid":146,"unread":true,"content":"<p>When you ask people about the most consequential years in popular music, there might be no year that comes up more often than 1964. Of course, the most important thing about that year is The Beatles landing in the United States and kicking off the British Invasion. But the year is endlessly discussed because so much else went on. </p><ul><li><p>The Rolling Stones released their debut album</p></li><li><p>Motown became a dominant force in pop music, releasing four number ones, three of which were by The Supremes</p></li><li><p>Bob Dylan dropped two albums</p></li><li><p>The Beach Boys continued their run of hits</p></li></ul><ol><li><p>“Everybody Loves Somebody” by Dean Martin</p></li><li><p>“Where Did Our Love Go” by The Supremes</p></li><li><p>“A Hard Day’s Night” by The Beatles</p></li><li><p>“Rag Doll” by Frankie Valli &amp; the Four Seasons</p></li><li><p>“Under the Boardwalk” by The Drifters</p></li></ol><p>These are five songs that I return to often. And weeks like this weren’t even that rare in 1964. Just one week later, you had the same songs in the top five, except “Rag Doll” was replaced by The Animals’ “House of the Rising Son,” the song that some claim made Dylan go electric and pushed rock music into a completely new direction.</p><p>The one claim that’s always fascinated me about 1964 is that it was a line of demarcation between an old and a new way to make music. If you were making hits in 1963 and didn’t change your sound in 1964, you were going to be waiting tables by the beginning of 1965. In other words, The Beatles-led British Invasion decimated the careers of scores of artists. But was this really the case?</p><p>To do this, I grabbed a list of all 175 acts who released at least one top 40 single in 1963. (Fun fact: the record for the most top 40 hits that year was shared by five acts: Bobby Vinton, Brenda Lee, Dion &amp; the Belmonts, Ray Charles, and The Beach Boys. Each had six top 40 hits.) I then decided to see which of those acts never released a hit in 1964 or any year after. In total, 88 of those 175 acts, or 50%, never had a top 40 hit again. </p><p>That’s kind of a lot. In other words, The Beatles and their fellow invading Brits killed a lot of careers. Or did they? By looking at only a single year we could be biased. And we are.</p><p>If we calculate that same rate for every single year between 1960 and 2020, we see that while the kill rate in 1964 was high, it wasn’t completely out of the ordinary. The median is around 40%. Having a multi-year career as a popular artist is just hard. By looking at the years with the highest rates, we can glean a few other things, though.</p><p>First, three of the top ten rates are 1962, 1963, and 1964. In other words, there is some credence to the theory that the British Invasion decimated many careers. Nevertheless, the fact that the rates in 1962 and 1963 are high tells me that sonic changes were brewing in the United States too. Had The Beatles not arrived, rock music probably still would have evolved in a way that would have left earlier hitmakers in the dust. That sonic evolution would have been different, though.</p><p><a href=\"https://www.theatlantic.com/culture/archive/2015/05/1991-the-most-important-year-in-music/392642/\" rel=\"\">changed their chart methodology</a><a href=\"https://www.cantgetmuchhigher.com/p/does-apple-music-sound-better-than?utm_source=publication-search\" rel=\"\">earlier newsletter</a></p><p>In other words, the 1990s were strange. And I think we are just beginning to grapple with that strangeness. Because of that, there was a ton of turnover on the charts. It’s hard for artists to keep up with trends when grunge, gangsta rap, swing, and a new breed of teen pop are all successful in a matter of years. Being a superstar isn’t easy.</p><p>Aggregating this data got me thinking about which artists have been able to survive the most musical changes and still find success. While there are artists, like Elton John and The Rolling Stones, who put out hits for decades, I want to point out one artist whose resilience still shocks me: Frankie Valli. </p><p>Born in 1934, Valli had his first major hit in 1962 with “Sherry,” a song performed with his group The Four Seasons. Before The Beatles splashed on American shores, Valli and his bandmates had eight more top 40 hits. But they were the kind of group that you’d expect to be decimated by the new sound of rock music. The Four Seasons were sort of a throwback even in 1963, Valli and his falsetto pointing toward the doo-wop of the last decade.</p><p>But Valli and his collaborators forged on. They made some musical missteps but they remained a musical force through 1967, releasing bonafide classics, like “Can’t Take My Eyes Off You.” Okay. So, he survived the British Invasion. Some others did too. But Valli didn’t go quietly as the 1960s came to a close. </p><p>In 1974, he scored a massive hit with “My Eyes Adored You,” a song that played well with the soft rock that was dominant at the time. Then disco began to boom and Valli remained undeterred. “Swearin' to God.” “Who Loves You.” “December, 1963 (Oh, What a Night).” The man could not be stopped.</p><div><p><a href=\"https://open.spotify.com/playlist/13jGfTC2Gm9HUA4HWyil3h?si=c8cd3f977fcc4216\" rel=\"\">A New One</a></p></div><p><em>Alligator Bites Never Heal </em></p><div><p><a href=\"https://open.spotify.com/playlist/5cSaewkxcLhIMv5okk4gzK?si=0b12825cb2d84f44\" rel=\"\">An Old One</a></p></div><p>As I was admiring 1964, I noticed that the week of October 10 had a mind-blowing top five. It included Roy Orbison’s “Oh, Pretty Woman,” Manfred Mann’s “Do Wah Diddy Diddy,” Martha &amp; the Vandellas’ “Dancing in the Street,” and The Shangri-Las’ “Remember (Walkin’ in the Sand).” There was one song that I wasn’t familiar with, though: “Bread and Butter” by The Newbeats.</p><p>“Bread and Butter” is fun, little novelty about bread, butter, toast, jam, and losing your lover. The most notable thing about the song is a half-screamed falsetto that appears periodically throughout the song as performed by Larry Henley. Incidentally, Henley is another good example of musical resilience. After his performing career ended, he wrote a few hits over the decades, including Bette Midler’s massive 1989 ballad “Wind Beneath My Wings.”</p><p><strong>Shout out to the paid subscribers who allow this newsletter to exist. Along with getting access to our entire archive, subscribers unlock biweekly interviews with people driving the music industry, monthly round-ups of the most important stories in music, and priority when submitting questions for our mailbag. Consider becoming a paid subscriber today!</strong></p><p><strong>Want to hear the music that I make? </strong></p>","contentLength":6046,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43373765"},{"title":"Show HN: A personal YouTube frontend based on yt-dlp","url":"https://github.com/christian-fei/my-yt","date":1742053542,"author":"modmodmod","guid":135,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43373242"},{"title":"Milk Kanban","url":"https://brodzinski.com/2025/03/milk-kanban.html","date":1742052722,"author":"ladronevincet","guid":145,"unread":true,"content":"<p>When people say Kanban, they tend to think of a specific set of practices. Whiteboards &amp; sticky notes (both almost universally virtual). Tasks moving through columns that represent workflow. Every now and then, WIP limits even.</p><p>As often as we do it with other things, it reduces a broader principle to a set of oversimplified techniques, which, in turn, tend to underdeliver in many contexts.</p><p>In its original meaning, Kanban represented a visual signal. The thing that communicated, well, something. It might have been a need, option, availability, capacity, request, etc.</p><p>In our Kanban systems, the actual Kanban is a sticky note.</p><p>It represents work, and given its closest environment (board, columns, other stickies, visual decorators), it communicates what needs, or needs not, to be done.</p><p>If it’s yellow, it’s a regular feature. If there’s a blocker on it, it requests focus. If there’s a long queue of neighbors, it suggests flow inefficiency. If it’s a column named “ready for…” it communicates available work and/or handoff.</p><p>A visual signal all the way.</p><p>Let’s decouple ourselves from the most standard Kanban board design. Let’s forget columns, sticky notes, and all that jazz.</p><p>Enters Kasia, our office manager at Lunar. One of the many things Kasia takes care of is making sure we don’t run out of kitchen supplies. The tricky part is that when you don’t drink milk yourself, it becomes a pain to check the cupboard with milk reserves every now and then to ensure we’re stocked.</p><p>Then, one day, I found this.</p><p>A simple index card taped to the last milk carton in a row stating, “Bring me to Kasia.” That’s it.</p><p>In the context, it really says that:</p><ul><li>we’re running out of (specific kind of) milk</li><li>there’s enough time to make an order (we don’t drink that much of cappuccinos and macchiatos)</li></ul><p>But it’s just a visual signal. Kanban at its very core.</p><p>What Kasia designed is a perfect Kanban system. It relies on visual signals, which are put in the context. Even better, unlike most Kanban boards I see across teams, the system is self-explanatory. Everything one needs to know is written on the index card.</p><p>It’s a safe assumption that, almost always, there’s a simpler visualization that would work just as well. We, process designers, often fall into the trap of overengineering our tools.</p><p>And it’s a healthy wake-up call when someone who knows close to nothing about our fancy stuff designs a system that we would unlikely think of. One that is a perfect implementation of the original spirit, even if it doesn’t follow any of the common techniques.</p><p>That’s what we can learn from Milk Kanban.</p>","contentLength":2624,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43373157"},{"title":"High-performance computing, with much less code","url":"https://news.mit.edu/2025/high-performance-computing-with-much-less-code-0313","date":1741960390,"author":"mpweiher","guid":743,"unread":true,"content":"<p>Many companies invest heavily in hiring talent to create the high-performance library code that underpins modern artificial intelligence systems. NVIDIA, for instance, developed some of the most advanced high-performance computing (HPC) libraries, creating a competitive moat that has proven difficult for others to breach.</p><p>But what if a couple of students, within a few months, could compete with state-of-the-art HPC libraries with a few hundred lines of code, instead of tens or hundreds of thousands?</p><p>That’s what researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) have shown with a new programming language called&nbsp;<a href=\"https://github.com/exo-lang/exo\">Exo 2</a>.</p><p>Exo 2 belongs to a new category of programming languages that MIT Professor Jonathan Ragan-Kelley calls “user-schedulable languages” (USLs). Instead of hoping that an opaque compiler will auto-generate the fastest possible code, USLs put programmers in the driver's seat, allowing them to write “schedules” that explicitly control how the compiler generates code. This enables performance engineers to transform simple programs that specify what they want to compute into complex programs that do the same thing as the original specification, but much, much faster.</p><p>One of the limitations of existing USLs (like the original Exo) is their relatively fixed set of scheduling operations, which makes it difficult to reuse scheduling code across different “kernels” (the individual components in a high-performance library).</p><p>In contrast, Exo 2 enables users to define new scheduling operations externally to the compiler, facilitating the creation of reusable scheduling libraries.&nbsp;Lead author Yuka Ikarashi, an MIT PhD student in electrical engineering and computer science and CSAIL affiliate, says that Exo 2 can reduce total schedule code by a factor of 100 and deliver performance competitive with state-of-the-art implementations on multiple different platforms, including Basic Linear Algebra Subprograms (BLAS) that power many machine learning applications. This makes it an attractive option for engineers in HPC focused on optimizing kernels across different operations, data types, and target architectures.</p><p>“It’s a bottom-up approach to automation, rather than doing an ML/AI search over high-performance code,” says Ikarashi. “What that means is that performance engineers and hardware implementers can write their own scheduling library, which is a set of optimization techniques to apply on their hardware to reach the peak performance.”</p><p>One major advantage of Exo 2 is that it reduces the amount of coding effort needed at any one time by reusing the scheduling code across applications and hardware targets. The researchers implemented a scheduling library with roughly 2,000 lines of code in Exo 2, encapsulating reusable optimizations that are linear-algebra specific and target-specific (AVX512, AVX2, Neon, and Gemmini hardware accelerators). This library consolidates scheduling efforts across more than 80 high-performance kernels with up to a dozen lines of code each, delivering performance comparable to, or better than, MKL, OpenBLAS, BLIS, and Halide.</p><p>Exo 2 includes a novel mechanism called “Cursors” that provides what they call a “stable reference” for pointing at the object code throughout the scheduling process. Ikarashi says that a stable reference is essential for users to encapsulate schedules within a library function, as it renders the scheduling code independent of object-code transformations.</p><p>“We believe that USLs should be designed to be user-extensible, rather than having a fixed set of operations,” says&nbsp;Ikarashi. “In this way, a language can grow to support large projects through the implementation of libraries that accommodate diverse optimization requirements and application domains.”</p><p>Exo 2’s design allows performance engineers to focus on high-level optimization strategies while ensuring that the underlying object code remains functionally equivalent through the use of safe primitives.&nbsp;In the future, the team hopes to expand Exo 2’s support for different types of hardware accelerators, like GPUs. Several ongoing projects aim to improve the compiler analysis itself, in terms of correctness, compilation time, and expressivity.</p><p>Ikarashi and Ragan-Kelley co-authored the paper with graduate students Kevin Qian and Samir Droubi, Alex Reinking of Adobe, and former CSAIL postdoc Gilbert Bernstein, now a professor at the University of Washington. This research was funded, in part, by the U.S. Defense Advanced Research Projects Agency (DARPA) and the U.S. National Science Foundation, while the first author was also supported by Masason, Funai, and Quad Fellowships.</p>","contentLength":4724,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43362667"},{"title":"Show HN: Nash, I made a standalone note with single HTML file","url":"https://keepworking.github.io/nash/","date":1741917082,"author":"yevgenyhong","guid":130,"unread":true,"content":"<p>Hello HN,\nI hope it will posted as well.\nI made a note in single html file.\nThis does not require a separate membership or installation of the software, and if you download and modify an empty file, you can modify and read it at any time, regardless of online or offline.\nIt can be shared through messengers such as Telegram, so it is also suitable to share contents with long articles and images. \nIt is also possible to host and blog because it is static html file content.</p>","contentLength":475,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43358914"},{"title":"Did the Particle Go Through the Two Slits, or Did the Wave Function?","url":"https://profmattstrassler.com/2025/03/13/did-the-particle-go-through-the-two-slits-or-did-the-wave-function/","date":1741877346,"author":"Tomte","guid":742,"unread":true,"content":"<p>What is really going on in the quantum double-slit experiment? The question raised in this post’s title seems to lie at the heart of the matter.  In this experiment, <a href=\"https://profmattstrassler.com/2025/01/16/double-trouble-the-quantum-two-slit-experiment-1/\" data-type=\"post\" data-id=\"20381\">which I recently reviewed here</a>, particles of some sort are aimed, one at a time, at a wall with two slits, and their arrival is recorded on a screen behind the wall. As a parade of particles proceeds, one by one, past the wall, an interference pattern somehow appears, emerging gradually like a spectre on the screen.</p><p>Interference is a familiar effect, commonly <a href=\"https://www.youtube.com/watch?v=Jqm4f55soJQ\">seen in water waves</a> and sound waves.  If water waves passed through a pair of slits in a wall, <a href=\"https://en.wikipedia.org/wiki/Double-slit_experiment#/media/File:Doubleslit3Dspectrum.gif\">interference would be observed</a> and no one would be surprised. But here we have one particle passing through the wall at a time; it’s not at all the same thing. How can we explain the interference effect in this case? </p><p>It’s natural to imagine that somehow either</p><ul><li>each particle acts like a wave, goes through both slits, and interferes with itself, or</li><li>the quantum wave function that describes each particle (or all the particles [?]) goes through both slits and interferes with itself.</li></ul><p>So… which is it? Did the particle go through both slits, or did the wave function?</p><p>In 1920s quantum physics, there is a very simple answer to this question.  </p><p>No — neither the particle nor the wave function <em>[not its wavy pattern or its peak(s) or any other part of it]</em> goes through the two slits.</p><ul><li><em><strong>What!? Then how can there be interference?</strong></em></li></ul><p>That question I will answer in a later post, probably next week or the following. But first, let’s confront the title of this post in a simpler context, so that we can see clearly why — in 1920s quantum physics — the answer to its question is “neither one”.</p><h2>The Double Door Experiment</h2><p>Key to understanding the double-slit experiment is to simplify it down to its bare essence. Having a two-dimensional problem where particles are going through slits in a wall is more complicated than necessary. Instead, let’s take a one-dimensional problem that <a href=\"https://profmattstrassler.com/2025/03/06/can-a-quantum-particle-move-in-two-directions-at-once/\" data-type=\"post\" data-id=\"21049\">we’ve already looked at</a>, where an object is in a superposition state of going to the left  going to the right. We already saw that this object is  to be viewed as both going to the left AND going to the right. By setting up measurements on both sides, we saw that it can only be measured to be doing one or the other, and never both. <a href=\"https://profmattstrassler.com/2025/03/06/can-a-quantum-particle-move-in-two-directions-at-once/\" data-type=\"post\" data-id=\"21049\">Superposition is an , not an </a>.  And a true particle can only have one position at a time.</p><h3>The Particle and the Doors: A First Look</h3><p>In this context, let’s ask the question: <em>can a particle simultaneously go through two doors on opposite sides of a room?</em> This is the same question as the two-slit question, because I can turn one into the other using tubes behind the slits, as in Fig. 1.</p><p>By sending a particle toward two slits, we can arrange for its wave function to be in the superposition state we want (Fig. 2)</p><p>and then we can ask whether we can observe it going through both doors.</p><p>Well, <a href=\"https://profmattstrassler.com/2025/03/06/can-a-quantum-particle-move-in-two-directions-at-once/\" data-type=\"post\" data-id=\"21049\">in a recent post</a> we put two balls in the same locations that we now want to place the doors, and we asked if a particle in this very same superposition state can hit both balls simultaneously. The answer was “no”.  The same argument applies here; the particle cannot be observed to pass through both doors simultaneously. It can only go through one or the other.</p><p>Why? A particle, which has a position and a momentum (even if unknown to us), cannot have  positions.  If it starts between the two doors, it can move through one door or the other, but it cannot do both, because then it would have two positions at once. </p><p>Maybe you’re not immediately convinced.  If not, stay tuned, as I’ll come back to this again later. </p><h3>The Wave Function and the Doors: A First Look</h3><p>But for now, let’s turn to the other question arising from my post’s title. Why can’t the particle’s wave function move through both doors, just like a water wave or sound wave does?</p><p>Actually, since wave functions don’t move (they just describe particles that do) what we really want to know is slightly different.  The initial wave function has a wavy pattern; does this wavy pattern go through both doors?</p><p>Certainly water waves and sound waves could go through both doors.  They are waves . So are the doors (or slits) they they can pass through. </p><p>But the wave function is , and <a href=\"https://profmattstrassler.com/articles-and-posts/quantum-basics/physical-space-and-the-space-of-possibilities-a-crucial-distinction/\" data-type=\"page\" data-id=\"20817\">not in physical space</a>. Conversely, the doors do not exist in the space of probabilities; <strong>doors are physical objects</strong>. Therefore the wave function (and its wavy patterns) cannot pass through the doors at all! </p><p>The very idea is nonsensical, the sort of thing that <a href=\"https://arthive.com/renemagritte/works/638327~The_improvement\">René Magritte</a> would have enjoyed painting.  Having the wave function (or its pattern) pass through physical doors would be akin to you entering into Shakespeare’s Romeo and Juliet to save the lovers from their fates, or enjoying the taste of an apple painted by Rembrandt, or walking through a giant hole in a physicist’s argument. Physical space and the space of possibilities are conceptually different; they have distinct meanings.  At best one space merely represents what is happening in the other.  And so the objects that exist in one don’t exist as objects in the other. (Even when these spaces have the same shape, which sometimes they do, <a href=\"https://profmattstrassler.com/articles-and-posts/quantum-basics/physical-space-and-the-space-of-possibilities-a-crucial-distinction/understanding-the-space-of-possibilities-an-example/\" data-type=\"page\" data-id=\"20919\">they represent different things, as indicated in the fact that they have different axes</a>.)</p><p>To convince you further of these statements, let’s take a look at a simpler example. Consider a system where there is just a single door, but there are two particles. Let’s see why the wave function of these particles (and its wave pattern) <strong>can’t even pass through one door</strong>, much less two.</p><h3>The Wave Function of Two Particles and a Single Door</h3><p>We’ll put the door on the right in physical space. Superposition states aren’t needed here, so instead we’ll send  toward the door, in simple <a href=\"https://profmattstrassler.com/2025/02/10/elementary-particles-do-not-exist-part-1/\" data-type=\"post\" data-id=\"20562\">wave-packet states</a>. These two particles will be given the same near-definite momentum, but their poorly known positions are shifted apart, so that they are separated in physical space. In pre-quantum language, the set-up is shown in Fig. 3.</p><p>What wave function do we need to describe this? It’s simplest to put the two particles in wave packet states with near-definite momentum, somewhat separated in space but with similar motion. You might first think the wave function for such a system would roughly look like Fig. 4:</p><p> That’s a trap that’s super-easy to fall into; such a wave function describes one particle in a superposition of two locations, not two particles. </p><p>Instead, because the first particle has position  and the second has position  respectively, their wave function, a function that exists in  with axes  and , takes the form . If we start with  near 2 and  near 0, as in Fig. 3, then the wave function for these two particles looks like Fig. 5: it has a peak near  and . (The dashed black lines are just there to guide your eyes.)  The peak indicates that  near 2 and  near 0 are the most probable values for the two particles’ positions.</p><p>Now, where’s the door that we want to try to make the wave function go through? Great question. In physical space it is located at . Let’s now draw that door in the space of possibilities, whose axes are  and .  How should we do that?</p><p>That’s fine; there’s no reason not to be confused the first time you think about it.  Here’s the answer.</p><p>Particle 1 goes through the door when , which is the vertical blue dashed line in Fig. 6. Meanwhile, particle 2 goes through it when , so that’s the horizontal blue dashed line.</p><p>Does that look like a door to you? Certainly it doesn’t look like the door in physical space. And that’s because in the space of possibilities, <strong>the dashed lines are not a door</strong>, with mass and thickiness and a material make-up.  Instead the lines represent a certain set of possibilities, namely that one of the particles is  the physical door.</p><p>In fact, there’s a special point, the intersection at  where the lines cross, that represents the possibility that both particles are simultaneously at the location of the door. No such intersection of lines exists in physical space.  This is an intersection of two classes of possibilities, and such a thing can only exist in the space of possibilities.</p><p>The lines divide the space into four regions, representing four more general classes of possibilities, shown in Fig. 7. In the lower left region, both particles are to the left of the door. At far right, particle 1 is to the right of the door while particle 2 is to the left; the reverse is true in the upper left region. Finally, at upper right is the region where both particles are to the right of the door.</p><p>The wave function’s pattern moves in the two dimensions that are spanned by the  and . axes. Both particles are moving to the right in physical space, at approximately the same speed. Consequently, the wave function, as it evolves, carries the most probable state of the system across three of the regions:</p><ul><li>initially both particles are to the left of the door </li><li>then particle 1 is to the right of the door while particle 2 remains to the left</li><li>and finally both particles are to the right of the door.</li></ul><p>In pre-quantum physics the path traversed by the two-particle system would look like Fig. 8:</p><p>The wave function evolves as shown in Fig. 9, very similarly to Fig. 8.</p><p>Now, is the wave function going  the door? Again, there is no door here; there are simply lines that tell us when one particle is coincident with the door, as well as a point where both particles are coincident with the door. It’s true that the wavy pattern and the peak of the wave function (which indicates the possibilities where the system is most likely to be found are passing across the lines.  But can we say the wave function (or its wavy pattern) passes  the lines? </p><p>No: moving through a door involves moving in physical space, along the -axis, through a gap in a door frame.  This is something the wave function does not — cannot — do.</p><h3>The Wave Function of Two Particles and Two Doors</h3><p>If you’re still not yet entirely convinced, consider what happens if we have two doors, one on each side. Let’s put our two particles each in a superposition state of moving leftward or moving rightward. Again we’ll set one particle off before the other, so that the first will reach the doors well before the second does.</p><p>Our pre-quantum view of such as system is that it now has four possibilities: particle 1 can be going right or left, and particle 2 can be going right or left, as shown in Fig. 10.  Only the upper-right option appeared in Fig. 3.</p><p>This requires a wave function that initially looks like Fig. 11, , one for each general possibility sketched in Fig. 10.</p><p>But where are the two doors? They appear in the space of possibilities on  lines; in addition to the blue lines we had in Figs. 6-9, corresponding to particles 1 or 2 being at the righthand door, we now have two more, shown in green in Fig. 12, corresponding to one or the other particle being at the lefthand door.</p><p>Notice the two intersections between the blue and green lines! What are these?! No such intersections between the doors can possibly occur in physical space. So this makes it even clearer that these lines cannot be identified with the doors. </p><p>What do these two intersections actually represent?  The upper left intersection combines the possibility that particle 1 is at the left door and simultaneously particle 2 is at the right door.  It’s the other way around at the lower right intersection.</p><p>Note <strong><em>there is no intersection, or any point at all, corresponding to particle 1 being at the left door and simultaneously being at the right door</em></strong>. Indeed, such a point would have , which is impossible; every point in the space of possibilities has a unique value of .</p><p>How does the wave function behave over time? It behaves as shown in Fig. 13:</p><p>What are the four peaks, and what are they doing? They correspond to the four possibilities shown in Fig. 10. Clockwise from the rightmost peak (which appeared in Fig. 9,)</p><ol><li> particle 1 goes through the right door, followed by particle 2.</li><li> particle 1 goes through the right door, after which particle 2 goes through the left door.</li><li> particle 1 goes through the left door, followed by particle 2.</li><li> particle 1 goes through the left door, after which particle 2 goes through the right door.</li></ol><p>You can tell which is which by looking at which colored line is crossed first, and which is crossed second, by each peak.</p><p>Any one of these four things may happen. Two, or more, may not. And not one of them includes the possibility that either particle goes through both doors simultaneously.</p><p>As another instructive variation, suppose we send particles 1 and 2 off at exactly the same moment. Then the wave function, shown in Fig. 13, looks very similar to Fig. 12, except that <strong>every peak goes through an intersection of the dashed lines,</strong> because the two particles arrive at the doors simultaneously. </p><p>Again there are four possibilities, </p><ol><li>both particles can arrive at the right door simultaneously, </li><li>both can arrive at the left door simultaneously,</li><li>particle 1 can arrive at the left door just as the particle 2 arrives at the right door</li></ol><p>And so <strong>it certainly  possible for particle 1 to go through the left door and particle 2 to go through the right door simultaneously.</strong> No problem with that. </p><p>However, it is simply impossible — illogical, in fact — for particle 1 to go through both doors simultaneously. There’s no spot in the space of possibilities that could even represent that inconsistent scenario.</p><h2>Lessons for the Double Slit Experiment</h2><p>The lesson? Many fascinating things happen in quantum physics once we have superpositions and multiple particles and multiple doors. But two things that cannot happen (in 1920’s quantum physics) include the following:</p><ul><li>No particle can go through two doors at once; it can have only one position at a time.</li><li>No wave function, living as it does in the space of possibilities, can pass through any door in physical space.</li></ul><p>The same applies for the two slits in the quantum double-slit experiment. One cannot make sense of that experiment without learning this lesson: <mark>from the viewpoint of 1920’s quantum physics, <strong>the interference effects do not arise from any object, whether particle or wave function or pattern in the wave function, physically moving through the physical slits in physical space.</strong></mark></p><p>So where do the interference effects come from?  The wave function’s pattern  travel across regions of possibility space that are  with the slits.  We need to work out the consequences of this observation, and interpret it properly.  Stay tuned to this channel; the answer is near at hand.</p>","contentLength":14582,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43353947"},{"title":"City simulator I made in Scratch","url":"https://scratch.mit.edu/projects/1061728417/","date":1741877191,"author":"Annulus","guid":144,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43353925"},{"title":"Lego says it wants to start to bring video game development in-house","url":"https://www.videogameschronicle.com/news/lego-is-starting-to-bring-its-game-development-in-house-key-exec-says/","date":1741826698,"author":"namanyayg","guid":143,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43349296"},{"title":"Wyvern's Open Satellite Feed","url":"https://tech.marksblogg.com/wyvern-open-data-feed.html","date":1741764005,"author":"marklit","guid":142,"unread":true,"content":"<p>Last month, Wyvern, a 36-person start-up with $16M USD in funding in Edmonton, Canada launched an open data programme for their VNIR, 23 to 31-band hyperspectral satellite imagery.</p><p>The imagery was captured with one of their three Dragonette 6U CubeSat satellites. These satellites were built by AAC Clyde Space which has offices in the UK, Sweden and a few other countries. They orbit 517 - 550 KM above the Earth's surface and have a spatial resolution at nadir (GSD) of 5.3M.</p><p>SpaceX launched all three of their satellites from Vandenberg Space Force Base in California. They were launched on April 15th, June 12th and November 11th, 2023 respectively.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/brave_DUuxrudwQm.png\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/brave_DUuxrudwQm.png\"></a><p>There are ~130 GB of GeoTIFFs being hosted in their AWS S3 bucket in Montreal. The 33 images posted were taken between June and two weeks ago.</p><p>In this post, I'll examine Wyvern's open data feed.</p><div><p>I'm using a 5.7 GHz AMD Ryzen 9 9950X CPU. It has 16 cores and 32 threads and 1.2 MB of L1, 16 MB of L2 and 64 MB of L3 cache. It has a liquid cooler attached and is housed in a spacious, full-sized Cooler Master HAF 700 computer case.</p><p>The system has 96 GB of DDR5 RAM clocked at 4,800 MT/s and a 5th-generation, Crucial T700 4 TB NVMe M.2 SSD which can read at speeds up to 12,400 MB/s. There is a heatsink on the SSD to help keep its temperature down. This is my system's C drive.</p><p>The system is powered by a 1,200-watt, fully modular Corsair Power Supply and is sat on an ASRock X870E Nova 90 Motherboard.</p><p>I'm running Ubuntu 24 LTS via Microsoft's Ubuntu for Windows on Windows 11 Pro. In case you're wondering why I don't run a Linux-based desktop as my primary work environment, I'm still using an Nvidia GTX 1080 GPU which has better driver support on Windows and I use ArcGIS Pro from time to time which only supports Windows natively.</p></div><div><p>I'll use GDAL 3.9.3, Python 3.12.3 and a few other tools to help analyse the data in this post.</p><div><pre>$sudoadd-apt-repositoryppa:deadsnakes/ppa\n$sudoadd-apt-repositoryppa:ubuntugis/ubuntugis-unstable\n$sudoaptupdate\n$sudoaptinstallgdal-binjqlibimage-exiftool-perllibtiff-toolspython3-pippython3.12-venv\n</pre></div><p>I'll set up a Python Virtual Environment and install some dependencies.</p><div><pre>$python3-mvenv~/.wyvern\n$~/.wyvern/bin/activate\n$python3-mpipinstallastropygeocoderpystacrichshapelysgp4\n</pre></div><div><pre>$gitclonehttps://github.com/marklit/geotiffs~/geotiffs\n$python3-mpipinstall-r~/geotiffs/requirements.txt\n</pre></div><div><pre>$~\n$wget-chttps://github.com/duckdb/duckdb/releases/download/v1.1.3/duckdb_cli-linux-amd64.zip\n$unzip-jduckdb_cli-linux-amd64.zip\n$chmod+xduckdb\n$~/duckdb\n</pre></div><div><pre></pre></div><p>I'll set up DuckDB to load every installed extension each time it launches.</p><div><pre>.timer on\n.width 180\nLOAD h3;\nLOAD lindel;\nLOAD json;\nLOAD parquet;\nLOAD spatial;\n</pre></div><p>The maps in this post were rendered with <a href=\"https://www.qgis.org/en/site/forusers/download.html\">QGIS</a> version 3.42. QGIS is a desktop application that runs on Windows, macOS and Linux. The application has grown in popularity in recent years and has ~15M application launches from users all around the world each month.</p><p>I used QGIS' <a href=\"https://github.com/marklit/tile_plus\">Tile+ plugin</a> to add geospatial context with Bing's Virtual Earth Basemap as well as CARTO's to the maps. The dark, non-satellite imagery maps are mostly made up of vector data from Natural Earth and Overture.</p></div><div><p>Below is <a href=\"https://scope.pulseorbital.com/\">PulseOrbital</a>'s list of estimated Tallinn flyovers by Wyvern's Dragonette constellation for March 8th and 9th, 2025.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/brave_FCOC1Fpnif.png\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/brave_FCOC1Fpnif.png\"></a><p>Below I'll try to estimate the current locations of each of their three satellites. I found the <a href=\"https://en.wikipedia.org/wiki/Two-line_element_set\">Two-line elements</a> (TLE) details on <a href=\"https://www.n2yo.com/satellite/?s=56225\">n2yo</a>.</p><p>I ran the following on March 10th, 2025. It produced a CSV file with names and estimated locations of their three satellites.</p><div><pre> \\\n                                   \\\n                                   \\\n                                  </pre></div><p>Below is a rendering of the above CSV data in QGIS.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_JmwpJdX0SF.jpg\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_JmwpJdX0SF.jpg\"></a></div><div><p>Wyvern have a STAC catalog listing the imagery locations and metadata around their capture. I'll download this metadata and get each image's address details with Mapbox's reverse geocoding service. Mapbox offer 100K geocoding searches per month with their free tier.</p><div><pre></pre></div><p>The above produced a 33-line JSONL file. Below is an example record.</p><div><pre>$head-n1enriched.jsonjq-S.\n</pre></div><div><pre></pre></div></div><div><p>I'll load their imagery metadata into DuckDB for analysis.</p><div><pre></pre></div><p>Below are the image counts by country and city. Some areas are rural and Mapbox didn't attribute any city to the image footprint's location.</p><div><pre></pre></div><div><pre>┌──────────────┬──────────────────────┬──────────────────────┐\n│ count_star() │       country        │         city         │\n│    int64     │       varchar        │       varchar        │\n├──────────────┼──────────────────────┼──────────────────────┤\n│            1 │ Australia            │ Jervois              │\n│            1 │ Australia            │ Norwin               │\n│            1 │ Australia            │ Ord River            │\n│            1 │ Australia            │ Skeleton Rock        │\n│            1 │ Australia            │ Yellabinna           │\n│            1 │ Bahrain              │                      │\n│            1 │ Botswana             │                      │\n│            1 │ Canada               │ Beaverdell           │\n│            1 │ Canada               │ Jasper               │\n│            1 │ Chile                │ Antofagasta          │\n│            1 │ Chile                │ San Pedro de Atacama │\n│            1 │ China                │                      │\n│            1 │ Côte d'Ivoire        │                      │\n│            2 │ Egypt                │ Al Ganaeen           │\n│            2 │ Egypt                │ Al Qantara East      │\n│            1 │ India                │ Gurh                 │\n│            1 │ Iran                 │                      │\n│            1 │ Iraq                 │                      │\n│            1 │ Italy                │                      │\n│            1 │ Kazakhstan           │                      │\n│            1 │ Mexico               │ Altamira             │\n│            1 │ Oman                 │                      │\n│            1 │ Saudi Arabia         │                      │\n│            1 │ Spain                │ Barcelona            │\n│            1 │ United Arab Emirates │                      │\n│            1 │ United States        │ Eureka               │\n│            2 │ United States        │ Los Angeles          │\n│            1 │ United States        │ New York             │\n│            1 │ United States        │ Pasadena             │\n│            1 │ United States        │ Priest River         │\n├──────────────┴──────────────────────┴──────────────────────┤\n│ 30 rows                                          3 columns │\n└────────────────────────────────────────────────────────────┘\n</pre></div><p>Below are the locations of the images.</p><div><pre></pre></div><a href=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_v2cucUh6HR.png\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_v2cucUh6HR.png\"></a><p>These are the months in which the imagery was captured.</p><div><pre></pre></div><div><pre>┌──────────────┬─────────┐\n│ count_star() │ month_  │\n│    int64     │ varchar │\n├──────────────┼─────────┤\n│            1 │ 2024-10 │\n│           11 │ 2024-11 │\n│            2 │ 2024-12 │\n│           14 │ 2025-01 │\n│            5 │ 2025-02 │\n└──────────────┴─────────┘\n</pre></div><p>The majority of imagery is from their first satellite but there are four images from their third. Their second and third satellites can collect a wider spectral range, with more spectral bands at a greater spectral resolution.</p><div><pre></pre></div><div><pre>┌──────────────┬────────────────┬────────┐\n│ count_star() │    platform    │  gsd   │\n│    int64     │    varchar     │ double │\n├──────────────┼────────────────┼────────┤\n│           29 │ Dragonette-001 │   5.26 │\n│            4 │ Dragonette-003 │   5.22 │\n└──────────────┴────────────────┴────────┘\n</pre></div><p>All of the imagery has been processed to level L1B and, with the exception of one image, to version 1.3.</p><div><pre></pre></div><div><pre>┌──────────────┬──────────────────┬────────────────────┐\n│ count_star() │ processing:level │ processing:version │\n│    int64     │     varchar      │      varchar       │\n├──────────────┼──────────────────┼────────────────────┤\n│           32 │ L1B              │ 1.3                │\n│            1 │ L1B              │ 1.2                │\n└──────────────┴──────────────────┴────────────────────┘\n</pre></div><p>Below I'll bucket the amount of cloud cover in their imagery to the nearest 10%.</p><div><pre></pre></div><div><pre>┌──────────────┬─────────────┐\n│ count_star() │ cloud_cover │\n│    int64     │   double    │\n├──────────────┼─────────────┤\n│           17 │         0.0 │\n│            7 │        10.0 │\n│            6 │        20.0 │\n│            1 │        30.0 │\n│            1 │        40.0 │\n│            1 │        50.0 │\n└──────────────┴─────────────┘\n</pre></div></div><div><p>These files are structured so it's easy to only read a portion of a file for any one resolution you're interested in. A file might be 100 MB but a JavaScript-based Web Application might only need to download 2 MB of data from that file in order to render its lowest resolution.</p><p>The following downloaded 130 GB of GeoTIFFs from their feed.</p><div><pre>$jq.assets.cloud_optimized_geotiffenriched.jsonxargs-P4-I%wget-c%\n</pre></div><p>Below you can see the five resolutions of imagery with the following GeoTIFF. These range from 6161-pixels wide down to 385-pixels wide.</p><div><pre>$python3~/geotiffs/main.pystackwyvern_dragonette-001_20250124T171659_0bb0a026.tiff\n</pre></div><div><pre></pre></div></div><div><p>Below is a 23 x 30 KM image of Los Angeles.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_pbqARpUBYs.jpg\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_pbqARpUBYs.jpg\"></a><p>This is its metadata for reference.</p><div><pre>$~/duckdb-jsonwyvern.duckdbjq-S.\n</pre></div><div><pre></pre></div><p>The following bands are present in the above image.</p><div><pre>Band_503nm  green   float32 0,0201 μm\nBand_510nm  green   float32 0,0204 μm\nBand_519nm  green   float32 0,0208 μm\nBand_535nm  green   float32 0,0214 μm\nBand_549nm  green   float32 0,022 μm\nBand_570nm  green   float32 0,0228 μm\nBand_584nm  yellow  float32 0,0234 μm\nBand_600nm  yellow  float32 0,024 μm\nBand_614nm  yellow  float32 0,0246 μm\nBand_635nm  red     float32 0,0254 μm\nBand_649nm  red     float32 0,026 μm\nBand_660nm  red     float32 0,0264 μm\nBand_669nm  red     float32 0,0268 μm\nBand_679nm  red     float32 0,0272 μm\nBand_690nm  red     float32 0,0276 μm\nBand_699nm  red     float32 0,028 μm\nBand_711nm  rededge float32 0,0284 μm\nBand_722nm  rededge float32 0,0289 μm\nBand_734nm  rededge float32 0,0294 μm\nBand_750nm  rededge float32 0,03 μm\nBand_764nm  rededge float32 0,0306 μm\nBand_782nm  rededge float32 0,0313 μm\nBand_799nm  nir     float32 0,032 μm\n</pre></div><p>Most images contain 23 bands of data though there are four images in this feed that contain 31 bands.</p><div><pre>$FILENAME*.tiffgdalinfo-jsonjq-S,</pre></div><div><pre>23, wyvern_dragonette-001_20240608T144036_fa4c4f71.tiff\n23, wyvern_dragonette-001_20240614T043114_805f0bb7.tiff\n23, wyvern_dragonette-001_20240620T145630_2d5d0eef.tiff\n23, wyvern_dragonette-001_20240628T062939_5fce57a3.tiff\n23, wyvern_dragonette-001_20240703T171837_4c406dd3.tiff\n23, wyvern_dragonette-001_20240709T145146_1e79473a.tiff\n23, wyvern_dragonette-001_20240728T084002_5e95f389.tiff\n23, wyvern_dragonette-001_20240802T063254_fe587307.tiff\n23, wyvern_dragonette-001_20240806T172508_6b59089b.tiff\n23, wyvern_dragonette-001_20240808T073501_51b92993.tiff\n23, wyvern_dragonette-001_20240808T171453_20e65134.tiff\n23, wyvern_dragonette-001_20240811T083914_08c61457.tiff\n23, wyvern_dragonette-001_20240816T065054_0e692903.tiff\n23, wyvern_dragonette-001_20240823T172127_4ef5c7ec.tiff\n23, wyvern_dragonette-001_20240902T015820_c8ba843e.tiff\n23, wyvern_dragonette-001_20240924T043743_be250f77.tiff\n23, wyvern_dragonette-001_20240924T060726_6131fb18.tiff\n23, wyvern_dragonette-001_20240930T070744_08fd7f5a.tiff\n23, wyvern_dragonette-001_20241003T001114_b9b1a0b8.tiff\n23, wyvern_dragonette-001_20241024T092200_c874e0e3.tiff\n23, wyvern_dragonette-001_20241026T073007_1f933ec9.tiff\n23, wyvern_dragonette-001_20241104T173856_870d7461.tiff\n23, wyvern_dragonette-001_20241107T060700_4e89ebe5.tiff\n23, wyvern_dragonette-001_20241219T073000_833394ce.tiff\n23, wyvern_dragonette-001_20250101T072826_f3aa9cc0.tiff\n23, wyvern_dragonette-001_20250123T172439_ec97451b.tiff\n23, wyvern_dragonette-001_20250124T171659_0bb0a026.tiff\n23, wyvern_dragonette-001_20250127T021633_c94c1fd6.tiff\n23, wyvern_dragonette-001_20250202T013329_a6b233a1.tiff\n31, wyvern_dragonette-003_20241224T002812_069c301b.tiff\n31, wyvern_dragonette-003_20241229T103412_4fb7ca06.tiff\n31, wyvern_dragonette-003_20241229T165203_12324bcb.tiff\n31, wyvern_dragonette-003_20250128T005455_e8a5c3ba.tiff\n</pre></div></div><div><p>If you open the properties for the above image's layer in QGIS and select the \"Symbology\" tab, you can re-map the bands being used for the red, green and blue channels being rendered. Try the following:</p><ul><li>Red band: \"Band 15: Band_690\"</li><li>Green band: \"Band 08: Band_600\"</li><li>Blue band: \"Band 03: Band_519\"</li></ul><p>Under the \"Min / Max Value Settings\" section, check the radio button next to \"Min / max\".</p><p>Below is what the settings should look like:</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_nNSNCNuaZl.png\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_nNSNCNuaZl.png\"></a><p>Hit \"Apply\" and the image should look more natural.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_wdup7xFYy8.jpg\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_wdup7xFYy8.jpg\"></a><p>Below is a comparison to Bing's imagery for this area.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/bing.jpg\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/bing.jpg\"></a><p>Below is a comparison to Esri's imagery for this area.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/esri.jpg\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/esri.jpg\"></a><p>Below is a comparison to Google's imagery for this area.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/google.jpg\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/google.jpg\"></a><p>Below is a comparison to Yandex's imagery for this area.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/yandex.jpg\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/yandex.jpg\"></a></div><div><p>QGIS 3.42 was released a few weeks ago and now has STAC catalog integration.</p><p>From the Layer Menu, click Add Layer -&gt; Add Layer from STAC Catalog.</p><p>Give the layer the name \"wyvern\" and paste in the following URL:</p><div><pre>https://wyvern-prod-public-open-data-program.s3.ca-central-1.amazonaws.com/catalog.json\n</pre></div><p>Below is what the fields should look like.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_RhyN7xgOik.png\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_RhyN7xgOik.png\"></a><p>Click OK, then Close on the next dialog and return to the main UI. Don't click the connect button as you'll receive an error message and it isn't needed for this feed.</p><p>Click the View Menu -&gt; Panels -&gt; Browser Panel. You should see a STAC item appear in that panel and underneath you should be able to browse the various collections Wyvern offer.</p><a href=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_Alvxkn7NkY.png\"><img alt=\"Wyvern\" src=\"https://tech.marksblogg.com/theme/images/wyvern/qgis-bin_Alvxkn7NkY.png\"></a><p>Right clicking any asset lets you both see a preview and details on the imagery. You can also download the imagery to your machine and into your QGIS project.</p></div>","contentLength":15431,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43340651"}],"tags":["dev","hn"]}