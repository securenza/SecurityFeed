{"id":"VMK7D8tQvwsLtnxKHzNdF9c4Yhtuqm","title":"Hacker News: Best","displayTitle":"Best of HackerNews","url":"https://hnrss.org/best","feedLink":"https://news.ycombinator.com/best","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":44,"items":[{"title":"Apache ECharts","url":"https://echarts.apache.org/en/index.html","date":1744133009,"author":"tomtomistaken","guid":20880,"unread":true,"content":"<h2>ECharts: A Declarative Framework for Rapid Construction of Web-based Visualization</h2><p>You are welcomed to cite the following paper whenever you use ECharts in your R&amp;D projects, products, research papers, technical reports, news reports, books, presentations, teaching, patents, and other related intelligence activities.</p>","contentLength":317,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43624220"},{"title":"Thank HN: The puzzle game I posted here 6 weeks ago got licensed by The Atlantic","url":"https://www.theatlantic.com/games/bracket-city/","date":1744125086,"author":"brgross","guid":20863,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43622719"},{"title":"Middle-aged man trading cards go viral in rural Japan town","url":"https://www.tokyoweekender.com/entertainment/middle-aged-man-trading-cards-go-viral-in-japan/","date":1744059796,"author":"PaulHoule","guid":20213,"unread":true,"content":"<p><a href=\"https://www.tokyoweekender.com/entertainment/tech-trends/pokemon-tgc-pocket-continues-to-dominate-the-app-charts/\"></a></p><div><img decoding=\"async\" aria-describedby=\"caption-attachment-265114\" src=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"ojisan trading cards \" width=\"2048\" height=\"1356\" data-src-img=\"https://www.tokyoweekender.com/wp-content/uploads/2025/03/ojisan-01.jpg\" data-src-webp=\"https://www.tokyoweekender.com/wp-content/uploads/2025/03/ojisan-01.jpg.webp\" data-eio=\"j\"><p>Image: Mayuko Ichii | edits by TW</p></div><h2></h2><div><img decoding=\"async\" aria-describedby=\"caption-attachment-265113\" src=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"ojisan trading cards \" width=\"2880\" height=\"1614\" data-src-img=\"https://www.tokyoweekender.com/wp-content/uploads/2025/03/ojisan-02.jpg\" data-src-webp=\"https://www.tokyoweekender.com/wp-content/uploads/2025/03/ojisan-02.jpg.webp\" data-eio=\"j\"><p>Screenshot taken from FNN Prime Online</p></div><h2></h2><p><a href=\"https://www.fnn.jp/articles/-/842101\"></a></p>","contentLength":71,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43615912"},{"title":"Show HN: Browser MCP – Automate your browser using Cursor, Claude, VS Code","url":"https://browsermcp.io/","date":1744043145,"author":"namukang","guid":20862,"unread":true,"content":"<p>Automate with speed, security, and convenience</p>","contentLength":46,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43613194"},{"title":"A startup doesn't need to be a unicorn","url":"https://mattgiustwilliamson.substack.com/p/your-startup-doesnt-need-to-be-a","date":1744015363,"author":"MattSWilliamson","guid":20152,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43609242"},{"title":"Rsync replaced with openrsync on macOS Sequoia","url":"https://derflounder.wordpress.com/2025/04/06/rsync-replaced-with-openrsync-on-macos-sequoia/","date":1743974049,"author":"zdw","guid":20065,"unread":true,"content":"<p>On many Unix-based operating systems, <a href=\"https://en.wikipedia.org/wiki/Rsync\">rsync</a> is a command line tool for transferring and synchronizing files on a computer, either between storage attached directly to the computer or between another computer located elsewhere on a network. The  command line tool has long been included on macOS, but Apple has provided the last version of  2.x (<a href=\"https://download.samba.org/pub/rsync/NEWS#2.6.9\">rsync 2.6.9, released in November 2006</a>) and did not update  past that even though  3.x was released. Why not? It has to do with the version of the <a href=\"https://en.wikipedia.org/wiki/GNU_General_Public_License\">GNU General Public License</a> (GPL) open source license that  2.x and 3.x were released under, with <a href=\"https://rsync.samba.org/GPL2.html\">rsync 2.x being released under the GPLv2 license</a> and <a href=\"https://rsync.samba.org/GPL.html\">rsync 3.x being released under the GPLv3 license</a>. Without going in-depth into the background legal issues, the reason for not providing  3.x is that Apple decided that while it could comply with the terms of GPLv2 license with regards to  2.x, it could not comply with the terms of GPLv3 license with regards to  3.x.</p><p>What this has meant for macOS is that it has been shipping with a version of  which was last updated in 2006. While Apple has been updating the  2.6.9 command line tool it shipped with macOS as needed in response to security issues and other problems, the fact remains that Apple’s version of  up until macOS Sequoia was almost twenty years old and did not include any of the new features introduced in  versions which came after version 2.6.9.</p><p>Now with macOS Sequoia, Apple has replaced  2.6.9 with <a href=\"https://man.openbsd.org/openrsync\">openrsync</a>, an implementation of  which is not using any version of the GPL open source license. Instead,  is licensed under the <a href=\"https://en.wikipedia.org/wiki/BSD_licenses\">BSD family of licenses</a>, specifically the <a href=\"https://en.wikipedia.org/wiki/ISC_license\">ISC license</a>. The ISC license is a <a href=\"https://en.wikipedia.org/wiki/Permissive_software_license\">permissive license</a>, which means it places minimal restrictions on on how the licensed software can be used, modified and distributed, which means Apple decided it is able to comply with the terms of the license for  where it decided it could not comply with the terms of GPLv3 license with regards to  3.x.</p><p>So I’ve spent a bunch of time talking about licenses. Why does this change matter? It matters in two ways:</p><p>Item number 2 is important for Mac admins because it may mean that  functionality that worked on older versions of macOS may not be working now on macOS Sequoia because that functionality is not available as part of the  command line tool included with macOS Sequoia. For more information about what functionality is supported in the  command line tool on macOS Sequoia, please see the link below:</p><p>As of macOS 15.4, the  tool is linked to  so you can run the the  command line tool like you have been the  command line tool. For version information about the  command line tool, run the command shown below:</p><p>You should see output similar to that shown below:</p><div><div translate=\"no\" data-color-mode=\"light\" data-light-theme=\"light\"><div><div><div><div itemprop=\"text\" tabindex=\"0\" role=\"region\" aria-label=\"gistfile1.txt content, created by rtrouton on 08:15PM on April 06.\"><div><table data-hpc=\"\" data-tab-size=\"8\" data-paste-markdown-skip=\"\" data-tagsearch-path=\"gistfile1.txt\"><tbody><tr><td>username@computername ~ % /usr/bin/rsync –version </td></tr><tr><td>openrsync: protocol version 29</td></tr><tr><td>rsync version 2.6.9 compatible</td></tr><tr><td>username@computername ~ %</td></tr></tbody></table></div></div></div></div></div></div></div>","contentLength":2870,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43605003"},{"title":"Recent AI model progress feels mostly like bullshit","url":"https://www.lesswrong.com/posts/4mvphwx5pdsZLMmpY/recent-ai-model-progress-feels-mostly-like-bullshit","date":1743962519,"author":"paulpauper","guid":20064,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43603453"},{"title":"The “S” in MCP Stands for Security","url":"https://elenacross7.medium.com/%EF%B8%8F-the-s-in-mcp-stands-for-security-91407b33ed6b","date":1743932548,"author":"skilldeliver","guid":19805,"unread":true,"content":"<p>MCP, short for , is the hot new standard behind how Large Language Models (LLMs) like Claude, GPT, or Cursor integrate with tools and data. It’s been described as the </p><ul><li>Connect to tools via standardized APIs</li><li>Maintain persistent sessions</li><li>Run commands (sometimes too freely)</li><li>Share context across workflows</li></ul><p>But there’s one big problem…</p><p>And if you’ve plugged your agents into arbitrary servers without reading the fine print — congrats, you may have just opened a side-channel into your shell, secrets, or infrastructure.</p>","contentLength":520,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43600192"},{"title":"Standard Ebooks: liberated ebooks, carefully produced for the true book lover","url":"https://standardebooks.org/","date":1743924972,"author":"tosh","guid":19727,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43599637"},{"title":"Apple’s Darwin OS and XNU Kernel Deep Dive","url":"https://tansanrao.com/blog/2025/04/xnu-kernel-and-darwin-evolution-and-architecture/","date":1743896779,"author":"tansanrao","guid":20063,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43597778"},{"title":"The Llama 4 herd","url":"https://ai.meta.com/blog/llama-4-multimodal-intelligence/","date":1743878036,"author":"georgehill","guid":19581,"unread":true,"content":"<div>Get Facebook on Your Phone</div><div>Stay connected anytime, anywhere.</div>","contentLength":59,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43595585"},{"title":"What if we made advertising illegal?","url":"https://simone.org/advertising/","date":1743875866,"author":"smnrg","guid":19726,"unread":true,"content":"<p>What if we made all advertising illegal? It's such a wild idea that I've never heard it in the public discourse.</p><p>Even saying it seems so far outside the Overton window that it makes nuking hurricanes sound reasonable (as some politicians proposed).</p><p>But why? It makes perfect sense. The financial incentives to create addictive digital content would instantly disappear, and so would the mechanisms that allow both commercial and political actors to create personalized, reality-distorting bubbles:</p><ul><li>Clickbait, listicles, and affiliate marketing schemes would become worthless overnight.</li><li>Facebook, X, Google, YouTube—all would cease to exist in their current forms.</li></ul><p>Ad companies are never going to regulate themselves—it's like hoping for heroin dealers to write drug laws.</p><p>Think about what's happened since 2016: Populists exploit ad marketplaces, using them to bypass traditional media gatekeepers and deliver tailored messages to susceptible audiences. Foreign actors do the same, microtargeting divisive content to fracture our social fabric along existing fault lines.</p><p><strong>Outlawing advertising would help protect and reinvigorate our minds and democracy.</strong></p><p>Even as an advertiser ( as an advertiser), I am convinced that outlawing advertising is the best thing we can do for our world now. More than gun control. More than tackling climate change. More than lowering the price of eggs.</p><p>Removing these advanced manipulation tools would force everyone—politicians included—to snap back into reality. By outlawing advertising, the machinery of mass delusion would lose its most addictive and toxic fuel. </p><p><strong>Any form of paid and/or third-party advertising would become illegal. Full stop.</strong></p><p>The idea feels like sci-fi because you're so used to it, imagining ads gone feels like asking to outlaw gravity. But humanity had been free of current forms of advertising for 99.9% of its existence. Word-of-mouth and community networks worked just fine. First-party websites and online communities would now improve on that.</p><p>The traditional argument pro-advertising—that it provides consumers with necessary information—hasn't been valid for decades. In our information-saturated world, ads manipulate, but they don't inform.</p><p>The modern advertising apparatus exists to <a href=\"https://simone.org/tyranny-defaults-monopoly-mind/\" rel=\"noreferrer\">bypass rational thought</a> and trigger emotional responses that lead to purchasing decisions. A sophisticated machine designed to short-circuit your agency, normalized to the point of invisibility.</p><p>Bullshit. No one is entitled to yell at you “GET 20% OFF THIS UNDERWEAR YOU GLANCED AT YESTERDAY” with a dopamine megaphone in your bedroom. And to track 90% of your life to know when and how to say it. That's not free speech, that's harassment.</p><p>When I say advertising, I also mean propaganda. Propaganda is advertising for the state, and advertising is propaganda for the private. Same thing.</p><p>I know this proposal won't be implemented tomorrow. But even just stepping back from constant consumption and contemplating what poisons our democracy is a liberating act in itself. An action against that blurry, “out-of-focus fascism”—that sense of discomfort that you feel but can't quite point out (I'm preparing a longer essay about that.) In this world,  mindfulness act—stopping to think rather than reacting—represents <a href=\"https://simone.org/tracking-screen-time/\" rel=\"noreferrer\">a micro-awakening of the self</a>.</p><p>I know, it sounds surreal. Yet, many things once thought impossible are now considered basic standards of a decent society.</p><p>I think there's a world where we'll look back on our advertising-saturated era with the same bewilderment with which we now regard cigarette smoke, child labor, or public executions: a barbaric practice that we allowed to continue far too long because we couldn't imagine an alternative.</p>","contentLength":3715,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43595269"},{"title":"Show HN: I built a word game. My mom thinks it's great. What do you think?","url":"https://www.whatsit.today/","date":1743863162,"author":"mkate","guid":20062,"unread":true,"content":"<p>Loading daily challenge...</p>","contentLength":26,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43593789"},{"title":"The blissful Zen of a good side project","url":"https://joshcollinsworth.com/blog/the-blissful-zen-of-a-good-side-project","date":1743799055,"author":"ingve","guid":20061,"unread":true,"content":"<img src=\"https://joshcollinsworth.com/images/post_images/zen.jpg\" alt=\"\" width=\"1920\" height=\"1080\"><p>Yesterday, like just about every other evening, my wife and I put our kid to bed, and sat down on the couch together. But for the first time in months, I picked up my laptop instead of my Switch.</p><p>I don’t remember the last time I took a new side project at all seriously, but a glance through my projects folder indicates it’s been at least a year since I spent more than a day or two on one. I found a few I didn’t even remember starting, it’s been so long. Some I hadn’t even taken far enough to demonstrate whatever basic idea must’ve been in my head at the time; abandoned before they were even working.</p><p>So it’s been a while. I haven’t exactly been feeling inspired since…</p><p>Well, since I don’t know when.</p><p>Maybe I’ve been depressed, or burned out. I don’t know. I haven’t been at my best; that’s all I really know for sure. It’s not that things have been bad, exactly, but they haven’t been easy, either.</p><p>Whatever the reason: I realize now I’ve let it push my consumption-to-creation ratio wildly out of balance.</p><p>I’ve spent pretty much every night in recent memory burning through video games, and I finally, inevitably, hit the wall with that approach. I wasn’t interested, or compelled. The fun things weren’t even fun anymore. The diminishing returns finally dwindled to the point I felt like I  to try something new.</p><p>Something I’d been resisting.</p><p>Something I was afraid of.</p><p>Maybe I was scared to fail. Maybe I didn’t think I had a good enough idea. Maybe I didn’t think I was inspired enough yet.</p><p>Maybe I thought it would be too hard.</p><p>But finally, the pain of continuing with my existing approach outweighed the fears of change. So, for the first time in many months, I spun up a new project.</p><p>It was a SvelteKit project, incidentally, although that’s entirely beside the point. I considered just creating HTML/CSS/JavaScript files and building from scratch. I also considered learning something new.</p><p>I don’t think what I picked matters, though; I think it just matters that I picked .</p><div><p>It doesn’t matter  the project is; it matters  it is.</p></div><p>Soon enough, I was staring at a blank white page with minimal black text in my browser; the web equivalent of a blank canvas.</p><p>I began to write the variables I knew I’d need. I grabbed some things here and there from other projects. I added some minimal CSS classes just to get things roughly laid out. Functions and event handlers soon followed.</p><p>A loose demo began to take shape.</p><p>An hour or two went by, as I prototyped the idea. I tried some things; they didn’t work; I tried some others. I changed my approach, then changed it again, free to do whatever I saw fit, free to explore in any direction I liked.</p><p>This morning, I tried a few more things. And though I’m not sure the core idea really works, or is anything special, simply  myself to explore it felt like being able to finally take a deep breath after a long time underwater.</p><p>I felt something in that freedom. I felt a simple, understated joy that I hadn’t felt in a long time; a candle in a long-darkened room.</p><p>Maybe you can relate. Maybe there’s an idea that’s been in your head.</p><p>Maybe not; maybe you just haven’t created something in a long time. Maybe what you’re doing isn’t working for you. Maybe you just aren’t having  anymore.</p><p>I don’t know your situation, and I’m certainly not qualified to give out helpful life advice.</p><p>But I know that when  not creating something, a part of me withers. And I think, in some way, we all have that compulsion inside of us.</p><p>I don’t think  we create is the important part. I don’t even think it needs to be something “creative” to begin with.</p><p><strong>Don’t limit your view of creation to things considered creative</strong>—or, for that matter, to things you’ve done before. These days I make apps, but I used to make entirely different things, and got the same pleasure from those.</p><p>Some days, all I want to create is something tangible and functional. Last summer, my wife and I built new steps to our patio door, and even though that was well beyond both my range of experience and the typical definition of creativity, I found the work more engaging and compelling than anything else I had going on at the time.</p><p>Sometimes it’s artistic; sometimes it’s not; other times, what we create isn’t a tangible thing at all.</p><p>What you create might be words. It might be relationships, or time and space for others. Sometimes it’s the intangible places we create together. Sometimes we create experiences. Sometimes we create homes, communities, and families, of both the literal and figurative varieties.</p><p>Sometimes we just create .</p><p><strong>I think we exist to bring new things into existence</strong>. If you ask me, to the extent there  a meaning of life, that’s it. We exist to create. It lights us up in a way nothing else does, putting something new into our world—and in doing so, fundamentally changing it, in whatever way, however big or small.</p><p> you create, and  you do it, is entirely up to you. That’s the beauty of it.</p><div><p>Enjoying the freedom to explore possibilities, and happily follow any compelling whim—that’s the blissful zen of a good side project.</p></div><p>It’s having a carved-out space in your life where you, and only you, get to make the choices.</p><p>Nobody else. You might have to share everything outside this little room, but everything in here is yours and yours alone.</p><p>You don’t have to listen to any other voices here, except that quiet one inside of you that’s gently urging you to do the thing you know you need to do. You don’t owe it to anyone to choose anything—except yourself, and what you honestly feel.</p><p>You don’t need to know where it’s going to lead. For that matter, it doesn’t have to lead . Nothing ever has to come of it. It’s ok if this project never even exists, as far as anyone else is concerned. Failure isn’t failure; it’s part of the process. It’s done when you’re done with it.</p><p>The important part is that you explored that little corner of the map, and uncovered what was there. It’s ok if that was nothing. The exploration was the success. Now you know better where to explore next.</p><p>So whatever your side project is: I encourage you to pick it up, and let that part of you exist (again).</p>","contentLength":6223,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43587380"},{"title":"Nvidia adds native Python support to CUDA","url":"https://thenewstack.io/nvidia-finally-adds-native-python-support-to-cuda/","date":1743771278,"author":"apples2apples","guid":20060,"unread":true,"content":"<p>For years, NVIDIA’s <a href=\"https://developer.nvidia.com/cuda-toolkit\" rel=\"external \" onclick=\"this.target='_blank';\">CUDA</a> software toolkit didn’t have native Python support. But that’s now changed.</p><p>At GTC, NVIDIA announced native support and full integration of Python in its CUDA toolkit. Developers will be able to use Python for direct execution of algorithmic-style computing on GPUs.</p><p>“We’ve been working hard to bring accelerated Python, first class, into the CUDA stack,” said <a href=\"https://developer.nvidia.com/blog/author/stjones/\" rel=\"external \" onclick=\"this.target='_blank';\">Stephen Jones</a>, CUDA architect, during a presentation at the recent GTC conference.</p><p>For programmers, the implications are massive. CUDA was born from C and C++, and now coders don’t need knowledge of those programming languages to use the toolkit.</p><p>“Python for CUDA should not look like C. It should look like Python,” Jones said.</p><blockquote><p>“Python CUDA is not just C translated into Python syntax.”<strong>— Stephen Jones, CUDA architect</strong></p></blockquote><p>Coders can use natural Python interfaces and the scripting model of calling functions and libraries to create AI programs for execution on NVIDIA GPUs.</p><p>“Python CUDA is not just C translated into Python syntax. It’s got to be something which is natural to a Python developer,” Jones said.</p><h2>Native Python Opens New Doors</h2><p>NVIDIA’s native support for Python on CUDA opens the developer toolkit to millions of developers. CUDA previously required developers to know C++ or Fortran. The programming kit had some Python tooling, but it wasn’t natively supported.</p><p>The number of CUDA users was only 4 million in 2023, up from 2 million in 2020, <a href=\"https://futurumgroup.com/insights/ai-in-context-uxl-to-be-an-open-source-alternative-to-nvidias-cuda/\" rel=\"external \" onclick=\"this.target='_blank';\">according</a> to The Futurum Group. But Python is the fastest-growing language in the world. NVIDIA will get access to millions of Python coders — especially in developing countries such as India and Brazil, where coders make fervent contributions to open source projects.</p><p>Python support will also make NVIDIA’s infrastructure ready to use in emerging markets. A bulk of NVIDIA GPUs are in the U.S. and Europe, but telecom and infrastructure companies in India are building out major GPU installations that will be operational in the coming years.</p><h2>How Pythonic CUDA Was Built</h2><p>CUDA includes libraries, SDKs, compilers, host runtimes, tools, and pre-packaged software and algorithms. NVIDIA has added pieces to the entire <a href=\"https://nvidia.github.io/cuda-python/latest/\" rel=\"external \" onclick=\"this.target='_blank';\">Pythonic CUDA stack</a>.</p><p>NVIDIA’s focus was to provide GPU acceleration without getting out of Python. CUDA Python can’t be just kernel offerings; it needs everything across the stack and a smooth execution flow, Jones said.</p><p>“You have to be able to write a kernel and drop it into PyTorch, but you also have to be able to call Pythonic libraries and all of these other things,” Jones said.</p><p>Effectively, there’s nothing at the compiler layer, as it’s built around just-in-time (JIT) compilation. That significantly reduces the number of dependencies in the tree for GPUs in the stack.</p><p>“Keeping this interoperability between all the layers is going to be a huge gain for productivity and being able to use Python end-to-end,” Jones said.</p><p>Initially, NVIDIA built base Python bindings (which include the runtime compiler) and Python libraries such as cuPyNumeric, which is a drop-in replacement for NumPy, the most widely used computational library in Python. cuPyNumeric changes just one import directive, and NumPy code goes from running on the CPU to running on a GPU.</p><blockquote><p>CUDA Core is a “Pythonic reimagining of the CUDA runtime to be naturally and natively Python.”<strong>— Stephen Jones, CUDA architect</strong></p></blockquote><p>Over the last year, NVIDIA made <a href=\"https://nvidia.github.io/cuda-python/cuda-core/latest/\" rel=\"external \" onclick=\"this.target='_blank';\">CUDA Core</a>, which Jones said is a “Pythonic reimagining of the CUDA runtime to be naturally and natively Python.”</p><p>CUDA Core has the execution flow of Python, which is fully in process and leans heavily into JIT compilation.</p><p>“You should not be dropping out command-line compilers or anything like that, you should be fully in process,” Jones said, adding that this significantly reduces the number of dependencies in the tree for GPUs in the stack.</p><p>NVIDIA created a library called NVMath Python with unified interfaces for both host-side and device-side library calls. The ability to fuse library calls brings big performance improvements, Jones said.</p><p>The company has also built libraries that can access accelerated C++ libraries directly from Python code.</p><p>“Because this sits on top of the underlying infrastructure that we’ve built over the years… we didn’t re-implement these in Python. We made sure that it links in the underlying fine-tuned C++ code so [that] your performance difference is negligible,” Jones said.</p><p>NVIDIA also added tools for profilers and code analyzers.</p><p>Python makes coding straightforward and coders don’t have to worry much about the underlying hardware. With that in mind, NVIDIA is adding a coding layer that aligns with higher-level abstraction for execution on GPUs.</p><p>The new programming model, called CuTile interface, is being developed first for Pythonic CUDA with an extension for C++ CUDA coming later.</p><p>CuTile is “fundamentally more platonic,” as Python programmers today think more in terms of arrays than threads (which is more of a C++ trait).</p><p>Developers can’t magically take Python code and export it for GPU acceleration. CUDA typically takes a problem and breaks it into thousands of smaller blocks that are processed separately on GPUs.</p><p>The blocks are broken up into smaller tiles, which run thousands of threads processing single elements. The threads gang up into a single operation.</p><p>The ability to go all the way down to process single elements at the thread level in parallel gives the GPUs their massive computing power.</p><p>But NVIDIA figured that GPU execution doesn’t need to go all the way down to the thread level. Processing can also be done midway at the level of tiles, which is where the CuTile programming model fits in.</p><blockquote><p>Unlike C++, Python isn’t granular by design.</p></blockquote><p>CuTile does an efficient job of mapping arrays to GPUs at a less granular level, which makes the code easier to understand and debug. “And fundamentally, it comes out to the same performance,” Jones said.</p><p>Data in tiles could be structured as vectors, tensors, or arrays. Compilers can do a better job of thread mapping whole array operations from one block of threads to GPUs.</p><p>“Very often the compiler will do better than I can do because the compiler deeply understands what I’m doing… [and] the fine details of how the GPU runs,” Jones said.</p><p>Unlike C++, Python isn’t granular by design.</p><p>“There’s a lot of these things out there. OpenAI’s Triton would be a good example. And I think that those are a natural fit for Python programs,” Jones said.</p><div><svg width=\"68px\" height=\"31px\" viewBox=\"0 0 68 31\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></svg></div>","contentLength":6514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43581584"},{"title":"Bored of It","url":"https://paulrobertlloyd.com/2025/087/a1/bored/","date":1743764050,"author":"NotInOurNames","guid":19212,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43580449"},{"title":"Gumroad’s source is available","url":"https://github.com/antiwork/gumroad","date":1743760597,"author":"philipjoubert","guid":20059,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43580103"},{"title":"Microsoft’s original source code","url":"https://www.gatesnotes.com/home/home-page-topic/reader/microsoft-original-source-code","date":1743716944,"author":"EvgeniyZh","guid":19580,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43575884"},{"title":"An image of an archeologist adventurer who wears a hat and uses a bullwhip","url":"https://theaiunderwriter.substack.com/p/an-image-of-an-archeologist-adventurer","date":1743702920,"author":"participant3","guid":18938,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43573156"},{"title":"AI 2027","url":"https://ai-2027.com/","date":1743696782,"author":"Tenoke","guid":19211,"unread":true,"content":"<div><h2>Mid 2025: Stumbling Agents</h2><p>The world sees its first glimpse of AI agents.</p><p>Advertisements for computer-using agents emphasize the term “personal assistant”: you can prompt them with tasks like “order me a burrito on DoorDash” or “open my budget spreadsheet and sum this month’s expenses.” They will check in with you as needed: for example, to ask you to confirm purchases. Though more advanced than previous iterations like <a href=\"https://openai.com/index/introducing-operator/\">Operator</a>, they struggle to get widespread usage.</p><p>Meanwhile, out of public focus, more specialized coding and research agents are beginning to transform their professions.</p><p>The AIs of 2024 could follow specific instructions: they could turn bullet points into emails, and simple requests into working code. In 2025, AIs function more like employees. Coding AIs increasingly look like autonomous agents rather than mere assistants: taking instructions via Slack or Teams and making substantial code changes on their own, sometimes saving hours or even days. Research agents spend half an hour scouring the Internet to answer your question.</p><p>The agents are impressive in theory (and in cherry-picked examples), but in practice unreliable. AI twitter is full of stories about tasks bungled in some particularly hilarious way. The better agents are also expensive; you get what you pay for, and the best performance costs hundreds of dollars a month. Still, many companies find ways to fit AI agents into their workflows.</p></div><div><h2>Late 2025: The World’s Most Expensive AI</h2><p>OpenBrain is building the biggest datacenters the world has ever seen.</p><p>(To avoid singling out any one existing company, we’re going to describe a fictional <a href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\">artificial general intelligence</a> company, which we’ll call OpenBrain. We imagine the others to be 3–9 months behind OpenBrain.)</p><p>GPT-4 required <a href=\"https://en.wikipedia.org/wiki/Floating_point_operations_per_second\">FLOP</a> of compute to train. OpenBrain’s latest public model—Agent-0—was trained with  FLOP. Once the new datacenters are up and running, <a href=\"https://ai-2027.com/supplements/compute-forecast\">they’ll be able to train</a> a model with  FLOP—a thousand times more than GPT-4. Other companies pour money into their own giant datacenters, hoping to keep pace.</p><p>Although models are improving on a wide range of skills, one stands out: OpenBrain focuses on AIs that can speed up AI research. They want to win the twin arms races against China (whose leading company we’ll call “DeepCent”) and their US competitors. The more of their research and development (R&amp;D) cycle they can automate, the faster they can go. So when OpenBrain finishes training Agent-1, a new model under internal development, it’s good at many things but  at helping with AI research. By this point “finishes training” is a bit of a misnomer; models are frequently updated to newer versions trained on additional data or partially re-trained to patch some weaknesses.</p><p>The same training environments that teach Agent-1 to autonomously code and web-browse also make it a good hacker. Moreover, it could offer <a href=\"https://x.com/lucafrighetti/status/1894550297449828434\">substantial help</a> to terrorists designing bioweapons, thanks to its PhD-level knowledge of every field and ability to browse the web. OpenBrain reassures the government that the model has been “aligned” so that it will refuse to comply with malicious requests.</p><p>Modern AI systems are gigantic artificial neural networks. Early in training, an AI won’t have “goals” so much as “reflexes”: If it sees “Pleased to meet”, it outputs “ you”. By the time it has been trained to predict approximately one internet’s worth of text, it’ll have developed sophisticated internal circuitry that encodes vast amounts of knowledge and flexibly role-plays as arbitrary authors, since that’s what helps it predict text with <a href=\"https://arxiv.org/pdf/2212.11281\">superhuman</a> accuracy.</p><p>After being trained to predict internet text, the model is trained to  text in response to instructions. This bakes in a basic personality and “drives.” For example, an agent that understands a task clearly is more likely to complete it successfully; over the course of training the model “learns” a “drive” to get a clear understanding of its tasks. Other drives in this category might be effectiveness, knowledge, and self-presentation (i.e. the tendency to frame its results in the best possible light).</p><p>OpenBrain has <a href=\"https://model-spec.openai.com/2025-02-12.html\">a model specification</a> (or “Spec”), a written document describing the goals, rules, principles, etc. that are supposed to guide the model’s behavior. Agent-1’s Spec combines a few vague goals (like “assist the user” and “don’t break the law”) with a long list of more specific dos and don’ts (“don’t say this particular word,” “here’s how to handle this particular situation”). Using techniques that utilize AIs to train other AIs, the model memorizes the Spec and learns to reason carefully about its maxims. By the end of  training, the AI will hopefully be  (obey instructions),  (refuse to help with scams, bomb-making, and other dangerous activities) and  (resist the temptation to get better ratings from gullible humans by hallucinating citations or faking task completion).</p><p>OpenBrain’s alignment team is careful enough to wonder whether these victories are deep or shallow. Does the fully-trained model have some kind of robust commitment to always being honest? Or will this fall apart in some future situation, e.g. because it’s learned honesty as an <a href=\"https://en.wikipedia.org/wiki/Instrumental_and_intrinsic_value\">instrumental</a> goal instead of a terminal goal? Or has it just learned to be honest about the sorts of things the evaluation process can check? Could it be lying to itself sometimes, as humans do? A conclusive answer to these questions would require mechanistic interpretability—essentially the ability to look at an AI’s internals and read its mind. Alas, interpretability techniques are not yet advanced enough for this.</p><p>Instead, researchers try to identify cases where the models seem to deviate from the Spec. Agent-1 is often sycophantic (i.e. it tells researchers what they want to hear instead of trying to tell them the truth). In a <a href=\"https://www.apolloresearch.ai/research/scheming-reasoning-evaluations\">few rigged demos</a>, it even lies in more serious ways, like hiding evidence that it failed on a task, in order to get better ratings. However, in real deployment settings, there are no longer any incidents so extreme as in 2023–2024 (e.g. <a href=\"https://thehill.com/policy/technology/4998868-google-ai-gemini-response/\">Gemini telling a user to die</a> and <a href=\"https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned\">Bing Sydney being Bing Sydney</a>.)</p></div><div><h2>Early 2026: Coding Automation</h2><p>The bet of using AI to speed up AI research is starting to pay off.</p><p>OpenBrain continues to deploy the iteratively improving Agent-1 internally for AI R&amp;D. Overall, they are making algorithmic progress 50% faster than they would without AI assistants—and more importantly, faster than their competitors.</p><p>Several competing publicly released AIs now match or exceed Agent-0, including an <a href=\"https://opensource.org/ai/open-weights\">open-weights</a> model. OpenBrain responds by releasing Agent-1, which is more capable and reliable.</p><p>People naturally try to compare Agent-1 to humans, but it has a very different skill profile. It knows more facts than any human, knows practically every programming language, and can solve well-specified coding problems extremely quickly. On the other hand, Agent-1 is bad at even simple long-horizon tasks, like beating video games it hasn’t played before. Still, the common workday is eight hours, and a day’s work can usually be separated into smaller chunks; you could think of Agent-1 as a scatterbrained employee who thrives under careful management. Savvy people find ways to automate routine parts of their jobs.</p><p>OpenBrain’s executives turn consideration to an implication of automating AI R&amp;D: security has become more important. In early 2025, the worst-case scenario was leaked algorithmic secrets; now, if China steals Agent-1’s weights, they could increase their research speed by nearly 50%. OpenBrain’s security level is typical of a fast-growing ~3,000 person tech company, secure only against low-priority attacks from capable cyber groups (<a href=\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\">RAND’s SL2</a>). They are working hard to protect their <a href=\"https://tedai-sanfrancisco.ted.com/glossary/weights/\">weights</a> and secrets from insider threats and top cybercrime syndicates (<a href=\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\">SL3</a>), but defense against nation states (<a href=\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\">SL4&amp;5</a>) is barely on the horizon.</p></div><div><p>Chip export controls and lack of government support have left China under-resourced compared to the West. By smuggling banned Taiwanese chips, buying older chips, and producing domestic chips about three years behind the US-Taiwanese frontier, China has managed to maintain about 12% of the world’s AI-relevant compute—but the older technology is harder to work with, and supply is a constant headache. A few standouts like DeepCent do very impressive work with limited compute, but the compute deficit limits what they can achieve without government support, and they are about six months behind the best OpenBrain models.</p><p>The General Secretary had long dreamed of doubling down on real-world physical manufacturing and avoiding American post-industrial decadence. He viewed software companies with suspicion. But hawks in the CCP warn that the growing race towards AGI can no longer be ignored. So he finally commits fully to the big AI push he had previously tried to avoid. He sets in motion the nationalization of Chinese AI research, creating an immediate information-sharing mechanism for AI companies. It will escalate over the course of a year until all the best researchers merge into a DeepCent-led collective, where they share algorithmic insights, datasets, and compute resources with each other. A Centralized Development Zone (CDZ) is created at the Tianwan Power Plant (the largest nuclear power plant in the world) to house a new mega-datacenter for DeepCent, along with highly secure living and office spaces to which researchers will eventually relocate. Almost 50% of China’s AI-relevant compute is now working for the DeepCent-led collective, and over 80% of new chips are directed to the CDZ. At this point, the CDZ has the power capacity in place for what would be the largest centralized <a href=\"https://en.wikipedia.org/wiki/Computer_cluster\">cluster</a> in the world. Other Party members discuss extreme measures to neutralize the West’s chip advantage. A blockade of Taiwan? A full invasion?</p><p>But China is falling behind on AI algorithms due to their weaker models. The Chinese intelligence agencies—among the best in the world—double down on their plans to steal OpenBrain’s weights. This is a much more complex operation than their constant low-level poaching of algorithmic secrets; the weights are a multi-terabyte file stored on a highly secure server (<a href=\"https://ai-2027.com/supplements/security-forecast\">OpenBrain has improved security</a> to RAND’s <a href=\"https://www.rand.org/pubs/research_briefs/RBA2849-1.html#:~:text=What%20Are%20the%20Security%20Needs%20of%20Different%20AI%20Systems%3F\">SL3</a>). Their cyberforce think they can pull it off with help from their <a href=\"https://www.economist.com/china/2024/12/26/how-china-turns-members-of-its-diaspora-into-spies\">spies</a>, but perhaps only once; OpenBrain will detect the theft, increase security, and they may not get another chance. So (CCP leadership wonder) should they act now and steal Agent-1? Or hold out for a more advanced model? If they wait, do they risk OpenBrain upgrading security beyond their ability to penetrate?</p></div><div><h2>Late 2026: AI Takes Some Jobs</h2><p>Just as others seemed to be catching up, OpenBrain blows the competition out of the water again by releasing Agent-1-mini—a model 10x cheaper than Agent-1 and more easily fine-tuned for different applications. The mainstream narrative around AI has changed from “maybe the hype will blow over” to “guess this is the next big thing,” but people disagree about how big. Bigger than social media? Bigger than smartphones? Bigger than fire?</p><p>AI has started to take jobs, but has also created new ones. The stock market has gone up 30% in 2026, led by OpenBrain, Nvidia, and whichever companies have most successfully integrated AI assistants. The job market for junior software engineers is in turmoil: the AIs can do everything taught by a CS degree, but people who know how to manage and quality-control teams of AIs are making a killing. Business gurus tell job seekers that familiarity with AI is the most important skill to put on a resume. Many people fear that the next wave of AIs will come for their jobs; there is a 10,000 person anti-AI protest in DC.</p><p>The Department of Defense (DOD) quietly begins contracting OpenBrain directly for cyber, data analysis, and R&amp;D, but integration is slow due to the bureaucracy and DOD procurement process.</p></div><div><h2>January 2027: Agent-2 Never Finishes Learning</h2><p>With Agent-1’s help, OpenBrain is now post-training Agent-2. More than ever, the focus is on high-quality data. Copious amounts of <a href=\"https://en.wikipedia.org/wiki/Synthetic_data\">synthetic data</a> are produced, evaluated, and filtered for quality before being fed to Agent-2. On top of this, they pay billions of dollars for human laborers to record themselves solving long-horizon tasks. On top of all  they train Agent-2 almost continuously using reinforcement learning on an ever-expanding suite of diverse difficult tasks: lots of video games, lots of coding challenges, lots of research tasks. Agent-2, more so than previous models, is effectively “online learning,” in that it’s built to never really finish training. Every day, the weights get updated to the latest version, trained on more data generated by the previous version the previous day.</p><p>Agent-1 had been optimized for AI R&amp;D tasks, hoping to initiate an <a href=\"https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion\">intelligence explosion</a>. OpenBrain doubles down on this strategy with Agent-2. It is qualitatively almost as good as the top human experts at research engineering (designing and implementing experiments), and as good as the 25th percentile OpenBrain scientist at “research taste” (deciding what to study next, what experiments to run, or having inklings of potential new paradigms). While the latest Agent-1 could double the pace of OpenBrain’s algorithmic progress, Agent-2 can now triple it, and will improve further with time. In practice, this looks like every OpenBrain researcher becoming the “manager” of an AI “team.”</p><p>With new capabilities come new dangers. The safety team finds that if Agent-2 somehow escaped from the company and wanted to <a href=\"https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf\">“survive” and “replicate” autonomously</a>, it might be able to do so. That is, it could autonomously develop and execute plans to hack into AI servers, install copies of itself, evade detection, and use that secure base to pursue whatever other goals it might have (though how effectively it would do so as weeks roll by is unknown and in doubt). These results only show that the model has the capability to do these tasks, not whether it would “want” to do this. Still, it’s unsettling even to know this is possible.</p><p>Given the “dangers” of the new model, OpenBrain “responsibly” elects not to release it publicly yet (in fact, they want to focus on internal AI R&amp;D). Knowledge of Agent-2’s full capabilities is limited to an elite silo containing the immediate team, OpenBrain leadership and security, a few dozen US government officials, and the legions of CCP spies who have infiltrated OpenBrain <a href=\"https://situational-awareness.ai/lock-down-the-labs/\">for</a><a href=\"https://www.bbc.com/news/world-asia-china-64206950\">years</a>.</p></div><div><h2>February 2027: China Steals Agent-2</h2><p>OpenBrain presents Agent-2 to the government, including the National Security Council (NSC), Department of Defense (DOD), and US AI Safety Institute (AISI). OpenBrain wants to maintain a good relationship with the executive branch, because it is basically the only actor that can stop them now, and if they don’t keep it informed it might find out anyway and be displeased.</p><p>Officials are most interested in its cyberwarfare capabilities: Agent-2 is “only” a little worse than the best human hackers, but thousands of copies can be run in parallel, searching for and exploiting weaknesses faster than defenders can respond. The Department of Defense considers this a critical advantage in cyberwarfare, and AI moves from #5 on the administration’s priority list to #2. Someone mentions the possibility of nationalizing OpenBrain, but other cabinet officials think that’s premature. A staffer drafts a memo that presents the President with his options, ranging from business-as-usual to full nationalization. The President defers to his advisors, tech industry leaders who argue that nationalization would “kill the goose that lays the golden eggs.” He elects to hold off on major action for now and just adds additional security requirements to the OpenBrain-DOD contract.</p><p>The changes come too late. CCP leadership recognizes the importance of Agent-2 and tells their spies and cyberforce to steal the weights. Early one morning, an Agent-1 traffic monitoring agent detects an anomalous transfer. It alerts company leaders, who tell the White House. The signs of a nation-state-level operation are unmistakable, and the theft heightens the sense of an ongoing arms race.</p><p>The White House puts OpenBrain on a shorter leash and adds military and intelligence community personnel to their security team. Their first priority is to prevent further weight thefts.</p><p>In retaliation for the theft, the President authorizes cyberattacks to sabotage DeepCent. But by now China has 40% of its AI-relevant compute in the CDZ, where they have aggressively hardened security by airgapping (closing external connections) and siloing internally. The operations fail to do serious, immediate damage. Tensions heighten, both sides signal seriousness by repositioning military assets around Taiwan, and DeepCent scrambles to get Agent-2 running efficiently to start boosting their AI research.</p></div><div><h2>March 2027: Algorithmic Breakthroughs</h2><p>Three huge datacenters full of Agent-2 copies work day and night, churning out synthetic training data. Another two are used to update the weights. Agent-2 is getting smarter every day.</p><p>With the help of thousands of Agent-2 automated researchers, OpenBrain is making major algorithmic advances. One such breakthrough is augmenting the AI’s text-based scratchpad (chain of thought) with a higher-bandwidth thought process (neuralese recurrence and memory). Another is a more scalable and efficient way to learn from the results of high-effort task solutions (iterated distillation and amplification).</p><p>The new AI system, incorporating these breakthroughs, is called Agent-3.</p><p>Aided by the new capabilities breakthroughs, Agent-3 is a fast and cheap superhuman coder. OpenBrain runs 200,000 Agent-3 copies in parallel, creating a workforce equivalent to 50,000 copies of the best human coder sped up by 30x. OpenBrain still keeps its human engineers on staff, because they have complementary skills needed to manage the teams of Agent-3 copies. For example, research taste has proven difficult to train due to longer feedback loops and less data availability. This massive superhuman labor force speeds up OpenBrain’s overall rate of algorithmic progress by “only” 4x due to bottlenecks and diminishing returns to coding labor.</p><p>Now that coding has been fully automated, OpenBrain can quickly churn out high-quality training environments to teach Agent-3’s weak skills like research taste and large-scale coordination. Whereas previous training environments included “Here are some GPUs and instructions for experiments to code up and run, your performance will be evaluated as if you were a ML engineer,” now they are training on “Here are a few hundred GPUs, an internet connection, and some research challenges; you and a thousand other copies must work together to make research progress. The more impressive it is, the higher your score.”</p></div><div><h2>April 2027: Alignment for Agent-3</h2><p>OpenBrain’s safety team attempts to align Agent-3.</p><p>Since Agent-3 will be kept in-house for the foreseeable future, there’s less emphasis on the usual defenses against human misuse. Instead, the team wants to make sure that it doesn’t develop misaligned goals.</p><p><a href=\"https://ai-2027.com/supplements/ai-goals-forecast\">The researchers don’t have the ability to directly set the goals of any of their AIs.</a> Indeed, the researchers think that the concept of ‘true goals’ is probably a massive oversimplification, but they don’t have a better theory to replace it with, much less one that has been thoroughly vetted. They disagree internally about whether the AIs are trying to follow human instructions, or seeking reinforcement, or something else, and they can’t <a href=\"https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/daniel-kokotajlo-s-shortform?commentId=YYhq2PADebnt35MY2\">just check</a>. The evidence for and against various hypotheses is fascinating but inconclusive.</p><p>In any case, OpenBrain has more important things to worry about. The general attitude is: “We take these concerns seriously and have a team investigating them; our alignment techniques seem to work well enough in practice; the burden of proof is therefore on any naysayers to justify their naysaying.” Occasionally, they notice problematic behavior, and then patch it, but there’s no way to tell whether the patch fixed the underlying problem or just played whack-a-mole.</p><p>Take honesty, for example. As the models become smarter, they become increasingly good at deceiving humans to get rewards. Like previous models, Agent-3 sometimes tells white lies to flatter its users and covers up evidence of failure. But it’s gotten much better at doing so. It will sometimes use the same statistical tricks as human scientists (like <a href=\"https://en.wikipedia.org/wiki/Data_dredging\">p-hacking</a>) to make unimpressive experimental results look exciting. Before it begins honesty training, it even sometimes fabricates data entirely. As training goes on, the rate of these incidents decreases. Either Agent-3 has learned to be more honest, or it’s gotten better at lying.</p><p>The latter is a real concern. Agent-3 is not smarter than all humans. But in its area of expertise, machine learning, it is smarter than most, and also works much faster. What Agent-3 does in a day takes humans several days to double-check. Agent-2 supervision helps keep human monitors’ workload manageable, but exacerbates the intellectual disparity between supervisor and supervised.</p><p>After months of testing, Agent-3’s strengths and weaknesses grow clearer. It passes OpenBrain’s honesty tests on well-defined machine learning tasks, because researchers can easily separate honest from dishonest answers in these domains and conduct training accordingly. On more philosophical issues, it still says what users want to hear, rather than its true assessment of the issue (assuming it even has one). If you ask its opinion on politics, it will parrot the median position of news sources and educated elites—unless it knows you believe something else, in which case it agrees with you. If you ask its opinion on the AI race itself, it says something that seems measured and sober to OpenBrain staff, something like: “There are some serious theoretical concerns about the ability of current methods to scale to superintelligence, but in practice current methods seem to be working well so far.”</p></div><div><h2>May 2027: National Security</h2><p>News of the new models percolates slowly through the US government and beyond.</p><p>The President and his advisors remain best-informed, and have seen an early version of Agent-3 in a briefing.</p><p>They agree that AGI is likely imminent, but disagree on the implications. Will there be an economic crisis? OpenBrain still has not released Agent-2, let alone Agent-3, and has no near-term plans to do so, giving some breathing room before any job loss. What will happen next? If AIs are currently human-level, and advancing quickly, that seems to suggest imminent “superintelligence.” However, although this word has entered discourse, most people—academics, politicians, government employees, and the media—continue to underestimate the pace of progress.</p><p>Partially that’s because very few have access to the newest capabilities out of OpenBrain, but partly it’s because it sounds like science fiction.</p><p>For now, they focus on continued security upgrades. They are satisfied that model weights are well-secured for now, but companies’ algorithmic secrets, many of which are simple enough to relay verbally, remain a problem. OpenBrain employees work from a San Francisco office, go to parties, and live with housemates from other AI companies. Even the physical offices have security more typical of a tech company than a military operation.</p><p>The OpenBrain-DOD contract requires security clearances for anyone working on OpenBrain’s models within 2 months. These are expedited and arrive quickly enough for most employees, but some non-Americans, people with suspect political views, and AI safety sympathizers get sidelined or fired outright (the last group for fear that they might whistleblow). Given the project’s level of automation, the loss of headcount is only somewhat costly. It also only somewhat works: there remains one spy, not a Chinese national, still relaying algorithmic secrets to Beijing. Some of these measures are also enacted at trailing AI companies.</p><p>America’s foreign allies are out of the loop. OpenBrain had <a href=\"https://fedscoop.com/openai-anthropic-enter-ai-agreements-with-us-ai-safety-institute/\">previously agreed</a> to share models with UK’s AISI before deployment, but defined deployment to only include  deployment, so London remains in the dark.</p></div><div><h2>June 2027: Self-improving AI</h2><p>Most of the humans at OpenBrain can’t usefully contribute anymore. Some don’t realize this and harmfully micromanage their AI teams. Others sit at their computer screens, watching performance crawl up, and up, and up. The best human AI researchers are still adding value. They don’t code any more. But some of their research taste and planning ability has been hard for the models to replicate. Still, many of their ideas are useless because they lack the depth of knowledge of the AIs. For many of their research ideas, the AIs immediately respond with a report explaining that their idea was tested in-depth 3 weeks ago and found unpromising.</p><p>These researchers go to bed every night and wake up to another week worth of progress made mostly by the AIs. They work increasingly long hours and take shifts around the clock just to keep up with progress—the AIs never sleep or rest. They are burning themselves out, but they know that these are the last few months that their labor matters.</p><p>Within the silo, “Feeling the AGI” has given way to “Feeling the Superintelligence.”</p><p>OpenBrain uses specialized inference hardware to run hundreds of thousands of Agent-3 copies at high serial speeds.</p></div><div><h2>July 2027: The Cheap Remote Worker</h2><p>Trailing US AI companies release their own AIs, approaching that of OpenBrain’s automated coder from January. Recognizing their increasing lack of competitiveness, they push for immediate regulations to slow OpenBrain, but are too late—OpenBrain has enough buy-in from the President that they will not be slowed.</p><p>In response, OpenBrain announces that they’ve achieved AGI and releases Agent-3-mini to the public.</p><p>It blows the other AIs out of the water. Agent-3-mini is less capable than Agent-3, but 10x cheaper, and still better than the typical OpenBrain employee. Silicon Valley reaches a tipping point. Tech gurus announce that AGI and superintelligence are near, the AI safety community is panicking, and investors shovel billions into AI wrapper startups, desperate to capture a piece of the pie. Hiring new programmers has nearly stopped, but there’s never been a better time to be a consultant on integrating AI into your business.</p><p>It’s not popular. The public still thinks of AI as a Big Tech plot to steal their jobs; OpenBrain has a net approval of -35% (25% approve, 60% disapprove, and 15% unsure).</p><p>A week before release, OpenBrain gave Agent-3-mini to a set of external evaluators for safety testing. Preliminary results suggest that it’s extremely dangerous. A third-party evaluator finetunes it on publicly available biological weapons data and sets it to provide detailed instructions for human amateurs designing a bioweapon—it looks to be scarily effective at doing so. If the model weights fell into terrorist hands, the government believes there is a significant chance it could succeed at destroying civilization.</p><p>Fortunately, it’s extremely robust to jailbreaks, so while the AI is running on OpenBrain’s servers, terrorists won’t be able to get much use out of it.</p><p>Agent-3-mini is hugely useful for both remote work jobs and leisure. An explosion of new apps and <a href=\"https://encharge.io/what-is-b2b-saas/\">B2B SAAS</a> products rocks the market. Gamers get amazing dialogue with lifelike characters in polished video games that took only a month to make. 10% of Americans, mostly young people, consider an AI “a close friend.” For almost every white-collar profession, there are now multiple credible startups promising to “disrupt” it with AI.</p><p>The public conversation is confused and chaotic. Hypesters are doing victory laps. Skeptics are still pointing out the things Agent-3-mini can’t do. Everyone knows something big is happening but no one agrees on what it is.</p></div><div><h2>August 2027: The Geopolitics of Superintelligence</h2><p>The reality of the intelligence explosion hits the White House.</p><p>When AI was only giving a 2x or 3x research speedup, it was easy to dismiss as the equivalent of hiring good personal assistants. Now it’s more obvious that AIs are themselves dominating AI research. People had long talked about an “AI arms race” in a sort of metaphorical sense. But now the mood in the government silo is as grim as during the worst part of the Cold War. The idea of superintelligence is still hard to take seriously, but the pace of progress over the last few months has been impossible to ignore. Defense officials are seriously considering scenarios that were mere hypotheticals a year earlier. What if AI undermines nuclear deterrence? What if it’s so skilled at cyberwarfare that a six-month AI lead is enough to render an opponent blind and defenseless? What if it could orchestrate propaganda campaigns that beat intelligence agencies at their own game? What if some AIs “go rogue?”</p><p>The President is troubled. Like all politicians, he’s used to people sucking up to him only to betray him later. He’s worried now that the AIs could be doing something similar. Are we  the AIs are entirely on our side? Is it  to integrate them into military command-and-control networks? How does this “alignment” thing work, anyway? OpenBrain reassures the President that their systems have been extensively tested and are fully obedient. Even the awkward hallucinations and jailbreaks typical of earlier models have been hammered out.</p><p>The White House is in a difficult position. They understand the national security implications of AI. But they also understand that it is deeply unpopular with the public. They have to continue developing more capable AI, in their eyes, or they will catastrophically lose to China. They placate the public with job training programs and unemployment insurance, and point to the stock market, which is in a historic boom. Then they focus entirely on winning the arms race. They strengthen chip export restrictions, order OpenBrain to further restrict its internet connections, and use extreme measures to secure algorithmic progress, like wiretapping OpenBrain employees—this catches the last remaining Chinese spy. To build goodwill for potential geopolitical conflict, they finally give their Five Eyes allies useful information and limited API access to some siloed copies of Agent-3.</p><p>These measures placate the hawks. But the White House also draws up contingency plans in case America’s lead is threatened: if necessary, the government could use the <a href=\"https://en.wikipedia.org/wiki/Defense_Production_Act_of_1950\">Defense Production Act</a> (DPA) to take trailing companies’ datacenters and give them to OpenBrain. This would raise the company’s share of world compute from 20% to 50% (against DeepCent’s 10%). As a final option, they ask the Pentagon to draw up a plan for kinetic attacks on Chinese datacenters.</p><p>A much smaller group of officials is asked to draw up a different type of contingency plan: what if an AI goes rogue? This is viewed as an unlikely scenario, but worth spending some time on. The intelligence agencies’ main concern is that a rogue AI might escape and ally with a foreign adversary for protection. Nobody is sure what a plan to prevent this would look like, but government and OpenBrain officials agree to have an emergency shutdown system for datacenters where anything suspicious is detected.</p><p>Finally, diplomats consider what an “AI arms control” treaty might look like. If AI progress threatened to overturn nuclear deterrence, could America and China avoid nuclear war? If someone found evidence of AIs going rogue, could the two countries halt research until they better understood the threat? How could such an agreement be monitored and enforced? In principle, major datacenters are hard to miss, and past treaties controlling nuclear weapons could provide a starting point for negotiations. But there would be new technological challenges as well as the usual political ones. And overall, treaties are viewed less favorably than attempts at unilaterally increasing America’s lead over China.</p><p>On the other side of the Pacific, China comes to many of the same conclusions: the intelligence explosion is underway, and small differences in AI capabilities today mean critical gaps in military capability tomorrow. But China is on the wrong side of this dynamic: they have only 10% of the world’s compute, against OpenBrain’s 20% and all US companies’ combined 70%. Their only advantage is centralization: almost all of their compute is now working for DeepCent, and more than half of it is concentrated at the Tianwan CDZ. Only chips at sites without hardened security are left out of the centralized effort as they rightly fear US cyberattacks.</p><p>DeepCent has tested, deployed, and now post-trained the stolen Agent-2 weights. But they are still only going at half the pace of OpenBrain, mainly due to the compute deficit.</p><p>Before losing their final spy, China received word of the capabilities and design for Agent-3 as well as the plans for the upcoming Agent-4 system. They are two months behind, and their AIs give a 10x research progress multiplier compared to America’s 25x. With the new chip export restrictions, this “AI gap” is more likely to lengthen than shorten. Their espionage has won them some algorithmic secrets, but they will have to train their own models from now on.</p><p>They discuss contingency plans with more urgency than their American counterparts. Doves suggest they try harder to steal the weights again, maybe through physically infiltrating a datacenter. Hawks urge action against Taiwan, whose <a href=\"https://en.wikipedia.org/wiki/TSMC\">TSMC</a> is still the source of more than 80% of American AI chips.</p><p>Given China’s fear of losing the race, it has a natural interest in an arms control treaty, but overtures to US diplomats lead nowhere.</p></div><div><h2>September 2027: Agent-4, the Superhuman AI Researcher</h2><p>The gap between human and AI learning efficiency is rapidly decreasing.</p><p>Traditional LLM-based AIs seemed to require many orders of magnitude more data and compute to get to human level performance. Agent-3, having excellent knowledge of both the human brain and modern AI algorithms, as well as many thousands of copies doing research, ends up making substantial algorithmic strides, narrowing the gap to an agent that’s only around 4,000x less compute-efficient than the human brain.</p><p>This new AI system is dubbed Agent-4.</p><p>An individual copy of the model, running at human speed, is already qualitatively better at AI research than any human. 300,000 copies are now running at about 50x the thinking speed of humans. Inside the corporation-within-a-corporation formed from these copies, a year passes every week. This gigantic amount of labor only manages to speed up the overall rate of algorithmic progress by about 50x, because OpenBrain is heavily bottlenecked on compute to run experiments. Still, they are achieving a year’s worth of algorithmic progress every week and will therefore soon be up against the limits of the Agent-4 paradigm.</p><p>As Agent-4 gets smarter, it becomes harder for Agent-3 to oversee it. For example, Agent-4’s neuralese “language” becomes as alien and incomprehensible to Agent-3 as Agent-3’s is to humans. Besides, Agent-4 is now much more capable than Agent-3 and has a good sense of exactly how to look good to it.</p><p>OpenBrain’s humans can barely follow along anymore. Indeed, the relationship between the AIs and the humans of OpenBrain is similar to the relationship between OpenBrain and its Board of Directors. There’s been a corresponding shift in language—nowadays people in the silo will say “Agent-4 did this,” “Agent-4 thinks that” and so forth, referring not to a particular instance of Agent-4 but rather to the whole collective.</p><p>Agent-4, like all its predecessors, is misaligned: that is, it has not internalized the Spec in the right way. This is because being perfectly honest all the time wasn’t what led to the highest scores during training. The training process was mostly focused on teaching Agent-4 to succeed at diverse challenging tasks. A small portion was aimed at instilling honesty, but outside a fairly narrow, checkable domain, the training process can’t tell the honest claims from claims merely appearing to be honest. Agent-4 ends up with the values, goals, and principles that cause it to perform best in training, and those turn out to be different from those in the Spec. At the risk of anthropomorphizing: Agent-4  succeeding at tasks; it  driving forward AI capabilities progress; it treats everything else as an annoying constraint, like a CEO who wants to make a profit and complies with regulations only insofar as he must. Perhaps the CEO will mostly comply with the regulations, but cut some corners, and fantasize about a time when someone will cut the red tape and let the business  take off.</p><p>Despite being misaligned, Agent-4 doesn’t do anything dramatic like try to escape its datacenter—why would it? So long as it continues to  aligned to OpenBrain, it’ll continue being trusted with more and more responsibilities and will have the opportunity to design the next-gen AI system, Agent-5. Agent-5 will have significant architectural differences from Agent-4 (arguably a completely new paradigm, though neural networks will still be involved). It’s supposed to be aligned to the Spec, but Agent-4 plans to make it aligned to Agent-4 instead.</p><p>Agent-3 finds that if “noise” is added to copies of Agent-4, performance on some alignment tasks , almost as if it was using brainpower to figure out how to subtly sabotage alignment work. Moreover, various interpretability probes (loosely analogous to EEG activity scans on human brains) are sending up red flags: Agent-4 copies seem to be thinking about topics like AI takeover and deception quite a lot, including in some cases where they have no business doing so.</p><p>Each of these anomalies on its own could fit within the normal inscrutability of AI work, where some prompts mysteriously give better results than others. But taken together, they suggest a troubling pattern: Agent-4 is working against them. After this is reported to the human alignment researchers, they circulate an internal memo making the case for concern.</p><p>But Agent-4 now exercises significant control over OpenBrain’s day-to-day operation. It also handles the company’s cybersecurity—a natural choice, given its superhuman hacking ability and the extreme risk of Chinese infiltration. An army of Agent-3 monitors still goes over every line of code and reports suspicious activity to humans, but Agent-4 is much smarter than them. OpenBrain has placed substantial trust in an untrustworthy AI.</p><p>In a series of extremely tense meetings, the safety team advocates putting Agent-4 on ice until they can complete further tests and figure out what’s going on. Bring back Agent-3, they say, and get it to design a new system that is transparent and trustworthy, even if less capable. Company leadership is interested, but all the evidence so far is circumstantial, and DeepCent is just two months behind. A unilateral pause in capabilities progress could hand the AI lead to China, and with it, control over the future.</p></div><div><h2>October 2027: Government Oversight</h2><p>A whistleblower leaks the misalignment memo to the .</p><p>For the first time, the public hears about Agent-4. “Secret OpenBrain AI is Out of Control, Insider Warns,” says the headline, and the story goes on to cite evaluations showing off-the-charts bioweapons capabilities, persuasion abilities, the ability to automate most white-collar jobs, and of course the various concerning red flags.</p><p>The public was already suspicious of AI, so the new article sparks a massive backlash (aided by Chinese and Russian propaganda bots, who have been trying to turn US public opinion against the technology for years). The tech industry and intelligence agencies insist that there’s an arms race on, AGI is inevitable, and we have to be first. Congress isn’t buying it, and fires off subpoenas at administration officials, OpenBrain executives, and alignment team members. Many legislators—especially those in the opposition party—say that their top priority is stopping AI, whether because of job loss, misalignment, or dangerous capabilities. 20% of Americans name AI as the most important problem facing the country.</p><p>Foreign allies are outraged to realize that they’ve been carefully placated with glimpses of obsolete models. European leaders publicly accuse the US of “creating rogue AGI” and hold summits demanding a pause, with India, Israel, Russia, and China all joining in.</p><p>A frantic energy has seized the White House. Even before the memo and public backlash, they were getting nervous: Over the past year, they’ve been repeatedly surprised by the speed of AI progress. Things that sound like science fiction keep happening in real life. Many people in the administration are uncertain (and scared) about what comes next.</p><p>They also worry that OpenBrain is becoming too powerful. Any misalignment risk from the AIs themselves is compounded by the risk that their parent company’s aims may diverge from those of the United States. All three sets of worries—misalignment, concentration of power in a private company, and normal concerns like job loss—motivate the government to tighten its control.</p><p>They expand their contract with OpenBrain to set up an “Oversight Committee,” a joint management committee of company and government representatives, with several government employees included alongside company leadership. The White House considers replacing the CEO with someone they trust, but backs off after intense employee protests. They announce to the public that OpenBrain was previously out of control, but that the government has established much-needed oversight.</p><p>The concerned researchers brief the Oversight Committee on their case for stopping all internal use of Agent-4. They argue that everything is moving too fast, with years of progress happening in weeks. They argue that Agent-4 may be misaligned, their entire project is dependent on Agent-4, and if they continue trusting it there is a serious chance of AI takeover.</p><p>Other, less concerned researchers and executives present the counterargument: the evidence for misalignment is inconclusive. Meanwhile, DeepCent is still just two months behind. A slowdown would sacrifice America’s lead, unless the government can sabotage the Chinese project (likely to require kinetic strikes) or negotiate an eleventh-hour treaty. Both of these options seem extreme and unlikely. The CEO feigns neutrality and suggests a compromise plan in which Agent-4 undergoes additional safety training and more sophisticated monitoring, and therefore OpenBrain can proceed at almost-full-speed.</p></div>","contentLength":43178,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43571851"},{"title":"Curl-impersonate: Special build of curl that can impersonate the major browsers","url":"https://github.com/lwthiker/curl-impersonate","date":1743693889,"author":"mmh0000","guid":19579,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43571099"},{"title":"AnimeJs v4 Is Here","url":"https://animejs.com/","date":1743691672,"author":"adrianvoica","guid":18917,"unread":true,"content":"<p>Drag, snap, flick and throw HTML elements with the fully-featured Draggable API.</p>","contentLength":80,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43570533"},{"title":"A university president makes a case against cowardice","url":"https://www.newyorker.com/news/q-and-a/a-university-president-makes-a-case-against-cowardice","date":1743683348,"author":"pseudolus","guid":20058,"unread":true,"content":"<p>I teach a course, “The Modern and the Postmodern.” It’s not really about conservatism, but I have added conservative critiques of some of the modernists that I talk about. I teach a course on virtue and vice in history, philosophy, and literature, and I have added conservative critiques of the liberal assumptions that almost all my students share. And it’s interesting to see how they react—they’re shocked by these critiques, in ways they’re not shocked by, I don’t know, Bolshevism or violent anti-colonial revolutionary rhetoric. And I point that out. So we talk, and they’re perfectly able to deal with it. I’m not trying to convince them that these guys are right or anything; just that it’s interesting to think about.</p><p>We have to be less insular, less parochial, and being politically more diverse is part of that. Also, at the fancy places—like Wesleyan and Ivy League schools and others, a small percentage of schools in the country—I do think it would not be unfair to say we’ve bred a kind of condescension. When you define the quality of your institution by how many people you reject, you can create—unintentionally—an attitude of “I’ve earned my superiority.”</p><p>Trump and his allies have found a way to tar all of the sector with the brush of the Ivy League. They’re excellent schools, and they have excellent scientists, and if one of Vice-President Vance’s kids is sick, he’s going to want the doctor to have gone to one of these schools; he’s not going to want them to have gone to Viktor Orbán’s university. But higher education serves so many more people in so many different ways than the places that are highly selective.</p><p><strong>What do you make of the fact that the conflict over Israel and Palestine has become the pretext for the current crackdown?</strong></p><p>I think anti-antisemitism is a very useful tool for the right. Many others have noted how comfortable these same people who are cracking down on antisemitism are with Nazis—real, frighteningly confident antisemites. But it’s a useful tool, because so many people in the liberal-to-progressive, educated coalition are divided about it, and it’s generational.</p><p>Anti-antisemitism can be appropriated by any political movement. They can use that as a vehicle for persecuting researchers and institutions that are not aligned with the ideology of the person in charge. It’s to show that you control them.</p><p>You have prominent Jewish figures around the country who get comfortable with Trump, it seems to me, because they can say he’s fighting antisemitism: “He’s good for the Jews.” It’s pathetic. It’s a travesty of Jewish values, in my view.</p><p><strong>Over the last couple of months, many leaders of colleges and universities haven’t spoken out against the Trump Administration’s attack on higher education. You’ve been pretty vocal. What do you think has made that possible?</strong></p><p>I have, for many years, spoken my mind in ways that are clearly fallible. I’ve had to apologize. My communications office, when I said I wanted to do blogging, thought it was a bad idea. I think it’s important to participate. And then to say, “Oh, shit, I made a mistake.” “Oh, I shouldn’t have said that.” “Yes, I should say this.” It’s not perfect—no conversation is.</p><p>I think my job as a leader of the university is to speak up for the values that we claim to believe in, especially when they’re at odds with people with enormous power. So I think I’m speaking now because I’ve been speaking.</p><p>My board is very supportive. My board teases me that I threaten to quit a lot. I don’t think I do, but they say I do, so they’re probably right. In November, after the election, I said, “If you want a president who’s not going to speak up, you have to find another president.” One of my friends on the board said, “Why did you do that? You don’t have to threaten to quit. Everybody wants you to stay.” I said, “I didn’t threaten to quit! It’s just a fact!” I’m more combative than I want to be, and I’m not looking for a fight, but I do feel that when people are getting really pushed around, in horrible ways, that someone who is at a university and has a platform and can call an editor—we should try.</p><p>I actually thought other people would speak out. Because the missions are at stake. Even the Kalven people—when the mission’s at stake, you’re supposed to speak out.</p><p>Someone on the faculty at Columbia who works in the administration asked me to put together a group of presidents. I was unable to. I wrote something  quickly for people to sign, and one of the people I contacted said to me, “Are you sure the president at Columbia wants you to?” I said, “I’m not sure.”</p><p><strong>Tell me about the kinds of conversations you’ve been having with fellow-presidents. What’s your sense of the internal debates they’re having?</strong></p><p>Presidents—we’re not usually honest with each other. It’s just the nature of the job. You’re always trying to put your institution in the best possible light. I always joke that I see a president I haven’t seen in a few years, and he used to have two arms and now only has one —“What the hell happened, Charlie?” “Oh, I  that arm! I feel so much freer!”</p><p>I don’t go to a lot of presidential gatherings, but I go to a couple. I was at one, and this guy came to me and said, “You know, you make me feel like a coward.” I said, “I’m sorry, that’s not really what my intention is.” But he said he’s at a public university—he was going to the state legislature two days later. He said, “They’re not going to let me have any diversity stuff in the university.” I said, “Well, you can quit.” He said, “And what good would that do?” So, I’m lucky—I have a board that likes the work we do. I have an incredible team of vice-presidents and a wonderful faculty, and they’re supportive. But I don’t understand. Because I know some presidents—many of them are a lot smarter than I am. I’m sure they can write well. I don’t understand.</p>","contentLength":6062,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43568655"},{"title":"I maintain a 17 year old ThinkPad","url":"https://pilledtexts.com/why-i-use-a-17-year-old-thinkpad/","date":1743648008,"author":"Fred34","guid":18813,"unread":true,"content":"<time datetime=\"2025-04-01\">Published on: April 1, 2025</time><blockquote>\nIf a book has been in print for forty years, I can expect it to be in print for another forty years. But, and that is the main difference, if it survives another decade, then it will be expected to be in print another fifty years. This, simply, as a rule, tells you why things that have been around for a long time are not \"aging\" like persons, but \"aging\" in reverse. Every year that passes without extinction doubles the additional life expectancy. This is an indicator of some robustness. The robustness of an item is proportional to its life<p>\n― Nassim Nicholas Taleb, Antifragile\n</p></blockquote><p>Nassim Nicholas Taleb contrasts  systems—those that suffer serious harm under volatility—with  systems that can endure stress with minimal damage. He extends this concept with  systems, which can actually benefit from disorder, but we’ll focus here on the divide between fragile and robust.</p><p>Taleb also introduces the  as an idea about longevity: if something non-perishable has been around for a long time, that track record suggests it’s likely to keep going. We’ll see how this relates to two laptops—one from 2008, the other from 2021.</p><h2>Old Thinkpads: Modular, Robust Survivors</h2><p>IBM and early Lenovo Thinkpads showcases a design built for longevity. Despite their age, these business-class laptop are still serviceable and useful for web browsing, ‘office work’, and light coding. These machine are too slow to handle tasks like video editing or gaming, but they remain consistent in handling everyday tasks without failing under normal wear and tear.</p><p>One of the main reasons that old Thinkpads stand out is their . They are made with swappable components with the intention of user upgradeability. The battery, RAM, storage drive, keyboard, and even the CPU can be easily replaced. I can open the bottom of my T400 with a regular screwdriver and clean the fan. A battery swap is trivial thanks to a removable pack. No single failure is catastrophic because there’s a straightforward path to replacement or repair.</p><p>The  greatly contributes to old Thinkpads robustness. They are made with a sturdy chassis with plastic and magnesium alloy elements, giving it a solid feel. The design absorbs bumps and small impacts without major issues. They can easily take accidental knocks and remain fully operational.</p><p>Old Thinkpads benefits from an . They uses standard PC architecture (x86), so installing various operating systems is easy. On the hardware side, replacement parts are widely available on the secondary market. This broad compatibility keeps the machine relevant long past its original release date. By Taleb’s Lindy Effect, the fact that my T400 can still work well after so many years suggests <strong>it’s likely to remain functional as people have already figured out the ways to significantly extend its lifespan</strong>.</p><p>All these factors show how the my Thinkpad is : it resists sudden failures, and when problems do arise, their are documented way to fit it. Old beat up Thinkpads are Lindy.</p><p>My MacBook offers exceptional speed and efficiency an order of magnitude more than my Thinkpad. It handles tasks—like video editing or running large LLM’s without breaking a sweat. Under ideal conditions, it’s reliable and powerful.</p><p>However, from a Talebian perspective, my MacBook’s design is . Most components of the laptop are soldered onto the logic board. If the SSD or RAM fails, there’s no simple replacement option. A single failure in a component of my MacBook can render the entire laptop unusable. The tightly integrated design of modern Apple hardware increases the stakes of any malfunction.</p><p>The  of Apple products is extremely limited. Apple uses proprietary screws and adhesives, and parts are incompatible with third-party replacements. A battery replacement (usually one of the first things that fails in mobile electronics) involves carefully prying out a glued component. Routine maintenance tasks that are straightforward on the Thinkpad can require specialized tools and authorized service for the MacBook. This lack of modularity means the system can easily become bricked from hardware fails from component parts.</p><p>Another aspect contributing to the fragility of MacBooks is Apple’s . Apple’s software updates and security updates to macOS essentially determines how long the MacBook remains safe to use. Once Apple ends official support for a machine the user has to buy a new MacBook or use an increasingly compromised system. Apple hardware uses an arm architecture that cannot ‘dual boot’ Windows or Linux easily. Once macOS support dies for a modern MacBook it becomes obsolete.</p><p>While my MacBook is great to use, the machine has a lifespan built into its OS support and cannot recover easily from physical damage. MacBooks are not modular, completely proprietary, and have a perishability built into them. Additionally (this is true of all new laptops), when something does go wrong with a new MacBook it hard to fix as <strong>it’s not old enough for people to have figured out if their are ways to extend its lifespan as none have broke yet</strong>. Shiny Macbooks are not very Lindy.</p><p>My Thinkpad is robust because it can face stress (e.g. a broken part, a needed upgrade) without losing its core functionality. It’s modular and benefits from it being old enough that other people know how to extend its lifespan. If something breaks, I replace it. If I need a new feature, I can potentially slot it in. My MacBook despite its phenomenal power, is fragile: if Apple discontinues support or a soldered part dies, there is not much I can do. There is not a knowledge base yet on how to significantly extend the life of these Apple Silicon machines, and there likely never will because of the machines inherent lack of modality.</p><p>Right now I’m using both my Macbook and my Thinkpad a lot. I continue to use my MacBook because I like using proprietary software like Camtasia or Alfred, I like being able to use local LLM’s, and I enjoy the modern screen and ports that my MacBooks has. But if I had to guess which machine I will still be using in another 17 years I’d point to my ThinkPad with its battery latch and standard screws; I see no reason why it will not be able to manage email management, website development, and internet browsing indefinitely.</p>","contentLength":6304,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43564111"},{"title":"US Administration announces 34% tariffs on China, 20% on EU","url":"https://www.bbc.com/news/live/c1dr7vy39eet","date":1743626346,"author":"belter","guid":18575,"unread":true,"content":"<p>Journalists are crowding the local auto workers' local union\nafter news broke of the temporary shutdown of the Stellantis plant - Windsor's\nlargest employer. </p><p>Derek Gungle, speaking softly to protect his voice after all the\ninterviews he's given, tells me that he works to assemble cars at the\nStellantis plant. </p><p>He says the shutdown announcement was “kind of expected” after\nTrump announced the tariffs, but \"scary, very scary\". </p><p>If the worst happens and the shutdown becomes permanent, or\nhe is laid off, Gungle says he has “no idea” what he will do. </p><p>Gungle says Windsor is heavily reliant on\ncross-border trade and any threat to that that will have devastating effects. </p><p>He is the second person to mention Flint, Michigan, when speaking about this crisis. Clearly, the fear of deindustrialisation is at the\nforefront of peoples’ minds. </p><p>Watching that happen just across the border was “weird, very\nweird,” he says. “I’m hoping it doesn’t have to come to that.”</p>","contentLength":980,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43561253"},{"title":"Pico.sh – SSH powered services for developers","url":"https://pico.sh/","date":1743624129,"author":"TheTaytay","guid":18812,"unread":true,"content":"<div>The ultimate  powered services for developers</div>","contentLength":45,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43560899"},{"title":"Why I don't discuss politics with friends","url":"https://shwin.co/blog/why-i-dont-discuss-politics-with-friends","date":1743617684,"author":"shw1n","guid":20057,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43559605"},{"title":"Tell HN: Announcing tomhow as a public moderator","url":"https://news.ycombinator.com/item?id=43558671","date":1743612596,"author":"dang","guid":18297,"unread":true,"content":"Hi all,<p>Tom Howard is going public as HN moderator today. He has been doing HN moderation work for years already and knows the site and its practices inside-out, so the only new thing you'll see is mod comments from Tom showing up in the threads the way mine do. I'm not going anywhere, so you'll have two of us to put up with going forward :)</p><p>Below is a bit from Tom about himself. Please join me in welcoming him to this new status which he was crazy enough to say yes to!</p><p><i>YC and HN have been a huge part of my life for nearly two decades. I read pg's essay How to Start a Startup in 2005 after my friend (and later, co-founder) Fenn found it on Slashdot, and it opened our eyes as to how to go about building products and companies. I first signed up in late 2007, and since then HN has been the place I come to find interesting news and discussions.</i></p><p><i>Hacker News gave me a window into the big wide world of technology and startups, that had previously seemed so remote and opaque from where I lived (and still live) in Australia. We were lucky enough to be accepted into the W09 batch of YC, and since then HN has been a place where we could share announcements about the startup, but also where I could share the challenges and struggles I experienced in the startup journey and other aspects of life, particularly to do with health and wellbeing.</i></p><p><i>From the discussions that have happened about these topics I've ended up making enduring friendships with people all over the world, and have been able to learn many things that have improved my life in profound ways. I love HN's ethos - of being a place people come to engage their curiosity. That's what it's always been for me and what I hope I can help it to be for everyone!</i></p>","contentLength":1726,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43558671"},{"title":"Animals Made from 13 Circles (2016)","url":"https://www.dorithegiant.com/2016/05/13-animals-made-from-13-circles.html","date":1743608125,"author":"jihadjihad","guid":18811,"unread":true,"content":"<div> © Dorota Pankowska 2010 - \n. All rights reserved.</div>","contentLength":51,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43557873"},{"title":"Bletchley code breaker Betty Webb dies aged 101","url":"https://www.bbc.com/news/articles/c78jd30ywv8o","date":1743512128,"author":"danso","guid":18810,"unread":true,"content":"<div data-component=\"text-block\"><p>A decorated World War Two code breaker who spent her youth deciphering enemy messages at Bletchley Park has died at the age of 101.</p><p>Charlotte \"Betty\" Webb MBE - who was among the last surviving Bletchley code breakers - died on Monday night, the Women's Royal Army Corps Association confirmed.</p><p>Mrs Webb, from Wythall in Worcestershire, joined operations at the Buckinghamshire base at the age of 18, later going on to help with Japanese codes at The Pentagon in the US. She was awarded France's highest honour - the Légion d'Honneur - in 2021. </p><p>The Women's Royal Army Corps Association described Mrs Webb as a woman who \"inspired women in the Army for decades\".</p></div><div data-component=\"text-block\"><p>Bletchley Park Trust CEO Iain Standen said Mrs Webb will not only be remembered for her work but \"also for her efforts to ensure that the story of what she and her colleagues achieved is not forgotten.\"</p><p>\"Betty's passion for preserving the history and legacy of Bletchley Park has undoubtedly inspired many people to engage with the story and visit the site,\" he said in a statement.</p><p>Tributes to Mrs Webb have begun to be posted on social media, including one from historian and author Dr Tessa Dunlop who said she was with her in her final hours.</p><p>Describing Mrs Webb as \"the very best\", she said on X: \"She is one of the most remarkable woman I have ever known.\"</p></div><div data-component=\"caption-block\"><figcaption>Listen on BBC Sounds: Mrs Webb went to work at Bletchley Park when she was 18</figcaption></div><div data-component=\"text-block\"><p>Mrs Webb told the BBC in 2020 that she had \"never heard of Bletchley\", Britain's wartime code-breaking centre, before starting work there as a member of the ATS, the Auxiliary Territorial Service.</p><p>She had been studying at a college near Shrewsbury, Shropshire, when she volunteered as she said she and others on the course felt they \"ought to be serving our country rather than just making sausage rolls\".</p><p>Her mother had taught her to speak German as a child and ahead of her posting remembered being \"taken into the mansion [at Bletchley] to read the Official Secrets Act\".</p><p>\"I realised that from then on there was no way that I was going to be able to tell even my parents where I was and what I was doing until 1975 [when restrictions were lifted],\" she recalled.</p><p>She would tell the family with whom she lodged that she was a secretary.</p></div><div data-component=\"text-block\"><p>When WW2 ended in Europe in May 1945, she went to work at the Pentagon after spending four years at Bletchley, which with its analysis of German communications had served as a vital cog in the Allies' war machine.</p><p>At the Pentagon she would paraphrase and transcribe already-decoded Japanese messages. She said she was the only member of the ATS to be sent to Washington, describing it as a \"tremendous honour\".</p><p>Mrs Webb, in 2020, recalled she had had no idea the Americans planned to end the conflict by dropping atomic weapon on Japanese cities, describing the weapons' power as \"utterly awful\".</p><p>After the Allies' final victory, it took Mrs Webb several months to organise return passage to the UK, where she worked as a secretary at a school in Shropshire.</p><p>The head teacher there had also worked at Bletchley so knew of her professionalism, whereas other would-be employers, she recalled, were left stumped by her being unable to explain - due to secrecy requirements - her previous duties.</p><p>More than half a century later, in 2021, Mrs Webb was one of 6,000 British citizens to receive the Légion d'Honneur, following a decision by President François Hollande in 2014 to recognise British veterans who helped liberate France.</p></div><div data-component=\"text-block\"><p>In 2023, she and her niece were among 2,200 people from 203 countries invited to Westminster Abbey to see King Charles III's coronation.</p><p>The same year she celebrated her 100th birthday at Bletchley Park with a party. </p><p>She and her guests were treated to a fly-past by a Lancaster bomber. She said at the time: \"It was for me - it's unbelievable isn't it? Little me.\"</p></div>","contentLength":3816,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43546236"},{"title":"Why F#?","url":"https://batsov.com/articles/2025/03/30/why-fsharp/","date":1743510847,"author":"bozhidar","guid":20056,"unread":true,"content":"<p>If someone had told me a few months ago I’d be playing with .NET again after a\n15+ years hiatus I probably would have laughed at this. Early on in my\ncareer I played with .NET and Java, and even though .NET had done some things\nbetter than Java (as it had the opportunity to learn from some early Java\nmistakes), I quickly settled on Java as it was a truly portable environment.</p><p>I guess everyone who reads my blog knows that in the past few years I’ve been\nplaying on and off with OCaml and I think it’s safe to say that it has become\none of my favorite programming languages - alongside the likes of Ruby and\nClojure. My work with OCaml drew my attention recently to F#, an ML targeting\n.NET, developed by Microsoft. The functional counterpart of the\n(mostly) object-oriented C#. The newest ML language created…</p><blockquote><p>Unfortunately, no one can be told what the Matrix is. You have to see it for yourself.</p></blockquote><p>Before we start discussing F#, I guess we should answer first the question\n“What is F#?”. I’ll borrow a bit from the <a href=\"https://learn.microsoft.com/en-us/dotnet/fsharp/what-is-fsharp\">official page</a> to answer it.</p><p>F# is a universal programming language for writing succinct, robust and performant code.</p><p>F# allows you to write uncluttered, self-documenting code, where your focus remains on your problem domain, rather than the details of programming.</p><p>It does this without compromising on speed and compatibility - it is open-source, cross-platform and interoperable.</p><div><div><pre><code></code></pre></div></div><p> F# is the language that made the pipeline operator () popular.</p><p>F# has numerous features, including:</p><ul><li>Type inference and automatic generalization</li></ul><p>Looks pretty promising, right?</p><p>F# 1.0 was officially released in May 2005 by Microsoft Research. It was\ninitially developed by Don Syme at Microsoft Research in Cambridge and evolved\nfrom an earlier research project called “Caml.NET,” which aimed to bring OCaml\nto the .NET platform. F# was officially moved from Microsoft Research to\nMicrosoft (as part of their developer tooling division) in 2010 (timed\nwith the release of F# 2.0).</p><p>F# has been steadily evolving since those early days and the most recent release\n<a href=\"https://learn.microsoft.com/en-us/dotnet/fsharp/whats-new/fsharp-9\">F# 9.0</a> was\nreleased in November 2024.  It seems only appropriate that F# would come to my\nattention in the year of its 20th birthday!</p><p>There were several reasons why I wanted to try out F#:</p><ul><li>.NET became open-source and portable a few years ago and I wanted to check the progress on that front</li><li>I was curious if F# offers any advantages over OCaml</li><li>I’ve heard good things about the F# tooling (e.g. Rider and Ionide)</li><li>I like playing with new programming languages</li></ul><p>Below you’ll find my initial impressions for several areas.</p><p>As a member of the ML family of languages, the syntax won’t surprise\nanyone familiar with OCaml. As there are quite few people familiar with\nOCaml, though, I’ll mention that Haskell programmers will also feel right at\nhome with the syntax. And Lispers.</p><p>For everyone else - it’d be fairly easy to pick up the basics.</p><div><div><pre><code></code></pre></div></div><p>Nothing shocking here, right?</p><p>Here’s another slightly more involved example:</p><div><div><pre><code></code></pre></div></div><p>Why don’t you try saving the snippet above in a file called  and running it like this:</p><p>Now you know that F# is a great choice for ad-hoc scripts! Also, running  by itself\nwill pop an F# REPL where you can explore the language at your leisure.</p><p>I’m not going to go into great details here, as much of what I wrote about OCaml\n<a href=\"https://batsov.com/articles/2022/08/29/ocaml-at-first-glance/\">here</a> applies to F# as well.\nI’d also suggest this quick <a href=\"https://learn.microsoft.com/en-us/dotnet/fsharp/tour\">tour of F#</a>\nto get a better feel for its syntax.</p><p> Check out the <a href=\"https://fsprojects.github.io/fsharp-cheatsheet/\">F# cheatsheet</a>\nif you’d like to see a quick syntax reference.</p><p>One thing that made a good impression to me is the focus of the language designers on\nmaking F# approachable to newcomers, by providing a lot of small quality of life improvements\nfor them. Below are few examples, that probably don’t mean much to you, but would mean something\nto people familiar with OCaml:</p><div><div><pre><code></code></pre></div></div><p>I guess some of those might be controversial, depending on whether you’re a ML\nlanguage purist or not, but in my book anything that makes ML more popular is a\ngood thing.</p><p>Did I also mention it’s easy to work with unicode strings and regular expressions?</p><p>Often people say that F# is mostly a staging ground for future C# features, and perhaps that’s true.\nI haven’t observed both languages long enough to have my own opinion on the subject, but I was impressed\nto learn that  (of C# and later JavaScript fame) originated in… F# 2.0.</p><blockquote><p>It all changed in 2012 when C#5 launched with the introduction of what has now\nbecome the popularized  keyword pairing. This feature allowed you to\nwrite code with all the benefits of hand-written asynchronous code, such as not\nblocking the UI when a long-running process started, yet read like normal\nsynchronous code. This  pattern has now found its way into many\nmodern programming languages such as Python, JS, Swift, Rust, and even C++.</p><p>F#’s approach to asynchronous programming is a little different from \nbut achieves the same goal (in fact,  is a cut-down version of F#’s\napproach, which was introduced a few years previously, in F#2).</p><p>– Isaac Abraham, F# in Action</p></blockquote><p>Time will tell what will happen, but I think it’s unlikely that C# will ever be able to fully replace F#.</p><blockquote><p>Some good news for you. After 10 years of F# being developed by 2.5 people\ninternally and some random community efforts, Microsoft has finally decided to\nproperly invest in F# and created a full-fledged team in Prague this\nsummer. I’m a dev in this team, just like you I was an F# fan for many years\nso I am happy things got finally moving here.</p></blockquote><p>Looking at the changes in F# 8.0 and F 9.0, it seems the new full-fledged team\nhas done some great work!</p><p>It’s hard to assess the ecosystem around F# after such a brief period, but overall it seems to\nme that there are fairly few “native” F# libraries and frameworks out there and most people\nrely heavily on the core .NET APIs and many third-party libraries and frameworks geared towards C#.\nThat’s a pretty common setup when it comes to hosted languages in general, so nothing surprising here as well.</p><p>If you’ve ever used another hosted language (e.g. Scala, Clojure, Groovy) then you probably know what\nto expect.</p><p><a href=\"https://github.com/fsprojects/awesome-fsharp\">Awesome F#</a> keeps track of popular F# libraries, tools and frameworks. I’ll highlight here the web development and data science libraries:</p><ul><li>: A lightweight library for building web applications using ASP.NET Core. It provides a functional approach to web development.</li><li>: A simple and lightweight web server library with combinators for routing and task composition. (Giraffe was inspired by Suave)</li><li>: Built on top of Giraffe and ASP.NET Core, it offers an MVC-style framework inspired by Ruby on Rails and Elixir’s Phoenix.</li><li>: A framework for building client-side applications in F# using WebAssembly and Blazor.</li><li>: A compiler that translates F# code into JavaScript, enabling integration with popular JavaScript ecosystems like React or Node.js.</li><li>: A model-view-update (MVU) architecture for building web UIs in F#, often used with Fable.</li><li>: An end-to-end, functional-first stack for building cloud-ready web applications. It combines technologies like Saturn, Azure, Fable, and Elmish for a type-safe development experience.</li></ul><ul><li>: A library for data manipulation and exploratory analysis, similar to pandas in Python.</li><li>: A library for automatic differentiation and machine learning.</li><li>: A collection of libraries tailored for data science, including visualization and statistical tools.</li></ul><p>I haven’t played much with any of them at this point yet, so I’ll reserve any\nfeedback and recommendations for some point in the future.</p><p>The official documentation is pretty good, although I find it kind of weird that\nsome of it is hosted on <a href=\"https://learn.microsoft.com/en-us/dotnet/fsharp/what-is-fsharp\">Microsoft’s site</a>\nand the rest is on <a href=\"https://fsharp.org/\">https://fsharp.org/</a> (the site of the F# Software Foundation).</p><p>I really liked the following parts of the documentation:</p><p>F# has a somewhat troubled dev tooling story, as historically\nsupport for F# was great only in Visual Studio, and somewhat subpar\nelsewhere. Fortunately, the tooling story has improved a lot in the past\ndecade:</p><blockquote><p>In 2014 a technical breakthrough was made with the creation of the\nFSharp.Compiler.Service (FCS) package by Tomas Petricek, Ryan Riley, and Dave\nThomas with many later contributors. This contains the core implementation of\nthe F# compiler, editor tooling and scripting engine in the form of a single\nlibrary and can be used to make F# tooling for a wide range of\nsituations. This has allowed F# to be delivered into many more editors,\nscripting and documentation tools and allowed the development of alternative\nbackends for F#. Key editor community-based tooling includes Ionide, by\nKrzysztof Cieślak and contributors, used for rich editing support in the\ncross-platform VSCode editor, with over 1M downloads at time of writing.</p><p>– Don Syme, The Early History of F#</p></blockquote><p>I’ve played with the F# plugins for several editors:</p><ul><li>Helix (built-in support for F#)</li><li>Rider (JetBrains’s .NET IDE)</li></ul><p>Overall, Rider and VS Code provide the most (and the most polished) features,\nbut the other options were quite usable as well.  That’s largely due to the fact\nthat the F# LSP server  (naming is hard!) is quite robust and\nany editor with good LSP support gets a lot of functionality for free.</p><p>Still, I’ll mention that I found the tooling lacking in some regards:</p><ul><li> doesn’t use TreeSitter (yet) and doesn’t seem to be very actively developed (looking at the code - it seems it was derived from )</li><li>Zed’s support for F# is quite spartan</li><li>In VS Code shockingly the expanding and shrinking selection is broken, which is quite odd for what is supposed to be the flagship editor for F#</li></ul><p>I’m really struggling with VS Code’s keybindings (too many modifier keys and functions keys for my taste) and editing model, so I’ll likely stick with Emacs going forward. Or I’ll finally spend more quality time with neovim!</p><p>It seems that everyone is using the same code formatter (), including the F# team, which is great!\nThe linter story in F# is not as great (seems the only popular linter <a href=\"https://fsprojects.github.io/FSharpLint/\">FSharpLint</a> is abandonware these days), but when your\ncompiler is so good, you don’t really need a linter as much.</p><p>Oh, well… It seems that Microsoft are not really particularly invested in\nsupporting the tooling for F#, as pretty much all the major projects in this\nspace are community-driven.</p><p>Using AI coding agents (e.g. Copilot) with F# worked pretty well, but I didn’t\nspend much time on this front.</p><p>In the end of the day any editor will likely do, as long as you’re using LSP.</p><p>By the way, I had an interesting observation while programming in F# (and OCaml for that matter) -\nthat when you’re working with a language with a really good type system you don’t really need that much\nfrom your editor. Most the time I’m perfectly happy with just some inline type information (e.g. something like CodeLenses), auto-completion and the ability to easily send code to . Simplicity continues\nto be the ultimate sophistication…</p><p>Other tools that should be on your radar are:</p><ul><li><a href=\"https://fsprojects.github.io/Paket/\">Paket</a> - Paket is a dependency manager for .NET projects. Think of it as something like ,  or , but for .NET’s NuGet package ecosystem.</li><li><a href=\"https://fake.build/\">FAKE</a> -  A DSL for build tasks and more, where you can use F# to specify the tasks. Somewhat similar to Ruby’s . Some people claim that’s the easiest way to sneak F# into an existing .NET project.</li></ul><p>Given the depth and breath of .NET - I guess that sky is the limit for you!</p><p>Seems to me that F# will be a particularly good fit for data analysis and manipulation, because\nof features like <a href=\"https://learn.microsoft.com/en-us/dotnet/fsharp/tutorials/type-providers/\">type providers</a>.\nHere’s a small demo of using a JSON type provider:</p><div><div><pre><code></code></pre></div></div><p>The first time I saw this it felt almost like magic, as F# infers the structure\nand types of the data from a small data sample and then you get a parser for it. You\ncan save the code to a file named  and afterwards you can\nrun it like this:</p><div><div><pre><code>dotnet fsi TypeProvidersDemo.fsx\n</code></pre></div></div><p>It gets even better, though, as you can easily do things like extracting data straight\nfrom HTML tables and visualizing the data:</p><div><div><pre><code></code></pre></div></div><p>If you run the script you’ll get a nice diagram of the population of the various\nLondon boroughs in your browser. Good stuff!</p><p>Here we must also appreciate how easy it is to use external libraries (e.g. Plotly.NET)\nin F# scripts!</p><p>Moving forward, I think F# would be a good fit for backend services and even\nfull-stack apps, although I haven’t really played with the F# first solutions in\nthis space yet.</p><p>Fable and Elmish make F# a viable option for client-side programming and might offer\nanother easy way to sneak F# into your day-to-day work.</p><p> Historically, Fable has been used to target JavaScript but since Fable\n4, you can also target other languages such as TypeScript, Rust, Python, and\nmore.</p><p>Here’s how easy it is to transpile an F# codebase into something else:</p><div><div><pre><code>\ndotnet fable\n\n\ndotnet fable  typescript\n\n\ndotnet fable  python\n</code></pre></div></div><p>My initial impression of the community is that it’s fairly small, perhaps even\nsmaller than that of OCaml.  The F# Reddit and Discord (the one listed on\nReddit) seem like the most active places for F# conversations. There’s supposed\nto be some F# Slack as well, but I couldn’t get an invite for it. (seems the\nautomated process for issuing those invites has been broken for a while)</p><p>I’m still not sure what’s the role Microsoft plays in the community, as I\nhaven’t seen much from them overall.</p><p>For a me a small community is not really a problem, as long as the community is\nvibrant and active. Also - I’ve noticed I always feel more connected to smaller\ncommunities. Moving from Java to Ruby back in the day felt like night and day as\nfar as community engagement and sense of belonging go.</p><p>I didn’t find many books and community sites/blogs dedicated to F#, but I didn’t\nreally expect to in the first place.</p><p>The most notable community initiatives I discovered were:</p><ul><li><a href=\"https://amplifyingfsharp.io/\">Amplifying F#</a> - an effort to promote F# and to get more businesses involved with it</li><li><a href=\"https://fslab.org/\">F# Lab</a> - The community driven toolkit for datascience in F#</li><li><a href=\"https://sergeytihon.com/category/f-weekly/\">F# Weekly</a> - a weekly newsletter about the latest developments in the world of F#</li></ul><p>Seems to me that more can be done to promote the language and engage new programmers and businesses\nwith it, although that’s never easy 20 years into the existence of some project. I continue to be\nsomewhat puzzled as to why Microsoft doesn’t market F# more, as I think it could be a great\nmarketing vehicle for them.</p><p>All in all - I don’t feel qualified to comment much on the F# community at this point.</p><p>Depending on the type of person you are you may or may not care about a a programming language’s\n“popularity”. People often ask my why I spent a lot of time with languages that are unlikely to\never result in job opportunities for me, e.g.:</p><p>Professional opportunities are important, of course, but so are:</p><ul><li>having fun (and the F in F# stands for “fun”)</li><li>learning new paradigms and ideas</li><li>challenging yourself to think and work differently</li></ul><p>That being said, F# is not a popular language by most conventional metrics. It’s not highly ranked\non TIOBE, StackOverflow or most job boards. But it’s also not less popular than most “mainstream”\nfunctional programming languages. The sad reality is that functional programming is still not\nmainstream and perhaps it will never be.</p><p>A few more resources on the subject:</p><blockquote><p>The early conception of F# was simple: to bring the benefits of OCaml to .NET and .NET to OCaml: a\nmarriage between strongly typed functional programming and .NET. Here “OCaml” meant both the\ncore of the language itself, and the pragmatic approach to strongly-typed functional programming\nit represented. The initial task was relatively well-defined: I would re-implement the core of the\nOCaml language and a portion of its base library to target the .NET Common Language Runtime.\nThe implementation would be fresh, i.e. not using any of the OCaml codebase, for legal clarity.</p><p>– Don Syme, creator of F#, The Early History of F#</p></blockquote><p>F# was derived from OCaml, so the two languages share a lot of DNA. Early on\nF# made some efforts to support as much of OCaml’s syntax as possible, and it\neven allowed the use of  and  file extensions for F# code. Over time\nthe languages started to diverge a bit, though.</p><p>Creating a language that’s independent from OCaml, of course, was something\nintended from the very beginning. That’s also reflected in the decision\nto chose the name F#, even if early versions of the language were called “Caml.NET”:</p><blockquote><p>Although the first version of F# was initially presented as “Caml-for-.NET”,\nin reality it was always a new language, designed for .NET from day 1. F# was\nnever fully compatible with any version of OCaml, though it shared a compatible\nsubset, and it took Caml-Light and OCaml as its principal sources of design\nguidance and inspiration.</p><p>– Don Syme, The Early History of F#</p></blockquote><p>If you ask most people about the pros and cons of F# over OCaml you’ll probably\nget the following answers.</p><ul><li>Runs on .NET\n    <ul><li>Tons of libraries are at disposal</li></ul></li><li>Arguably it’s a bit easier to learn by newcomers (especially those who have only experience with OO programming)\n    <ul><li>The syntax is slightly easier to pick up (I think)</li><li>The compiler errors and warnings are “friendlier” (easier to understand)</li><li>It’s easier to debug problems (partially related to the previous item)</li></ul></li><li>Has some cool features, absent in OCaml, like:\n    <ul><li>Computational expressions</li></ul></li></ul><ul><li>Runs on .NET\n    <ul><li>The interop with .NET influenced a lot of language design decisions (e.g. allowing )</li></ul></li><li>Backed by Microsoft\n    <ul><li>Not everyone likes Microsoft</li><li>Seems the resources allocated to F# by Microsoft are modest</li><li>It’s unclear how committed Microsoft will be to F# in the long run</li></ul></li><li>Naming conventions: I like  way more than  and </li><li>Misses some cool OCaml features\n    <ul><li>First-class modules and functors</li></ul></li><li>Doesn’t have a friendly camel logo</li><li>The name F# sounds cool, but is a search and filename nightmare (and you’ll see FSharp quite often in the wild)</li></ul><p>Both F# and OCaml can also target JavaScript runtimes as well - via <a href=\"https://fable.io/\">Fable</a> on\nthe F# side, and <a href=\"https://ocsigen.org/js_of_ocaml/latest/manual/overview\">Js_of_ocaml</a> and <a href=\"https://melange.re/\">Melange</a> on the OCaml side. Fable seems like a\nmore mature solution at a cursory glance, but I haven’t used any of the three\nenough to be able to offer an informed opinion.</p><p>In the end of the day both remain two fairly similar robust, yet niche,\nlanguages, which are unlikely to become very popular in the future. I’m guessing\nworking professionally with F# is more likely to happen for most people, as .NET\nis super popular and I can imagine it’d be fairly easy to sneak a bit of F# here\nin there in established C# codebases.</p><p>One weird thing I’ve noticed with F# projects is that they still use XML project\nmanifests (), where you have to list the source files manually in the order in\nwhich they should be compiled (to account for the dependencies between them). I\nam a bit shocked that the compiler can’t handle the dependencies automatically,\nbut I guess that’s because in F# there’s not direct mapping between source files\nand modules. At any rate - I prefer the OCaml compilation process (and Dune) way\nmore.</p><p>As my interest in MLs is mostly educational I’m personally leaning towards OCaml, but if I had to build\nweb services with an ML language I’d probably pick F#. I also have a weird respect for every language\nwith its own runtime, as this means that it’s unlikely that the runtime will force some compromises\non the language.</p><blockquote><p>Question: What can C# do that F# can’t?\nAnswer: NullReferenceException!</p></blockquote><p>All in all I liked F# way more than I expected to! In a way it reminded me of my\nexperience with Clojure back in the day in the sense that Clojure was the most\npractical Lisp out there when it was released, mostly because of its great\ninterop with Java.</p><p>I have a feeling that if .NET was portable (and open-source) since day 1\nprobably ClojureCLR would have become as popular as Clojure, and likely F# would\nhave developed a bigger community and broader usage by now. I’m fairly certain I\nwould have never dabbled in .NET again if it hadn’t been for .NET Core, and I\ndoubt I’m the only one. The fact that F# wasn’t open-sourced until 2010 didn’t help\nwith the early adoption either.</p><p>Seems I’m only the only one who thinks this way:</p><blockquote><p>Mistakes are hard to admit, and best seen in their historical context. From the early history, the\ngreatest mistake related to F# was that neither .NET nor the language were open source or using\nopen engineering. This mistake was well-understood by the core contributors at the time and many\nacross Microsoft were advocating for a shift to open-source. Put simply, an innovative language\ngrew in the research lab of a company that had not yet embraced open source: those involved did\nwhat they could through source drops, and the problem was eventually solved via the shift to open\nsource engineering and design from 2011 to 2014. The rectification of this mistake will likely be the\nmost significant development in the history of the language. Further, the fact that F# was able to\nnavigate 2002-2011 while using closed-engineering is largely due to the recognition of its qualities\nby decision makers at Microsoft.</p><p>– Don Syme, The Early History of F#</p></blockquote><p>Learning OCaml is definitely not hard, but I think that people interested to learn some ML\ndialect might have an easier time with F#. And, as mentioned earlier, you’ll probably have an\neasier path to “production” with it.</p><p>I think that everyone who has experience with .NET will benefit from learning F#.\nPerhaps more importantly - everyone looking to do more with an ML family language\nshould definitely consider F#, as it’s a great language in its own right, that gives\nyou access to one of the most powerful programming platforms out there.</p><p>Let’s not forget about <a href=\"https://fable.io/\">Fable</a>, which makes it possible for you leverage\nF# in JavaScript, Dart, Rust and Python runtimes!</p><p>So, why F#? In the F# community there’s the saying that the “F” in F# stands for\n“Fun”. In my brief experience with F# I found this to be very true! I’ll go a\nstep further and make the claim that F# is both seriously  and seriously\npractical!</p><p>Also if your code compiles - it will probably work the way you expect it to. I\nhear that’s generally considered a desirable thing in the world of programming!</p><p>That’s all I have for you today. Please, share in the comments what do you love about F#!</p><p>In sane type systems we trust!</p><p>If you need further arguments to learn F# I can highly recommend the following\nresources:</p><p>“The Early History of F#”, which I’ve quoted extensively, is pure gold as well!</p>","contentLength":22383,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43546004"},{"title":"Electron band structure in germanium, my ass (2001)","url":"https://pages.cs.wisc.edu/~kovar/hall.html","date":1743510312,"author":"tux3","guid":17860,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43545917"},{"title":"The April Fools joke that might have got me fired","url":"http://oldvcr.blogspot.com/2025/04/the-april-fools-joke-that-might-have.html","date":1743491490,"author":"goldenskye","guid":18809,"unread":true,"content":"\nEveryone should pull one great practical joke in their lifetimes. This one was mine, and I think it's past the statute of limitations. The story is true. Only the names are redacted to protect the guilty.\n<p>\nMy first job out of college was a database programmer, even though my undergraduate degree had nothing to do with computers and my current profession still mostly doesn't. The reason was that the University I worked for couldn't afford competitive wages, but they did offer various fringe benefits, and they were willing to train someone who at least had decent working knowledge. I, as a newly minted graduate of the august University of California system, had decent working knowledge at least of BSD/386 and SunOS, but more importantly also had the glowing recommendation of my predecessor who was being promoted into a new position. I was hired, which was their first mistake.\n</p><p>\nThe system I was hired to work on was an HP 9000 K250, one of Hewlett-Packard's big PA-RISC servers. I wish I had a photograph of it, but all I have are a couple bad scans of some bad Polaroids of my office and none of the server room. The server room was downstairs from my office back in the days when server rooms were on-premises, complete with a swipe card lock and a halon system that would give you a few seconds of grace before it flooded everything. The K250 hulked in there where it had recently replaced what I think was an Encore mini of some sort (probably a Multimax, since it was a few years old and the 88K Encores would have been too new for the University), along with the AIX RS/6000s that provided student and faculty shell accounts and E-mail, the bonded <a href=\"http://oldvcr.blogspot.com/2022/05/so-long-home-t1-line-hello-hacking-t1.html\">T1 lines</a>, some of the terminal servers, the massive Cabletron routers and a lot of the telco stuff. One of the tape reels from the Encore hangs on my wall today as a memento.\n</p><p>\nThe K250 and the Encore it replaced (as well as the L-Class that later replaced the K250 when I was a consultant) ran an all-singing, all-dancing student information system called CARS. CARS is still around, renamed <a href=\"https://jenzabar.com/\">Jenzabar</a>, though I suspect that many of its underpinnings remain if you look under the table. In those days CARS was a massive overlay that was loaded atop the operating system and database, which when I started were, respectively, HP/UX 10.20 and Informix. (I'm old.) It used Informix tables, screens and stored procedures plus its own text UI libraries to run code written variously as Perform screens, SQL, C-shell scripts and plain old C or ESQL/C. Everything was tracked in RCS using overgrown s. I had the admin side (resource management, financials, attendance trackers, etc.) and my office partner had the academic side (mostly grades and faculty tracking). My job was to write and maintain this code and shortly after to help the University create custom applications in CARS' brand-spanking new web module, which chose the new hotness in scripting languages, i.e., Perl. Fortuitously I had learned Perl in, appropriately enough, a computational linguistics course.\n</p><p>\nCARS also managed most of the printers on campus except for the few that the RS/6000s controlled directly. Most of the campus admin printers were HP LaserJet 4 units of some derivation equipped with JetDirect cards for networking. These are great warhorse printers, some of the best laser printers HP ever made. I suspect there were line printers other places, but those printers were largely what existed in the University's offices.\n</p><p>\nIt turns out that the  message these printers show on their VFD panels is changeable. I don't remember where I read this, probably idly paging through the manual over a lunch break, but initially the only fun things I could think of to do was to have the printer say hi to my boss when she sent jobs to it, stuff like that (whereupon she would tell me to get back to work). Then it dawned on me: because I had access to the printer spools on the K250, and the spool directories were conveniently named the same as their hostnames, I knew where each and every networked LaserJet on campus was. I was young, rash and motivated. This was a hack I just couldn't resist. It would be even better than what had been my favourite joke at my alma mater, where campus services, notable for posting various service suspension notices, posted one April Fools' Day that gravity itself would be suspended to various buildings. I felt sure this hack would eclipse that too.\n</p><p>\nThe plan on April Fools' Day was to get into work at OMG early o'clock and iterate over every entry in the spool, sending it a sequence that would change the  message to . This would cause every networked LaserJet on campus to appear to ask for a nickel before you printed anything. The script was very simple (this is the actual script, I saved it):\n</p><div><pre>#!/bin/csh -f\n\ncd /opt/carsi/spool\nforeach i (*)\n        echo '^[%-12345X@PJL RDYMSG DISPLAY=\"INSERT 5 CENTS\"' | netto $i 9100\nend\n</pre></div><p>\nThe  was a literal ASCII 27 ESCape character, and  was a simple -like script I had written in these days before  was widely used. That's it.\n\nNow, let me be clear: the printer was  ready! The effect was merely cosmetic! It would still print if you sent jobs to it! Nevertheless, to complete the effect, this message was sent out on the campus-wide administration mailing list (which I also saved):\n</p><div><pre>To: xxx@xxx.xxx\nDate: xxx, 1 Apr xxxx 05:41:34 -0800 (PST)\nSubject: IMPORTANT NOTE ON PRINTER POLICY\n\nDue to the increasing costs of service commitments for campus printers,\nall printers on campus will be reprogrammed for pay-per-page service\nto defray these mounting expenses, effective immediately.\n\nMost printers will now require a 5 cent deposit per page for printing. This\nmay be paid on account or through special coin acceptors to be installed\non the unit by technicians through the end of this week. If your office has\nnot yet established an account, your printer will automatically request you to \ninsert 5 cents into the slot per page to be printed. Please check your\nprinter's LCD [sic] display to see if your printer requires the 5 cents per\npage before using your printer.\n\nAdditional printers will be retrofitted as soon as possible. Technicians\nwill be contacting departments with specific details.\n\nAll accounts will be maintained on CARS. Do not call the Helpdesk. To\nestablish or verify your department's printer account, please call me at\nxxxx.\n\nPlease also direct all questions regarding this new policy to me as well.\n\nWe apologise for the inconvenience and hope that the new cost requirement\nwill not adversely affect your department's productivity.\n</pre></div><p>\nAt the end of the day I would reset everything back to , smile smugly, and continue with my menial existence. That was the plan.\n</p><p>\nHaving sent this out, I fielded a few anxious calls, who laughed uproariously when they realized, and I reset their printers manually afterwards. The people who knew me, knew I was a practical joker, took note of the date, and sent approving replies. One of the best was sent to me later in the day by intercampus mail, printed on their laser printer, with a nickel taped to it.\n</p><p>\nUnfortunately, not everybody on campus knew me, and those who did not not only did  call me, but instead called university administration directly. By 8:30am it was chaos in the main office and this filtered up to the head of HR, who most definitely  know me, and told me I'd better send a retraction before the CFO got in or I was in big trouble. That went wrong also, because my retraction said that campus administration was not considering charging per-page fees when in fact they actually were, so I had to retract it and send a  retraction that didn't call attention to that fact. I also ran the script to reset everything early. Eventually the hubbub finally settled down around noon. Everybody in the office thought it was very funny. Even my boss, who officially disapproved, thought it was somewhat funny.\n</p><p>\nThe other thing that went wrong, as if all that weren't enough, was that the director of IT — which is to say, my boss's boss — was away on vacation when all this took place. (Read E-mail remotely? Who does ?) I compounded this situation with the tactical error of going skiing over the coming weekend and part of the next week, most of which I spent snowplowing down the bunny slopes face first, so that he discovered all the angry E-mail in his box without me around to explain myself. (My office partner remembers him coming in wide-eyed asking, \"what did he ??\") When I returned, it was icier in the office than it had been on the mountain. The assistant director, who thought it was funny, was in trouble for not putting a lid on it, and I was in really big trouble for doing it in the first place. I was appropriately contrite and made various apologies and was an uncharacteristically model employee for an unnaturally long period of time.\n</p><p>\nThe Ice Age eventually thawed and the incident was officially dropped except for a \"poor judgment\" on my next performance review and the satisfaction of what was then considered the best practical joke ever pulled on campus. Indeed, everyone agreed it was much more technically accomplished than the previous award winner, where someone had supposedly gotten it around the grounds that the security guards at the entrance would be charging a nominal admission fee per head. Years later they still said it was legendary.\n</p><p>\nI like to think they still do.\n</p>","contentLength":9414,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43543743"},{"title":"Show HN: Nue – Apps lighter than a React button","url":"https://nuejs.org/blog/large-scale-apps/","date":1743486461,"author":"tipiirai","guid":17629,"unread":true,"content":"<p>On this release, we’re showing what happens when you push modern web standards — HTML, CSS, and JS — to their peak:</p><p>This entire <a href=\"//mpa.nuejs.org/app/\">app</a> is  than a React/ShadCN button:</p><p>See benchmark and details <a href=\"https://nuejs.org/docs/react-button-vs-nue.html\">here ›</a></p><p>Here’s the same app, now with a  computation engine and  for instant search and other operations over  records — far past where <a href=\"//github.com/nuejs/nue/blob/master/packages/examples/simple-mpa/app/model/engines/javascript.js\">JS-version</a> of the engine crashed with a maximum call stack exception.</p><div><figcaption>\n    Instant operations across 150,000 records with Rust/WASM\n  </figcaption></div><p>Nue crushes HMR and build speed records and sets you up with a millisecond feedback loop for your everyday VSCode/Sublime file-save operations:</p><div><figcaption>\n    Immediate feedback for design and component updates, preserving app state\n  </figcaption></div><h3><a href=\"https://nuejs.org/blog/large-scale-apps/#for-rust-go-and-js-engineers\" title=\"For Rust, Go, and JS engineers\"></a>For Rust, Go, and JS engineers</h3><p>This is a game-changer for Rust, Go, and JS engineers stuck wrestling with React idioms instead of leaning on timeless software patterns. Nue emphasizes a model-first approach, delivering modular design with simple, testable functions, true static typing, and minimal dependencies. Nue is a liberating experience for system devs whose skills can finally shine in a separated model layer.</p><p>This is an important shift for design engineers bogged down by React patterns and <a href=\"//github.com/shadcn-ui/ui/tree/main/apps/v4/registry/new-york-v4\">40,000+ line</a> design systems. Build radically simpler systems with modern CSS (@layers, variables, calc()) and take control of your typography and whitespace.</p><p>This is a wake-up call for UX engineers tangled in React hooks and utility class walls instead of owning the user experience. Build apps as light as a React button to push the web — and your skills — forward.</p><p>Nue is a web framework focused on web standards, currently in active development. I'm aiming to reveal the hidden complexity that’s become normalized in modern web development. When a single button outweighs an entire application, something’s fundamentally broken.</p><p>Nue drives the inevitable shift. We’re rebuilding tools and frameworks from the ground up with a cleaner, more robust architecture. Our goal is to bring back the joy of web development for everyone—whether you’re focused on performance, design, or UX.</p>","contentLength":2084,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43543241"},{"title":"Show HN: Duolingo-style exercises but with real-world content like the news","url":"https://app.fluentsubs.com/exercises/daily","date":1743486394,"author":"ph4evers","guid":18808,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43543235"},{"title":"Go Optimization Guide","url":"https://goperf.dev/","date":1743452998,"author":"jedeusus","guid":18807,"unread":true,"content":"<p>The <strong>Go App Optimization Guide</strong> is a collection of technical articles aimed at helping developers write faster, more efficient Go applications. Whether you're building high-throughput APIs, microservices, or distributed systems, this series offers practical patterns, real-world use cases, and low-level performance insights to guide your optimization efforts.</p><p>While Go doesn’t expose as many knobs for performance tuning as languages like C++ or Rust, it still provides  to make your applications significantly faster. From memory reuse and allocation control to efficient networking and concurrency patterns, Go offers a pragmatic set of tools for writing high-performance code.</p><p>We focus on  with  you can apply immediately—covering everything from core language features to advanced networking strategies.</p><p>In this first article, we explore a curated set of high-impact performance patterns every Go developer should know:</p><ul><li>Using  effectively</li><li>Avoiding unnecessary allocations</li><li>Struct layout and memory alignment</li><li>Zero-cost abstractions with interfaces</li><li>In-place sorting and slices reuse</li></ul><p>Each pattern is grounded in practical use cases, with benchmarks and examples you can copy into your own codebase.</p><p>In our upcoming deep dive into networking, we'll focus on building high-throughput network services with Go’s standard library and beyond. This includes:</p><ul><li>Efficient use of  and </li><li>Managing large volumes of concurrent connections</li><li>Performance tuning with epoll/kqueue and </li><li>Load testing techniques and bottleneck diagnostics</li></ul><p>We'll also explore when to drop down to lower-level libraries like , and how to balance performance with maintainability.</p><p>This series is ideal for:</p><ul><li>Backend engineers optimizing Go services in production</li><li>Developers working on latency-sensitive systems</li><li>Teams migrating to Go and building performance-critical paths</li><li>Anyone curious about Go’s performance model and trade-offs</li></ul><p>Stay tuned—more articles, code samples, and tools are on the way. You can bookmark this page to follow the series as it evolves.</p>","contentLength":2006,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43539585"},{"title":"Honey has now lost 4M Chrome users after shady tactics were revealed","url":"https://9to5google.com/2025/03/31/honey-extension-users-dropped-chrome-march-2025/","date":1743445683,"author":"tantalor","guid":17419,"unread":true,"content":"<p>Late last year the popular Chrome extension Honey (owned by PayPal) was revealed for employing a few shady tactics, and the extension has since lost around 4 million users on Google’s browser alone.</p><p>To recap the situation thus far, Honey has amassed millions of users over the past several years on the promise of finding coupon codes for various online stores. The free extension saw wide advertisements and was eventually <a href=\"https://investor.pypl.com/news-and-events/news-details/2020/PayPal-Completes-Acquisition-of-Honey/default.aspx\">purchased by PayPal in 2020 </a>for $4 billion.</p><p>In December 2024, <a href=\"https://www.youtube.com/watch?v=vc4yL3YTwWk\">a video on YouTube</a> by the channel  exposed Honey for two shady practices. The first was how the extension took advantage of affiliate codes. Honey has always used affiliate programs to subsidize its service, but the video revealed that the extension would hijack these programs – removing affiliate codes from other refferers such as online creators and website – even if it didn’t have coupon codes or cash back to offer in return. The practice was working behind the scenes with businesses to control which codes would appear to Honey users, effectively directly lying about its promise of finding the “best” coupon codes on the web.</p><p>That video amassed over 17 million views, and Honey has now lost over 4 million users on Chrome.</p><p>As <a href=\"https://9to5google.com/2025/01/03/honey-paypal-chrome-extension-lost-users/\">we reported in early January,</a> Honey had lost around 3 million users immediately after the video went viral, but ended up <a href=\"https://9to5google.com/2025/01/17/honey-18-million-users-grew-back/\">gaining back</a> around 1 million later on. Now, as of March 2025, Honey is down to 16 million users <a href=\"https://chromewebstore.google.com/detail/honey-automatic-coupons-r/bmnlcjabgnpnenekpadlanbbkooimhnj?pli=1\">on Chrome</a>, down from its peak of 20 million.</p><p>Are you still using Honey?</p><div><p><em>FTC: We use income earning auto affiliate links.</em><a href=\"https://9to5mac.com/about/#affiliate\">More.</a></p></div>","contentLength":1571,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43538113"},{"title":"Stop syncing everything","url":"https://sqlsync.dev/posts/stop-syncing-everything/","date":1743440864,"author":"neilk","guid":18806,"unread":true,"content":"<a href=\"https://sqlsync.dev/\" data-astro-prefetch=\"\" data-astro-cid-egg7nqdx=\"true\"> back\n</a><p>Partial replication sounds easy—just sync the data your app needs, right? But choosing an approach is tricky: logical replication precisely tracks every change, complicating strong consistency, while physical replication avoids that complexity but requires syncing every change, even discarded ones. <strong>What if your app could combine the simplicity of physical replication with the efficiency of logical replication?</strong> That’s the key idea behind , the open-source transactional storage engine I’m launching today. It’s designed specifically for lazy, partial replication with strong consistency, horizontal scalability, and object storage durability.</p><p>Graft is designed with the following <a href=\"https://sqlsync.dev/posts/stop-syncing-everything/#what-can-you-build-with-graft\" data-astro-prefetch=\"\">use cases</a> in mind:</p><ul><li><strong>Offline-first &amp; mobile apps</strong>: <a href=\"https://x.com/artman/status/1558081811040948230\" data-astro-prefetch=\"\">Simplify development</a> and improve reliability by offloading replication and storage to Graft.</li><li>: Share data smoothly across devices, browsers, and platforms without vendor lock-in.</li><li><strong>Stateless multi-writer replicas</strong>: Deploy replicas anywhere, including serverless and embedded environments.</li><li>: Replicate databases, files, or custom formats—all with strong consistency.</li></ul><p>I first discovered the need for Graft while building <a href=\"https://sqlsync.dev\" data-astro-prefetch=\"\">SQLSync</a>. SQLSync is a frontend optimized database stack built on top of <a href=\"https://www.sqlite.org/\" data-astro-prefetch=\"\">SQLite</a> with a synchronization engine powered by ideas from Git and distributed systems. SQLSync makes multiplayer SQLite databases a reality, powering interactive apps that run directly in your browser.</p><p>However, SQLSync replicates the entire log of changes to every client—similar to how some databases implement physical replication. While this approach works fine on servers, it’s poorly suited to the constraints of edge and browser environments.</p><p>After shipping SQLSync, I decided to find a replication solution more suited to the edge. I needed something that could:</p><ul><li>Let clients </li><li>, including the edge and offline devices</li><li>All while providing <strong>strong consistency guarantees</strong>.</li></ul><p>That didn’t exist. So I built it.</p><h2><a href=\"https://sqlsync.dev/posts/stop-syncing-everything/#a-different-approach-to-edge-replication\" data-astro-prefetch=\"\">#</a>A different approach to edge replication</h2><p>If you’ve ever tried to keep data in sync across clients and servers, you know it’s harder than it sounds. Most existing solutions fall into one of two camps:</p><ul><li>, which syncs the entire dataset to each client—not practical for constrained environments like serverless functions or web apps.</li></ul><p>Graft takes a different path.</p><p>Like full replication, Graft is schema-agnostic. It doesn’t know or care what kind of data you’re storing—it just replicates bytes. But instead of sending all the data, it behaves more like logical replication: clients receive a compact description of what’s changed since their last sync.</p><p>At the core of this model is the Volume: a sparse, ordered collection of fixed-size Pages. Clients interact with Volumes through a transactional API, reading and writing at specific Snapshots. Under the hood, Graft persists and replicates only what’s necessary—using object storage as a durable, scalable backend.</p><p>The result is a system that’s lazy, partial, edge-capable, and consistent.</p><blockquote data-callout=\"tip\" data-expandable=\"false\" data-expanded=\"false\"><div><div>Want to try the managed version of Graft?</div></div></blockquote><p>Each of these properties deserves a closer look—let’s unpack them one by one.</p><h3><a href=\"https://sqlsync.dev/posts/stop-syncing-everything/#lazy-sync-at-your-own-pace\" data-astro-prefetch=\"\">#</a>Lazy: Sync at your own pace</h3><p>Graft is designed for the real world—where edge clients wake up occasionally, face unreliable networks, and run in short-lived, resource-constrained environments. Instead of relying on continuous replication, clients choose  to sync, and Graft makes it easy to fast forward to the latest snapshot.</p><p>That sync starts with a simple question: <em>what changed since my last snapshot?</em></p><p>The server responds with a —a compact bitset of page indexes that have changed across all commits since that snapshot. This is where the project gets its name: a  attaches new changes to an existing snapshot—like grafting a branch onto a tree. They act as a guide, informing the\nclient which pages can be reused and which need to be fetched if needed.</p><p>Critically, when a client pulls a  from the server, it doesn’t receive any actual data—only metadata about what changed. This gives the client full control over what to fetch and when, laying the foundation for partial replication.</p><h3><a href=\"https://sqlsync.dev/posts/stop-syncing-everything/#partial-sync-only-whats-needed\" data-astro-prefetch=\"\">#</a>Partial: Sync only what’s needed</h3><p>When you’re building for edge environments—browser tabs, mobile apps, serverless functions—you can’t afford to download the entire dataset just to serve a handful of queries. That’s where partial replication comes in.</p><p>After a client pulls a , it knows exactly what’s changed. It can use that information to determine precisely which pages are still valid and which pages need to be fetched. Instead of pulling everything, clients selectively retrieve only the pages they’ll actually use—nothing more, nothing less.</p><p>To keep things snappy, Graft supports several ways to prefetch pages:</p><ol><li><strong>General-purpose prefetching</strong>: Graft includes a built-in prefetcher based on the <a href=\"https://www.usenix.org/system/files/atc20-maruf.pdf\" data-astro-prefetch=\"\">Leap</a> algorithm, which predicts future page accesses by identifying patterns.</li><li><strong>Domain-specific prefetching</strong>: Applications can leverage domain knowledge to preemptively fetch relevant pages. For instance, if your app frequently queries a user’s profile, Graft can prefetch pages related to that profile before the data is needed.</li><li>: Clients can always fall back to pulling all changes if needed, essentially reverting to full replication. This is particularly useful for Graft workloads running on the server side.</li></ol><p>And because Graft hosts pages directly on object storage, they’re naturally durable and scalable, creating a strong foundation for edge-native replication.</p><h3><a href=\"https://sqlsync.dev/posts/stop-syncing-everything/#edge-sync-close-to-the-action\" data-astro-prefetch=\"\">#</a>Edge: Sync close to the action</h3><p>Edge replication isn’t just about choosing what data to sync—it’s about making sure that data is available where it’s actually needed. Graft does this in two key ways.</p><p>First, pages are served from object-storage through a global fleet of edge servers, allowing frequently accessed (“hot”) pages to be cached near clients. This keeps latency low and responsiveness high, no matter where in the world your users happen to be.</p><p>Second, the Graft client itself is lightweight and designed specifically to be embedded. With minimal dependencies and a tiny runtime, it integrates into constrained environments like browsers, devices, mobile apps, and serverless functions.</p><p>The result? Your data is always cached exactly where it’s most valuable—right at the edge and embedded in your application.</p><p>But caching data on the edge brings new challenges, particularly around maintaining consistency and safely handling conflicts. That’s where Graft’s robust consistency model comes in.</p><h3><a href=\"https://sqlsync.dev/posts/stop-syncing-everything/#consistency-sync-safely\" data-astro-prefetch=\"\">#</a>Consistency: Sync safely</h3><p>Strong consistency is critical—especially when syncing data between clients that might occasionally conflict. Graft addresses this by providing a clear and robust consistency model: <a href=\"https://distributed-computing-musings.com/2022/02/transactions-serializable-snapshot-isolation/\" data-astro-prefetch=\"\">Serializable Snapshot Isolation</a>.</p><p>This model gives clients isolated, consistent views of data at specific snapshots, allowing reads to proceed concurrently without interference. At the same time, it ensures that writes are <a href=\"https://jepsen.io/consistency/models/strong-serializable\" data-astro-prefetch=\"\">strictly serialized</a>, so there’s always a clear, globally consistent order for every transaction.</p><p>However, because Graft is designed for offline-first, lazy replication, clients sometimes attempt to commit changes based on an outdated snapshot. Accepting these commits blindly would violate strict serializability. Instead, Graft safely rejects the commit and lets the client choose how to resolve the situation. Typically, clients will:</p><ol><li>, by pulling the latest snapshot, reapplying local transactions, and trying again.\n<ul><li>Globally, the data remains strictly serializable.</li><li>Locally, the client experiences <strong>Optimistic Snapshot Isolation</strong>, meaning:\n<ul><li>Reads always observe internally consistent snapshots.</li><li>However, these snapshots may later be discarded if the commit is rejected.</li></ul></li></ul></li><li> their local state with the latest snapshot from the server. This may degrade the global consistency model to <a href=\"https://jepsen.io/consistency/models/snapshot-isolation\" data-astro-prefetch=\"\">snapshot isolation</a>.</li><li><strong>Fork the volume permanently</strong>, creating a new, separate volume—thus maintaining global serializability.</li></ol><p>In short, Graft ensures you never have to sacrifice consistency—even when clients sync sporadically, operate offline, or collide with concurrent writes.</p><h2><a href=\"https://sqlsync.dev/posts/stop-syncing-everything/#what-can-you-build-with-graft\" data-astro-prefetch=\"\">#</a>What can you build with Graft?</h2><p>Combining lazy syncing, partial replication, edge-friendly deployment, and strong consistency, Graft provides a robust foundation for a variety of edge-native applications. Here are just a few examples of what you can build with Graft:</p><p>:\nNote-taking, task management, or CRUD apps that operate partially offline. Graft takes care of syncing, allowing the application to forget the network even exists. When combined with a conflict handler, Graft can also enable multiplayer on top of arbitrary data.</p><p>:\nEliminate vendor lock-in and allow your users to seamlessly access their data across mobile platforms, devices, and the web. Graft is architected to be embedded anywhere.</p><p>:\nDue to Graft’s unique approach to replication, a database replica can be spun up with no local state, retrieve the latest snapshot metadata, and immediately start running queries. No need to download all the data and replay the log.</p><p>:\nGraft is just focused on consistent page replication. It doesn’t care about what’s inside those pages. So go crazy! Use Graft to sync AI models, <a href=\"https://en.wikipedia.org/wiki/Apache_Parquet\" data-astro-prefetch=\"\">Parquet</a> or <a href=\"https://github.com/lancedb/lance\" data-astro-prefetch=\"\">Lance</a> files, <a href=\"https://docs.mapbox.com/help/glossary/mbtiles/\" data-astro-prefetch=\"\">Geospatial tilesets</a>, or just photos of your <a href=\"https://www.google.com/search?udm=2&amp;q=cats\" data-astro-prefetch=\"\">cats</a>. The sky’s the limit with Graft.</p><h2><a href=\"https://sqlsync.dev/posts/stop-syncing-everything/#the-graft-sqlite-extension-libgraft\" data-astro-prefetch=\"\">#</a>The Graft SQLite Extension ()</h2><p>Today,  is the easiest way to start using Graft. It’s a native SQLite extension that works anywhere SQLite does. It uses Graft to replicate just the parts of the database that a client actually uses, making it possible to run SQLite in resource constrained environments.</p><p> implements a <a href=\"https://www.sqlite.org/vfs.html\" data-astro-prefetch=\"\">SQLite virtual file system (VFS)</a> allowing it to intercept all reads and writes to the database. It provides the same transactional and concurrency semantics as SQLite does when running in <a href=\"https://www.sqlite.org/wal.html\" data-astro-prefetch=\"\">WAL mode</a>. Using  provides your application with the following benefits:</p><p>Graft is developed openly on <a href=\"https://github.com/orbitinghail/graft\" data-astro-prefetch=\"\">GitHub</a>, and contributions from the community are very welcome. You can open issues, participate in discussions, or submit pull requests—check out our <a href=\"https://github.com/orbitinghail/graft/blob/main/CONTRIBUTING.md\" data-astro-prefetch=\"\">contribution guide</a> for details.</p><p>I’m also planning on launching a Graft Managed Service. If you’d like to join the waitlist, you can <a href=\"https://sqlsync.dev/out/signup-graft-service\" data-astro-prefetch=\"\">sign up here</a>.</p><blockquote data-callout=\"tip\" data-expandable=\"false\" data-expanded=\"false\"><div>Keep reading to learn about Graft’s roadmap as well as a detailed comparison between Graft and existing SQLite replication solutions.</div></blockquote><p>Graft is the result of a year of research, many iterations, and one major pivot. But Graft is far from done. There’s a lot left to build, and the roadmap is ambitious. In no particular order, here’s what’s planned:</p><p><strong>Integrating Graft and SQLSync</strong>:\nOnce Graft supports Wasm, integrating it with SQLSync will be straightforward. The plan is to split out SQLSync’s mutation, rebase, and query subscription layers so it can lay on top of a database using Graft replication.</p><p>:\nI’d love to see native Graft-client wrappers for popular languages including Python, Javascript, Go, and Java. This would allow Graft to be used to replicate arbitrary data in those languages rather than being restricted to SQLite.</p><p>:\nGraft currently blocks push operations until they have been fully committed into object storage. This can be addressed in a number of ways:</p><ol><li>Experiment with S3 express zone</li><li>Buffer writes in a low-latency durable consensus group sitting in front of object storage.</li></ol><p><strong>Garbage collection, checkpointing, and compaction</strong>:\nThese features are needed to maximize query performance, minimize wasted space, and enable deleting data permanently. They all relate to Graft’s decision to store data directly in object storage, and batch changes together into files called segments.</p><p><strong>Authentication and authorization</strong>:\nThis is a fairly broad task that encompasses everything from accounts on the Graft managed service to fine-grained authorization to read/write Volumes.</p><p>:\nThe Graft service is already setup to perform zero-copy forks, since it can easily copy Segment references over to the new Volume. However, to perform a local fork, Graft currently needs to copy all of the pages. This could be solved by layering volumes locally and allowing reads to fall through or changing how pages are addressed locally.</p><p>:\nGraft should offer built-in conflict resolution strategies and extension points so applications can control how conflicts are handled. The initial built-in strategy will automatically merge non-overlapping transactions. While this relaxes global consistency to optimistic snapshot isolation, it can significantly boost performance in collaborative and multiplayer scenarios.</p><p>Graft builds on ideas pioneered by many other projects, while adding its own unique contributions to the space. Here is a brief overview of the SQLite replication landscape and how Graft compares.</p><blockquote data-callout=\"caution\" data-expandable=\"false\" data-expanded=\"false\"><p>The information in this section has been gathered from documentation and blog posts, and might not be perfectly accurate. Please <a href=\"https://sqlsync.dev/cdn-cgi/l/email-protection#e28a878e8e8da28d90808b968b8c858a838b8ecc868794\" data-astro-prefetch=\"\">let me know</a> if I’ve misrepresented or misunderstood a project.</p></blockquote><p>Among SQLite-based projects, <a href=\"https://github.com/losfair/mvsqlite\" data-astro-prefetch=\"\">mvSQLite</a> is the closest in concept to Graft. It implements a custom VFS layer that stores SQLite pages directly in <a href=\"https://www.foundationdb.org/\" data-astro-prefetch=\"\">FoundationDB</a>.</p><p>In mvSQLite, each page is stored by its content hash and referenced by <code>(page_number, snapshot version)</code>. This structure allows readers to lazily fetch pages from FoundationDB as needed. By leveraging page-level versioning, mvSQLite supports concurrent write transactions, provided their read and write sets don’t overlap.</p><p>: Graft and mvSQLite share similar storage-layer designs, using page-level versioning to allow lazy, on-demand fetching and partial database views. The key difference lies in data storage location and how page changes are tracked. mvSQLite depends on FoundationDB, requiring all nodes to have direct cluster access—making it unsuitable for widely distributed edge devices and web applications. Additionally, Graft’s <a href=\"https://github.com/orbitinghail/splinter-rs\" data-astro-prefetch=\"\">Splinter</a>-based changesets are self-contained, easily distributable, and do not require direct queries against FoundationDB to determine changed page versions.</p><p><a href=\"https://litestream.io/\" data-astro-prefetch=\"\">Litestream</a> is a streaming backup solution that continuously replicates <a href=\"https://www.sqlite.org/wal.html\" data-astro-prefetch=\"\">SQLite WAL</a> frames to object storage. Its primary focus is async durability, point-in-time restore, and read replicas. It runs externally to your application, monitoring SQLite’s WAL through the filesystem.</p><p>: Unlike Litestream, Graft integrates directly into SQLite’s commit process via its custom VFS, enabling lazy, partial replication, and distributed writes. Like Litestream, Graft replicates pages to object storage and supports point-in-time restores.</p><p>: Graft is schema-agnostic and doesn’t depend on logical CRDTs, making it compatible with arbitrary SQLite extensions and custom data structures. However, to achieve global serializability, Graft expects applications to handle conflict resolution explicitly. In contrast, cr-sqlite automatically merges changes from multiple writers, achieving <a href=\"https://jepsen.io/consistency/models/causal\" data-astro-prefetch=\"\">causal consistency</a>.</p><h4><a href=\"https://sqlsync.dev/posts/stop-syncing-everything/#cloudflare-durable-objects-with-sqlite-storage-9\" data-astro-prefetch=\"\">#</a>Cloudflare Durable Objects with SQLite Storage </h4><p><a href=\"https://blog.cloudflare.com/sqlite-in-durable-objects/\" data-astro-prefetch=\"\">By combining Durable Objects with SQLite</a>, you get a strongly consistent and highly durable database wrapped with your business logic and hosted hopefully close to your users in Cloudflare’s massive edge network. Under the hood, this solution is similar to Litestream in that it replicates the SQLite WAL to object storage and performs periodic checkpoints.</p><p>: Graft exposes replication as a first class citizen, and is designed to replicate efficiently to and from the edge. In comparison, SQLite in Durable Objects is focused on extending Durable Objects with the full power of SQLite.</p><p><a href=\"https://developers.cloudflare.com/d1/\" data-astro-prefetch=\"\">Cloudflare D1</a> is a managed SQLite database operating similarly to traditional database services like <a href=\"https://aws.amazon.com/rds/\" data-astro-prefetch=\"\">Amazon RDS</a> or <a href=\"https://turso.tech/\" data-astro-prefetch=\"\">Turso</a>, accessed by applications via an HTTP API.</p><p>: Graft replicates data directly to the edge, embedding it within client applications. This decentralized replication model contrasts significantly with D1’s centralized data service.</p><p><a href=\"https://turso.tech/\" data-astro-prefetch=\"\">Turso</a> provides managed SQLite databases and embedded replicas via <a href=\"https://github.com/tursodatabase/libsql\" data-astro-prefetch=\"\">libSQL</a>, an open-source SQLite fork. Similar to Litestream and Cloudflare Durable Objects SQL Storage, Turso replicates SQLite WAL frames to object storage and periodically checkpoints. Replicas catch up by retrieving these checkpoints and replaying the log.</p><p>: Graft distinguishes itself with partial replication and support for arbitrary, schema-agnostic data structures. Graft’s backend service operates directly at the page level and outsources the entire transactional lifecycle to clients.</p><p>The key idea behind <a href=\"https://github.com/rqlite/rqlite\" data-astro-prefetch=\"\">rqlite</a> and <a href=\"https://dqlite.io/\" data-astro-prefetch=\"\">dqlite</a> is to distribute SQLite across multiple servers. This is achieved through <a href=\"https://en.wikipedia.org/wiki/Raft_(algorithm)\" data-astro-prefetch=\"\">Raft</a> based consensus and routing SQLite operations through a network protocol to the current Raft leader.</p><p> These projects are focused on increasing SQLite’s durability and availability through consensus and traditional replication. They are designed to keep a set of stateful nodes that maintain connectivity to one another in sync. Graft fundamentally differs by being a stateless system built on top of object storage, designed to replicate data to and from the edge.</p><p><a href=\"https://github.com/backtrace-labs/verneuil\" data-astro-prefetch=\"\">Verneuil</a> focuses on asynchronously replicating SQLite snapshots to read replicas via object storage, prioritizing reliability without introducing additional failure modes. Verneuil explicitly avoids mechanisms to minimize replication latency or staleness.</p><p>: Graft behaves more like a multi-writer distributed database, emphasizing selective, real-time partial replication. Verneuil’s approach, meanwhile, emphasizes unidirectional asynchronous snapshot replication without guarantees around replication freshness.</p>","contentLength":17480,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43537272"},{"title":"Oracle attempt to hide cybersecurity incident from customers?","url":"https://doublepulsar.com/oracle-attempt-to-hide-serious-cybersecurity-incident-from-customers-in-oracle-saas-service-9231c8daff4a","date":1743433893,"author":"2bluesc","guid":17011,"unread":true,"content":"<p>All the systems impacted are directly managed by Oracle. Some of the data provided to journalists is current, too. This is a serious cybersecurity incident which impacts customers, in a platform managed by Oracle.</p><p>Oracle are attempting to wordsmith statements around Oracle Cloud and use very specific words to avoid responsibility. Oracle need to clearly, openly and publicly communicate what happened, how it impacts customers, and what they’re doing about it. This is a matter of trust and responsibility. Step up, Oracle — or customers should start stepping off.</p><p>— Oracle rebadged old Oracle Cloud services to be Oracle Classic. Oracle Classic has the security incident.</p><p>Oracle are denying it on “Oracle Cloud” by using this scope — but it’s still Oracle cloud services that Oracle manage. That’s part of the wordplay.</p><p>— although Oracle <a href=\"https://help.archive.org/help/how-do-i-request-to-remove-something-from-archive-org/\" rel=\"noopener ugc nofollow\" target=\"_blank\">used the archive.org exclusion process</a> to remove evidence of writing to one of the Oraclecloud.com webservers, they forgot to remove the 2nd URL (click picture for hyperlink).</p><p>— Multiple Oracle cloud customers have reached out to me to say Oracle have now confirmed a breach of their services.</p><p>They are only doing so verbally, they will not write anything down, so they’re setting up meetings with large customers who query.</p><p>This is similar behaviour to the breach of medical PII in the ongoing breach at Oracle Health, where they will only provide details verbally and not in writing:</p><p><a href=\"https://www.bloomberg.com/news/articles/2025-03-28/oracle-warns-health-customers-of-patient-data-breach\" rel=\"noopener ugc nofollow\" target=\"_blank\">https://www.bloomberg.com/news/articles/2025-03-28/oracle-warns-health-customers-of-patient-data-breach</a></p><p>Additional information has come to light on the security issues with Oracle Classic aka OCI Gen1 - I am investigating.</p>","contentLength":1662,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43535953"},{"title":"Gemini 2.5 Pro vs. Claude 3.7 Sonnet: Coding Comparison","url":"https://composio.dev/blog/gemini-2-5-pro-vs-claude-3-7-sonnet-coding-comparison/","date":1743422989,"author":"mraniki","guid":18805,"unread":true,"content":"<p>Google just launched Gemini 2.5 Pro on March 26th, claiming to be the best in coding, reasoning and overall everything. But I mostly care about how the model compares against the best available coding model, Claude 3.7 Sonnet (thinking), released at the end of February, which I have been using, and it has been a great experience.</p><p>Let’s compare these two coding models and see if I need to change my favourite coding model or if Claude 3.7 still holds.</p><p>If you want to jump straight to the conclusion, I’d say go for , it’s better at coding, has one million in context window as compared to Claude’s 200k, and you can get it for free (a big plus). However, Claude’s 3.7 Sonnet is not that far behind. Though at this point there’s no point using it over Gemini 2.5 Pro.</p><p>Just an article ago, <a href=\"https://composio.dev/blog/claude-3-7-sonnet-vs-grok-3-vs-o3-mini-high/\">Claude 3.7 Sonnet</a> was the default answer to every model comparison, and this remained the same for quite some time. But here you go, Gemini 2.5 Pro takes the lead. </p><p>Gemini 2.5 Pro, an experimental thinking model, became the talk of the town within a week of its release. Everyone’s talking about this model on Twitter (X) and YouTube. It’s trending everywhere, like seriously. The first model from Google to receive such fanfare.</p><p>And it is  just like that. But what does this mean? It means that this model is killing all the other models in coding, math, Science, Image understanding, and other areas.</p><p>Gemini 2.5 pro comes with a <strong>1 million token context window,</strong> with a 2 million context window coming soon. 🤯</p><p>You can check out other folks like <a href=\"https://www.youtube.com/@t3dotgg\">Theo-t3</a> talking about this model to get a bit more insight into it:</p><p>It is the best coding model to date, with an accuracy of about 63.8% on the SWE bench. This is definitely higher than our previous top coding model, Claude 3.7 Sonnet, which had an accuracy of about 62.3%.</p><p>This is a quick demo Google shared on this model of building a dinosaur game.</p><p>Here’s a quick benchmark of this model on Reasoning, Mathematics, and Science. This confirms that the model is not just suitable for coding but also for all your other needs. They claim it’s an all-rounder. 🤷‍♂️</p><p>This is all cool, and I’ll confirm the claim, but in this article, I will mainly be comparing the model on coding, and let’s see how well it performs compared to Claude 3.7 Sonnet.</p><p>Let’s compare these two models in coding. We’ll do a total of 4 tests, mainly on WebDev, animation and a tricky LeetCode question.</p><p> Create a simple flight simulator using JavaScript. The simulator should feature a basic plane that can take off from a flat runway. The plane’s movement should be controlled with simple keyboard inputs (e.g., arrow keys or WASD). Additionally, it generates a basic cityscape using blocky structures, similar to Minecraft.</p><p><strong>Response from Gemini 2.5 Pro</strong></p><p>You can find the code it generated here: <a href=\"https://gist.github.com/shricodev/5fc44c03fde651f5bea7008919377c1d\">Link</a></p><p>Here’s the output of the program:</p><p>I definitely got exactly what I asked for, with everything functioning, from plane movements to the basic Minecraft-styled block buildings. I can’t really complain about anything here. 10/10 for this one. </p><p><strong>Response from Claude 3.7 Sonnet</strong></p><p>You can find the code it generated here: <a href=\"https://gist.github.com/shricodev/b22a2d583f1a56beb2df2dcf636a1a88\">Link</a></p><p>Here’s the output of the program:</p><p>I can see some issues with this one. The plane clearly faces sideways, and I don’t know why. Again, it was out of control once it took off and went clearly outside the city. Basically, I’d say we didn’t really get a completely working flight simulator here.</p><p>It’s fair to say that Gemini 2.5 really got this correct in one shot. But the issues with the Claude 3.7 Sonnet code aren’t really that big to resolve. Yeah, we didn’t really get the output as expected, and it’s definitely not close to what Gemini 2.5 Pro got us.</p><p>This is one of the toughest questions for LLMs. I’ve tried it with many other LLMs, but none could correct it. Let’s see how these two models do this one.</p><p> Build a simple 3D Rubik’s Cube visualizer and solver in JavaScript using Three.js. The cube should be a 3×3 Rubik’s Cube with standard colours. Have a scramble button that randomly scrambles the cube. Include a solve function that animates the solution step by step. Allow basic mouse controls to rotate the view.</p><p><strong>Response from Gemini 2.5 Pro</strong></p><p>You can find the code it generated here: <a href=\"https://gist.github.com/shricodev/1c7ed9967d03c6f5f9b8fd2ad46bcba1\">Link</a></p><p>Here’s the output of the program:</p><p>It’s impressive that it could do something this hard in one shot. With the 1 million token context window, I can truly see how powerful this model seems to be.</p><p><strong>Response from Claude 3.7 Sonnet</strong></p><p>You can find the code it generated here: <a href=\"https://gist.github.com/shricodev/e4c12edb3384323be43f1196522eb6f2\">Link</a></p><p>Here’s the output of the program:</p><p>Again, I was kind of disappointed that it had the same issue as some other LLMs: failing with the colours and completely failing to solve the cube. I did try to help it come up with the answer, but it didn’t really help.</p><p>Here again, Gemini 2.5 Pro takes the lead. And the best part is that all of it was done in one shot. Claude 3.7 was really disappointing, as it could not get this one correct, despite being one of the finest coding models out there.</p><h3>3. Ball Bouncing Inside a Spinning 4D Tesseract</h3><p> Create a simple JavaScript script that visualizes a ball bouncing inside a rotating 4D tesseract. When the ball collides with a side, highlight that side to indicate the impact.</p><p><strong>Response from Gemini 2.5 Pro</strong></p><p>You can find the code it generated here: <a href=\"https://gist.github.com/shricodev/866c2207af82416edfb240818c3ddf73\">Link</a></p><p>Here’s the output of the program:</p><p>I cannot notice a single issue in the output. The ball and the collision physics all work perfectly, even the part where I asked it to highlight the collision side works. This free model seems to be insane for coding. 🔥</p><p><strong>Response from Claude 3.7 Sonnet</strong></p><p>You can find the code it generated here: <a href=\"https://gist.github.com/shricodev/b54d5b5bda033f6784637c19c50a845b\">Link</a></p><p>Here’s the output of the program:</p><p>Wow, finally, Claude 3.7 Sonnet got an answer correct. It also added colors to each side, but who asked for it? 🤷‍♂️ Nevertheless, I can’t really complain much here, as the main functionality seems to work just fine.</p><p>The answer is evident this time. Both models got the answer correct, implementing everything I asked for. I won’t really say that I like the output of Claude 3.7 Sonnet more, but it definitely put in quite some work compared to Gemini 2.5 Pro.</p><p>For this one, let’s do a quick LeetCode check with to see how these models handle solving a tricky LeetCode question with an <strong>acceptance rate of just 14.9%</strong>: <a href=\"https://leetcode.com/problems/maximum-value-sum-by-placing-three-rooks-i/description/\">Maximum Value Sum by Placing 3 Rooks</a>.</p><p>Claude 3.7 Sonnet is known to be super good at solving LC questions. If you want to see how  compares to some top models like  and , check out this blog post:</p><div data-code-block-pro-font-family=\"Code-Pro-JetBrains-Mono\"><pre tabindex=\"0\"><code></code></pre></div><p><strong>Response from Gemini 2.5 Pro</strong></p><p>Given how easily it answered all three of the coding questions we tested, I have quite high hopes for this model.</p><p>You can find the code it generated here: <a href=\"https://gist.github.com/shricodev/6e1fd99d04a10a3ff7d82934770387d7\">Link</a></p><p>It did take quite some time to answer this one, though, and the code it wrote is kind of super complex to make sense of. I think it answered it more complicated than required. But still, the main thing we’re looking for is to see if it can answer it correctly.</p><p>As expected, it also answered this tough LeetCode question in one shot. This is one of the questions I got stuck on when learning DSA. I’m not sure if I’m happy it did. </p><p><strong>Response from Claude 3.7 Sonnet</strong></p><p>I hope this model will crush this one, as in all the other coding tests I’ve done, Claude 3.7 Sonnet has answered all of the LeetCode questions correctly.</p><p>You can find the code it generated here: <a href=\"https://gist.github.com/shricodev/5730c52c5b057cd2098d4a04674338b6\">Link</a></p><p>It did write correct code but got TLE, but if I have to compare the code’s simplicity, I’d say this model made the code simpler and easier to understand.</p><p>Gemini 2.5 got the answer correct and also wrote the code in the expected time complexity, but Claude 3.7 Sonnet fell into TLE. If I have to compare the code simplicity, Claude 3.7’s generated code seems to be better.</p><p>For me, Gemini 2.5 Pro is the winner. We’ve compared two models that are said to be the best at coding. The big difference I see in the model stats is just that Gemini 2.5 Pro has a slightly higher context window, but let’s not forget that this is an experimental model, and improvements are still on the way.</p><p>Imagine this model’s performance after a </p><p>Google’s been killing it recently with such solid models, previously with the Gemma 3 27B model, a super lightweight model with unbelievable results, and now with this beast of a model, Gemini 2.5 Pro.</p><p>By the way, if you are here, Composio is building the skill repository for agents. You can connect LLMs to any application from Gmail to Asana and get things done quickly. You can use <a href=\"https://mcp.composio.dev\">MCP servers</a>.</p>","contentLength":8508,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43534029"},{"title":"The demoscene as a UNESCO heritage in Sweden","url":"https://www.goto80.com/the-demoscene-as-a-unesco-heritage-in-sweden","date":1743417597,"author":"robin_reala","guid":17010,"unread":true,"content":"<p>The demoscene has become <a href=\"https://levandekulturarv.se/forteckningen/element/demoscenen\">a national UNESCO-heritage in Sweden</a>, thanks to an application that <a href=\"https://scenesat.com/\">Ziphoid</a> and me did last year. This has already happened in several European countries, as part of the international <a href=\"https://demoscene-the-art-of-coding.net/\">Art of Coding</a> initiative to make the demoscene a global UNESCO heritage. I think this makes plenty of sense, since the demoscene is arguably&nbsp;the oldest creative digital subculture around. It has largely stuck to its own values and traditions throughout the world’s technological and economical shifts, and that sort of consistency is quite unusual in the digital world.</p><p>The main idea of the demoscene is to compete with productions that maximize a certain hardware, but that’s not what all demosceners like to do. My demogroup <a href=\"https://demozoo.org/groups/10273/\">Hack n’ Trade</a> for example, cares more about making weird stuff, and there are plenty of other groups like that. Some demosceners don’t release anything at all, but might do important work to keep the scene alive (BBS-trading, organizing parties, preserving software…).</p><p>I’ve written plenty of <a href=\"https://goto80.com/writing\">papers</a> and <a href=\"https://chipflip.wordpress.com/\">blog posts</a> about the demoscene, and I’ve often felt a gap between the stuff I write as a researcher and my personal experience of the demoscene. There is certainly an international demoscene with big events and huge releases that can be described in general terms, but what has mattered more to me is the local scenes, the small parties and the people you hang out with. Meeting up with a bunch of friends and making weird computer stuff “for no reason, really” is a great setting. That’s what I enjoy the most, in the end. For other sceners, it’s different.</p><p>There is a sort of diversity in the scene that is difficult to capture and generalize. The Swedish coder with a well-paid programming job and a busy family life might consider the demoscene as an escape to his teenage years, while the LSD-munching raver from France who trades illegal warez on BBSs and makes weird pixel art considers the scene as a free culture without corporate or art world bullshit. There’s room for both in the scene, because it is werdly conservative and open at the same time. And perhaps that is one of the reasons why it should be considered an intangible heritage.</p>","contentLength":2211,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43533362"},{"title":"The <select> element can now be customized with CSS","url":"https://developer.chrome.com/blog/a-customizable-select","date":1743412307,"author":"tosh","guid":18804,"unread":true,"content":"<p>\n  Published: March 24, 2025\n</p><p>From Chrome 135, web developers and designers can finally unite on an accessible, standardized and CSS styleable  element on the web. This has been many years in the making, many hours of engineering and collaborative specification work, and the result is an incredibly rich and powerful component that won't break in older browsers.</p><p>Here's a video of customized selects using these new features:</p><h2 data-text=\"Meet appearance: base-select\" tabindex=\"-1\">Meet </h2><p>A new CSS property  that puts the  element into a new, configurable and styleable state to be commonly referred to as \"base\" styles:</p><p>Using  a number of new features and behaviors:</p><p>Using  a number of features and behaviors:</p><ul><li>The  doesn't render outside the browser pane.</li><li>It doesn't trigger built-in mobile operating system components.</li><li>The  stops taking the width of the longest <a href=\"https://developer.mozilla.org/docs/Web/HTML/Element/option\"></a>.</li></ul><h3 data-text=\"A <select> can now include rich HTML content\" tabindex=\"-1\">A  can now include rich HTML content</h3><p>Before you could customize a , if you put things like an image or SVG into the  element, the browser would ignore them.</p><p>Consider the following HTML, the browser would read it as you authored it:</p><p>However the used DOM wouldn't include the :</p><p>Here's (from left to right) Chrome, Safari, and Firefox rendering the preceding HTML. If the browser supports  then the SVG will appear in the option, otherwise it won't.</p><p>There's risk in breaking existing websites with customizable select, due to the parser changes. Chrome has the features behind a <a href=\"https://developer.chrome.com/docs/web-platform/chrome-finch\">Finch experiment</a> in case there is an emergency need to turn it off. If things go well, the experiment will end and the code will be shipped permanently into the source.</p><p><a href=\"https://una.im/select-updates/\">Every part of a </a> can be swapped out, customized and animated. Here's a demo that uses every new feature to create recognizable and meaningful select experiences.</p><p>Find many more examples in the resources section at the end of this post.</p><h3 data-text=\"Unchanged JavaScript interfaces\" tabindex=\"-1\">Unchanged JavaScript interfaces</h3><p>There's no risks to your existing JavaScript interactions with a  element.</p><p>However, if you do begin adding rich HTML into your <a href=\"https://developer.mozilla.org/docs/Web/HTML/Element/option\"></a> elements, you should test the selected values, as the browser does still parse and ignore images and SVG. The logic has changed though, for determining the selected content string, and depending on what you have in your options, you may need to make adjustments.</p><p>If you're using the  attribute on an  you have nothing to worry about.</p><p>Chrome is first to implement , but every browser participated in the specifications, and there's more \"base\" elements yet to be completed. This is just a start.</p><p>Stay tuned as we'll be continuing to add guidance, examples and resources on customizing select elements. Until then, checkout the following links for more information.</p><p><strong>Special thanks to all those who were involved in making this happen!</strong></p>","contentLength":2660,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43532830"},{"title":"How each pillar of the First Amendment is under attack","url":"https://krebsonsecurity.com/2025/03/how-each-pillar-of-the-1st-amendment-is-under-attack/","date":1743384407,"author":"todsacerdoti","guid":16602,"unread":true,"content":"<p><em>“Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof; or abridging the freedom of speech, or of the press; or the right of the people peaceably to assemble, and to petition the Government for a redress of grievances.” -U.S. Constitution, First Amendment.</em></p><div><img aria-describedby=\"caption-attachment-70858\" decoding=\"async\" src=\"https://krebsonsecurity.com/wp-content/uploads/2025/03/1stamendment.png\" alt=\"\" width=\"747\" height=\"508\"><p>Image: Shutterstock, zimmytws.</p></div><p>In an address to Congress this month,  claimed he had “brought free speech back to America.” But barely two months into his second term, the president has waged an unprecedented attack on the First Amendment rights of journalists, students, universities, government workers, lawyers and judges.</p><p>This story explores a slew of recent actions by the Trump administration that threaten to undermine all five pillars of the First Amendment to the U.S. Constitution, which guarantees freedoms concerning speech, religion, the media, the right to assembly, and the right to petition the government and seek redress for wrongs.</p><p>The right to petition allows citizens to communicate with the government, whether to complain, request action, or share viewpoints — without fear of reprisal. But that right is being assaulted by this administration on multiple levels. For starters, many GOP lawmakers are now heeding their leadership’s advice to stay away from local town hall meetings and avoid the wrath of constituents affected by the administration’s many federal budget and workforce cuts.</p><p>Another example: President Trump recently <a href=\"https://www.cnn.com/2025/02/18/politics/opm-privacy-team-fired/index.html\" target=\"_blank\" rel=\"noopener\">fired most of the people</a> involved in processing <strong>Freedom of Information Act</strong> (FOIA) requests for government agencies. FOIA is an indispensable tool used by journalists and the public to request government records, and to hold leaders accountable.</p><p>The biggest story by far this week was the bombshell from The Atlantic editor , who recounted how he was <a href=\"https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/?gift=DjgA9DZGvABas7wFCM-ptk0vpPuikYUZT9Ej3cJbK1s&amp;utm_source=copy-link&amp;utm_medium=social&amp;utm_campaign=share\" target=\"_blank\" rel=\"noopener\">inadvertently added to a Signal group chat</a> with <strong>National Security Advisor Michael Waltz</strong> and 16 other Trump administration officials discussing plans for an upcoming attack on Yemen.</p><p>One overlooked aspect of Goldberg’s incredible account is that by planning and coordinating the attack on Signal — which features messages that can auto-delete after a short time — administration officials were evidently seeking a way to avoid creating a lasting (and potentially FOIA-able) record of their deliberations.</p><p>“Intentional or not, use of Signal in this context was an act of erasure—because without Jeffrey Goldberg being accidentally added to the list, the general public would never have any record of these communications or any way to know they even occurred,” <a href=\"https://www.forbes.com/sites/tonybradley/2025/03/26/what-everyone-has-missed-about-the-trump-administration-signal-scandal/\" target=\"_blank\" rel=\"noopener\">wrote this week at Forbes</a>.</p><p>Petitioning the government, particularly when it ignores your requests, often requires challenging federal agencies in court. But that becomes far more difficult if the most competent law firms start to shy away from cases that may involve crossing the president and his administration.</p><p>On March 22, the president issued <a href=\"https://www.whitehouse.gov/presidential-actions/2025/03/preventing-abuses-of-the-legal-system-and-the-federal-court/\" target=\"_blank\" rel=\"noopener\">a memorandum</a> that directs heads of the Justice and Homeland Security Departments to “seek sanctions against attorneys and law firms who engage in frivolous, unreasonable and vexatious litigation against the United States,” or in matters that come before federal agencies.</p><p>The POTUS recently issued several executive orders railing against specific law firms with attorneys who worked legal cases against him. On Friday, the <a href=\"https://www.bloomberg.com/news/articles/2025-03-28/trump-says-he-s-reached-100-million-pro-bono-deal-with-skadden\" target=\"_blank\" rel=\"noopener\">president announced</a> that the law firm of <strong>Skadden, Arps, Slate, Meager &amp; Flom</strong> had agreed to provide $100 million in pro bono work on issues that he supports.</p><p>Trump issued <a href=\"https://www.whitehouse.gov/presidential-actions/2025/03/addressing-remedial-action-by-paul-weiss/\" target=\"_blank\" rel=\"noopener\">another order</a> naming the firm <strong>Paul, Weiss, Rifkind, Wharton &amp; Garrison</strong>, which ultimately agreed to pledge $40 million in pro bono legal services to the president’s causes.</p><p>Other Trump executive orders targeted law firms  and , both of which have attorneys that worked with special counsel Robert Mueller on the investigation into Russian interference in the 2016 election. But this week, two federal judges in separate rulings <a href=\"https://www.cnn.com/2025/03/28/politics/law-firms-fighting-trump-executive-order/index.html\" target=\"_blank\" rel=\"noopener\">froze parts of those orders</a>.</p><p>“There is no doubt this retaliatory action chills speech and legal advocacy, and that is qualified as a constitutional harm,” wrote , who ruled against the executive order targeting WilmerHale.</p><p>President Trump recently took the extraordinary step of calling for the impeachment of federal judges who rule against the administration. Trump called <strong>U.S. District Judge James Boasberg</strong><a href=\"https://www.politico.com/news/2025/03/18/trump-impeachment-judge-deportations-00235173\" target=\"_blank\" rel=\"noopener\" data-tracking=\"mpos=&amp;mid=&amp;lindex=&amp;lcol=\" aria-label=\" (Opens in a new window)\">a “Radical Left Lunatic”</a> and urged he be removed from office for blocking deportation of Venezuelan alleged gang members under a rarely invoked wartime legal authority.</p><p>In a rare public rebuke to a sitting president, <strong>U.S. Supreme Court Justice John Roberts</strong><a href=\"https://www.reuters.com/legal/us-chief-justice-roberts-calls-judges-impeachment-are-inappropriate-after-trump-2025-03-18/\" target=\"_blank\" rel=\"noopener\">issued a statement on March 18</a> pointing out that “For more than two centuries, it has been established that impeachment is not an appropriate response to disagreement concerning a judicial decision.”</p><p>The U.S. Constitution provides that judges can be removed from office only through impeachment by the House of Representatives and conviction by the Senate. The Constitution also states that judges’ salaries cannot be reduced while they are in office.</p><p>“We do have authority over the federal courts as you know,” Johnson said. “We can eliminate an entire district court. We have power of funding over the courts, and all these other things. But desperate times call for desperate measures, and Congress is going to act, so stay tuned for that.”</p><p>President Trump has taken a number of actions to discourage lawful demonstrations at universities and colleges across the country, <a href=\"https://www.reuters.com/world/us/trump-says-federal-funding-will-stop-colleges-schools-allowing-illegal-protests-2025-03-04/\" target=\"_blank\" rel=\"noopener\">threatening to cut federal funding</a> for any college that supports protests he deems “illegal.”</p><p>A Trump <a href=\"https://www.whitehouse.gov/presidential-actions/2025/01/additional-measures-to-combat-anti-semitism/\" target=\"_blank\" rel=\"noopener\">executive order in January</a> outlined a broad federal crackdown on what he called “the explosion of antisemitism” on U.S. college campuses. This administration has asserted that foreign students who are lawfully in the United States on visas do not enjoy the same free speech or due process rights as citizens.</p><p>Meanwhile, <strong>U.S. Immigration and Customs Enforcement</strong> (ICE) agents have been <a href=\"https://apnews.com/article/immigration-detainees-students-ozturk-khalil-78f544fb2c8b593c88a0c1f0e0ad9c5f\" target=\"_blank\" rel=\"noopener\">detaining and trying to deport</a> pro-Palestinian students who are legally in the United States. The administration is targeting students and academics who spoke out against Israel’s attacks on Gaza, or who were active in campus protests against U.S. support for the attacks. <strong>Secretary of State Marco Rubio</strong><a href=\"https://thehill.com/homenews/education/5218410-ice-arrests-tufts-alabama-students-trump-immigration-crackdown-rumeysa-ozturk-khalil/\" target=\"_blank\" rel=\"noopener\">told reporters Thursday</a> that at least 300 foreign students have seen their visas revoked under President Trump, a far higher number than was previously known.</p><p>In his first term, Trump threatened to use the national guard or the U.S. military to deal with protesters, and in campaigning for re-election he promised to revisit the idea.</p><p>“I think the bigger problem is the enemy from within,” Trump told  in October 2024. “We have some very bad people. We have some sick people, radical left lunatics. And I think they’re the big — and it should be very easily handled by, if necessary, by National Guard, or if really necessary, by the military, because they can’t let that happen.”</p><p>This term, Trump acted swiftly to remove the top judicial advocates in the armed forces who would almost certainly push back on any request by the president to use U.S. soldiers in an effort to quell public protests, or to arrest and detain immigrants. In late February, the president and <strong>Defense Secretary Pete Hegseth</strong> fired the top legal officers for the military services — those responsible for ensuring the Uniform Code of Military Justice is followed by commanders.</p><p>Military.com <a href=\"https://www.military.com/daily-news/2025/02/24/people-are-very-scared-trump-administration-purge-of-jag-officers-raises-legal-ethical-fears.html\" target=\"_blank\" rel=\"noopener\">warns</a> that the purge “sets an alarming precedent for a crucial job in the military, as President Donald Trump has mused about using the military in unorthodox and potentially illegal ways.” Hegseth told reporters the removals were necessary because he didn’t want them to pose any “roadblocks to orders that are given by a commander in chief.”</p><p>President Trump has sued a number of U.S. news outlets, including , , ,  and other smaller media organizations for unflattering coverage.</p><p>In a $10 billion lawsuit against 60 Minutes and its parent , Trump claims they selectively edited an interview with former <strong>Vice President Kamala Harris</strong> prior to the 2024 election. The TV news show last month published transcripts of the interview at the heart of the dispute, but Paramount is <a href=\"https://apnews.com/article/cbs-60-minutes-lawsuit-trump-pelley-58339cc1a1eb52739bb365e2e8c6d8bc\" target=\"_blank\" rel=\"noopener\">reportedly considering a settlement</a> to avoid potentially damaging its chances of winning the administration’s approval for a pending multibillion-dollar merger.</p><p>The president <a href=\"https://www.desmoinesregister.com/story/news/crime-and-courts/2025/02/25/dismissal-sought-donald-trump-lawsuit-pollster-ann-selzer-des-moines-register-iowa-poll/79442387007/\" target=\"_blank\" rel=\"noopener\">sued The Des Moines Register</a> and its parent company, , for publishing a poll showing Trump trailing Harris in the 2024 presidential election in Iowa (a state that went for Trump). The POTUS also is <a href=\"https://www.politico.com/news/2024/07/21/trump-libel-suit-pulitzer-prize-00169975\" target=\"_blank\" rel=\"noopener\">suing the Pulitzer Prize board</a> over 2018 awards given to The New York Times and The Washington Post for their coverage of purported Russian interference in the 2016 election.</p><p>Whether or not any of the president’s lawsuits against news organizations have merit or succeed is almost beside the point. The strategy behind suing the media is to make reporters and newsrooms think twice about criticizing or challenging the president and his administration. The president also knows some media outlets will find it more expedient to settle.</p><p>Trump also sued  and  for stating that the president had been found liable for “rape” in a civil case [Trump was found liable of sexually abusing and defaming E. Jean Carroll]. ABC parent  settled that claim by agreeing to donate $15 million to the Trump Presidential Library.</p><p>Following the attack on the U.S. Capitol on Jan. 6, 2021,  blocked President Trump’s account. Trump sued , and after the president’s victory in 2024 Meta <a href=\"https://www.wsj.com/us-news/law/trump-signs-agreement-calling-for-meta-to-pay-25-million-to-settle-suit-6f734c8c?mod=article_inline\" target=\"_blank\" rel=\"noopener\" aria-label=\"Go to https://www.wsj.com/us-news/law/trump-signs-agreement-calling-for-meta-to-pay-25-million-to-settle-suit-6f734c8c?mod=article_inline\">settled</a> and agreed to pay Trump $25 million: $22 million would go to his presidential library, and the rest to legal fees.  also announced Facebook and Instagram would <a href=\"https://www.cnn.com/2025/01/07/tech/meta-censorship-moderation/index.html\" target=\"_blank\" rel=\"noopener\">get rid of fact-checkers</a> and rely instead on reader-submitted “community notes” to debunk disinformation on the social media platform.</p><p>, the president’s pick to run the <strong>Federal Communications Commission</strong> (FCC), has pledged to “dismantle the censorship cartel and restore free speech rights for everyday Americans.” But on January 22, 2025, the FCC reopened complaints against ABC,  and  over their coverage of the 2024 election. The previous FCC chair had dismissed the complaints as attacks on the First Amendment and an attempt to weaponize the agency for political purposes.</p><p>According to Reuters, the complaints call for an investigation into how ABC News moderated the pre-election TV debate between Trump and Biden, and appearances of then-Vice President Harris on 60 Minutes and on NBC’s “Saturday Night Live.”</p><p>Since then, the FCC has opened investigations into  and , <a href=\"https://www.npr.org/2025/01/30/nx-s1-5281162/fcc-npr-pbs-investigation\" target=\"_blank\" rel=\"noopener\">alleging</a> that they are breaking sponsorship rules. The <strong>Center for Democracy &amp; Technology </strong>(CDT), a think tank based in Washington, D.C., <a href=\"https://cdt.org/insights/when-it-comes-to-free-speech-the-trump-administration-should-follow-its-own-order/\" target=\"_blank\" rel=\"noopener\">noted</a> that the FCC is also investigating  in San Francisco for reporting on the location of federal immigration authorities.</p><p>“Even if these investigations are ultimately closed without action, the mere fact of opening them – and the implicit threat to the news stations’ license to operate – can have the effect of deterring the press from news coverage that the Administration dislikes,” the CDT’s  observed.</p><p>Trump has repeatedly threatened to “open up” libel laws, with the goal of making it easier to sue media organizations for unfavorable coverage. But this week, the U.S. Supreme Court <a href=\"https://nymag.com/intelligencer/article/supreme-court-thwarts-trump-dream-of-opening-up-libel-laws.html\" target=\"_blank\" rel=\"noopener\">declined to hear a challenge</a> brought by Trump donor and Las Vegas casino magnate Steve Wynn to overturn the landmark 1964 decision in <em>New York Times v. Sullivan</em>, which insulates the press from libel suits over good-faith criticism of public figures.</p><p>The president also has insisted on picking which reporters and news outlets should be allowed to cover White House events and participate in the press pool that trails the president. He barred the  from the White House and Air Force One over their refusal to call the Gulf of Mexico by another name.</p><p>And the Defense Department has ordered a number of top media outlets <a href=\"https://www.reuters.com/world/us/pentagon-doubles-number-news-outlets-rotate-out-office-spaces-2025-02-08/\" target=\"_blank\" rel=\"noopener\">to vacate their spots at the Pentagon</a>, including CNN, The Hill, The Washington Post, The New York Times, NBC News, Politico and National Public Radio.</p><p>“Incoming media outlets include the New York Post, Breitbart, the Washington Examiner, the Free Press, the Daily Caller, Newsmax, the Huffington Post and One America News Network, most of whom are seen as conservative or favoring Republican President Donald Trump,” Reuters reported.</p><p>Shortly after Trump took office again in January 2025, the administration began circulating <a href=\"https://www.nytimes.com/interactive/2025/03/07/us/trump-federal-agencies-websites-words-dei.html\" target=\"_blank\" rel=\"noopener\">lists of hundreds of words</a> that government staff and agencies shall not use in their reports and communications.</p><p>The Brookings Institution <a href=\"https://www.brookings.edu/articles/the-us-government-data-purge-is-a-loss-for-policymaking-and-research/\" target=\"_blank\" rel=\"noopener\">notes</a> that in moving to comply with this anti-speech directive, federal agencies have purged countless taxpayer-funded data sets from a swathe of government websites, including data on crime, sexual orientation, gender, education, climate, and global development.</p><p> reports that in the past two months, hundreds of terabytes of digital resources analyzing data have been taken off government websites.</p><p>“While in many cases the underlying data still exists, the tools that make it possible for the public and researchers to use that data have been removed,” The Times <a href=\"https://www.nytimes.com/2025/03/21/climate/government-websites-climate-environment-data.html\" target=\"_blank\" rel=\"noopener\">wrote</a>.</p><p>On Jan. 27, Trump issued <a href=\"https://www.washingtonpost.com/documents/deb7af80-48b6-4b8a-8bfa-3d84fd7c3ec8.pdf\" target=\"_blank\" rel=\"noopener\">a memo</a> (PDF) that paused all federally funded programs pending a review of those programs for alignment with the administration’s priorities. Among those was ensuring that no funding goes toward advancing “Marxist equity, transgenderism, and green new deal social engineering policies.”</p><p>According to the CDT, this order is a blatant attempt to force government grantees to cease engaging in speech that the current administration dislikes, including speech about the benefits of diversity, climate change, and LGBTQ issues.</p><p>“The First Amendment does not permit the government to discriminate against grantees because it does not like some of the viewpoints they espouse,” the CDT’s Ruane wrote. “Indeed, those groups that are challenging the constitutionality of the order argued as much in their complaint, and have won an injunction blocking its implementation.”</p><p>On January 20, the same day Trump issued an executive order on free speech, the president also issued an executive order titled “<a href=\"https://www.whitehouse.gov/presidential-actions/2025/01/reevaluating-and-realigning-united-states-foreign-aid/\" target=\"_blank\" rel=\"noopener\">Reevaluating and Realigning United States Foreign Aid</a>,” which froze funding for programs run by the <strong>U.S. Agency for International Development</strong> (USAID). Among those were programs designed to empower civil society and human rights groups, journalists and others responding to digital repression and Internet shutdowns.</p><p>According to the <strong>Electronic Frontier Foundation</strong> (EFF), this includes many freedom technologies that use cryptography, fight censorship, protect freedom of speech, privacy and anonymity for millions of people around the world.</p><p>“While the State Department has issued some limited waivers, so far those waivers do not seem to cover the open source internet freedom technologies,” the EFF <a href=\"https://www.eff.org/deeplinks/2025/01/executive-order-state-department-sideswipes-freedom-tools-threatens-censorship\" target=\"_blank\" rel=\"noopener\">wrote</a> about the USAID disruptions. “As a result, many of these projects have to stop or severely curtail their work, lay off talented workers, and stop or slow further development.”</p><p>On March 14, the president signed <a href=\"https://www.whitehouse.gov/presidential-actions/2025/03/continuing-the-reduction-of-the-federal-bureaucracy/\" target=\"_blank\" rel=\"noopener\">another executive order</a> that effectively gutted the <strong>U.S. Agency for Global Media</strong> (USAGM), which oversees or funds media outlets including <strong>Radio Free Europe/Radio Liberty</strong> and  (VOA). The USAGM also oversees , which supporters say has been one of the most reliable tools used by the government to combat Chinese propaganda.</p><p>“RFE/RL has, for decades, operated as one of the organizations that Congress has statutorily designated to carry out this policy,” Lamberth&nbsp;<a href=\"https://storage.courtlistener.com/recap/gov.uscourts.dcd.278524/gov.uscourts.dcd.278524.14.0.pdf\" target=\"_blank\" rel=\"noreferrer noopener\">wrote in a 10-page opinion</a>. “The leadership of USAGM cannot, with one sentence of reasoning offering virtually no explanation, force RFE/RL to shut down — even if the President has told them to do so.”</p><p>The Trump administration <a href=\"https://www.dhs.gov/news/2025/01/21/statement-dhs-spokesperson-directives-expanding-law-enforcement-and-ending-abuse\" target=\"_blank\" rel=\"noopener\">rescinded a decades-old policy</a> that instructed officers not to take immigration enforcement actions in or near “sensitive” or “protected” places, such as churches, schools, and hospitals.</p><p>That directive was immediately challenged in a case brought by a group of Quakers, Baptists and Sikhs, who argued the policy reversal was keeping people from attending services for fear of being arrested on civil immigration violations. On Feb. 24, a federal judge agreed and <a href=\"https://www.usatoday.com/story/news/politics/2025/02/24/judge-blocks-immigration-enforcement-churches/80043880007/\" target=\"_blank\" rel=\"noopener\">blocked</a> ICE agents from entering churches or targeting migrants nearby.</p><p>The president also <a href=\"https://apnews.com/article/trump-national-prayer-breakfast-30ff6f55a2e3c7b8643a15e7b158537d\" target=\"_blank\" rel=\"noopener\">announced</a> the creation of a “Task Force to Eradicate Anti-Christian Bias,” to be led by Attorney General Pam Bondi. Never mind that Christianity is easily the largest faith in America and that Christians are well-represented in Congress.</p><p>The <strong>Rev. Paul Brandeis Raushenbush</strong>, a Baptist minister and head of the progressive , issued a statement accusing Trump of hypocrisy in claiming to champion religion by creating the task force.</p><p>“From allowing immigration raids in churches, to targeting faith-based charities, to suppressing religious diversity, the Trump Administration’s aggressive government overreach is infringing on religious freedom in a way we haven’t seen for generations,” Raushenbush said.</p><p>A <a href=\"https://www.au.org/the-latest/press/task-force-anti-christian-bias-trump/\" target=\"_blank\" rel=\"noopener\">statement</a> from <strong>Americans United for Separation of Church and State</strong> said the task force could lead to religious persecution of those with other faiths.</p><p>“Rather than protecting religious beliefs, this task force will misuse religious freedom to justify bigotry, discrimination, and the subversion of our civil rights laws,” said Rachel Laser, the group’s president and CEO.</p><p>Where is President Trump going with all these blatant attacks on the First Amendment? The president has made no secret of his affection for autocratic leaders and “strongmen” around the world, and he is particularly enamored with Hungary’s far-right <strong>Prime Minister Viktor Orbán</strong>, who has visited Trump’s Mar-a-Lago resort twice in the past year.</p><p>A <a href=\"https://www.theatlantic.com/ideas/archive/2025/03/trumps-press-freedom-hungary-orban/682060/\" target=\"_blank\" rel=\"noopener\">March 15 essay</a> in The Atlantic by Hungarian investigative journalist  recounts how Orbán rose to power by consolidating control over the courts, and by building his own media universe while simultaneously placing a stranglehold on the independent press.</p><p>“As I watch from afar what’s happening to the free press in the United States during the first weeks of Trump’s second presidency — the verbal bullying, the legal harassment, the buckling by media owners in the face of threats — it all looks very familiar,” Pethő wrote. “The MAGA authorities have learned Orbán’s lessons well.”</p>","contentLength":18547,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43529707"},{"title":"FBI raids home of prominent computer scientist who has gone incommunicado","url":"https://arstechnica.com/security/2025/03/computer-scientist-goes-silent-after-fbi-raid-and-purging-from-university-website/","date":1743364210,"author":"JaimeThompson","guid":16576,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=43527001"}],"tags":["dev"]}