{"id":"25JnLB7bCaiYJ","title":"Tech News","displayTitle":"Tech News","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":148,"items":[{"title":"Uber Cofounder Kalanick Says AI Means Some Consultants Are in 'Big Trouble'","url":"https://slashdot.org/story/25/04/15/1918257/uber-cofounder-kalanick-says-ai-means-some-consultants-are-in-big-trouble?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744745400,"author":"msmash","guid":23476,"unread":true,"content":"Uber cofounder Travis Kalanick thinks AI is about to shake up consulting -- and for \"traditional\" professionals, not in a good way. From a report: The former Uber CEO said consultants who mostly follow instructions or do repetitive tasks are at risk of being replaced by AI. \"If you're a traditional consultant and you're just doing the thing, you're executing the thing, you're probably in some big trouble,\" he said. He joked about what that future of consultancy might look like: \"Push a button. Get a consultant.\" \n\nHowever, Kalanick said the professionals who would come out ahead would be the ones who build tools rather than just use them. \"If you are the consultant that puts the things together that replaces the consultant, maybe you got some stuff,\" he said. \"You're going to profitable companies with competitive moats, making that moat bigger,\" he explained. \"Making their profit bigger is probably pretty interesting from a financial point of view.\"","contentLength":963,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"India’s BluSmart swept up in Gensol investigation alleging misuse of EV loans","url":"https://techcrunch.com/2025/04/15/indian-ride-hailing-startup-blusmart-swept-up-in-gensol-investigation-alleging-misuse-of-ev-loans/","date":1744745041,"author":"Jagmeet Singh","guid":23475,"unread":true,"content":"<article>India’s market regulator launched a probe Tuesday into Gensol Engineering after finding alleged misuse of electric vehicle loans. BluSmart, a ride-hailing startup connected to Gensol that was once seen as an emerging Uber rival in the South Asian market, has also been swept up into the investigation. The Securities and Exchange Board of India (SEBI) […]</article>","contentLength":359,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Figma sent a cease-and-desist letter to Lovable over the term ‘Dev Mode’","url":"https://techcrunch.com/2025/04/15/figma-sent-a-cease-and-desist-letter-to-lovable-over-the-term-dev-mode/","date":1744744660,"author":"Julie Bort","guid":23444,"unread":true,"content":"<article>We may be witnessing the makings of a new tech industry feud between competitors. Figma has sent a cease-and-desist letter to popular no-code AI startup Lovable, Figma confirmed to TechCrunch.&nbsp; The letter tells Lovable to stop using the term “Dev Mode” for a new product feature. Figma, which also has a feature called Dev Mode, […]</article>","contentLength":339,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"You Should Still Learn To Code, Says GitHub CEO","url":"https://developers.slashdot.org/story/25/04/15/1853254/you-should-still-learn-to-code-says-github-ceo?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744743180,"author":"msmash","guid":23449,"unread":true,"content":"You should still learn to code, says GitHub's CEO. And you should start as soon as possible. From a report: \"I strongly believe that every kid, every child, should learn coding,\" Thomas Dohmke said in a recent podcast interview with EO. \"We should actually teach them coding in school, in the same way that we teach them physics and geography and literacy and math and what-not.\" Coding, he added, is one such fundamental skill -- and the only reason it's not part of the curriculum is because it took \"us too long to actually realize that.\" \n\nDohmke, who's been a programmer since the 90s, said he's never seen \"anything more exciting\" than the current moment in engineering -- the advent of AI, he believes, has made the field that much easier to break into, and is poised to make software more ubiquitous than ever. \"It's so much easier to get into software development. You can just write a prompt into Copilot or ChatGPT or similar tools, and it will likely write you a basic webpage, or a small application, a game in Python,\" Dohmke said. \"And so, AI makes software development so much more accessible for anyone who wants to learn coding.\" \n\nAI, Dohmke said, helps to \"realize the dream\" of bringing an idea to life, meaning that fewer projects will end up dead in the water, and smaller teams of developers will be enabled to tackle larger-scale projects. Dohmke said he believes it makes the overall process of creation more efficient. \"You see some of the early signs of that, where very small startups -- sometimes five developers and some of them actually only one developer -- believe they can become million, if not billion dollar businesses by leveraging all the AI agents that are available to them,\" he added.","contentLength":1727,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI hires team behind GV-backed AI eval platform Context.ai","url":"https://techcrunch.com/2025/04/15/openai-hires-team-behind-gv-backed-ai-eval-platform-context-ai/","date":1744740798,"author":"Ivan Mehta","guid":23419,"unread":true,"content":"<article>Context.ai, a startup building evaluations and analytics for AI models, announced Tuesday that its co-founders will join OpenAI.&nbsp; Context.ai plans to wind down its products following the acqui-hire, per a message on the company’s website. When reached for comment, OpenAI declined to reveal the terms of the deal. “Evals are a requirement to building high-performing […]</article>","contentLength":377,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google bets on geothermal to power data centers in Taiwan","url":"https://techcrunch.com/2025/04/15/google-bets-on-geothermal-to-power-data-centers-in-taiwan/","date":1744740130,"author":"Tim De Chant","guid":23418,"unread":true,"content":"<article>Swedish company Baseload Capital is developing the project.</article>","contentLength":59,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google DeepMind Is Hiring a 'Post-AGI' Research Scientist","url":"https://slashdot.org/story/25/04/15/182244/google-deepmind-is-hiring-a-post-agi-research-scientist?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744740120,"author":"msmash","guid":23421,"unread":true,"content":"An anonymous reader shares a report: None of the frontier AI research labs have presented any evidence that they are on the brink of achieving artificial general intelligence, no matter how they define that goal, but Google is already planning for a \"Post-AGI\" world by hiring a scientist for its DeepMind AI lab to research the \"profound impact\" that technology will have on society. \n\n\"Spearhead research projects exploring the influence of AGI on domains such as economics, law, health/wellbeing, AGI to ASI [artificial superintelligence], machine consciousness, and education,\" Google says in the first item on a list of key responsibilities for the job. Artificial superintelligence refers to a hypothetical form of AI that is smarter than the smartest human in all domains. This is self explanatory, but just to be clear, when Google refers to \"machine consciousness\" it's referring to the science fiction idea of a sentient machine. \n\nOpenAI CEO Sam Altman, DeepMind CEO Demis Hassabis, Elon Musk, and other major and minor players in the AI industry are all working on AGI and have previously talked about the likelihood of humanity achieving AGI, when that might happen, and what the consequences might be, but the Google job listing shows that companies are now taking concrete steps for what comes after, or are at least are continuing to signal that they believe it can be achieved.","contentLength":1394,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Anthropic forms a new team to grow its AWS business","url":"https://techcrunch.com/2025/04/15/anthropic-forms-a-new-team-to-grow-its-aws-business/","date":1744738652,"author":"Kyle Wiggers","guid":23417,"unread":true,"content":"<article>In a sign of Anthropic’s increasingly cozy relationship with Amazon, Anthropic has formed a new team to recruit AWS customers to use its AI products. The team, which Anthropic appears to have begun hiring several months ago, aims to “accelerate” the adoption of Anthropic’s AI among AWS accounts by “building programs that […] scale across […]</article>","contentLength":357,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI is Building a Social Network","url":"https://tech.slashdot.org/story/25/04/15/1648226/openai-is-building-a-social-network?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744737600,"author":"msmash","guid":23420,"unread":true,"content":"An anonymous reader shares a report: OpenAI is working on its own X-like social network, according to multiple sources familiar with the matter. While the project is still in early stages, we're told there's an internal prototype focused on ChatGPT's image generation that has a social feed. CEO Sam Altman has been privately asking outsiders for feedback about the project, our sources say. It's unclear if OpenAI's plan is to release the social network as a separate app or integrate it into ChatGPT, which became the most downloaded app globally last month. \n\nLaunching a social network in or around ChatGPT would likely increase Altman's already-bitter rivalry with Elon Musk. In February, after Musk made an unsolicited offer to purchase OpenAI for $97.4 billion, Altman responded: \"no thank you but we will buy twitter for $9.74 billion if you want.\" Entering the social media market also puts OpenAI on more of a collision course with Meta, which we're told is planning to add a social feed to its coming standalone app for its AI assistant. When reports of Meta building a rival to the ChatGPT app first surfaced a couple of months ago, Altman shot back on X again by saying, \"ok fine maybe we'll do a social app.\"","contentLength":1222,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Publishing platform Medium says it’s sticking with DEI","url":"https://techcrunch.com/2025/04/15/publishing-platform-medium-says-its-sticking-with-dei/","date":1744737203,"author":"Sarah Perez","guid":23366,"unread":true,"content":"<article>Publishing platform Medium says it’s still committed to diversity, equity, and inclusion (DEI), even as many other U.S. tech companies have scaled back their efforts in this space to appease the Trump administration. In a blog post published on Monday, Medium CEO Tony Stubblebine backed the company’s diverse community, saying that businesses shouldn’t have to […]</article>","contentLength":373,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Anthropic’s Claude can now read your Gmail","url":"https://techcrunch.com/2025/04/15/anthropics-claude-now-read-your-gmail/","date":1744736400,"author":"Maxwell Zeff","guid":23364,"unread":true,"content":"<article>Anthropic announced on Tuesday that its AI chatbot, Claude, now integrates with Google Workspace, allowing it to search and reference your emails in Gmail, scheduled events in Google Calendar, and documents in Google Docs. The integration is rolling out in beta first to subscribers to Anthropic’s Max, Team, Enterprise, and Pro plans. Administrators managing multi-user […]</article>","contentLength":378,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google’s Veo 2 video generating model comes to Gemini","url":"https://techcrunch.com/2025/04/15/googles-veo-2-video-generator-comes-to-gemini/","date":1744736400,"author":"Kyle Wiggers","guid":23365,"unread":true,"content":"<article>Google is bringing its Veo 2 video-generating AI model to users who pay for Gemini Advanced, the company’s premium AI plan. The expansion comes as Google looks to deliver an answer to OpenAI’s Sora video generation platform, and as competition in the space grows fiercer. Two weeks ago, one of the more formidable synthetic media […]</article>","contentLength":339,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Notorious image board 4chan hacked and internal data leaked","url":"https://techcrunch.com/2025/04/15/notorious-image-board-4chan-hacked-and-internal-data-leaked/","date":1744736061,"author":"Lorenzo Franceschi-Bicchierai, Amanda Silberling","guid":23363,"unread":true,"content":"<article>The infamous website was taken down and working intermittently, while hackers leaked alleged data like moderators email addresses, and source code.</article>","contentLength":147,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Android Phones Will Soon Reboot Themselves After Sitting Unused For 3 Days","url":"https://it.slashdot.org/story/25/04/15/1636208/android-phones-will-soon-reboot-themselves-after-sitting-unused-for-3-days?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744735200,"author":"msmash","guid":23367,"unread":true,"content":"An anonymous reader shares a report: A silent update rolling out to virtually all Android devices will make your phone more secure, and all you have to do is not touch it for a few days. The new feature implements auto-restart of a locked device, which will keep your personal data more secure. It's coming as part of a Google Play Services update, though, so there's nothing you can do to speed along the process. \n\nGoogle is preparing to release a new update to Play Services (v25.14), which brings a raft of tweaks and improvements to myriad system features. First spotted by 9to5Google, the update was officially released on April 14, but as with all Play Services updates, it could take a week or more to reach all devices. When 25.14 arrives, Android devices will see a few minor improvements, including prettier settings screens, improved connection with cars and watches, and content previews when using Quick Share.","contentLength":924,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Deel’s CEO is now in Dubai, complicating Rippling’s lawsuit","url":"https://techcrunch.com/2025/04/15/deels-ceo-is-now-in-dubai-complicating-ripplings-lawsuit/","date":1744734736,"author":"Charles Rollet","guid":23362,"unread":true,"content":"<article>Rippling’s efforts to serve Deel CEO Alex Bouaziz have been significantly complicated by the fact that Bouaziz and his lawyer are now in Dubai, according to internal correspondence seen by TechCrunch. The UAE is a country with a reputation of being a safe haven for those wanting to avoid extradition. Rippling is trying to serve […]</article>","contentLength":337,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Witness a dynamic dialogue between two visionary CEOs","url":"https://techcrunch.com/2025/04/15/witness-a-dynamic-dialogue-between-two-visionary-ceos/","date":1744734651,"author":"Cindy Zackney","guid":23361,"unread":true,"content":"<article>Step into an extraordinary fireside chat featuring Ali Ghodsi, the visionary co-founder and CEO of Databricks, alongside Dario Amodei, the innovative co-founder and CEO of Anthropic. Discover how their groundbreaking partnership is set to accelerate the evolution of domain-specific AI agents. During this free, virtual event, you’ll also gain exclusive access to three additional sessions […]</article>","contentLength":397,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI is reportedly developing its own X-like social media platform","url":"https://techcrunch.com/2025/04/15/openai-is-reportedly-developing-its-own-x-like-social-media-platform/","date":1744733537,"author":"Aisha Malik","guid":23346,"unread":true,"content":"<article>OpenAI is building its own X-like social media network, according to a new report from The Verge. The project is still in the early stages, but there’s an internal prototype focused on&nbsp;ChatGPT’s image generation that contains a social feed. The report states that it’s unknown if OpenAI plans to launch the social network as a […]</article>","contentLength":339,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI ships GPT-4.1 without a safety report","url":"https://techcrunch.com/2025/04/15/openai-ships-gpt-4-1-without-a-safety-report/","date":1744733525,"author":"Maxwell Zeff","guid":23345,"unread":true,"content":"<article>On Monday, OpenAI launched a new family of AI models, GPT-4.1, which the company said outperformed some of its existing models on certain tests, particularly benchmarks for programming. However, GPT-4.1 didn’t ship with the safety report that typically accompanies OpenAI’s model releases, known as a model or system card. As of Tuesday morning, OpenAI had […]</article>","contentLength":366,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Components of an Ideal Layer 2 Rollup Design","url":"https://hackernoon.com/the-components-of-an-ideal-layer-2-rollup-design?source=rss","date":1744732821,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23431,"unread":true,"content":"<p>The ideal rollup design allows efficient (off-chain) verifiable computation with fast finality. Here, efficiency means:</p><p>\\\n• Reduced replicated computation. We do not want to use resources, e.g., use an enormous amount of electricity, when it is unnecessary for the required level of security. Reduced replication should also reduce the cost per transaction, making the system more scalable from an economic perspective.</p><p>\\\n• High confidence in results. This is the converse to replication: users should be able to trust the results from the verified computation, even though the replication factor might be lower.</p><p>\\\n• High throughput. The overall system throughput should be high, so that the system will perform well with a high workload.</p><p>\\\n• Low latency. Proposed transactions should not have to wait too long in queues. Users should have reasonable confidence that once a transaction is accepted, it will have the desired/expected effect.</p><p>\\\nWhat an “ideal” design might look like depends on other factors, such as the expected workload. For example, as systems become more capable, will applications need to run larger transactions that have a high gas limit? What is the distribution of execution times? With a design that separates transaction order finality and state finality, as long as the average transaction processing rate is sufficient, the system should be able to tolerate occasional high execution time transactions, since users will primarily care about transaction order finality, assuming that the expensive transaction do not interfere or interact with most users’ contracts’ state.</p><p>\\\nThis is still an area of research and some design constraints are unknown. We present a sketch of an “ideal” design below.</p><h2>3.1 VM Job Queue and Transaction Order Finality</h2><p>The ideal rollup design uses “instant” finality of a PoS blockchain (e.g. Tendermint, Eth2) to obtain transaction order finality. That is, transaction proposals are essentially jobs entered into the virtual machine job queue; once entered into the queue, its order is final.</p><p>\\\nThis implies that the transaction callData cannot be validated with full virtual machine semantics, since that requires close coupling between the log and the virtual machine. One extreme design choice is to allow arbitrary messages to be logged to target the VM’s job queue, and rely on the cost of logging to deter denial-of-service attacks. This means, however, that the cost of VM execution to verify and discard ill-formed message (e.g., unsigned, unparseable, nonexistent contract entry points, etc) must be included as part of the cost of message handling.</p><p>\\\nMessage posting has to cost something in order to prevent denial-of-service attacks. This means some checks must already be done at the underlying blockchain: the message itself must be signed, and it must authorize payment from the EOA to minimally pay for the message posting itself, as well as a (limited) payment authorization for the VM execution (gas limit).</p><p>\\\nSince signature check is effectively a sunk cost, an alternative is to perform some very simple verification of proposed transactions:</p><p>\\\n• Transaction authorization: valid signature on the proposal.</p><p>\\\n• EOA account has enough tokens to pay for message posting.</p><p>\\\n• (Optional) EOA account has enough tokens to pay for the maximum gas payment, using an lower-bound estimate from the queue of transactions for which state finality has not been reached.</p><p>\\\nThe contract call parameters (callData) is just opaque bytes at this point.</p><p>\\\nAll signed transaction proposals with these basic checks are considered “well-formed transactions” (WFTs). Note that we do not perform contract entry point-specific type checks or other per-contract pre-condition checks at the bridge. Well-formedness does not imply that the message makes sense. WFTs that do not pass message format checks will simply be aborted with the sender charged a small gas fee: in our formalism, this means that the interpretation is that tc returns with its input state. The same thing applies for other pre-conditions: those would be checked by the contract code (e.g., the equivalent of require checks in Solidity) and similarly cause the transaction to be aborted. This conforms with the decoupled nature of the system design: the bridge contract does not know what (possibly new) contracts have been instantiated on the rollup, and doing typechecking would be impractical.</p><p>\\\nContract invocations in Ethereum-like blockchains are internally structured as essentially remote procedure calls, with a message that must be (partially) parsed to identify the intended entry point and discover the type signature, and then to further parse and typecheck the rest of the message. While it might be reasonable to say that the message encoding is architecturally fixed and performed by the rollup VM, it is feasible—as is done by Solidity for the EVM—to perform this in the contract code itself (in Solidity’s case, in the language runtime which performs the RPC dispatch). Since different contract language runtimes could, in principle, require completely different data serialization formats, performing message format verification in the bridge is infeasible without knowing details about how each contract’s RPC message receiver/demultiplexor is implemented.</p><p>\\\nThe simplest design is to view the bridge contract as accepting WFTs and require runtime checking for rollup-specific, contract-language specific, or contractspecific pre-conditions.</p><p>\\\nThe arrival order at the job queue maintained by the bridge contract does not necessarily specify the execution order. Clearly, as long as a rollup allows transaction proposers to offer variable gas fees (as opposed to a fixed market rate as a gating threshold), jobs will need to be sorted by gas price. And while using gas price as the primary key and arrival order as the secondary key might approximate a “fair” order, it allows a frontrunner to trivially creating pseudoconjugate transactions by proposing a pair of transactions at a slightly higher and slightly lower gas fee. More research is needed here, especially since implementing an approximate fair scheduler will introduce additional latency to the transaction processing.</p><p>(1) Bennet Yee, Oasis Labs;</p><p>(2) Dawn Song, Oasis Labs;</p><p>(3) Patrick McCorry, Infura;</p><p>(4) Chris Buckland, Infura.</p>","contentLength":6360,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Opening Financial Markets to Everyone: An Interview with Valentin Preobrazhenskiy, CEO of LATOKEN","url":"https://hackernoon.com/opening-financial-markets-to-everyone-an-interview-with-valentin-preobrazhenskiy-ceo-of-latoken?source=rss","date":1744732803,"author":"Jon Stojan Journalist","guid":23430,"unread":true,"content":"<h3><strong>Can you introduce yourself and tell us about LATOKEN?</strong></h3><p>\\\nI’m Valentin Preobrazhenskiy, CEO and founder of LATOKEN, one of the leading cryptocurrency exchanges focused on altcoins. Previously, I managed a hedge fund where I developed a passion for discovering promising investments and now help traders find hidden crypto gems while empowering founders to successfully launch tokens that gain real community traction.</p><h3><strong>How did you get the idea to launch LATOKEN?</strong></h3><p>Before LATOKEN, I ran a long-short equity hedge fund where I successfully predicted geopolitical risks in 2014, moving my portfolio away from exposure to Russian markets towards more global opportunities. At that turning point, I had two choices: join the highly competitive Wall Street environment or pursue an entirely new avenue—blockchain technology—that very few understood at the time.</p><p>\\\nOrganizing hundreds of tech meetups opened my eyes to blockchain and ICO trends. Ethereum, launched by Vitalik Buterin, particularly intrigued me because startups suddenly had the tools to essentially “print their own money” through tokenization. It became clear to me that blockchain would soon revolutionize asset ownership. Millions of assets would be tokenized, demanding a completely new infrastructure. That’s when I transitioned part of my team from my home equity loan platform to build LATOKEN. We launched our ICO in 2017 and quickly grew from there.</p><h3><strong>How has LATOKEN evolved since launching?</strong></h3><p>Today, LATOKEN supports more than 4 million user accounts from 127 countries and lists over 2,000 digital assets. We're consistently ranked among the top 50 crypto exchanges globally according to CoinMarketCap and CoinGecko, and Forbes named us one of the Top 30 Remote Employers worldwide. Our strength lies in identifying innovative tokens early, providing investors a first-mover advantage.</p><h3><strong>What fuels your passion for this mission?</strong></h3><p>My passion is deeply personal. Growing up in post-Soviet Russia during the economic collapse of the 1990s profoundly shaped my worldview. I vividly remember being with my family, picking berries in a peaceful forest, while at home, hyperinflation had wiped out our savings overnight. My parents, both highly skilled engineers, lost their jobs during that turbulent time.</p><p>\\\nStudying economics at the New Economic School further reinforced my belief in secure property rights as the foundation for stability and growth. Blockchain captivated me precisely because it provides a transparent, secure method to protect wealth, independent of unreliable institutions or politics. That potential continues to inspire everything I do at LATOKEN.</p><h3><strong>How will blockchain and altcoins reshape the financial industry?</strong></h3><p>Blockchain addresses one critical global issue: secure property rights without costly institutional oversight. Traditional financial systems require extensive infrastructure—armies, police, courts, central banks—to guarantee property ownership. Many countries simply can't sustain such complex institutions, leaving billions excluded from financial stability.</p><p>\\\nBlockchain technology eliminates these barriers, allowing anyone to open accounts and trade digital assets easily, like signing up for an email service. Beyond inclusivity, altcoins offer a hedge against fiat currency devaluation and create a web3 economy where users become stakeholders and founders scale rapidly.</p><h3><strong>What role does AI play in the crypto world?</strong></h3><p>AI significantly streamlines crypto operations, helping traders discover new tokens through advanced analytics, recommendations, and market summarization. At LATOKEN, we've embraced AI to automate processes like customer interactions during token listings, qualifying leads, and even transforming our HR department. AI-powered tools screen resumes, conduct candidate assessments, and organize streamlined interviews. This allowed us to efficiently build and manage a fully remote global team of over 150 experts, reflecting the blockchain ethos of transparency and efficiency internally.</p><h3><strong>What's your outlook on the current crypto market?</strong></h3><p>Currently, altcoins face challenging liquidity conditions due to high interest rates drawing capital away from the crypto sector. However, I view this as a temporary downturn. As soon as macroeconomic pressures ease, liquidity will rapidly return—first into Bitcoin and Ethereum, and later into strong altcoins backed by vibrant communities and practical use-cases. Hedge funds are already positioning themselves to capitalize on these undervalued assets, signaling an upcoming market revival.</p><h3><strong>What are your thoughts on recent crypto policy developments in the US?</strong></h3><p>Recent regulatory moves in the US have been cautiously optimistic. Authorities recognize the value of stablecoins and tokenized treasuries to expand the dollar's global footprint without cumbersome intermediaries. By halting the push for a central bank digital currency, the US has subtly embraced decentralized innovation over centralized alternatives, potentially unlocking institutional capital and fostering wider adoption.</p><h3><strong>Tell us about your involvement with the Founder Institute.</strong></h3><p>At the Founder Institute, a global startup accelerator with alumni companies exceeding $20 billion in valuation, I served as both a Director and Mentor. I guided early-stage entrepreneurs through the critical phases of refining their ideas, crafting viable products, and raising funds. Drawing on my LATOKEN journey, I shared firsthand experiences on scaling operations, overcoming fundraising challenges, and staying competitive in fast-evolving markets.</p><h3>What about your role in the Blockchain Economic Forum?</h3><p>Launching the Blockchain Economic Forum (BEF) in 2017 is among my proudest achievements. BEF became a unique global platform connecting blockchain innovators with policymakers and institutional investors. We held impactful forums in cities like Davos, New York, San Francisco, and London, gathering influential leaders including presidents, EU policymakers, SEC leadership, and top economists. The aim was to facilitate transition of DeFi into the mainstream financial system. I love connecting founders to build the future and made over 500 documented tech meetups.</p><p>I’ve had the privilege of judging international startup competitions focused on Web3 at Gain Web3 Pitch Competitions in partnership with Duke University's Web3 Ecosystem, DevCon and Blockchain life forums in 2024. Judging allowed me to help founders sharpen their market strategies, refine their products, and prepare for scaling.</p><h3><strong>Do you have any unique or controversial views you'd like to share?</strong></h3><p>I believe that the universal goal of life can be measured as global economy capitalization with a Nasdaq as a well-known proxy. Currency is a control right to use energy for the self-replication of symbiosis of programs, constituting Sapience. Future cash flow essentially reflects strategic viability of life. I find this concept useful to prioritize conflicting goals and run a  to share this framework.</p><p>My mission remains steadfast: ensure every person has meaningful access to economic opportunity. Whether through LATOKEN, mentoring founders, or facilitating global forums, my goal is removing barriers to financial inclusion. Access to the global financial system shouldn't be a privilege—it should be universally accessible, creating a more stable and united world.</p>","contentLength":7350,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Zuckerberg Had a 'Crazy Idea' in 2022 For Facebook - Purge All Users' Friends","url":"https://tech.slashdot.org/story/25/04/15/1536244/zuckerberg-had-a-crazy-idea-in-2022-for-facebook---purge-all-users-friends?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744732800,"author":"msmash","guid":23348,"unread":true,"content":"Meta CEO Mark Zuckerberg considered resetting all Facebook users' friend connections to boost the platform's declining relevance, according to internal emails revealed Monday in a landmark FTC antitrust trial. In a 2022 message to executives, Zuckerberg proposed \"wiping everyone's graphs and having them start again,\" referring to users' friend networks. Facebook head Tom Alison questioned the idea's viability, citing Instagram's reliance on friend connections. Zuckerberg later testified that the plan was never implemented and that Facebook has \"evolved\" from its original purpose. \n\nThe FTC argues Meta violated competition laws by acquiring Instagram ($1B) and WhatsApp ($19B) as part of a \"buy or bury\" strategy outlined in Zuckerberg's 2008 email stating, \"It is better to buy than compete.\"","contentLength":800,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Here’s how Pacific Fusion plans to build a fusion power plant","url":"https://techcrunch.com/2025/04/15/heres-how-pacific-fusion-plans-to-build-a-fusion-power-plant/","date":1744732800,"author":"Tim De Chant","guid":23343,"unread":true,"content":"<article>Pacific Fusion also announced the hiring of a key executive from competitor Helion.</article>","contentLength":83,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Former Tesla supply chain leaders create Atomic, an AI inventory solution","url":"https://techcrunch.com/2025/04/15/former-tesla-supply-chain-leaders-create-atomic-an-ai-inventory-solution/","date":1744732800,"author":"Sean O'Kane","guid":23344,"unread":true,"content":"<article>Tesla famously struggled to scale up production of the Model 3 sedan in 2018 — so much so that CEO Elon Musk said his company was weeks away from collapsing. That near-death experience helped spawn a whole new company called Atomic that’s built around using AI to streamline supply chains. Co-founded by former Tesla employees […]</article>","contentLength":336,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Founders Fund’s new $4.6B fund indicates an era of big VC spending","url":"https://techcrunch.com/2025/04/15/founders-funds-new-4-6b-fund-indicates-an-era-of-big-vc-spending/","date":1744732415,"author":"Julie Bort","guid":23342,"unread":true,"content":"<article>Peter Thiel’s Founders Fund has completed the raise of its third growth fund, according to an SEC filing. Beyond the sum — which is a big step up from its previous $3.4 billion growth fund&nbsp;closed in early 2022 — there’s a couple of other interesting things to note about this raise. For one, it’s more […]</article>","contentLength":318,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Mark Zuckerberg once considered deleting all your Facebook friends","url":"https://techcrunch.com/2025/04/15/mark-zuckerberg-once-considered-deleting-all-your-facebook-friends/","date":1744730699,"author":"Sarah Perez","guid":23303,"unread":true,"content":"<article>Meta CEO Mark Zuckerberg once considered deleting everyone’s Facebook friends in an effort to boost the social network’s cultural relevance. This “potentially crazy idea,” as the exec called it at the time, was revealed on Monday as a part of the evidence introduced during the first day of the U.S. government’s antitrust trial against Meta. […]</article>","contentLength":358,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"FCC Chairman Tells Europe To Choose Between US or Chinese Communications Tech","url":"https://tech.slashdot.org/story/25/04/15/1514205/fcc-chairman-tells-europe-to-choose-between-us-or-chinese-communications-tech?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744730400,"author":"msmash","guid":23304,"unread":true,"content":"FCC Chairman Brendan Carr has issued a stark ultimatum to European allies, telling them to choose between US and Chinese communications technology. In an interview with Financial Times, Carr urged \"allied western democracies\" to \"focus on the real long-term bogey: the rise of the Chinese Communist party.\" The warning comes as European governments question Starlink's reliability after Washington threatened to switch off its services in Ukraine. \n\nUK telecoms BT and Virgin Media O2 are currently trialing Starlink's satellite internet technology but haven't signed full agreements. \"If you're concerned about Starlink, just wait for the CCP's version, then you'll be really worried,\" said Carr. Carr claimed Europe is \"caught\" between Washington and Beijing, with a \"great divide\" emerging between \"CCP-aligned countries and others\" in AI and satellite technology. He also accused the European Commission of \"protectionism\" and an \"anti-American\" attitude while suggesting Nokia and Ericsson should relocate manufacturing to the US to avoid Trump's import tariffs.","contentLength":1067,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reach 1,000+ AI leaders: Host a Side Event during TechCrunch Sessions: AI","url":"https://techcrunch.com/2025/04/15/host-your-very-own-side-event-during-techcrunch-sessions-ai/","date":1744729200,"author":"TechCrunch Events","guid":23300,"unread":true,"content":"<article>Looking to position your brand in front of the brightest minds in artificial intelligence? Hosting a Side Event during TechCrunch Sessions: AI Week is your opportunity to do just that. Reach 1,200+ attendees and the surrounding Berkeley tech scene. From June 1 to June 7, TechCrunch invites startups, investors, and builders to bring unique and […]</article>","contentLength":350,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Notion releases an AI-powered email client for Gmail","url":"https://techcrunch.com/2025/04/15/notion-releases-its-ai-driven-email-inbox/","date":1744729200,"author":"Rebecca Szkutak","guid":23301,"unread":true,"content":"<article>Notion released Notion Mail, an AI-powered email client for Gmail that integrates with the rest of Notion’s workflow management platform, on Tuesday. Notion Mail connects to Notion users’ Gmail accounts and uses AI to help users organize their emails, draft responses, schedule meetings, and search across messages. Any Notion user can sign up, and Notion […]</article>","contentLength":365,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Final days to apply to speak at TechCrunch All Stage","url":"https://techcrunch.com/2025/04/15/final-days-to-apply-to-speak-at-techcrunch-all-stage/","date":1744729200,"author":"TechCrunch Events","guid":23302,"unread":true,"content":"<article>The application to speak at TechCrunch All Stage closes this Friday, April 18 — don’t miss your chance to share hard-won insights with 1,200+ startup founders and VCs. If you’ve been in the trenches and cracked tough growth problems, now’s the time to step up and share your scaling strategies onstage at TC All Stage, […]</article>","contentLength":332,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Blockchain Consensus Mechanisms, Once and For All: PoW, PoS, and Rollups","url":"https://hackernoon.com/blockchain-consensus-mechanisms-once-and-for-all-pow-pos-and-rollups?source=rss","date":1744725634,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23429,"unread":true,"content":"<h2>2.10 Deciding on the Correct State</h2><p>The mechanism by which the correct state is decided is security critical. There are many different design choices that have been explored, with different security assumptions and scaling efficiency. By security assumptions, we mean not only common cryptographic assumptions (e.g., one-way functions), but also compute resources such as hashing power and monetary resources such as control of some fraction of the total stake. By scaling efficiency, we mean both in terms of normal resource usage and in terms of resources needed to achieve a desired level of security. Table 1 shows several different rollups and their state transition security mechanisms.</p><p>\\\nWhile Bitcoin uses a PoW-based log, there is no explicit decision to be made about the correct state since no state is recorded.</p><p>\\\nIn Ethereum v1, PoW is used and hashing is the resource bottleneck. All miners are validators, and the security assumption is that malicious actors cannot control more than half of the hashing power or mount a “51% attack.” Here, validation means re-executing the transactions to verify that the new stateRoot matches. Invalid blocks are ignored and not considered as extending the chain.</p><p>\\\nOne issue is that even though it appears that all miners independently validate transactions, the incentives for rational miners are to behave otherwise. Because the execution order and stateRoot must be placed in the same block and thus are tightly coupled, there is a performance advantage for small miners to join together and form a mining pool/cooperative. Rather than individual miners re-executing transactions from the block to compute the stateRoot, a mining pool could compute the stateRoot once on the pool’s fastest machine, and then devotes all of their compute power to solving the hash puzzle. This obviously also centralizes what would have been replicated transaction executions, robbing the system of the degree of independent verification represented by the mining pool members.</p><p>\\\nThis is not (yet) an acute problem, since hashing costs dominate that of VM execution to process the transactions, and the savings from sharing stateRoot is not significant. The incentive to do so increases if/when the gas limit becomes high enough so that VM execution cost becomes noticeable.</p><p>\\\nEthereum v2, Cosmos, etc are PoS based blockchains.</p><p>\\\nAll consensus committee members are also validators, and the security assumption is that malicious actors cannot amass more than a supermajority (usually 2/3) of the total stake. Validators earn block rewards. Stake-based voting and reward distribution remove most of the incentives to mount Sybil attacks, but does not address other attacks such as exploiting zero days, which are common-mode faults.</p><p>\\\nZero-knowledge (ZK) rollups use zkSNARKs to prove the correctness of the rollup virtual machine execution. Because security proof verification is involved, a single honest verifier is enough to keep the executor/prover honest.</p><p>\\\nThe key idea is that proof verification is very cheap; thus, the security parameter for the number of validator—proof verifiers—can be easily increased. Unfortunately, proof generation is relatively expensive, so while payment transactions are feasible (ZCash [7]), the case for general smart contract computation is more difficult. Proof generation for Ethereum-style computation is being developed/researched (zkEVM [11]). It remains to be seen how good a scaling solution this represents, since the rollup where the proof generation occurs may be slow/resource intensive, so even though the underlying blockchain might be able to run bridge contracts for many ZK rollup rollups, the aggregate throughput and efficiency may still be insufficient for general, complex applications.</p><p>\\\nThe proof verification algorithm takes time to run. This should be done within the bridge contract, and the typical description of ZK rollups is that an invalid proof is treated as if no proof were submitted, i.e., bridge contract aborts the faux proof submission transaction. As long as there is enough replication in the underlying blockchain so that the consensus there reflects the correct execution of proof verification, the security of the rollup is guaranteed.</p><p>\\\n<strong>2.10.4 Optimistic Rollups</strong></p><p>\\\nIn optimistic rollups, validators are any entity that can re-execute the transactions and compare the resultant state. An executor commits its result as a Disputable Assertion (DA) to the underlying blockchain, and any validator that finds a discrepancy can issue a challenge (and the validator becomes a challenger). After dispute resolution, if the DA is found to be incorrect, the executor is slashed and the successful challenger earns a reward. This means a single honest validator is enough to keep the executor honest.</p><p>\\\nValidators must be given time to re-execute the transactions and to generate challenges. Because reexecution is more expensive, this can create a significant delay for state finality: a DA is only considered accepted when the disputation period has passed. The appropriate length of the disputation period depends on the maximum gas allowed in a rolled up batch of transactions and other factors; current designs allow as much as a week.</p><p>\\\nIn Arbitrum, users are expected to not have to wait for the disputation period, based on the notion of “trustless finality”. The scenario is that a user has submitted a transaction and it is in-flight: a DA includes it, but the disputation period has not yet passed. The user wishes to propose a new transaction that depends on its result. If there are doubts about the DA, the user might be hesitant to propose the new transaction. The argument is that since the user could act as a validator and re-execute all the transactions leading up to the DA and thus independently validate their mental model of system state, they should be able to freely submit their new transaction proposal. This is essentially using transaction order finality: users trust the underlying blockchain’s recording of the rollup transaction order and that the VM is defined and implemented correctly to be deterministic.</p><p>\\\nAnother argument is because having multiple executors/validators is feasible. Here, they can post additional DAs (for new transactions) that depend on earlier DAs that have not yet reached state finality. These additional DAs provide additional assurance that the earlier DAs are correct, since presumably the new dependent DAs have validated the earlier DAs. Currently, Arbitrum has a single centralized executor, though anyone can be a validator/challenger.</p><p>\\\nVerifiers suffer from the verifier’s dilemma [10, 5]. Even though proof verification might be cheap, it is cheaper still to assume that somebody else has done the verification, when the odds that an executor will try to cheat appears to be low.</p><p>\\\n<strong>2.10.5 Bare-Metal Fraud Proofs</strong></p><p>\\\nThe bare-metal fraud proof approach is a traditional fast-path / slow-path approach seen in systems design, where the fast path efficiently handles the common case, with a slower path that acts as a fallback for the uncommon case(s). Here, a single honest node in the fast path suffices to trigger slow-path verification. It as agnostic with respect to the rollup VM, since there is no need to single-step VM execution to find exactly where an error occurred. To understand the bare-metal fraud proof approach, it is useful to understand the system architecture.</p><p>\\\nThe bare-metal fraud proof approach can be viewed as a form of optimistic rollup, but with a committee of nodes executing in parallel verifying each other rather than taking the executor vs challenger view. The VM execution of smart contracts is separated from consensus. There are two types of committees: a consensus committee executing a consensus protocol, and one or more compute committees executing the VM—similar to rollup executors running smart contracts off-chain—doing the heavier lifting of general smart contract execution. The consensus layer records the resultant VM state from the compute committee.</p><p>\\\nUnlike the consensus committee which runs a single consensus protocol, we view the compute layer as running two protocols: the fast-path protocol of  (DD), where we can use a smaller sized primary committee; and the slow-path protocol of  (DR), where a (much) larger backup committee would be used. The goal, which is justified by the security parameter calculations (see Appendix A), is to use small primary committees without compromising security. This is the source of the efficiency improvement of the bare-metal fraud proof approach: the amount of replicated computation is significantly reduced in the fast path, with an incentive design such that the slow path should never be used.</p><p>\\\nNote that transaction ordering is an orthogonal design decision from the use of DD/DR. It can be decoupled and committed to the consensus layer as separate log entries prior to smart contract execution, or a leader from the compute committee could be selected (possibly rotating) to choose an execution order from the available transaction proposals.</p><p>\\\nHowever execution schedules are determined, all members of the compute committee run in parallel and determines the state that would result from the execution of a batch of transactions. Compute committee members sign their computed output states. Equivocation is punished by slashing stake like in many consensus designs, and we will assume that each committee member will sign at most one state as the result from the execution of a batch of transactions henceforth.</p><p>\\\nThe key idea behind DD is that when all compute committee members agrees on the resultant state, we can commit it to the log, and this is secure as long as the size of the primary compute committee has enough members so that the probability that  of the reporting members are honest is negligibly small. If there is any disagreement among the primary committee member, we do not know which of the reported output states is correct—this is the key difference from other state validation schemes: DD only performs error detection and not error correction. Instead, we switch to the DR protocol with the larger backup committee, and  output state is deemed to be the correct one. In essence, the DR protocol is a parameter to the bare-metal fraud proof approach: the DR protocol can use a much larger committee—even all available nodes—and use much more resources. Because those DD nodes that reported a differing output state from that determined by DR will have their stake slashed, there is no incentive to deviate from the protocol unless the adversary can either control the entire DD committee or enough of the backup committee for DR to fail.</p><p>\\\nNote that the choice of DR does  have to only involve larger committees: we could use a bisection algorithm to find the single VM instruction at which the computation of the two (or more) resultant states first diverged [14, 8]. While this approach is great from an algorithmic standpoint, it is challenging to implement since the entire VM instruction set must be re-implemented in the bridge contract to see which instruction executed incorrectly and thus resolve the discrepancy. Maintaining VM agnosticism allows the system greater flexibility: a VM can be designed to allow the VM programs to be compiled to (sandboxed) native code, allowing applications such as data analysis that is not currently feasible on blockchains or rollups.</p><p>\\\nThe consensus layer accepting and committing a state from DD/DR yields state finality. Just as an exploit using zero-day vulnerability/bug in implementation would be a common-mode failure in all blockchains is handled using replaying transactions from checkpoints, external challengers can provide evidence of malfeasance even when DD/DR fails. In such a scenario, the transactions since the last checkpoint (or the disputed point) is replayed in the same order, using software with bug fixes applied, to compute the correct state.</p><p>\\\nThe Oasis network is a blockchain system that utilizes the bare-metal fraud proof approach. Multiple rollup VMs or “ParaTimes” are supported. Transaction ordering is handled via a mempool, and a rotating leader in the compute committee chooses the transaction order in its transaction batch. This reduces the number of consensus transactions since transaction order finality is not critical when the rollup execution is fast, though decoupling can be introduced in later iterations as needed. The Oasis ParaTime architecture, where the compute layer results are subject to DD/DR before being committed to the consensus layer, is a minimal rollup design: the bridge contract that validates the rollup VMs is baked-in and only supports DD/DR validation, keeping the consensus layer simple.</p><p>(1) Bennet Yee, Oasis Labs;</p><p>(2) Dawn Song, Oasis Labs;</p><p>(3) Patrick McCorry, Infura;</p><p>(4) Chris Buckland, Infura.</p>","contentLength":12921,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why L2s on Public Chains Offer the Best of Both Worlds","url":"https://hackernoon.com/why-l2s-on-public-chains-offer-the-best-of-both-worlds?source=rss","date":1744725629,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23428,"unread":true,"content":"<li><p>Cross-border exchange of wholesale cbdcs using automated market-makers (2023)</p></li><li><p>Adams, H., Zinsmeister, N., Salem moody, M., River Keefer, u., Robinson, D.: Uniswap v3 Core (2021)</p></li><li><p>Auer, R., Haslhofer, B., Kitzler, S., Saggese, P., Victor, F.: The technology of decentralized finance (defi) (2023)</p></li><li><p>Buterin, V.: Ethereum: A Next-Generation Smart Contract and Decentralized Application Platform. (2014)</p></li><li><p>Buterin, V., Illum, J., Nadler, M., Schar, F., Soleimani, A.: Blockchain privacy and regulatory compliance: Towards a practical equilibrium. Available at SSRN (2023)</p></li><li><p>Chaum, D., Grothoff, C., Moser, T.: How to issue a central bank digital currency (2021)</p></li><li><p>Egorov, M.: Curve Whitepaper: Automatic market-making with dynamic peg (2021)</p></li><li><p>Fiege, U., Fiat, A., Shamir, A.: Zero knowledge proofs of identity. In: Proceedings of the nineteenth annual ACM symposium on Theory of computing. pp. 210–217 (1987)</p></li><li><p>Gangwal, A., Gangavalli, H.R., Thirupathi, A.: A survey of layer-two blockchain protocols (2022)</p></li><li><p>Gogol, K., Killer, C., Schlosser, M., Boeck, T., Stiller, B.: SoK: Decentralized Finance (DeFi) - Fundamentals, Taxonomy and Risks. vol. 2022 March. IEEE Computer Society (2023)</p></li><li><p>Gudgeon, L., Werner, S.M., Perez, D., Knottenbelt, W.J.: Defi protocols for loanable funds: Interest rates, liquidity and market efficiency (2020)</p></li><li><p>Lipton, A., Sepp, A.: Automated market-making for fiat currencies (2021)</p></li><li><p>Nakamoto, S.: Bitcoin: A Peer-to-Peer Electronic Cash System (2008), <a href=\"https://www.bitcoin.org\">www.bitcoin.org</a></p></li>","contentLength":1465,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Publishers and Law Professors Back Authors in Meta AI Copyright Battle","url":"https://news.slashdot.org/story/25/04/15/0519205/publishers-and-law-professors-back-authors-in-meta-ai-copyright-battle?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744725600,"author":"msmash","guid":23281,"unread":true,"content":"Publishers and law professors have filed amicus briefs supporting authors who sued Meta over its AI training practices, arguing that the company's use of \"thousands of pirated books\" fails to qualify as fair use under copyright law. \n\nThe filings [PDF] in California's Northern District federal court came from copyright law professors, the International Association of Scientific, Technical and Medical Publishers (STM), Copyright Alliance, and Association of American Publishers. The briefs counter earlier support for Meta from the Electronic Frontier Foundation and IP professors. \n\nWhile Meta's defenders pointed to the 2015 Google Books ruling as precedent, the copyright professors distinguished Meta's use, arguing Google Books told users something \"about\" books without \"exploiting expressive elements,\" whereas AI models leverage the books' creative content. \n\n\"Meta's use wasn't transformative because, like the AI models, the plaintiffs' works also increased 'knowledge and skill,'\" the professors wrote, warning of a \"cascading effect\" if Meta prevails. STM is specifically challenging Meta's data sources: \"While Meta attempts to label them 'publicly available datasets,' they are only 'publicly available' because those perpetuating their existence are breaking the law.\"","contentLength":1286,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lucid Gravity First Drive: An electric SUV that doesn’t make compromises","url":"https://techcrunch.com/2025/04/15/lucid-gravity-first-drive-an-electric-suv-that-doesnt-make-compromises/","date":1744723800,"author":"Abigail Bassett","guid":23282,"unread":true,"content":"<article>Lucid has spent years working on its second EV — a plush van-like SUV designed to be the category killer that could take market share from the likes of other luxury EV and internal combustion people haulers like the Rivian R1S, Cadillac Escalade IQ, BMW X7, and Audi Q8. The Saudi-backed company’s aim was to […]</article>","contentLength":318,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Swap Volume and Gas Fees Impact CBDC Exchange Costs","url":"https://hackernoon.com/how-swap-volume-and-gas-fees-impact-cbdc-exchange-costs?source=rss","date":1744722015,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23427,"unread":true,"content":"<p>\\\nThe simulation outcomes are depicted in Figs. 4, 5 and 6. Fig. 8 in the appendix presents the historical total swap costs for transaction volumes of 10k, 100k, and 1mn EUR for CHF for each day over the last 3 years with fixed gas fees. Fig 4 extends this analysis for various gas fees and presents the difference between the costs of L2L3 Exchange and L1 Mariana. Notably, L2-L3-Exchange outperforms for volumes of 10k and 1mn. This outperformance varies, influenced not only by transaction volume but also by current gas fees, as shown in fig. 4. For gas fees surpassing 800 EUR, L2-L3-Exchange outperforms for any transaction volume. For lower gas fees, such as 15 EUR, the out performance range is observed for volumes representing less than 0.01% or more than 0.7% of the provided liquidity. The reason for L2-L3-Exchange outperforming for smaller transactions lies in the minimization of gas fees through the application of L2 and L2s. Fig. 5 breaks down total swap costs, indicating that gas fees dominate the costs for L1 Mariana in smaller transactions, compared to the swap fee for L2-L3-Exchange. For larger transactions, price impact becomes the predominant component of total swap costs.</p><p>\\\nThe outperformance of the L2-L3-Exchange over L1-Mariana and its ability to handle price impact effectively stem from the use of L3 with CLMM, as illustrated in Figs. 6. The analysis of L3 selection indicates the use of L3 with Cryptoswap Invariant 2-token pool for smaller transactions, while the 3-token pool of Cryptoswap Invariant is unused for any transaction volumes. L3 with CLMM and 2-token pool Cryptoswap Invariant outperforms, in certain situations, the 3-token pool of CryptoSwap Mariana despite liquidity fragmentation, with each L3 having three times less liquidity than L1 Mariana. Fig. fig. 5 explains the role of gas, swap, and price impact components in overall transaction costs. The simulation showed that applying more AMMs, despite the liquidity fragmentation, outperforms the application of just one AMM: 100mn to L1- Mariana and 33.33mn to each L3. Fig. 9 simulates the swap costs when various total liquidity is provided.</p><p>(1) Krzysztof Gogol, University of Zurich (gogol@ifi.uzh.ch);</p><p>(2) Johnnatan Messias, Matter Labs;</p><p>(3) Malte Schlosser, University of Zurich;</p><p>(4) Benjamin Kraner, University of Zurich;</p><p>(5) Claudio Tessone, University of Zurich.</p>","contentLength":2371,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Understanding CallData in Blockchain Transaction Execution","url":"https://hackernoon.com/understanding-calldata-in-blockchain-transaction-execution?source=rss","date":1744722004,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23426,"unread":true,"content":"<h2>2.8 Execution Parameters: callData</h2><p>When we name states via transaction order, it is a “natural” name as a sequence of state-transformation functions as applied to the genesis or a checkpoint state. The state-transformations must be fully specified, i.e., the transaction data (callData) are function parameters to the transaction call that, when curried, allow us to view the transaction as state transforms.</p><p>\\\nIn order for the commitment of transactions to make sense, it must include all callData for the state to be computed. This is a  requirement. Transactions (their callData) does not have to be directly in the blocks, though that is the simplest design choice. If a highly available data repository, i.e., a  (e.g., IPFS [3]), can be used, then lists of transactions can be stored there and the on-chain data can simply be the name by which the transaction list can be obtained.</p><p>\\\nHere, feasibility must include some notion of verifying data availability, e.g., signatures from a quorum of availability providers. It is not enough to use a simple content-addressable storage (CAS) without availability guarantees, since otherwise we face the following dilemma when an adversary computes the CAS name without actually making the data available. In such a scenario, we either sacrifice liveness, having to wait indefinitely for the callData to become available, or try to use timeouts and treat unavailable callData as implicit aborted transactions and move on. This latter choice sacrifices finality: a user can nullify their transactions after the transaction’s execution order has been decided—by making their callData unavailable— if the user decides that the execution order is not to their advantage, so until state finality has been reached, transaction order finality does not uniquely specify a resultant state.</p><p>\\\nNote that Ethereum’s stateRoot has a symmetric CAS availability problem. The state output from a transaction is needed as input to the next transaction, and a lack of availability here means that the new state’s representation cannot be easily computed, destroying liveness.[4]</p><p>Execution ordering can be quite important, since any given two state transforming functions might not commute with each other. The notion of “front running” is not new with blockchains but has been unethically (and illegally) practiced in stock and commodities markets [12]. Front-running uses the ability to influence execution ordering results, where additional orders are injected in front of (and often also behind) orders that may move the market. For example, if Trey submits a transaction  to buy a large amount of some commodity, it is likely to cause a price increase (“move the market”). If Fanny knew about his order and can inject in a pair of transactions to sandwich his: the net is a <em>pseudo-conjugate transaction</em> g’ = f; g; f∗ , where f denotes a transaction to buy the same commodity at market price, and f ∗ denotes a “pseudo-inverse” transaction to sell the same amount, at what will be a higher market price, to exit the market and reap profits.[5] In Bitcoin, Ethereum, and most layer 2 rollup designs, the (layer 1) miners choose transactions from a mempool of proposed transactions and can choose and order transactions within the new block in any order that they want.</p><p>\\\nIdeally, transactions that offer approximately the same gas fees should perhaps be handled on a first-come, first-serve basis, with the order decided based on approximate timestamps. Standard Bitcoin, Ethereum, and rollup designs are all vulnerable to order conjugation, though there are research on ways to maintain fair ordering for some definition of fairness [9, 13, 4].</p><p>\\\nHow to decide on an execution ordering is a largely orthogonal design decision. The scheme used in Bitcoin and Ethereum (v1) is leaderless and probabilistic, since miners can independently choose the transactions to include in the blocks they mine. For L2 rollups with decoupled ordering and state value determination, the transaction order can be determined in many ways: (1) as a “null hypothesis”, in L1 submission order (susceptible to L1 front running); (2) via trusted off-chain schedulers that (fairly) order batches of transactions; (3) via trustless decentralized applications on other blockchains that perform batch scheduling, using commit-reveal of transaction details to prevent biased ordering; etc. The potential design space is large, and exploring this is on-going research.</p><p>(1) Bennet Yee, Oasis Labs;</p><p>(2) Dawn Song, Oasis Labs;</p><p>(3) Patrick McCorry, Infura;</p><p>(4) Chris Buckland, Infura.</p><p>[4] Obviously the input state can be reconstructed by transaction replay, but that is not efficient.</p>","contentLength":4707,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hertz Says Customers' Personal Data, Driver's Licenses Stolen In Data Breach","url":"https://yro.slashdot.org/story/25/04/15/0128202/hertz-says-customers-personal-data-drivers-licenses-stolen-in-data-breach?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744722000,"author":"BeauHD","guid":23255,"unread":true,"content":"An anonymous reader quotes a report from TechCrunch: Car rental giant Hertz has begun notifying its customers of a data breach that included their personal information and driver's licenses. The rental company, which also owns the Dollar and Thrifty brands, said in notices on its website that the breach relates to a cyberattack on one of its vendors between October 2024 and December 2024. The stolen data varies by region, but largely includes Hertz customer names, dates of birth, contact information, driver's licenses, payment card information, and workers' compensation claims. Hertz said a smaller number of customers had their Social Security numbers taken in the breach, along with other government-issued identification numbers. Notices on Hertz's websites disclosed the breach to customers in Australia, Canada, the European Union, New Zealand, and the United Kingdom. Hertz also disclosed the breach with several U.S. states, including California and Maine. Hertz said at least 3,400 customers in Maine were affected but did not list the total number of affected individuals, which is likely to be significantly higher. Emily Spencer, a spokesperson for Hertz, would not provide TechCrunch with a specific number of individuals affected by the breach but said it would be \"inaccurate to say millions\" of customers are affected. The company attributed the breach to a vendor, software maker Cleo, which last year was at the center of a mass-hacking campaign by a prolific Russia-linked ransomware gang.","contentLength":1514,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fusion power has a fuel problem; Hexium has a laser-powered solution","url":"https://techcrunch.com/2025/04/15/fusion-power-has-a-fuel-problem-hexium-has-a-laser-powered-solution/","date":1744722000,"author":"Tim De Chant","guid":23254,"unread":true,"content":"<article>Hexium has emerged from stealth with $8 million in seed funding.</article>","contentLength":64,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Phantom Neuro grabs $19M to help amputees put their phantom limbs to use","url":"https://techcrunch.com/2025/04/15/phantom-neuro-grabs-19m-to-help-amputees-gain-control-of-their-phantom-limbs/","date":1744721899,"author":"Ingrid Lunden","guid":23253,"unread":true,"content":"<article>The science fiction trope of humans superpowered by computer and bionic implants is fast becoming a reality, and today, a startup hoping for a role in how that plays out is announcing some funding.&nbsp; Phantom Neuro, which is developing a wristband-like device that gets implanted under the skin to let a person control prosthetic limbs, […]</article>","contentLength":341,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Fuse and Check Point Are Trying to Build the First Blockchain Firewall—Here’s What That Means","url":"https://hackernoon.com/fuse-and-check-point-are-trying-to-build-the-first-blockchain-firewallheres-what-that-means?source=rss","date":1744721575,"author":"Ishan Pandey","guid":23425,"unread":true,"content":"<h3>Can Real-Time Cybersecurity Work in Web3?</h3><p>The blockchain ecosystem has been defined by its ability to decentralize power. But in doing so, it’s also opened itself to a growing volume of exploits, smart contract bugs, and wallet-level attacks. This raises a central question: Can real-time cybersecurity protocols, like those used in Web2 infrastructure, be implemented in decentralized systems?</p><p>\\\n<a href=\"https://www.fuse.io\">Fuse</a>, a layer 2 blockchain focused on crypto payments, believes the answer lies in collaboration. On April 15, it announced a partnership with <a href=\"https://www.checkpoint.com/\">Check Point Software</a> to deploy the first advanced blockchain firewall designed to prevent threats in real time. The move signals a shift from reactive security to proactive defense.</p><p>\\\nRather than detecting malicious transactions after they occur, the partnership aims to stop them before execution. According to Fuse, the approach draws on Check Point’s three decades of experience in threat intelligence and firewall technology—now applied to a blockchain setting.</p><h3>What Makes This Firewall Different?</h3><p>Traditional blockchain security measures, such as smart contract audits and static code analysis, occur post-deployment. These are essential but insufficient, especially as attacks become more dynamic. The proposed solution is a dedicated AI-powered firewall that functions at the infrastructure level, integrated across the Fuse network.</p><p>\\\nMark Smargon, CEO of Fuse, explained the intent behind the move:</p><blockquote><p><strong>“Prevention is always better than a cure, particularly with crypto networks that serve as the backbone for global payments. With Check Point providing a dedicated security layer, we’re confident that we can not only deter hackers, who are becoming increasingly sophisticated, but pioneer a cybersecurity model that will become the gold standard for protecting web3 protocols.”</strong></p></blockquote><p>\\\nThe security layer will leverage <a href=\"https://www.checkpoint.com/\">Check Point’s</a> proprietary threat prevention models, which are trained on historical and real-time data to block transactions flagged as malicious. According to Dan Danay, Head of Web 3.0 Security at Check Point, this type of security architecture mirrors the evolution from static antivirus tools to real-time cloud-based monitoring in the traditional web:</p><blockquote><p><strong>“Just as robust cybersecurity powered the rise of Web 2.0, real-time prevention will be key to Web3’s mainstream adoption.”</strong></p></blockquote><h3>How the Threat Prevention Layer Works</h3><p>Rather than functioning as a simple list of known bad actors, the security layer integrates with Fuse's transaction pipeline to actively inspect intent. It leverages AI-powered threat engines and real-time data feeds from Check Point’s global cyber intelligence network. Fuse's approach does not stop at smart contracts. Wallet interactions, dApp behavior, and node communications will also be subject to live monitoring. According to the teams, this breadth of coverage is key for reducing attack surfaces and enabling developer trust.</p><p>\\\nThe firewall will not act as a gatekeeper to decentralization but as an internal risk assessment tool. Developers, node operators, and users will retain autonomy but can opt into an additional layer of security baked directly into the protocol.</p><h3>Ember Nodes and the Future of Fuse’s Network</h3><p>The announcement comes shortly after the launch of Fuse’s Ember Nodes, a governance and validation system backed by venture participants such as Collider Ventures, TRGC, and Blockchain Founders Fund. These nodes allow users to acquire ownership and participate in decision-making, a process that could be enhanced by real-time threat analytics.</p><p>\\\nWith thousands of active users and a growing number of stablecoin transactions processed daily, Fuse has chosen to build security into the core of its payment-focused infrastructure. This is a notable departure from retrofitting security tools after scaling. The hope is that by implementing this level of scrutiny now, Fuse can avoid the pattern observed in other networks—where vulnerabilities are only addressed after they are exploited.</p><h3>Broader Implications for Web3 Infrastructure</h3><p>Security remains one of the largest friction points for Web3 adoption. Protocols like Fuse that prioritize infrastructure-level security may begin to redefine baseline expectations for operational safety across chains. While Fuse is currently focused on B2B and B2C payments, the model it’s implementing with Check Point could apply across other verticals: gaming, decentralized finance, and supply chain platforms.</p><p>\\\nWhether the industry will follow remains to be seen. But with regulatory scrutiny increasing and users demanding stronger protections, moving from detection to prevention might become not just a differentiator—but a requirement.</p><p>In my view, this partnership sets a precedent for what blockchain networks should begin to consider non-negotiable. Security shouldn’t be a feature, it should be infrastructure. Fuse's integration with Check Point isn’t about marketing a firewall to web3 audience, it’s about acknowledging that decentralization without defense is unsustainable in the long term. </p><p>\\\nIf other L2s or payment blockchains follow suit, we may finally see a turning point where security architecture in Web3 begins to match the financial value these systems are expected to move.</p><p>\\\nDon’t forget to like and share the story!  </p><p>:::tip\n<strong><em>Vested Interest Disclosure:</em></strong><em>This author is an independent contributor publishing via our&nbsp;. HackerNoon has reviewed the report for quality, but the claims herein belong to the author. #DYO</em></p>","contentLength":5504,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What Happens When You Swap 1 Million Euros in CBDCs?","url":"https://hackernoon.com/what-happens-when-you-swap-1-million-euros-in-cbdcs?source=rss","date":1744718402,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23424,"unread":true,"content":"<p>To ensure comparability with L1-Mariana , we consider three CBDCs: Swiss Franc (CHF), Euro (EUR), and Singaporean Dollar (SGD) and back-test the total costs of CBDCs swaps in L1-Mariana and L2-L3-Exchange systems. We consider the buy transaction of EUR for CHF for volumes ranging from 1 EUR to 1mn EUR. The price impact for CLMMs are calculated based on Eq. 8, and the Newton-Raphson method is applied for Cryptoswap Invariants, both for  = 2 and  = 3. The implementation of all methods is available in a public GitHub repository [17] and was based on the smart contract code of Curve v2.</p><p>The analysis uses the historical exchange rates of CHF-EUR and CHF-SGD for the last three years (daily closing values from Yahoo Finance). We assume that arbitrageurs maintain prices aligned between CBDCs in AMMs and the FX market, which allows us to calculate the historical AMM pools’ compositions based on these FX rates.</p><p>\\\n We assume 100mn CHF is provided to each system for liquidity provisions. As L1-Mariana operates Cryptoswap Invariant with one 3-token pool CHF-EUR-SGD, the pool’s value is 100mn CHF. In L2-L3-Exchange, we consider three L3 operators, each running AMM-DEX setup. The 100mn CHF liquidity is equally divided among the L3 operators. The first L3 operator uses a Cryptoswap Invariant with CHF-EUR-SGD pool (like in L1-Mariana), and the pool is valued 100/3 mn CHF. The second L3 also employs Cryptoswap Invariant, but with two 2-token pools: CHF-EUR and CHF-SGD, each valued 100/6 mn CHF. The third L3 operator utilizes CLMM with CHF-EUR and CHF-SGD pools, each valued 100/6 mn CHF. The L2-L3-Exchange pool architecture is illustrated in Fig. 7 in the appendix.</p><p>\\\n Each liquidity pool charges swap fee of 1bp (i.e., 0.0001) of transaction volume.</p><p>\\\n Gas fees for swaps on Ethereum, referred to in the Project Mariana, oscillated between 5 EUR and 50 EUR over the last three years [6]. The gas costs on L2s are, on average, 50 times lower compared to the underlying L1 [16], [32]. Based on these facts, we consider 15 EUR gas fees for a swap on L1 and 15EUR/50 on the L2-L3 network.</p><p>(1) Krzysztof Gogol, University of Zurich (gogol@ifi.uzh.ch);</p><p>(2) Johnnatan Messias, Matter Labs;</p><p>(3) Malte Schlosser, University of Zurich;</p><p>(4) Benjamin Kraner, University of Zurich;</p><p>(5) Claudio Tessone, University of Zurich.</p>","contentLength":2316,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"From Styled Components to Tailwind CSS: A HackerNoon Migration Story","url":"https://hackernoon.com/from-styled-components-to-tailwind-css-a-hackernoon-migration-story?source=rss","date":1744714818,"author":"beni mahat","guid":23423,"unread":true,"content":"<p>\\\nEvery so often, a tech stack decision that once felt right starts to show its limits—like realizing just how inefficient a screwdriver is after using a power drill. That’s been the case with HackerNoon’s use of . For years, it served us well—offering scoped styles, dynamic theming, and full control within our React components. But as our codebase evolved and tools like  matured, it became clear that a </p><p>\\\nThis post is a breakdown of our shift from Styled Components to Tailwind CSS, why we made the move, how I approached the transition, and what the process has looked like so far. If you're working with legacy styles or considering Tailwind for your own projects, hopefully this gives you something useful (or at least relatable) to walk away with.</p><p>I wasn’t part of the team when Styled Components was first chosen to handle our CSS, but at the time, <strong>Tailwind CSS hadn’t even been released</strong>, and Styled Components made a lot of sense for HackerNoon’s front-end architecture.</p><p>\\\nIt allowed developers to write CSS directly within JavaScript, making components fully self-contained. This approach felt very “React-native” in nature—<strong>encapsulated, reusable, and, at the time, thought to be easier to maintain</strong> across a growing codebase and team. The dynamic styling capabilities, built-in theming support, and ability to pass props directly into styles worked especially well for the wide variety of pages and layouts we were building. For a long time, <strong>Styled Components served HackerNoon well</strong>.</p><h2>What Made Us Consider Switching to Tailwind?</h2><p>Over time, our codebase grew—and so did the complexity of managing styles.</p><p>\\\nStyled Components gave us flexibility, but that came at a cost: , , and a <strong>cluttered component structure</strong> filled with increasingly long styled blocks. It was getting harder to trace styles or reuse them effectively without duplicating code.</p><p>\\\nWe also noticed many of our styles were repeating across components. That’s when  started to make a lot of sense. The utility-first approach felt like a way to streamline everything—from layout to responsiveness and even theming.</p><p>\\\nBut let’s be real: for a <strong>small dev team like HackerNoon’s</strong>, the idea of refactoring a massive codebase  felt like a huge undertaking. Still, we couldn’t ignore how widely Tailwind was being adopted in the dev community. We wanted in.</p><p>The hardest part of this switch? </p><p>\\\nInstalling Tailwind was straightforward, but once it was active, Tailwind’s global styles—thanks to Preflight—started clashing with our existing components. Styles were broken left and right.</p><p>\\\nA lifesaver here was setting  in the  file. That move <strong>disabled most of Tailwind’s base resets</strong>, which brought back some order. Sure, there were still minor styling issues to fix, but things looked less like a war zone.</p><p>\\\nFrom there, I had to <strong>establish new conventions</strong>—how we’d handle global styles, reuse classes, and build theme-aware components with Tailwind. Once that foundation was laid, I was ready to build.</p><p>\\\nAnd here's the part I’m still amazed by: <strong>AI made this process actually enjoyable.</strong></p><p>\\\nRefactoring thousands of lines of code solo would’ve been madness. But I used ChatGPT to convert our styled components into Tailwind one at a time. For simple components—layouts, spacing, structure—it was a breeze. Just paste, tweak, and go.</p><p>\\\n AI didn’t get everything right. More complex, themed components still required <strong>manual coding and plenty of hours</strong>. But having a solid base to start from made things so much easier. Tailwind’s documentation also helped fill the gaps, and once I fully embraced the , things started to click.</p><h2>What the Migration Looks Like So Far</h2><p>I’m happy to say <strong>Tailwind is now live on HackerNoon!</strong> 🎉</p><p>\\\nAs of now, the  to Tailwind CSS, with Styled Components completely removed. Most of the other pages still rely on Styled Components, and they’ll be converted gradually—<strong>one component, one page at a time</strong>.</p><p>\\\nThis slower approach has actually been a blessing. Refactoring each component gave me the opportunity to  the design and structure of our pages. Alongside the Tailwind conversion, we introduced a , better layout usage, new components, and even a <strong>custom-built theme picker</strong> that puts our old theming system to shame.</p><p>\\\nAfter working at HackerNoon for over 4 years, I feel  diving into our codebase again. Tailwind has made building fun again. It’s clean, consistent, and powerful—and I’m excited to keep pushing the conversion forward. Who knows? Maybe soon, we’ll be deleting  from our  for good. 😉</p><h2>Final Tailwinding Thoughts</h2><p>The move to Tailwind CSS wasn’t just about swapping out a styling library—it was about modernizing our frontend workflow, embracing consistency, and simplifying development. While Styled Components helped shape HackerNoon’s interface during a critical growth phase, Tailwind is giving us the <strong>flexibility, speed, and maintainability</strong> we need as we continue to scale.</p><p>\\\nIt’s still a work in progress—our app still has plenty of Styled Components—but seeing Tailwind live on our homepage and in newly refactored components has been incredibly rewarding. The fact that I can pair AI with my own expertise to refactor faster has made this transition feel not only doable but exciting.</p><p>\\\nHackerNoon is evolving, and our styles are evolving with it. One component at a time.</p>","contentLength":5342,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What You Need to Know About Gas Fees and Slippage","url":"https://hackernoon.com/what-you-need-to-know-about-gas-fees-and-slippage?source=rss","date":1744714812,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23422,"unread":true,"content":"<p>The major metric to consider for evaluation of the cross-border CBDCs exchange is the cost of the CBDCs swap. In general, the total cost of DeFi service consists of three components: [31], [19]</p><p>\\\n<em>TotalCost = GasFee + DeFiExplicitFee + DeFiImplicitFee</em></p><p>\\\n are paid to the blockchain operators for executing the transaction. In the case of transactions on roll-ups, the gas fee is comprised of both the L1 and L2 gas fee components.</p><p>\\\n is charged by the DeFi protocol for the provided service. In the case of token swap at AMM-DEX, the liquidity pool fee (LP Fee) is the explicit fee charged by the DEX, and part of it (or whole) is distributed to the liquidity providers (LPs) to the pool.</p><p>\\\n are indirect fees specific to the design of the DeFi protocol. Price impact and slippage are implicit fees accrued by a trader when swapping tokens at AMM [31], [19] and refer to the difference between quoted and executed price by the AMM. Price impact is caused by the transaction volume and slippage (positive or negative) results from other swaps occurring within the same block as the transaction swap.</p><p>\\\nFurther the following model for the total cost of swap is considered:</p><p>\\\n<em>TotalSwapCost = GasFee + LPFee + PriceImpact</em></p><p>\\\nLP Fee is typically the percentage of the transaction volume, and liquidity providers supply capital to the AMM’s liquidity pools in exchange for participation in LP fees. Price impact is the change in exchange price caused by the transaction volume and is specific to the AMM type and the liquidity pool size. The next section presents the major AMM types and corresponding price impact calculation methods.</p><h2>5.1 Automated Market Makers</h2><p>\\\n\\\n<strong>Constant Product with Concentrated Liquidity Market Maker (CLMM) - Uniswap v3</strong></p><p>\\\n\\\n<strong>Stableswap Invariant - Curve v1</strong></p><p>\\\n\\\n<strong>Cryptoswap Invariant - Curve v2</strong> As in equation (4), but with K defined as</p><p>(1) Krzysztof Gogol, University of Zurich (gogol@ifi.uzh.ch);</p><p>(2) Johnnatan Messias, Matter Labs;</p><p>(3) Malte Schlosser, University of Zurich;</p><p>(4) Benjamin Kraner, University of Zurich;</p><p>(5) Claudio Tessone, University of Zurich.</p>","contentLength":2064,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple details how it plans to improve its AI models by privately analyzing user data","url":"https://techcrunch.com/2025/04/15/apple-details-how-it-plans-to-improve-its-ai-models-by-privately-analyzing-user-data/","date":1744714435,"author":"Ivan Mehta","guid":23186,"unread":true,"content":"<article>In the wake of criticism over the underwhelming performance of its AI products, especially in areas like notification summaries, Apple on Monday detailed how it is trying to improve its AI models by analyzing user data privately with the aid of synthetic data. Using an approach called “differential privacy,” the company said it would first […]</article>","contentLength":351,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"China Halts Rare Earth Exports Globally","url":"https://news.slashdot.org/story/25/04/15/0144259/china-halts-rare-earth-exports-globally?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744711200,"author":"BeauHD","guid":23168,"unread":true,"content":"Longtime Slashdot reader AmiMoJo shares the news that China has halted all rare earth exports globally -- including to the U.S., Japan, and Germany. Fortune reports: After Trump unveiled his \"Liberation Day\" tariffs on April 2, China retaliated on April 4 with its own duties as well as export controls on several rare earth minerals and magnets made from them. So far, those export controls have translated to a halt across the board, cutting off the U.S. and other countries, according to the New York Times. That's because any exports of the minerals and magnets now require special licenses, but Beijing has yet to fully establish a system for issuing them, the report said.\n \nIn the meantime, shipments of rare earths have been halted at many ports, with customs officials blocking exports to any country, including to the U.S. as well as Japan and Germany, sources told theÂTimes. China's Ministry of Commerce issued export restrictions alongside the General Administration of Customs, prohibiting Chinese businesses from any engagement with U.S. firms, especially defense contractors. While the Trump administration unveiled tariff exemptions on a range of key tech imports late Friday night, China's magnet exports were still halted through the weekend, industry sources told the Times. Beijing's export halt is notable because China has a stranglehold on global supplies of rare earths and magnets derived from them. They also represent an asymmetric advantage in that rare earths constitute a small share of China's exports but have an outsize impact on trade partners like the U.S., which relies on them as critical inputs for the auto, chip, aerospace, and defense industries.","contentLength":1689,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Waymo and Uber prepare to launch robotaxi service in Atlanta this summer","url":"https://techcrunch.com/2025/04/15/waymo-and-uber-prepare-to-launch-robotaxi-service-in-atlanta-this-summer/","date":1744711200,"author":"Kirsten Korosec","guid":23185,"unread":true,"content":"<article>Uber is inviting customers in Atlanta to join a list if they’re interested in hailing a Waymo robotaxi as the companies prepare to launch a commercial service in the city. Uber and Waymo last September announced plans to offer a robotaxi service in Austin and Atlanta in early 2025 as part of an expanded partnership. […]</article>","contentLength":325,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Setup a CI/CD Pipeline with GitHub Actions","url":"https://hackernoon.com/how-to-set-up-cicd-with-github-actions?source=rss","date":1744703447,"author":"Daniel Adeboye","guid":23209,"unread":true,"content":"<p>Let’s be real, tech moves fast. New frameworks, tools, and best practices seem to pop up every other week. It’s exciting, but also a bit overwhelming. If you’re trying to build and ship projects while keeping up with everything, it can feel like a lot.</p><p>\\\nThat’s where <a href=\"https://hackernoon.com/139-stories-to-learn-about-cicd\">CI/CD</a>, short for Continuous Integration and Continuous Deployment, can help. It takes care of the repetitive stuff like testing and deploying, so you can focus on writing actual features. I’ve personally found GitHub Actions to be a solid choice for setting up CI/CD workflows right inside a GitHub repo.</p><p>\\\nIn this article, I’ll walk you through how to set up a simple CI/CD pipeline using GitHub Actions. The goal is to reduce manual errors, make our code easier to deploy, and save some time and stress in the process.</p><p>\\\nBefore we start, here are a few things you’ll want to have or know, just so you don’t get stuck halfway through.</p><ul><li>Basic understanding of YAML syntax and GitHub</li></ul><h2>Creating Your First CI/CD Pipeline</h2><p>You can choose to create your YAML file in VS Code or directly on GitHub. In this guide, we’ll create it directly on GitHub to keep things simple and easy to follow.</p><p>\\\nGo to your GitHub repository (or open your code editor) and create a new folder named  Inside that, create another folder called workflows, and then add a new file named  You can name your YAML file whatever you like.</p><p>Next, we need to define our YAML file, which is a linter workflow that checks for docstrings in our codebase.</p><p>\\\nStart your YAML file by giving your pipeline a name and setting up the Git trigger — in other words, defining when you want the pipeline to run. In this guide, we’ll set it up to run whenever there’s a push to the&nbsp;&nbsp;branch or when a pull request is opened against it.</p><pre><code>name: Python Linting\n\non:\n  push:\n    branches: main\n  pull_request:\n    branches: main \n</code></pre><p>\\\nNext, we need to tell the pipeline what to do when a push or pull request happens. In this case, we want it to review our code by setting up Python and installing the&nbsp;&nbsp;package so it can run a linting check on our repository.</p><pre><code>jobs:\n  lint:\n    name: Run PyLint\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Check out repository\n      uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install pylint\n</code></pre><p>\\\nAfter setting up Python and installing the  package, the next step is to define the configuration that pylint will use during the pipeline run.</p><p>\\\nWe’ll start by disabling all of ’s default checks using , which gives us a clean slate. Then, we’ll enable just two specific checks:  (which flags missing function docstrings) and  (which highlights bad indentation). We’ll also set  to allow for longer lines of code while still keeping things readable.</p><p>\\\nYou can check out the full list of  codes and what they do here.</p><p>\\\nYour  config should look like this:</p><pre><code> - name: Run PyLint\n      run: |\n        pylint --disable=all --enable=C0116,W0311 --max-line-length=100 $(git ls-files '*.py')\n</code></pre><p>\\\nAnd that’s it — you’ve just created your first pipeline workflow! Make sure your project structure matches what we’ve covered in this guide, as any differences might prevent the pipeline from running correctly. Once everything is set up, commit your changes and push them to the&nbsp;&nbsp;branch.  <img src=\"https://cdn.hackernoon.com/images/bvfdRlftZCRXmrVygxq2Gdqu5iY2-r633j1q.png\" alt=\"\"></p><p>\\\nOnce you have committed your workflow, you should see a yellow dot next to your commit message. This signifies that your pipeline is up and running.</p><p>:::info\nIf the pipeline fails, you’ll see a red dot next to the workflow. If it passes, it turns green.</p><p>Next, let's add a Python file to test the workflow and check if it correctly flags missing docstrings. Click on 'Add file,' then 'Create new file,' and name it&nbsp;. Once you've added your code, commit the file and push it to the&nbsp;&nbsp;branch.</p><pre><code>def some_function():\n    \"\"\"\n    Description of what this function does.\n\n    Returns:\n        Type: Description of what is returned\n    \"\"\"\n    pass \n</code></pre><p>To test the pipeline we just created, click on GitHub actions. You should see all your workflows. Click on the workflow to see more details.</p><p>Now, let's break down how the workflow was triggered and what happened next. Click on&nbsp;Run PyLint&nbsp;to view the detailed results.</p><p>The pipeline works by setting up a job that first checks out your repository, then sets up Python 3.11 (as specified in our YAML file). It installs the necessary dependencies and runs the&nbsp;&nbsp;configuration script. Once the script passes, the pipeline sets up Python again and checks the repository one more time to make sure everything is working correctly before completing the job.</p><p>In summary, when you create a pipeline, GitHub will automatically run your configured checks (in this case, pylint) on your code whenever you commit to the main branch or make a pull request. This helps catch errors early in the development process.</p><p>As we wrap up this guide on GitHub Actions, it’s clear that using this practice can seriously supercharge your development process. By automating checks to make sure your code is running smoothly, you’ll save tons of time and avoid bugs when pushing code to production.</p><p>\\\nThat’s the real power of GitHub Actions — its flexibility. It lets you build workflows that are tailored to your project’s needs. Whether you're flying solo as an indie developer or working within a team, CI/CD helps you ship features faster and build a better product.</p><p>\\\nSo, go ahead and convince your team lead to integrate CI/CD into your company’s workflow. Watch your team start shipping better code, faster!</p>","contentLength":5673,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Girls Who Code founder Reshma Saujani spills business tea with Meghan, Duchess of Sussex","url":"https://techcrunch.com/2025/04/15/girls-who-code-founder-reshma-saujani-spills-business-tea-with-meghan-duchess-of-sussex/","date":1744702200,"author":"Dominic-Madori Davis","guid":23145,"unread":true,"content":"<article>Reshma Saujani, founder of the non-profit Girls Who Code, got straight to the point.&nbsp; “If I had applied to be the CEO of Girls Who Code, I wouldn’t have gotten the job,” she told Meghan, Duchess of Sussex, on the latest episode of the duchess’ podcast, “Confessions of a Female Founder.” “I didn’t code,” Saujani […]</article>","contentLength":337,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"CT Scans Projected to Result in 100,000 New Cancers in The US","url":"https://science.slashdot.org/story/25/04/14/2333207/ct-scans-projected-to-result-in-100000-new-cancers-in-the-us?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744700400,"author":"BeauHD","guid":23136,"unread":true,"content":"A new study projects that CT scans conducted in 2023 may result in around 103,000 future cancer cases in the U.S. due to low-dose ionizing radiation. \"[I]t would put CT scans on par with other significant risk factors for cancer, like alcohol consumption, at least at a population level,\" reports ScienceAlert. From the report: At an individual level, the theoretical chance of developing cancer from a CT scan is thought to be very minimal, if it exists at all, and patients should not be scared of undergoing these tests if they are deemed medically necessary. However, the number of CT examinations performed each year in the US has increased by more than 30 percent since 2007, and researchers suggest that unwarranted tests are exposing the population to unnecessary radiation. [...]\n \nThe anonymous data comes from 143 hospitals and outpatient facilities across the US, catalogued in the UCSF International CT Dose Registry. Using statistics from 2016 to 2022, researchers predicted 93 million CT examinations were carried out in 2023, on roughly 62 million patients. Based on the associated radiation risks, the team estimates that CT scans in 2023 may be tied to 103,000 future cancers. The findings have been published in JAMA Internal Medicine.","contentLength":1254,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The TechBeat: Google Gemini Did Not Disappoint on These Blockchain x AI Use Cases (4/15/2025)","url":"https://hackernoon.com/4-15-2025-techbeat?source=rss","date":1744697456,"author":"Techbeat","guid":23208,"unread":true,"content":"<p>By <a href=\"https://hackernoon.com/u/techbyadam\">@techbyadam</a> [ 3 Min read ] \n Building software with Cursor is super fast, and you should definitely use it. However, there are some downsides. <a href=\"https://hackernoon.com/i-blew-euro400-on-cursor-heres-what-i-learned-so-you-dont-have-to\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/zbruceli\">@zbruceli</a> [ 5 Min read ] \n Google A2A - a first look at another agent-agent protocol and compared to Anthropic’s MCP. <a href=\"https://hackernoon.com/google-a2a-a-first-look-at-another-agent-agent-protocol\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ishanpandey\">@ishanpandey</a> [ 2 Min read ] \n A new partnership between Addressable and Sevio will enable programmatic display ads on major crypto platforms, making web3 target more efficient.  <a href=\"https://hackernoon.com/is-web3-advertising-finally-solving-its-targeting-problem-addressable-and-sevio-expand-web3-ads-reach\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/albertlieyeongdok\">@albertlieyeongdok</a> [ 6 Min read ] \n Discover 8 powerful tools transforming prompt engineering from trial-and-error into scalable systems—featuring visual workflows, auto-tuned prompts, and memory- <a href=\"https://hackernoon.com/escape-prompt-hell-with-these-8-must-have-open-source-tools\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/muhammdusman\">@muhammdusman</a> [ 8 Min read ] \n So you want to become better than 99% of programmers. But you are doing the exact same things that 99% of programmers are already doing. <a href=\"https://hackernoon.com/how-to-become-a-top-1percent-programmer-the-path-you-have-to-take\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/igorluchenkov\">@igorluchenkov</a> [ 6 Min read ] \n Storybook enables isolated component building, API mocking, easier testing, streamlined design reviews, and visual regression detection. <a href=\"https://hackernoon.com/why-every-front-end-team-needs-storybook\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/thomascherickal\">@thomascherickal</a> [ 10 Min read ] \n 20 Mind-Blowing Science-Fiction AI and Blockchain Use Cases that will amaze, thrill, and shock you with their scope and immense possibilities.  <a href=\"https://hackernoon.com/google-gemini-did-not-disappoint-on-these-blockchain-x-ai-use-cases\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/languagemodels\">@languagemodels</a> [ 5 Min read ] \n New DeepMind study introduces SAFE and LongFact to fact-check AI, showing LLMs can outperform humans at evaluating long-form factual responses. <a href=\"https://hackernoon.com/the-ai-truth-test-new-study-tests-the-accuracy-of-13-major-ai-models\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ace2489\">@ace2489</a> [ 9 Min read ] \n The value of programming languages that don't hide the details. <a href=\"https://hackernoon.com/should-you-learn-rust-and-zig-yes-yes-you-should\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/sergey-baloyan\">@sergey-baloyan</a> [ 6 Min read ] \n The psychology driving the market isn’t random; it’s a game of human nature, and the winners know how to play it.  <a href=\"https://hackernoon.com/crypto-whales-are-laying-the-groundwork-for-the-next-bull-run\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/hackernooncontests\">@hackernooncontests</a> [ 3 Min read ] \n Join the Web3 Development Writing Contest by GetBlock &amp; HackerNoon! Write about blockchain APIs, dApp development &amp; more for a chance to win from $5,000. <a href=\"https://hackernoon.com/win-your-share-of-$5000-in-the-web3-development-writing-contest-by-getblock-and-hackernoon\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/dataimpulse\">@dataimpulse</a> [ 5 Min read ] \n Web scraping in 2025 faces AI defenses, legal hurdles, and new rules. Learn smart, compliant strategies to keep your data flows running smooth. <a href=\"https://hackernoon.com/web-scraping-in-2025-staying-on-track-with-new-rules\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/gpolf\">@gpolf</a> [ 3 Min read ] \n Why Web3 projects keep launching with million-dollar dreams and $30K marketing budgets, and why that's killing their growth before it starts. <a href=\"https://hackernoon.com/the-gtm-budget-struggle\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/thisweekinaieng\">@thisweekinaieng</a> [ 8 Min read ] \n Genspark AI has emerged as a formidable new player in the AI agent space, positioning itself as a comprehensive super agent. <a href=\"https://hackernoon.com/insane-one-click-mcp-ai-agent-hits-the-market\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/scottdclary\">@scottdclary</a> [ 9 Min read ] \n Excellence isn't about running the race better, it's about changing the track entirely. <a href=\"https://hackernoon.com/is-excellence-an-accident\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/marinaagliullina\">@marinaagliullina</a> [ 5 Min read ] \n Certain UX frameworks may bring confusion to product teams and lead to misled product decisions. But we can avoid these traps of user personas and empathy maps <a href=\"https://hackernoon.com/stereotypes-over-valuable-insights-how-some-ux-frameworks-can-deceive-you\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/id\">@id</a> [ 13 Min read ] \n The social sequencer is a new media synth interactive art piece to explore the concept of the emergence theory through sound.  <a href=\"https://hackernoon.com/the-internet-has-a-pulse-and-this-sequencer-lets-you-hear-it\">Read More.</a></p>","contentLength":2948,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Marshmallow, the UK insurance startup for migrants, raises $90M at a $2B+ valuation","url":"https://techcrunch.com/2025/04/14/marshmallow-the-uk-insurance-startup-for-migrants-raises-90m-at-a-2b-valuation/","date":1744696789,"author":"Ingrid Lunden","guid":23135,"unread":true,"content":"<article>U.K. startup Marshmallow has blown up over the years by using innovations in data science to build car insurance policies for immigrants and other consumers who have been overlooked or priced out of traditional insurance. Now, with a million drivers insured and a profitable annual revenue run rate of $500 million, Marshmallow has raised a […]</article>","contentLength":346,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Indian IT Faces Its Kodak Moment","url":"https://it.slashdot.org/story/25/04/15/0259250/indian-it-faces-its-kodak-moment?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744693200,"author":"msmash","guid":23129,"unread":true,"content":"An anonymous reader shares a report: Generative AI offers remarkable efficiency gains while presenting a profound challenge for the global IT services industry -- a sector concentrated in India and central to its export economy. \n\nFor decades, Indian technology firms thrived by deploying their engineering talent to serve primarily Western clients. Now they face a critical question. Will AI's productivity dividend translate into revenue growth? Or will fierce competition see these gains competed away through price reductions? \n\nIndustry soundings suggest the deflationary dynamic may already be taking hold. JPMorgan's conversations with executives, deal advisors and consultants across India's technology hubs reveal growing concern -- AI-driven efficiencies are fuelling pricing pressures. This threatens to constrain medium-term industry growth to a modest 4-5%, with little prospect of acceleration into fiscal year 2026. This emerging reality challenges the earlier narrative that AI would primarily unlock new revenue streams.","contentLength":1037,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Chinese Robotaxis Have Government Black Boxes, Approach US Quality","url":"https://tech.slashdot.org/story/25/04/14/2327229/chinese-robotaxis-have-government-black-boxes-approach-us-quality?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744687800,"author":"BeauHD","guid":23120,"unread":true,"content":"An anonymous reader quotes a report from Forbes: Robotaxi development is speeding at a fast pace in China, but we don't hear much about it in the USA, where the news focuses mostly on Waymo, with a bit about Zoox, Motional, May, trucking projects and other domestic players. China has 4 main players with robotaxi service, dominated by Baidu (the Chinese Google.) A recent session at last week's Ride AI conference in Los Angeles revealed some details about the different regulatory regime in China, and featured a report from a Chinese-American YouTuber who has taken on a mission to ride in the different vehicles.\n \nZion Maffeo, deputy general counsel for Pony.AI, provided some details on regulations in China. While Pony began with U.S. operations, its public operations are entirely in China, and it does only testing in the USA. Famously it was one of the few companies to get a California \"no safety driver\" test permit, but then lost it after a crash, and later regained it. Chinese authorities at many levels keep a close watch over Chinese robotaxi companies. They must get approval for all levels of operation which control where they can test and operate, and how much supervision is needed. Operation begins with testing with a safety driver behind the wheel (as almost everywhere in the world,) with eventual graduation to having the safety driver in the passenger seat but with an emergency stop. Then they move to having a supervisor in the back seat before they can test with nobody in the vehicle, usually limited to an area with simpler streets.\n \nThe big jump can then come to allow testing with nobody in the vehicle, but with full time monitoring by a remote employee who can stop the vehicle. From there they can graduate to taking passengers, and then expanding the service to more complex areas. Later they can go further, and not have full time remote monitoring, though there do need to be remote employees able to monitor and assist part time. Pony has a permit allowing it to have 3 vehicles per remote operator, and has one for 15 vehicles in process, but they declined comment on just how many vehicles they actually have per operator. Baidu also did not respond to queries on this. [...] In addition, Chinese jurisdictions require that the system in a car independently log any \"interventions\" by safety drivers in a sort of \"black box\" system. These reports are regularly given to regulators, though they are not made public. In California, companies must file an annual disengagement report, but they have considerable leeway on what they consider a disengagement so the numbers can't be readily compared. Chinese companies have no discretion on what is reported, and they may notify authorities of a specific objection if they wish to declare that an intervention logged in their black box should not be counted. On her first trip, YouTuber Sophia Tung found Baidu's 5th generation robotaxi to offer a poor experience in ride quality, wait time, and overall service. However, during a return trip she tried Baidu's 6th generation vehicle in Wuhan and rated it as the best among Chinese robotaxis, approaching the quality of Waymo.","contentLength":3166,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MindEye2 (Not Pretrained) vs. MindEye1","url":"https://hackernoon.com/mindeye2-not-pretrained-vs-mindeye1?source=rss","date":1744686004,"author":"Image Recognition","guid":23207,"unread":true,"content":"<h2>A.3 MindEye2 (not pretrained) vs. MindEye1</h2><p>Table 6 shows how MindEye2 outperforms MindEye1 even without pretraining on other subjects. Models were trained using the full 40 sessions of training data from subject 1. This suggests that improvements from MindEye1 to MindEye2 are not explained solely from pretraining on other subjects, but that benefits also come from improved model architecture and training procedure.</p><p>(1) Paul S. Scotti, Stability AI and Medical AI Research Center (MedARC);</p><p>(2) Mihir Tripathy, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(3) Cesar Kadir Torrico Villanueva, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(4) Reese Kneeland, University of Minnesota and a Core contribution;</p><p>(5) Tong Chen, The University of Sydney and Medical AI Research Center (MedARC);</p><p>(6) Ashutosh Narang, Medical AI Research Center (MedARC);</p><p>(7) Charan Santhirasegaran, Medical AI Research Center (MedARC);</p><p>(8) Jonathan Xu, University of Waterloo and Medical AI Research Center (MedARC);</p><p>(9) Thomas Naselaris, University of Minnesota;</p><p>(10) Kenneth A. Norman, Princeton Neuroscience Institute;</p><p>(11) Tanishq Mathew Abraham, Stability AI and Medical AI Research Center (MedARC).</p>","contentLength":1200,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MindEye2: Shared-Subject Models Enable fMRI-To-Image With 1 Hour of Data: Single-Subject Evaluations","url":"https://hackernoon.com/mindeye2-shared-subject-models-enable-fmri-to-image-with-1-hour-of-data-single-subject-evaluations?source=rss","date":1744683479,"author":"Image Recognition","guid":23206,"unread":true,"content":"<h2>A.5 Single-Subject Evaluations</h2><p>Tables 7 and 8 show more exhaustive evaluation metrics computed for every subject individually using 40-hours and 1-hour of fine-tuning data respectively.</p><p>(1) Paul S. Scotti, Stability AI and Medical AI Research Center (MedARC);</p><p>(2) Mihir Tripathy, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(3) Cesar Kadir Torrico Villanueva, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(4) Reese Kneeland, University of Minnesota and a Core contribution;</p><p>(5) Tong Chen, The University of Sydney and Medical AI Research Center (MedARC);</p><p>(6) Ashutosh Narang, Medical AI Research Center (MedARC);</p><p>(7) Charan Santhirasegaran, Medical AI Research Center (MedARC);</p><p>(8) Jonathan Xu, University of Waterloo and Medical AI Research Center (MedARC);</p><p>(9) Thomas Naselaris, University of Minnesota;</p><p>(10) Kenneth A. Norman, Princeton Neuroscience Institute;</p><p>(11) Tanishq Mathew Abraham, Stability AI and Medical AI Research Center (MedARC).</p>","contentLength":967,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How AI Agents Could Have Supercharged Pfizer’s COVID-19 Vaccine Development","url":"https://hackernoon.com/how-ai-agents-could-have-supercharged-pfizers-covid-19-vaccine-development?source=rss","date":1744682935,"author":"tanush29","guid":23205,"unread":true,"content":"<h2>Reimagining Drug Discovery With Autonomous Intelligence</h2><p>In early 2020, Pfizer and BioNTech delivered what many thought was impossible: a viable COVID-19 vaccine developed and distributed in record time. It was a monumental achievement in modern medicine. But as someone working closely with AI agents in complex, high-stakes systems, I often wonder if that process could’ve been even faster.</p><p>\\\nThis is not about rewriting history. It asks: <em>How can we prepare smarter for the future?</em> Could the AI agent systems we’re building today have accelerated the race for a vaccine? I believe the answer is yes.</p><p>In plain terms, AI agents are systems that can reason, act, and learn over time, often working autonomously, with a clear sense of memory, goals, and feedback. Unlike traditional software, they aren’t just passive tools. They’re active collaborators.</p><p>\\\nWe use them in software engineering to automate code reviews, triage bugs, and optimize performance. However, the same framework can be extended beyond code into healthcare, drug discovery, and clinical trials.</p><h2>💉 The Vaccine Pipeline Agent by Agent</h2><p>Let’s take a step back and reimagine the COVID-19 vaccine development process as powered by a team of AI agents. Each one plays a unique role:</p><p>Takes in epidemiological data, past trial structures, and mutation forecasts to draft optimized protocols in hours, not weeks. It adapts trial arms based on real-time inputs from the field.</p><h3>2. Literature Scout Agent</h3><p>Scans tens of thousands of scientific papers and updates researchers daily. Instead of manually reviewing papers, scientists would get distilled, tailored insights synthesized from the latest studies.</p><p>Predicts likely side effects before they appear. It learns from global vaccine databases, patient records, and similar case studies to flag early risks and adapt trial criteria.</p><p>It understands FDA, EMA, and WHO documentation requirements. It formats outputs automatically to ensure smoother submissions, with proper justifications and auditability built in.</p><p>\\\nEach agent can run 24/7, adapt based on feedback, and collaborate with others through a central reasoning layer. Think of it as a tireless digital task force working in sync with real scientists.</p><h2>⚡ What Would This Have Changed?</h2><p>| Phase | Traditional Timeline | With AI Agents | Benefit |\n|----|----|----|----|\n| Protocol Design | 2–3 weeks | ~1 day | Faster iteration |\n| Literature Integration | Manual &amp; slow | Continuous synthesis | No missed insights |\n| Risk Modeling | Post-trial analysis | Pre-trial + real-time | Proactive risk mitigation |\n| Regulatory Formatting | Reactive | Embedded from start | Faster approval and delivery |</p><p>This doesn’t mean replacing people. It means freeing them from the repetitive and time-intensive parts of the job, allowing them to focus on judgment, innovation, and ethics.</p><h2>🚀 Beyond COVID: A New Model for R&amp;D</h2><p>We’re talking about a new category:  Clinical R&amp;D as a Service. These AI agents could be deployed securely across research teams, hospitals, and pharma companies, sharing knowledge in real time while respecting data boundaries.</p><p>\\\nFederated learning, explainability, and memory-enhanced LLMs would form the backbone. What email was for communication? These AI agents could be used for discovery.</p><p>Pfizer set a historic precedent. But we’re now entering an age where speed alone isn’t enough; we need smart speed. With the right agent-based systems in place, the future of drug discovery could be safer, faster, and far more collaborative.</p><p>\\\nI’ve seen the impact of AI agents in software development firsthand. There’s no reason we can’t apply the same logic, architecture, and intelligence to solving healthcare’s biggest challenges.</p><p>\\\nIf you’re working on this problem, I’d love to collaborate.</p><p><em>Written by Tanush Sharanarthi, a staff software engineer at IBM who builds real-time multi-agent systems for intelligent developer tools and enterprise platforms. Passionate about using AI to solve problems that matter.</em></p>","contentLength":4004,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reconstruction Evaluations Across Varying Amounts of Training Data: Mindeye2","url":"https://hackernoon.com/reconstruction-evaluations-across-varying-amounts-of-training-data-mindeye2?source=rss","date":1744682732,"author":"Image Recognition","guid":23204,"unread":true,"content":"<h2>A.4 Reconstruction Evaluations Across Varying Amounts of Training Data</h2><p>Here, we present a further analysis of how model performance scales with training data. All of the results presented in Figures 6, 7, and 8 are calculated on only subject 1.</p><p>(1) Paul S. Scotti, Stability AI and Medical AI Research Center (MedARC);</p><p>(2) Mihir Tripathy, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(3) Cesar Kadir Torrico Villanueva, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(4) Reese Kneeland, University of Minnesota and a Core contribution;</p><p>(5) Tong Chen, The University of Sydney and Medical AI Research Center (MedARC);</p><p>(6) Ashutosh Narang, Medical AI Research Center (MedARC);</p><p>(7) Charan Santhirasegaran, Medical AI Research Center (MedARC);</p><p>(8) Jonathan Xu, University of Waterloo and Medical AI Research Center (MedARC);</p><p>(9) Thomas Naselaris, University of Minnesota;</p><p>(10) Kenneth A. Norman, Princeton Neuroscience Institute;</p><p>(11) Tanishq Mathew Abraham, Stability AI and Medical AI Research Center (MedARC).</p>","contentLength":1026,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Climate Crisis Has Tripled Length of Deadly Ocean Heatwaves, Study Finds","url":"https://news.slashdot.org/story/25/04/15/0148201/climate-crisis-has-tripled-length-of-deadly-ocean-heatwaves-study-finds?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744681800,"author":"msmash","guid":23097,"unread":true,"content":"The climate crisis has tripled the length of ocean heatwaves, a study has found, supercharging deadly storms and destroying critical ecosystems such as kelp forests and coral reefs. From a report: Half of the marine heatwaves since 2000 would not have happened without global heating, which is caused by burning fossil fuels. The heatwaves have not only become more frequent but also more intense: 1C warmer on average, but much hotter in some places, the scientists said. \n\nThe research is the first comprehensive assessment of the impact of the climate crisis on heatwaves in the world's oceans, and it reveals profound changes. Hotter oceans also soak up fewer of the carbon dioxide emissions that are driving temperatures up. \"Here in the Mediterranean, we have some marine heatwaves that are 5C hotter,\" said Dr Marta Marcos at the Mediterranean Institute for Advanced Studies in Mallorca, Spain, who led the study. \"It's horrible when you go swimming. It looks like soup.\" \n\nAs well as devastating underwater ecosystems such as sea grass meadows, Marcos said: \"Warmer oceans provide more energy to the strong storms that affect people at the coast and inland.\"","contentLength":1166,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"MindEye2 Dataset: fMRI Preprocessing and Normalization","url":"https://hackernoon.com/mindeye2-dataset-fmri-preprocessing-and-normalization?source=rss","date":1744680382,"author":"Image Recognition","guid":23203,"unread":true,"content":"<p>fMRI responses correspond to normalized single-trial betas output from GLMSingle (Prince et al., 2022). We use preprocessed flattened fMRI voxels in 1.8-mm native volume space corresponding to the “nsdgeneral” brain region, defined by the NSD authors as the subset of voxels in posterior cortex most responsive to the visual stimuli presented (between 13,000 to 16,000 voxels per participant). MindEye2 was developed using a training and test set of subject 1’s data, with other subjects’ data untouched until final training of models. The fMRI data from both the training and test set was normalized using a voxel-wise Z-scoring procedure using the mean and standard deviation calculated using only the training set. Despite the shared1000 test trials being distributed across the scanning sessions for each subject, we chose to keep the test set consistent no matter the number of sessions being used for training. We also adjusted the number of training sessions after the normalization step, allowing us to keep the statistical properties of the shared1000 test set consistent between experiments with varying amounts of training data. This may inadvertently give a small normalization advantage to models trained with fewer training sessions, as the models are normalized with additional data not made available for training.</p><p>(1) Paul S. Scotti, Stability AI and Medical AI Research Center (MedARC);</p><p>(2) Mihir Tripathy, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(3) Cesar Kadir Torrico Villanueva, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(4) Reese Kneeland, University of Minnesota and a Core contribution;</p><p>(5) Tong Chen, The University of Sydney and Medical AI Research Center (MedARC);</p><p>(6) Ashutosh Narang, Medical AI Research Center (MedARC);</p><p>(7) Charan Santhirasegaran, Medical AI Research Center (MedARC);</p><p>(8) Jonathan Xu, University of Waterloo and Medical AI Research Center (MedARC);</p><p>(9) Thomas Naselaris, University of Minnesota;</p><p>(10) Kenneth A. Norman, Princeton Neuroscience Institute;</p><p>(11) Tanishq Mathew Abraham, Stability AI and Medical AI Research Center (MedARC).</p>","contentLength":2121,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Behind the Scenes: The Making of MindEye2","url":"https://hackernoon.com/behind-the-scenes-the-making-of-mindeye2?source=rss","date":1744680089,"author":"Image Recognition","guid":23202,"unread":true,"content":"<p>PSS: project lead, drafted the initial manuscript and contributed to all parts of MindEye2 development. MT (core contributor): MindEye2 ablations, SDXL unCLIP vs. Versatile Diffusion comparisons, improved distributed training code, and experimented with approaches not used in the final model including training custom ControlNet and T2I adapters, using retrieval on COCO CLIP captions, and using diffusion priors to align fMRI to text embeddings. CKTV (core contributor): retrained and evaluated MindEye1 models, image captioning evaluations and writing, improved manuscript formatting, ROI-optimized stimuli experiments, and experimented with approaches not used in the final model including trying out different pretrained model embeddings, experimenting with T2I-Adapters and depth conditioning, experimenting with using past/future timepoints as additional conditioning, experimenting with blip2 for text prediction, and experimenting with behavioral embeddings. RK (core contributor): brain correlations, human preference experiments, recalculated metrics for 40- hour setting Ozcelik and VanRullen (2023) and Takagi and Nishimoto (2023) results, evaluations with varying amounts of training data across all models, assistance with data normalization, significant contributions to manuscript writing. TC: UMAP visualizations, improved the design for Figure 1, and experimented with approaches not used in the final model including using past/future timepoints as additional conditioning and using flattened voxels in MNI space instead of native space. AN: helped with ablations and experimented with replacing soft CLIP loss with soft SigLIP loss (Zhai et al., 2023) (not used in final model). CS: FAISS retrieval with MS-COCO (Appendix A.8) and experimented with approaches not used in the final model including experimenting with using past/future timepoints as additional conditioning, experimenting with blip2 for text prediction, and experimenting with behavioral embeddings. JX: helped with ablations, manuscript revisions and table formatting, experimented with approaches not used in the final model including experimenting with blip2 for text prediction, experimenting with behavioral embeddings, and improving model architecture. TN: assisted with human preference experiments. KN: oversaw the project, manuscript revisions and framing. TMA: oversaw the project, manuscript revisions and framing, helped keep project on-track thorugh MedARC and Stability AI communication.</p><p>(1) Paul S. Scotti, Stability AI and Medical AI Research Center (MedARC);</p><p>(2) Mihir Tripathy, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(3) Cesar Kadir Torrico Villanueva, Medical AI Research Center (MedARC) and a Core contribution;</p><p>(4) Reese Kneeland, University of Minnesota and a Core contribution;</p><p>(5) Tong Chen, The University of Sydney and Medical AI Research Center (MedARC);</p><p>(6) Ashutosh Narang, Medical AI Research Center (MedARC);</p><p>(7) Charan Santhirasegaran, Medical AI Research Center (MedARC);</p><p>(8) Jonathan Xu, University of Waterloo and Medical AI Research Center (MedARC);</p><p>(9) Thomas Naselaris, University of Minnesota;</p><p>(10) Kenneth A. Norman, Princeton Neuroscience Institute;</p><p>(11) Tanishq Mathew Abraham, Stability AI and Medical AI Research Center (MedARC).</p>","contentLength":3271,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Becoming a Writer in a Hyperconnected World","url":"https://hackernoon.com/becoming-a-writer-in-a-hyperconnected-world?source=rss","date":1744679817,"author":"Marcio S Galli","guid":23201,"unread":true,"content":"<p>I want to become a writer, a better writer. We share this objective, I know. And I know too of a nice thing from our history. That grandmother’s hands on our shoulders meant . Two layers above any urgent call. I remember these stories. But what to do now in a world of too many publications, too many platforms and tools helping us, or claiming to be helping us? It’s not easy, especially now that we are witnessing so many systems improving in terms of narratives.</p><p>\\\nIn today’s world, it’s not easy to know if collaborating online is helping us. With too many systems carrying on narratives of support, we may feel flooded. Or overwhelmed in a way that can be comparable to writer’s block.</p><p>\\\nI wanted to write this letter because I found something cool about HackerNoon: HackerNoon the publication, HackerNoon the platform for writers, HackerNoon the community. But because that wasn’t clear before, we should go back to that day:</p><p>\\\nThat was the day when interacting with HackerNoon meant I was feeling like being somebody, towards a writer, on one hand. But, on the other hand, I felt suspicious about that communication. About that communication, about my own narratives about myself against the world:</p><blockquote><p>@taboca - You Have Been Nominated for at Least one Noonies Award!</p></blockquote><p>\\\nSo what do we do when we are in doubt? I did. I asked my friends, again, my network. And some of them said things like \"Heh, you and 20K others!\" Well, no one said that, but I heard that anyway. So I was confused, thinking, \"Well, that's how marketing is now.\" That is a sentence, a saying. And what goes from there, we know, how things go in real life. We skip like we look away from an ad.</p><p>\\\nBut I was lucky that, at that time, I had a bigger problem. Latent, real. That problem, our problem. That I wanted to become a writer, a better writer. So, I had a decision to make. A note: Nothing was so clear, so strong, so focused. I can't fully say why, at that point in time, I took a different direction. Maybe I was tired of not helping myself. Or maybe I sensed something from the publication. So what I did was new. And it something like \"Okay, let us play!\"</p><p>\\\nI didn't do it with a mood as in \"I am mad with the publication; I will hack them too!” No sir. I somehow took a calmer path, I went along. I needed the publication as much as they needed me. The decision came out like this:</p><blockquote><p>I was nominated, therefore I am.</p></blockquote><p>\\\nSo I wrote. And next year, nominated for 3 categories. Then again, let us go back to friends. The same. But now, a silence was heard. Of course, as something different was said:</p><p>\\\nLet us write. From a nomination to writing more, to being nominated in three categories:</p><ul></ul><p>Things were happening. I was surprised by the level of sensibility of the publication. I sensed that real people were there. That someone read it for real. Psychology? Someone else saw something that maybe I saw but was afraid to say out loud. So, writing by writing, through writing, we were building. Building, to a certain extent, in a world that needs protection, from the other interactions we know too:</p><p>\\\nAt some point, I stumbled upon a real editor. And he invited me to a fellowship after granting a user credential of verified contributor. So here, I celebrate something special, very important, that a platform indeed may come first, but right there, through their communications, you will see a style, a culture. It’s not different from a book. I was in front of a book, a good book where you can feel the style, the voice of the author, through authors, through editors, through their narratives:</p><p>\\\nThrough e-mails, their narratives. They were showing who they were, through writing, through their well-done or clear writing, a writing that touches and supports. So I can say, we can, we kept on going. We were collaborating. They were real. I was real.</p><p>\\\nIt was real, that fellowship,  so real that I could not accept. Looking back - comparing before and then - I was in front of something far from that initial idea. So I declined as I could not commit as they wanted. That is the change, suspicious to a point of almost missing. Then, playing along. To being. To being challenged. So for that publication, HackerNoon, I would like to say:</p><p>\\\nAnd then something else happened, too. I left. I disappeared: I left as in one that says goodbye. I left for about 2 years. What I did, meanwhile, was a result of that movement. I took things to the next level:</p><p>\\\nI wrote straight for one year, every day, from a coffee shop. Like Forest Gump running. I granted myself that fellowship, following the right to write. And too with other hands, such as supported by Julia Cameron’s The Right to Write.</p><p>\\\nNow I can look back, and when I look back, there is this thing, a being, trying to be, a writer, through writing. When I think about HackerNoon, when I say thanks, I like to say like that, again&gt;:</p><p>\\\nTo close, I celebrate that good/bad thing around us. We live in a world of abundance with too many events happening. There are too many interactions that may be signal or noise. So, indeed, it’s challenging to separate things, flooded with too many systems, platforms, communities, you name it. So if your path is a path  or another path, I ask you to be gentle with yourself. Indeed, there are too many systems out there with too many narratives. And I remind us, too, that being gentle starts with being respectful.</p>","contentLength":5391,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"If Getting Laid-off is Bad, Wait Till You See What AI Does to Corporates","url":"https://hackernoon.com/if-getting-laid-off-is-bad-wait-till-you-see-what-ai-does-to-corporates?source=rss","date":1744678584,"author":"Neer Varshney","guid":23200,"unread":true,"content":"<p>I know the word layoff is on the mind of a majority of corporate workers right now, and it is no joke.</p><p>\\\nThis job market is brutal, and the number of texts I get from talented, highly-skilled people unable to find a job is revolting.</p><p>\\\nWe are told we must adjust to a new reality where AI would steal most jobs, leaving us with “nothing” and having no economic prospects to sustain our lives.</p><p>\\\nBut is this fear really about AI?&nbsp;Or is it about how short-lived our certainties have always been?</p><p>\\\n<strong>ironically free us from the very system we fear losing.</strong></p><p>\\\nThere are many things that become so ominous to our life that we don’t realize how short a time they have been around.</p><p>\\\nLandline phones, televisions, Facebook — all came into our lives as disruptive technologies and stopped being the center of our lives before we realized it.</p><p>\\\nThe same is going to happen to the conventional . While so deeply ingrained in our modern consciousness, it represents <strong>a surprisingly brief experiment in the long arc of human labor history.</strong></p><p>\\\nAs AI reshapes how things get done, we stand to witness another transformation — one that is seeing us return to more goal-oriented rather than time-oriented work patterns.</p><h3>The Final Nail In the Coffin Of Industrial Revolution Labor Patterns</h3><p>A world of year-end reviews, clocking 40 hours a week, and more corporate shenanigans that people who have held real jobs, unlike me, tell me about have brought comfort to people they are realizing is being pulled from under them.</p><p>\\\nYet, this wasn’t the case for like 95% of human history. We organized our labor around immediate needs and natural cycles.</p><p>\\\nThe strict delineation of work time versus personal time would have seemed peculiar to our ancestors until the 18th century.</p><p>\\\nYou all think a 4-day work week is a new progressive, modern way of working that we are experimenting with. Blah! Hunter-gatherers in the Stone Age worked just three to five hours daily.</p><p>\\\nThe radical transformation of work schedules came with the Industrial Revolution, when labor became increasingly detached from natural rhythms and human needs.</p><p>\\\nBy 1817, people were working unprecedented 80-100 hour weeks. Factory workers in mid-19th century England endured punishing 16-hour days, 311 days annually.</p><p>\\\nWorkers lost control, prompting organized resistance to excessive work hours.</p><p>\\\nThe breakthrough in the struggle came in the early 20th century.</p><p>\\\nIn 1926, Henry Ford implemented the 40-hour workweek after discovering diminishing returns from longer hours.</p><p>\\\nIn 1940, the 40-hour workweek became U.S. law, establishing what we now know as the standard schedule.</p><p>\\\nThe term \"9-to-5\" became so emblematic of standardized work schedules that it entered popular culture.</p><p>\\\nIn historical context, this rigid time-based approach to work has existed for less than a century — a mere blip in humanity's 300,000-year history.</p><p>\\\nI think, substantial progress in AI would put the final nail in the coffin of everything that was wrong with the Industrial Revolution and the exploitation of labor that came with it.</p><p>\\\nWhile we put machines to work as manufacturing takes a more important role than ever before.</p><h3>The Bigger Picture of AI-Driven Layoffs</h3><p>Corporations exist for a single reason — to fetch returns for shareholders. It doesn’t matter how many times your manager says you’re like a family.</p><p>\\\nSo, there are two things that are set to pan out. Either a company optimizes its workflow, doing more with a smaller headcount, or sees its business collapse.</p><p>\\\n<strong>In the next decade, it may become a more financially safe decision to be an entrepreneur or independent creator than being a 9-to-5er.</strong></p><p>\\\nThe jobs that remain relevant in the AI era will likely emphasize what humans accomplish rather than simply how long they work — a change that, viewed historically, represents <strong>less a revolution than a homecoming to more natural patterns of human productivity.</strong></p><p>Estimated work hours falling post-AGI, continuing the trend from the peak of the early industrial age in the 18th century.</p><p>\\\nA recent Pew study found that 52% of Americans are worried about how AI is used in the workplace, yet only 16% incorporate it in any way in their work. I think there lies the crux of the issue.</p><p>\\\nIf you’re more worried about keeping your job than swinging the hammer, you’ll miss the nail entirely, in my humble view.</p><p>\\\nIf you think this is some hypothetical novelty of the future — just look at the past couple of years.</p><p>\\\nCompanies like Cursor, Midjourney, and ElvenLabs are launching path-breaking products with a team of 10 people or so. Meanwhile, remind me, what is IBM doing?</p><p>\\\n<strong>AI is going to take down more inefficiently-run large corporations than it does talented people.</strong></p><p>\\\nIt is going to play a role in balancing out the scales in power in favor of the passionate, hard-working, obsessed little guy; take my word for it.</p>","contentLength":4861,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple To Analyze User Data on Devices To Bolster AI Technology","url":"https://apple.slashdot.org/story/25/04/15/0050203/apple-to-analyze-user-data-on-devices-to-bolster-ai-technology?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744678200,"author":"msmash","guid":23096,"unread":true,"content":"Apple will begin analyzing data on customers' devices in a bid to improve its AI platform, a move designed to safeguard user information while still helping it catch up with AI rivals. From a report: Today, Apple typically trains AI models using synthetic data -- information that's meant to mimic real-world inputs without any personal details. But that synthetic information isn't always representative of actual customer data, making it harder for its AI systems to work properly. \n\nThe new approach will address that problem while ensuring that user data remains on customers' devices and isn't directly used to train AI models. The idea is to help Apple catch up with competitors such as OpenAI and Alphabet, which have fewer privacy restrictions. The technology works like this: It takes the synthetic data that Apple has created and compares it to a recent sample of user emails within the iPhone, iPad and Mac email app. By using actual emails to check the fake inputs, Apple can then determine which items within its synthetic dataset are most in line with real-world messages.","contentLength":1086,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Developer Productivity with GitHub Copilot & AI Tools by Aditya Mishra","url":"https://hackernoon.com/developer-productivity-with-github-copilot-and-ai-tools-by-aditya-mishra?source=rss","date":1744678063,"author":"R Systems","guid":23199,"unread":true,"content":"<p>GitHub Copilot, utilizing OpenAI's Codex, is an AI-powered tool seamlessly integrated into your code editor. It goes beyond traditional autocomplete by offering real-time suggestions for code, functions, snippets, and even entire blocks based on your inputs. Trained on millions of open-source repositories, Copilot acts as a smart, context-aware assistant that accelerates coding, minimizes bugs, and enhances the overall development experience.</p><p>\\\nCopilot is a great pair programming gen AI tool which allows developers to work efficiently and solve complex programs quickly. It is an easy to use AI tool which is configured in visual studio by default. If a user has a valid licence then user can use it to reduce the work load with the help of co-pilot.</p><p>\\\nThere are mainly two ways to give the prompt to the co-pilot-</p><ol><li> if a developer comment and give the prompt then co-pilot will provide the solution for it</li></ol><pre><code>```\n\n ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-cc036vv.png)\n\n\n2. By using copilot chat window\n\n\\\n</code></pre><pre><code> ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-r51363k.png)\n\nCopilot has a great in-build features where a developer can see the code explanations, create test cases, optimizing code, fix the errors, add documentations and get the help. To do so users just need to type / in copilot chat window. \\n \n</code></pre><pre><code> ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-6l2362i.png)\n\nBelow are the few best features of co-pilot where it is explained why this is a very useful tool\n\n### **Context-Aware Suggestions:**\n\nCopilot goes beyond simple prediction; it comprehends the context of your code. By analysing variables, functions, and imported libraries, it offers highly relevant suggestions. This streamlines the coding process, making it more intuitive and reducing the need for developers to frequently search for syntax or function names.\n\n### **Enriched Productivity:**\n\nCopilot accelerates the development process by providing relevant code suggestions, auto-completions, allowing developers to focus more on solving complex problems. It provides code suggestions which is relevant to the coding framework.\n\n\\\ne.g. Here, we can see that, we have just given a prompt to generate a code for uploading a document in temp folder and co-pilot suggested a code within a seconds \\n \n</code></pre><pre><code> ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-cg336b6.png)\n\n### **Property Defining:**\n\nA developer can create properties or dto’s within seconds with the help of co-pilot because co-pilot can sense what properties could be required based on class name.\n\n\\\n</code></pre><pre><code> ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-c7436lc.png)\n\n### **Documentation:**\n\nCopilot helps us in documenting the code like methods, properties etc correctly.\n\n\\\nHere in below example, a developer can document all the properties with the help of co-pilot with the /doc command in co-pilot chat window\n\n\\\n</code></pre><pre><code> ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-di536m1.png)\n\n### **Improved Code Quality:**\n\nWith intelligent suggestions based on best practices, Copilot helps reduce errors and improves the overall quality of the codebase, ensuring adherence to coding standards. It suggests middleware setups and secure practices to protect sensitive data.\n\n\\\ne.g. here we can see that, there is an error in our code because this method doesn.t exists in our code. Now, I have given a prompt to co-pilot to fix it.\n\n\\\n</code></pre><pre><code> ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-4z636v4.png)\n\nPost giving a command, we can see here, copilot has suggested a code within seconds to create the missing method following all coding standards like documentation and all. Now developer can accept or cancel the suggested code based on their requirement.\n\n\\\n</code></pre><pre><code> ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-l2736wc.png)\n\n### **Unit Testing:**\n\nGenerates unit tests for controllers, services, or business logic. Suggests test cases based on methods being tested, supporting tools like xUnit or NUnit.\n\n\\\ne.g., Here we can see that with the /test command, co-pilot has created the unit test cases within a second. We can select the code or we can give the file reference and line number for which test cases are required to be created\n\n\\\n</code></pre><pre><code> ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-6w836dz.png)\n\nPost clicking on enter, co-pilot suggests a test cases which are required for the specific cases\n\n\\\n</code></pre><pre><code> ![](https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-sm93696.png)\n\n### **Code Optimization:**\n\nCopilot helps developers in optimizing the code so that it should Identifies repetitive code and suggests reusable methods or patterns.\n\n\\\nIn below example, we can see that, by giving the command /optimize, copilot has suggested the optimized code with explanation that what has been done for the optimization and how it will be beneficial for a developer.\n\n\\\n</code></pre><h2><strong>Learning and Skill Development:</strong></h2><p>Copilot serves as more than just an assistant—it’s a valuable learning resource. For novice developers or those venturing into new programming languages, it offers a great opportunity to explore libraries, tools, and techniques. It can provide examples to illustrate specific functionalities and help you write idiomatic code in languages you’re less familiar with.</p><p>GitHub Copilot and similar AI-driven tools are transforming the landscape of software development by boosting productivity, reducing errors, and enhancing code quality. These innovative solutions empower developers to code more efficiently, collaborate seamlessly, and discover new techniques throughout the process. However, they do come with their own set of challenges, which require careful consideration and thoughtful implementation. By combining the capabilities of AI tools with their own expertise, developers can achieve remarkable efficiency and create high-quality software at an accelerated pace. Whether you’re an aspiring developer starting your journey or a seasoned engineer tackling complex projects, GitHub Copilot and other AI technologies are invaluable resources in today’s dynamic development environment.</p><p>:::info\nThis article by&nbsp; placed as a runner-up in Round 1 of R Systems Blogbook: Chapter 1.</p>","contentLength":6287,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"🛠️ Fixing the Decline: 5 Proven Ways to Boost Credit Card Authorization Rates","url":"https://hackernoon.com/fixing-the-decline-5-proven-ways-to-boost-credit-card-authorization-rates?source=rss","date":1744676601,"author":"Aditya Vilas Deshpande","guid":23198,"unread":true,"content":"<blockquote><p>Credit card declines are no longer just an annoyance - they’re a multi-billion dollar growth leak.</p></blockquote><p>\\\nIf you read my last post, you already know the story: <strong><em>Credit card authorization failures quietly destroy revenue across the internet.</em></strong> Most of them aren't due to fraud. And most can be prevented.</p><p>\\\n<em>This post isn't about the problem — it's about the fix.</em></p><p>\\\nLet's walk through five proven strategies modern merchants use to reduce declines, recover sales, and improve customer experience.</p><h2>1️⃣ <strong>Use Tokenization (It's More Than Just Buzz)</strong></h2><p>Tokenization replaces a real credit card number with a unique, secure token. If the original card gets updated or reissued, the token can stay valid.</p><ul><li><p>Automatically updates when a customer's card expires or changes.</p></li><li><p>Reduces declines from \"invalid card\" or \"expired card\" issues.</p></li><li><p>Adds a layer of fraud protection = higher issuer confidence.</p></li><li><p>Merchants using network tokenization (Visa, Mastercard) report <strong>5–10% higher approval rates</strong> for stored cards.</p></li><li><p>Google Pay and Apple Pay already use tokens under the hood.</p></li></ul><blockquote><p>Bonus: It's PCI-friendly and more secure.</p></blockquote><ul><li>Ask your payment processor if they support network tokenization (not just gateway-level).</li><li>Use tokens for subscriptions, saved cards, and one-click checkouts.</li></ul><h2>2️⃣ <strong>Smart Retry Logic (Don't Just Hit \"Retry\" Blindly)</strong></h2><p>According to Recurly's data, up to 70% of failed recurring payments can be recovered with smart retry logic. Most payment failures — especially soft ones like \"insufficient funds\" or \"issuer unavailable\" — don't need a new card. They need better timing.</p><ul><li>Don't retry the same payment at fixed intervals (e.g., every 24 hours).</li><li>Don't retry hard declines like \"invalid account\" or \"lost/stolen card.\"</li><li>Don't retry indefinitely — it triggers issuer suspicion.</li></ul><p>Retry after salary cycles (e.g., 1st, 15th of the month).</p><p>Use exponential backoff with max retry limits.</p><p>Customize retry based on the decline code category.</p><p>Pause after 2–3 failures, then prompt user intervention.</p><blockquote><p>Pro Tools: Stripe Smart Retries, Chargebee Dunning, Recurly Retry Logic</p></blockquote><h2>3️⃣ <strong>Keep Cards Updated Automatically</strong></h2><p>Visa Account Updater (VAU) and Mastercard Automatic Billing Updater (ABU) automatically refresh saved card data (expiration, CVV, card number) when a card is replaced. These services prevent declines caused by expired or reissued cards, some of the most common soft declines in subscription businesses.</p><p>Imagine a customer getting a new card issued due to a lost or compromised card. Without an account updater, their saved payment method fails on the next billing cycle, leading to involuntary churn. With the account updater enabled, you'll get the new details automatically without the customer doing anything.</p><blockquote><p>Real-World Result: Merchants using account updater services in subscription-heavy industries have reported an average of 6–8% higher payment success rates. (PYMNTS Subscription Commerce Tracker)</p></blockquote><ul><li>Most modern PSPs (Braintree, Stripe, Adyen, Authorize.net) offer opt-in support.</li><li>Enable it for any service storing cards-on-file</li><li>It works exceptionally well when paired with tokenization.</li></ul><p>Card issuers often base their fraud decisions not just on the customer — but on how clean your transaction metadata is. Missing or inconsistent information triggers AVS mismatches, geolocation red flags, and descriptor confusion — all of which can lead to declines.</p><ul><li>Billing ZIP/Address: Use Address Verification System (AVS) where available</li><li>Merchant Category Code (MCC): Make sure it matches your actual business</li><li>Descriptor: What appears on the user's statement — make it recognizable</li><li>3D Secure (3DS): Consider enabling 3DS 2.0 for high-risk transactions or EU cards under PSD2</li><li>IP &amp; Device Info: Helps fight false positives, especially for mobile</li></ul><p>Regularly audit your PSP or gateway logs to see what metadata is being passed. Ensure consistency between checkout forms, backend payloads, and processor config.</p><blockquote><p>Real-World Example: One travel merchant cleaned up its AVS and MCC mismatches and saw a 4% jump in approval rates for U.S. cards in under 30 days.</p></blockquote><h2>5️⃣ <strong>Collaborate With Issuers (Yes, It's Possible)</strong></h2><p>Most declines come back with vague reason codes like:</p><ul></ul><p>These tell you nothing actionable. And when merchants retry blindly, they burn issuer trust, which can cause even more declines.</p><p>Enter issuer collaboration tools:</p><p>🧩 Ethoca (Mastercard) and Verifi (Visa)</p><p>\\\nThese services provide:</p><ul><li>Real-time issuer feedback</li><li>Resolution pathways for flagged transactions</li></ul><p>\\\n<em>They're also starting to enable approval intelligence — helping issuers understand legitimate merchant behavior over time.</em></p><p>Newer versions of 3D Secure allow merchants to share over 100 data points with issuers — improving approval confidence without always requiring a user challenge. Issuers often give higher approval rates to merchants that use enhanced 3DS.</p><blockquote><p>Real-World Result: Retailers using Ethoca + 3DS 2.0 have seen approval lifts of 5–10% in cross-border transactions, where false declines are highest.</p></blockquote><h3>🧾 Separate soft vs hard declines</h3><p>Retry only the fixable ones. Hard declines (e.g., stolen cards) need a new payment method.</p><h3>📈 Track authorization rates by country, card type, and issuer</h3><p>Some banks or regions are better than others. Route traffic accordingly.</p><h3>📦 Use fallback payment methods</h3><p>If a card fails, offer PayPal, ACH, or Buy Now, Pay Later (BNPL) at checkout.</p><h3>Decline Recovery Is Revenue Recovery</h3><p>Every failed payment isn't a technical issue — it's a broken promise. A moment where a willing customer tries to give you money… and the system says no.</p><p>\\\nBut this moment is also fixable.</p><p>\\\nWhether you're building a mobile checkout flow, managing a subscription engine, or running a payment gateway, the tools are already in place:</p><ul><li>Update them automatically</li><li>Work with issuers, not against them.</li></ul><p>\\\nImproving your authorization rate by even 1% can unlock millions in annual revenue — without a single new customer acquired.</p><ul><li>PYMNTS: False Decline Report</li><li>Chargebee: Dunning Best Practices</li><li>Recurly: Involuntary Churn Guide</li><li>Visa Developer – Decline Codes</li></ul><h3>✍️ One-Liner Pitch to Your CTO or PM</h3><p>Let's stop burning revenue on fixable declines — even a 1% lift in authorization rates is millions in saved revenue.\"</p><p>🔄 \"From Decline to Delight: The Future of Frictionless Payments\" (A look at AI-driven fraud detection, payment orchestration layers, and what's next in approval rate optimization.)</p><p>:::info\nWould you like to take a stab at answering some of these questions? The link for the template is&nbsp;. Interested in reading the content from all of our writing prompts? Click&nbsp;.</p>","contentLength":6522,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"RLWRLD raises $14.8M to build a foundational model for robotics","url":"https://techcrunch.com/2025/04/14/rlwrld-raises-14-4m-to-build-foundation-model-for-robotics/","date":1744675200,"author":"Kate Park","guid":23089,"unread":true,"content":"<article>As robotics has advanced, industry has steadily adopted more robots to automate away many kinds of grunt work. More than 540,000 new industrial robots were installed worldwide in 2023, taking the number of total industrial robots active to above 4 million, per IFR. Industrial robots typically excel at repetitive tasks, but they find it challenging […]</article>","contentLength":355,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Firebase Studio: Everything You Need to Know About","url":"https://hackernoon.com/firebase-studio-everything-you-need-to-know-about?source=rss","date":1744674343,"author":"Vladislav Guzey","guid":23197,"unread":true,"content":"<p>I recently tried using Firebase Studio, which has been an interesting experience I want to share with you. It’s a free, browser-based tool from Google that allows you to build full-stack web apps with AI assistance. Want to know more? Then, read this article until the end.</p><p>Firebase Studio was officially unveiled during&nbsp;&nbsp;(early April 2025) as one of Firebase’s major new updates.</p><p>\\\nIn short, Firebase Studio is a cloud-based development environment by Google that lives at&nbsp;<a href=\"http://studio.firebase.google.com/\">studio.firebase.google.com</a>. It combines:</p><ul><li><p>A full IDE based on VS Code (Code OSS)</p></li><li><p>AI assistance from Gemini (Google’s LLM)</p></li><li><p>Deep integration with Firebase services (Firestore, Auth, Hosting, Functions, etc.)</p></li><li><p>A visual app prototyping agent that can generate a full-stack app from a prompt</p></li></ul><p>It’s meant to help you go from idea to deployed app entirely from your browser — with no setup, installations, or local environments. </p><p>\\\nTo be honest, it’s not a new thing from Google; it’s a rebranded and updated version of&nbsp;<a href=\"https://proflead.dev/posts/will-project-idx-replace-vs-code-for-developers/\">Project IDX</a>.</p><p>\\\nI would say that currently, the core feature is prototyping.</p><h2>Prototyping With Firebase Studio</h2><p>&nbsp;I think it’s one of Firebase Studio’s most powerful features. It allows you to start building an app by simply describing what you want in natural language. I’ll show you a real example later in this article.</p><p>What makes this feature so impactful is that it:</p><ul><li><p>&nbsp;— great for testing ideas quickly.</p></li><li><p>&nbsp;— lets you focus on unique features.</p></li><li><p>&nbsp;— so you can edit, extend, and deploy immediately.</p></li><li><p><strong>One-Click Deployment to Production —</strong>&nbsp;once you’re satisfied with your application, Firebase Studio makes it trivial to deploy it. It leverages&nbsp;&nbsp;under the hood so that with a single&nbsp;&nbsp;button, your web app is built and deployed globally on Google’s CDN.</p></li></ul><p>Currently, it supports Next.js projects, but Google is planning to expand to other frameworks soon.</p><h2>How Is It Different From the Firebase Console?</h2><p>Firebase Studio is made for&nbsp;. You write code, test it, preview your app, and deploy — all from within Firebase Studio.</p><p>\\\nThe Firebase Console manages the project settings, database rules, analytics, and production configurations. Firebase Studio builds on top of that by letting you code, prototype, and iterate faster than ever.</p><p>\\\nSo, these are two completely different tools.</p><h2>Use Cases for Firebase Studio</h2><ol><li>&nbsp;Build working versions of your app in hours, not days. Great for pitching ideas or testing concepts.</li><li>&nbsp;Show functional versions of apps to clients without having to maintain a local environment.</li><li>: Perfect for students, educators, and boot camps. No installations. No config headaches. Just code.</li><li><strong>Solo Developers &amp; Hackathons</strong>: Move fast and build entire apps from your browser during weekend projects or events.</li><li><strong>Cross-Team Collaboration:</strong>&nbsp;Allow frontend and backend devs to work in the same environment. Coming soon: real-time coding collaboration.</li><li>&nbsp;Easily experiment with AI-driven features using built-in Gemini integration and Genkit setup.</li></ol><h2>Getting Started With Firebase Studio</h2><p>It’s straightforward. Follow these steps:</p><ul><li><p>Sign in with your Google account.​</p></li><li><p>On the dashboard, locate the&nbsp;<strong>“Prototype an app with AI”</strong>&nbsp;field.​ In the input field, enter a natural language description of your app. For example:&nbsp;<em>A simple recipe maker that generates recipes based on the ingredients I have in my fridge. Simple UI, green color scheme.</em></p></li><li><p>Optionally, upload an image to guide the app’s design, such as a color scheme or layout inspiration, and click the “Prototype with AI” button.</p></li><li><p>Firebase Studio will generate a blueprint outline. If you aren’t happy with it, you can use the chat pane to adjust the blueprint and click “Edit” to modify the blueprint.</p></li></ul><ul><li><p>Once the app is generated, a preview will appear.</p></li></ul><ul><li><p>To request modifications or add features, use the chat interface, element selector, or the “annotate” button.</p></li></ul><ul><li><p>Once you are happy with the result, you can publish the application to the Firebase App Hosting by clicking the “Publish” button. Then, Firebase Studio will guide you through the process. If you are stuck, you can watch&nbsp;<a href=\"https://youtu.be/DzlvILoMYiQ\">my video tutorial</a>&nbsp;with a more detailed explanation.</p></li></ul><p>Firebase Studio itself is currently in&nbsp;&nbsp;and offers a free tier for developers:​</p><h3>Free Tier (Preview Access)</h3><ul><li><p>&nbsp;per user at no cost.</p></li><li><p>&nbsp;for members of the Google Developer Program.</p></li><li><p>&nbsp;for Premium members of the Google Developer Program.</p></li></ul><p>However, there are some instances when costs may apply.</p><ul><li>: Deploying your app requires a linked billing account, transitioning your project to the Blaze (pay-as-you-go) plan.</li><li>: Utilizing Gemini for AI assistance beyond the free tier may lead to charges, especially for Google Workspace users who need a valid Gemini Code Assist subscription. ​But make sure you set up&nbsp;<a href=\"https://youtu.be/PSqoJdlIae8\">a budget alarm</a>.</li><li>: Services like Firestore, Cloud Functions, and Cloud Storage have free usage quotas, but exceeding these limits will result in charges.</li></ul><p>This tool is still in preview, so you may encounter some bugs or limitations. While Gemini is helpful, it can occasionally misinterpret prompts — so be ready to revise your input or fine-tune the results. If Google continues improving it, this could become the default IDE for Firebase developers.</p><p>\\\nHave you already tried it? I’d love to hear your thoughts in the comments below.</p><p>\\\nThanks for reading — cheers! 😉</p>","contentLength":5274,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Samsung Pauses One UI 7 Rollout Worldwide","url":"https://mobile.slashdot.org/story/25/04/14/236246/samsung-pauses-one-ui-7-rollout-worldwide?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744674000,"author":"BeauHD","guid":23095,"unread":true,"content":"Samsung has paused the global rollout of its One UI 7 update after a serious bug was reported that prevented some Galaxy S24 owners from unlocking their phones. The Verge reports: While the complaints seem to have specifically come from South Korean owners of Galaxy S24 series handsets, Samsung has played it safe and paused the rollout across all models worldwide. While some users will have already downloaded the update to One UI 7, using the app CheckFirm we've confirmed that the update is no longer listed on Samsung's servers as the latest firmware version across several Galaxy devices, with older patches appearing instead. Samsung hasn't confirmed the pause in the rollout, nor plans to issue a fix for users who have already downloaded the One UI 7 update. We've reached out to the company for comment.","contentLength":814,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Risks To Children Playing Roblox 'Deeply Disturbing,' Say Researchers","url":"https://games.slashdot.org/story/25/04/14/2259206/risks-to-children-playing-roblox-deeply-disturbing-say-researchers?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744671600,"author":"BeauHD","guid":23077,"unread":true,"content":"A new investigation reveals that children as young as five can easily access inappropriate content and interact unsupervised with adults on Roblox, despite the platform's child-friendly image and recent safety updates. The Guardian reports: Describing itself as \"the ultimate virtual universe,\" Roblox features millions of games and interactive environments, known collectively as \"experiences.\" Some of the content is developed by Roblox, but much of it is user-generated. In 2024, the platform had more than 85 million daily active users, an estimated 40% of whom are under 13. While the company said it \"deeply sympathized\" with parents whose children came to harm on the platform, it said \"tens of millions of people have a positive, enriching and safe experience on Roblox every day.\"\n \nHowever, in an investigation shared with the Guardian, the digital-behavior experts Revealing Reality discovered \"something deeply disturbing ... a troubling disconnect between Roblox's child-friendly appearance and the reality of what children experience on the platform.\" [...] Despite new tools launched last week aimed at giving parents more control over their children's accounts, the researchers concluded: \"Safety controls that exist are limited in their effectiveness and there are still significant risks for children on the platform.\"","contentLength":1336,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Debates over AI benchmarking have reached Pokémon","url":"https://techcrunch.com/2025/04/14/debates-over-ai-benchmarking-have-reached-pokemon/","date":1744669675,"author":"Kyle Wiggers","guid":23088,"unread":true,"content":"<article>Not even Pokémon is safe from AI benchmarking controversy. Last week, a post on X went viral, claiming that Google’s latest Gemini model surpassed Anthropic’s flagship Claude model in the original Pokémon video game trilogy. Reportedly, Gemini had reached Lavender Town in a developer’s Twitch stream; Claude was stuck at Mount Moon as of late […]</article>","contentLength":357,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intel To Sell Majority Stake In Altera For $4.46 Billion To Fund Revival Effort","url":"https://slashdot.org/story/25/04/14/1943245/intel-to-sell-majority-stake-in-altera-for-446-billion-to-fund-revival-effort?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744668600,"author":"BeauHD","guid":23055,"unread":true,"content":"Intel will sell a 51% stake in its Altera programmable chip unit to private equity firm Silver Lake for $4.46 billion, aiming to cut costs, raise cash, and streamline the company's focus as it shifts toward becoming a contract chip manufacturer. CNBC reports: The deal, announced on Monday, values Altera at $8.75 billion, a sharp decline from the $17 billion Intel paid in 2015. [...] Since last year, Intel has taken steps to spin Altera out as a separate unit and said it planned to sell a portion of its stake. \"Today's announcement reflects our commitment to sharpening our focus, lowering our expense structure and strengthening our balance sheet,\" [CEO Lip-Bu Tan], who took the helm after former top boss Pat Gelsinger's ouster, said.\n \nAltera makes programmable chips that can be used for various purposes from telecom equipment to military. Reuters had first reported in November that Silver Lake was among potential suitors competing for a minority stake in Altera. The deal is expected to close in the second half of 2025, after which Intel expects to deconsolidate Altera's financial results from Intel's financial statements, the company said.","contentLength":1157,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Lime’s scooter and e-bike batteries will be recycled by Redwood Materials","url":"https://techcrunch.com/2025/04/14/limes-scooter-and-ebike-batteries-will-be-recycled-by-redwood-materials/","date":1744666717,"author":"Kirsten Korosec","guid":23056,"unread":true,"content":"<article>Shared micromobility company Lime has reached an agreement to send batteries used in its scooters and e-bikes to Redwood Materials, which will extract and recycle critical minerals such as lithium, cobalt, nickel, and copper. The agreement announced Monday makes Redwood Materials the exclusive battery recycling partner for Lime’s shared scooters and e-bikes located in cities […]</article>","contentLength":385,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"UK Laws Are Not 'Fit For Social Media Age'","url":"https://news.slashdot.org/story/25/04/14/1937244/uk-laws-are-not-fit-for-social-media-age?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744666200,"author":"BeauHD","guid":23054,"unread":true,"content":"An anonymous reader quotes a report from the New York Times: British laws restricting what the police can say about criminal cases are \"not fit for the social media age (source paywalled; alternative source),\" a government committee said in a report released Monday in Britain that highlighted how unchecked misinformation stoked riots last summer. Violent disorder, fueled by the far right, affected several towns and cities for days after a teenager killed three girls on July 29 at a Taylor Swift-themed dance class in Southport, England. In the hours after the stabbings, false claims that the attacker was an undocumented Muslim immigrant spread rapidly online. In a report looking into the riots, a parliamentary committee said a lack of information from the authorities after the attack \"created a vacuum where misinformation was able to grow.\" The report blamed decades-old British laws, aimed at preventing jury bias, that stopped the police from correcting false claims. By the time the police announced the suspect was British-born, those false claims had reached millions.\n \nThe Home Affairs Committee, which brings together lawmakers from across the political spectrum, published its report after questioning police chiefs, government officials and emergency workers over four months of hearings. Axel Rudakubana, who was sentenced to life in prison for the attack, was born and raised in Britain by a Christian family from Rwanda. A judge later found there was no evidence he was driven by a single political or religious ideology, but was obsessed with violence. [...] The committee's report acknowledged that it was impossible to determine \"whether the disorder could have been prevented had more information been published.\" But it concluded that the lack of information after the stabbing \"created a vacuum where misinformation was able to grow, further undermining public confidence,\" and that the law on contempt was not \"fit for the social media age.\"","contentLength":1972,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI continues naming chaos despite CEO acknowledging the habit","url":"https://arstechnica.com/ai/2025/04/when-is-4-1-greater-than-4-5-when-its-openais-newest-model/","date":1744664031,"author":"Benj Edwards","guid":23040,"unread":true,"content":"<p>On Monday, OpenAI <a href=\"https://openai.com/index/gpt-4-1/\">announced</a> the GPT-4.1 model family, its newest series of AI language models that brings a 1 million token context window to OpenAI for the first time and continues a long tradition of very confusing AI model names. Three confusing new names, in fact: GPT‑4.1, GPT‑4.1 mini, and GPT‑4.1 nano.</p><p>According to OpenAI, these models outperform <a href=\"https://arstechnica.com/information-technology/2024/05/chatgpt-4o-lets-you-have-real-time-audio-video-conversations-with-emotional-chatbot/\">GPT-4o</a> in several key areas. But in an unusual move, GPT-4.1 will only be available through the developer API, not in the consumer <a href=\"https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/\">ChatGPT</a> interface where most people interact with OpenAI's technology.</p><p>The 1 million token context window—essentially the amount of text the AI can process at once—allows these models to ingest roughly 3,000 pages of text in a single conversation. This puts OpenAI's context windows on par with <a href=\"https://arstechnica.com/ai/2025/03/google-says-the-new-gemini-2-5-pro-model-is-its-smartest-ai-yet/\">Google's Gemini models</a>, which have offered similar extended context capabilities for some time.</p>","contentLength":884,"flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2025/04/confused_man_2-1152x648.jpg","enclosureMime":"","commentsUrl":null},{"title":"Hacked Crosswalks In Bay Area Play Deepfake-Style Messages From Tech Billionaires","url":"https://it.slashdot.org/story/25/04/14/1932207/hacked-crosswalks-in-bay-area-play-deepfake-style-messages-from-tech-billionaires?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744663800,"author":"BeauHD","guid":23039,"unread":true,"content":"Several crosswalk buttons in Palo Alto and nearby cities were hacked over the weekend to play deepfake-style satirical audio clips mimicking Elon Musk and Mark Zuckerberg. Authorities have disabled the altered systems, but the identity of the prankster remains unknown. SFGATE reports: Videos of the altered crosswalks began circulating on social media throughout Saturday and Sunday. [...] A city employee was the first to report an issue with one of the signals at University Avenue and High Street in downtown Palo Alto, Horrigan-Taylor told SFGATE via email. Officials later discovered that as many as 12 intersections in downtown Palo Alto had been affected.\n \n\"The impact is isolated,\" Horrigan-Taylor said. \"Signal operations are otherwise unaffected, and motorists are reminded to always exercise caution around pedestrians.\" Officials told the outlet they've removed any devices that were tampered with and the compromised voice-over systems have since been disabled, with footage obtained by SFGATE showing several were covered in caution tape, blinking constantly and unpressable.","contentLength":1091,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Rippling is trying to serve Deel’s CEO, but bailiffs can’t find him","url":"https://techcrunch.com/2025/04/14/rippling-is-trying-to-serve-deels-ceo-but-bailiffs-cant-find-him/","date":1744662778,"author":"Charles Rollet","guid":23036,"unread":true,"content":"<article>HR tech startup Rippling is trying to serve Deel CEO Alex Bouaziz with papers as part of a blockbuster lawsuit against its competitor. There’s just one problem: French bailiffs hired by Rippling can’t seem to find Bouaziz, Irish newspaper Business Post reports. Rippling sued Deel earlier this year in Ireland alleging the company paid one […]</article>","contentLength":349,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meta Starts Using Data From EU Users To Train Its AI Models","url":"https://meta.slashdot.org/story/25/04/14/1926259/meta-starts-using-data-from-eu-users-to-train-its-ai-models?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744661400,"author":"BeauHD","guid":23016,"unread":true,"content":"Meta said the company plans to start using data collected from its users in the European Union to train its AI systems. Engadget reports: Starting this week, the tech giant will begin notifying Europeans through email and its family of apps of the fact, with the message set to include an explanation of the kind of data it plans to use as part of the training. Additionally, the notification will link out to a form users can complete to opt out of the process. \"We have made this objection form easy to find, read, and use, and we'll honor all objection forms we have already received, as well as newly submitted ones,\" says Meta.\n \nThe company notes it will only use data it collects from public posts and Meta AI interactions for training purposes. It won't use private messages in its training sets, nor any interactions, public or otherwise, made by users under the age of 18. As for why the company wants to start using EU data now, it claims the information will allow it to fine tune its future models to better serve Europeans. \"We believe we have a responsibility to build AI that's not just available to Europeans, but is actually built for them. That's why it's so important for our generative AI models to be trained on a variety of data so they can understand the incredible and diverse nuances and complexities that make up European communities,\" Meta states.\n \n\"That means everything from dialects and colloquialisms, to hyper-local knowledge and the distinct ways different countries use humor and sarcasm on our products. This is particularly important as AI models become more advanced with multi-modal functionality, which spans text, voice, video, and imagery.\"","contentLength":1683,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"NATO Inks Deal With Palantir For Maven AI System","url":"https://tech.slashdot.org/story/25/04/14/1917246/nato-inks-deal-with-palantir-for-maven-ai-system?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744659000,"author":"BeauHD","guid":23015,"unread":true,"content":"An anonymous reader quotes a report from DefenseScoop: NATO announced Monday that it has awarded a contract to Palantir to adopt its Maven Smart System for artificial intelligence-enabled battlefield operations. Through the contract, which was finalized March 25, the NATO Communications and Information Agency (NCIA) plans to use a version of the AI system -- Maven Smart System NATO -- to support the transatlantic military organization's Allied Command Operations strategic command. NATO plans to use the system to provide \"a common data-enabled warfighting capability to the Alliance, through a wide range of AI applications -- from large language models (LLMs) to generative and machine learning,\" it said in a release, ultimately enhancing \"intelligence fusion and targeting, battlespace awareness and planning, and accelerated decision-making.\" [...] NATO's Allied Command Operations will begin using Maven within the next 30 days, the organization said Monday, adding that it hopes that using it will accelerate further adoption of emerging AI capabilities. Palantir said the contract \"was one of the most expeditious in [its] history, taking only six months from outlining the requirement to acquiring the system.\"","contentLength":1223,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Chinese marketplace DHgate becomes a top US app as trade war intensifies","url":"https://techcrunch.com/2025/04/14/chinese-marketplace-dhgate-becomes-a-top-us-app-as-trade-war-intensifies/","date":1744658376,"author":"Sarah Perez","guid":23009,"unread":true,"content":"<article>The Trump trade war has gone viral on TikTok, pushing a Chinese e-commerce app, DHgate, to the top of the U.S. App Store. After Trump increased U.S. tariffs on Chinese imports by 145%, numerous Chinese suppliers and manufacturers began making TikTok videos explaining to consumers how the global luxury goods market actually works. The clothing, […]</article>","contentLength":351,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meet Neptune, a TikTok alternative where creators can hide likes and follower counts","url":"https://techcrunch.com/2025/04/14/meet-neptune-a-tiktok-alternative-where-creators-can-hide-likes-and-follower-counts/","date":1744657064,"author":"Lauren Forristal","guid":23008,"unread":true,"content":"<article>Neptune is one of the newest short-form video apps on the block seeking to compete with major players like TikTok, Instagram Reels, and YouTube Shorts.&nbsp; The app, currently in beta, has attracted attention from hundreds of thousands of users, with 970 testers participating and 400,000 people on the waitlist, per the company. Neptune announced Monday […]</article>","contentLength":357,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"VMware Revives Its Free ESXi Hypervisor","url":"https://it.slashdot.org/story/25/04/14/1851214/vmware-revives-its-free-esxi-hypervisor?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744656660,"author":"msmash","guid":22986,"unread":true,"content":"VMware has resumed offering a free hypervisor. News of the offering emerged in a throwaway line in the Release Notes for version 8.0 Update 3e of the Broadcom business unit's ESXi hypervisor. From a report: Just below the \"What's New\" section of that document is the statement: \"Broadcom makes available the VMware vSphere Hypervisor version 8, an entry-level hypervisor. You can download it free of charge from the Broadcom Support portal.\" \n\nVMware offered a free version of ESXi for years, and it was beloved by home lab operators and vAdmins who needed something to tinker with. But in February 2024, VMware discontinued it on grounds that it was dropping perpetual licenses and moving to subscriptions.","contentLength":707,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EU Issues US-bound Staff With Burner Phones Over Spying Fears","url":"https://yro.slashdot.org/story/25/04/14/1814239/eu-issues-us-bound-staff-with-burner-phones-over-spying-fears?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744654440,"author":"msmash","guid":22985,"unread":true,"content":"The European Commission is issuing burner phones and basic laptops to some US-bound staff to avoid the risk of espionage [non-paywalled source], a measure traditionally reserved for trips to China. Financial Times: Commissioners and senior officials travelling to the IMF and World Bank spring meetings next week have been given the new guidance, according to four people familiar with the situation. They said the measures replicate those used on trips to Ukraine and China, where standard IT kit cannot be brought into the countries for fear of Russian or Chinese surveillance. \n\n\"They are worried about the US getting into the commission systems,\" said one official. The treatment of the US as a potential security risk highlights how relations have deteriorated since the return of Donald Trump as US president in January. Trump has accused the EU of having been set up to \"screw the US\" and announced 20 per cent so-called reciprocal tariffs on the bloc's exports, which he later halved for a 90-day period. \n\nAt the same time, he has made overtures to Russia, pressured Ukraine to hand over control over its assets by temporarily suspending military aid and has threatened to withdraw security guarantees from Europe, spurring a continent-wide rearmament effort. \"The transatlantic alliance is over,\" said a fifth EU official.","contentLength":1332,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hertz says customers’ personal data and driver’s licenses stolen in data breach","url":"https://techcrunch.com/2025/04/14/hertz-says-customers-personal-data-and-drivers-licenses-stolen-in-data-breach/","date":1744653719,"author":"Zack Whittaker","guid":23007,"unread":true,"content":"<article>The car rental giant attributed the breach to Cleo, whose customers had data stolen by a ransomware gang in 2024.</article>","contentLength":113,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI Unveils Coding-Focused GPT-4.1 While Phasing Out GPT-4.5","url":"https://slashdot.org/story/25/04/14/1726250/openai-unveils-coding-focused-gpt-41-while-phasing-out-gpt-45?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744651560,"author":"msmash","guid":22984,"unread":true,"content":"OpenAI unveiled its GPT-4.1 model family on Monday, prioritizing coding capabilities and instruction following while expanding context windows to 1 million tokens -- approximately 750,000 words. The lineup includes standard GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano variants, all available via API but not ChatGPT. \n\nThe flagship model scores 54.6% on SWE-bench Verified, lagging behind Google's Gemini 2.5 Pro (63.8%) and Anthropic's Claude 3.7 Sonnet (62.3%) on the same software engineering benchmark, according to TechCrunch. However, it achieves 72% accuracy on Video-MME's long video comprehension tests -- a significant improvement over GPT-4o's 65.3%. \n\nOpenAI simultaneously announced plans to retire GPT-4.5 -- their largest model released just two months ago -- from API access by July 14. The company claims GPT-4.1 delivers \"similar or improved performance\" at substantially lower costs. Pricing follows a tiered structure: GPT-4.1 costs $2 per million input tokens and $8 per million output tokens, while GPT-4.1 nano -- OpenAI's \"cheapest and fastest model ever\" -- runs at just $0.10 per million input tokens. \n\nAll models feature a June 2024 knowledge cutoff, providing more current contextual understanding than previous iterations.","contentLength":1248,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI plans to phase out GPT-4.5, its largest-ever AI model, from its API","url":"https://techcrunch.com/2025/04/14/openai-plans-to-wind-down-gpt-4-5-its-largest-ever-ai-model-in-its-api/","date":1744650000,"author":"Kyle Wiggers","guid":22963,"unread":true,"content":"<article>OpenAI said on Monday that it would soon wind down the availability of GPT-4.5, its largest-ever AI model, via its API. GPT-4.5 was released only in late February. Developers will have access to GPT-4.5 via OpenAI’s API until July 14, after which they’ll have to transition to another model in OpenAI’s catalog, the company says. […]</article>","contentLength":341,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"OpenAI’s new GPT-4.1 AI models focus on coding","url":"https://techcrunch.com/2025/04/14/openais-new-gpt-4-1-models-focus-on-coding/","date":1744650000,"author":"Kyle Wiggers","guid":22964,"unread":true,"content":"<article>OpenAI on Monday launched a new family of models called GPT-4.1. Yes, “4.1” — as if the company’s nomenclature wasn’t confusing enough already. There’s GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano, all of which OpenAI says “excel” at coding and instruction following. Available through OpenAI’s API but not ChatGPT, the multimodal models have a 1-million-token context […]</article>","contentLength":387,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Blockchain Systems Use Checkpoints for Recovery and Finality","url":"https://hackernoon.com/why-blockchain-systems-use-checkpoints-for-recovery-and-finality?source=rss","date":1744649070,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23093,"unread":true,"content":"<p>Replaying all transactions from genesis is expensive and as a blockchain system is used it quickly becomes prohibitively so for new participants wishing to join the system. The storage cost of the blockchain blocks grows linearly over time, and for Ethereum maintaining any sort of availability for old trie state can become quite expensive. In the past, Bitcoin performed a sort of uber-commit by releasing new clients with “checkpoints”, where the state at some block height is built into the client. Blocks with lower block numbers can be safely discarded, since everyone has a state—the checkpoint state—from which to replay newer transactions. Bitcoin has since removed checkpoints because it was viewed as creating confusion/misconceptions around the security model.</p><p>\\\nIn addition to reducing the entry cost for joining the system, checkpointing reduces the cost of record keeping for existing participants. This is a “meta” level of finality: the effect of transactions that landed prior to the checkpoint cannot be disputed, since the records associated with them are likely to be unavailable.</p><p>\\\nBeyond cost of entry or on-going operational costs, checkpoints are also used in conjunction with governance mechanisms for catastrophic error recovery. Many blockchain systems that have experienced problems, e.g., massive token losses due to bugs in critical blockchain code or smart contracts, have resorted to hard forks to recover from such errors despite transactions reaching state finality; checkpointing too soon— if records older than checkpoints are not kept around— would prevent recovery by reverting to the checkpoint state and (optionally) re-executing (using fixed versions of the code, etc) transactions in their original logged order.</p><p>\\\n<strong>2.7.1 Checkpoints vs Long-Range Attacks</strong></p><p>\\\nNote that checkpoints addresses a different problem than long-range attacks. In long-range attacks, we are worried about exposure of old cryptographic signing keys used by past consensus committee members in a PoS design [2]. Such members may have exited the ecosystem and their old keys are no longer handled carefully; worse, such past members may rationally decided to auction their signing keys on the dark web, since they no longer hold any tokens and have nothing to lose. Such keys are useless when used to present bogus information to blockchain participants that know the current committee composition and have been tracking transactions and committee elections. However, consider a threat model where a Rip van Winkle victim wakes up after a period of inactivity and is somehow placed in an  style virtual world / faux information bubble. That bubble filters out legitimate information about a PoS blockchain’s current state and instead only makes available information constructed to make a forked chain—made feasible due to a super-threshold number of exfiltrated/compromised keys of members from an old consensus committee [2].</p><p>\\\nThe Inception information bubble is an interesting threat model. If applied to PoW blockchains, a victim cannot know if the chain that they see is indeed the longest chain—the “longest” predicate amounts to a universal quantifier, and global information is needed. Estimates for how long the chain  be might be feasible if there is trusted time, but that’s probabilistic in nature: block production rate depends on both protocol parameter changes and the number of active miners, which has more to do with the economic attractiveness for participating (relative to all other investments) than with computation power limitations. Furthermore, such a length estimate only applies to the whole chain segment since the victim fell asleep and does not help much with the “longest” predicate since the fork can be quite recent.</p><p>\\\nWithout Inception-like powers to mount eclipse attacks [6], an adversary should be unable to confuse potential victims. A potential victim can verify that they have a current view of the blockchain: they just securely query  sources for the hashes of recent blocks on the chain. If a majority  of these hashes are on the same chain and these sources are honest, not eclipsed, and have continued to be blockchain observers , the potential victim will be able to distinguish the global consensus chain from a forked chain created with long-range leaked keys. Here  ≤  is a security parameter, which can be chosen so that the Inception-esque adversary will have to additionally compromise prohibitively many more keys (or their holders) than just those of old consensus committee members, since any blockchain observer can witness recent blocks and thus  can be much larger than the size of a consensus committee.</p><p>\\\n<strong>2.7.2 Zero-day Attacks / Common-mode Failures</strong></p><p>\\\nCheckpointing is intended for addressing the handling of relatively  zero-day attacks where a super-threshold number of the current consensus committee members have been compromised, or a newly discovered vulnerability in the rollup software is being exploited. We do not envision it being useful for handling attacks that had not been noticed for a long time, since any actual means of addressing it will be complicated. The cascading causal relationship of newer transactions depending on the output states of older transactions is likely to lead to an explosion of transactions that will be aborted in a new interpretation of their effects when they had successfuly committed before.</p><p>\\\nThe design decision is whether to perform checkpointing at all, and if so, how old—in real time, block numbers, etc—must a finalized transaction be before it might be included in a checkpoint. This decision is essentially the blockchain version of a  in many legal systems. Unlike normal statutes of limitations that specify a time limit that is specific to the type of crime—and for some crimes there are no limits—here the checkpoint is global in scope: all transactions, regardless of which contracts they might be associated with, have to be treated the same way.</p><p>\\\nThe checkpoint’s state / value association is a temporal barrier: transactions earlier than the checkpoint have “checkpoint finality”, since records that would enable their replay in the alternate bug-fixed environment are unavailable. Note that unlike transaction order finality and state finality which typically occur at the same time as when their log entries are made, i.e., at log finality, checkpoint finality could occur long after the identification of a state as a checkpoint candidate. For example, a system could log that a state will become the next checkpoint once the blockchain’s block height reaches a certain value (which is expected to occur in about six months, say) or when a quorum of time oracles attest that a certain date has been reached. The log entry makes the decision irrevocable, but checkpoint finality does not necessarily occur until other gating conditions are met.</p><p>\\\nSeparating state finality from checkpoint finality to handle the possibility of catastrophic failures introduces risk for those who need to take actions external to the rollup based on state finality. External actions cannot always be rolled back. We believe that this can be handled using an insurance model: for example, an insurance policy based on the type of external action and risk profile could be offered to make participants whole, should a checkpoint/replay invoked due to a catastrophic failure cause the proper external action to change.</p><p>(1) Bennet Yee, Oasis Labs;</p><p>(2) Dawn Song, Oasis Labs;</p><p>(3) Patrick McCorry, Infura;</p><p>(4) Chris Buckland, Infura.</p>","contentLength":7587,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Making Sense of Blockchain Execution and Transaction Order","url":"https://hackernoon.com/making-sense-of-blockchain-execution-and-transaction-order?source=rss","date":1744649070,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23094,"unread":true,"content":"<p>In this section, we introduce ideas, notation, and terminology used to describe and delineate the design space of smart contract systems, using some existing well-known systems as reference points. Applying these ideas will help us create a simpler, easier-tounderstand mathematical / mental model of what all blockchain systems do, and to discuss / analyze tradeoffs in current and future designs. These notions apply both to standard blockchains as well as to scaling solutions such as rollups.</p><p>The append-only logs used in Bitcoin and Ethereum v1 are Proof-of-Work (PoW) based designs, whereas those used in Ethereum v2, Cosmos, Polkadot, Oasis, etc are Proof-of-Stake (PoS) based designs.</p><p>\\\nAt the level of abstraction needed here, the only thing that we care about is that the append operation for a PoW log is probabilistic, and an entry is not considered successful until about 6 additional entries have been made (the distance to the end of the chain is a security parameter here). Typically the idea for needing additional entries in PoW is called “probabilistic finality”.</p><p>\\\nPoS logs use committee elections and digital signatures instead of solving cryptographic puzzles, and once the consensus protocol completes and a new log entry is made, it is considered final. While it takes time for the consensus protocol to run, no additional entries are required and this is often referred to as “instant finality.”</p><p>\\\nWe will refer to the general idea as “log finality,” whether probabilistic (with appropriate security parameter) or instant. Log finality is the mechanism upon which other notions of finality is built: log finality only says that some entry is successfully appended to the log, but says nothing about what that entry means.</p><h3>2.2 Virtual Machine State</h3><p>Since “state” can be encoded and represented in many ways, we need to start with mathematical necessities to describe what we mean by “state” in a way that is divorced from any particular representation. By “state”, we mean a function from a key set, its domain, to a value set, its range, i.e., State : Key → Value. In Bitcoin, Key would essentially be public keys, and Value would be numbers representing the quantity of Bitcoin tokens under the control of the corresponding private keys. In Ethereum-like systems, Key would be a union of several disjoint sets, e.g., public key hashes associated with Externally Owned Accounts (EOAs), contract addresses, contract address and 256-bit address tuples for naming persistent store locations, etc. Correspondingly, Value would be public keys, EOA balances, contracts’ code and balance, and 256-bit values from contracts’ persistent store, etc.[1]</p><h3>2.3 Transactions As Curried Functions</h3><p>Users of blockchain-based systems propose transactions that are recorded by being appended to the blockchain. We normally think of transactions as altering state. In a mathematical description, they are functions that  state, i.e., State → State. Smart contract entry points take arguments— in Ethereum, the callData—and does not fit this type signature; however, by currying all the user-supplied arguments including authorization information (msg.sender, etc), all transactions can be modeled in this manner.[2]</p><p>\\\n\\\nThis is a useful separation since most contract virtual machines implement standard ACID transaction semantics, and an explicit transaction abort reverting the contract state (failure atomicity) is just tc returning its input state, though gas fees for computation performed until the abort must still be paid.</p><h3>2.4 Natural Names of State</h3><p>Because users think of their transactions as being executed in a strict serial order and submit transactions based on their model of what the current system state (e.g., their EOA balance), a natural way to refer to any reachable state is the sequence of transactions that yields that state.</p><p>\\\n<strong>2.4.1 Names And Composition of Transformations</strong></p><p>\\\n\\\nNote that for Bitcoin, Ethereum, and Arbitrum, the natural name is exactly what is recorded on the blockchain. Other smart contract systems may only  record the execution order, e.g., as part of a zkSNARK proving correct execution.</p><p>\\\n<strong>2.4.2 Names Are Not Unique</strong></p><p>\\\nNote that names are not unique. Many states have multiple names. If two transactions f and g commute at a given state s, i.e., the resultant state is (f; g)(s) = (g; f)(s), then there are (at least) two names for the resultant state. Of course, if both f and g were proposed, the system will eventually decide on some order. This is analogous to how 0+ 1+ 2 and 0 + 2 + 1 are both ways to name the value 3.</p><p>\\\nNote also that some states have no names in this nomenclature. For example, a state where an EOA controls more tokens than the total token supply is unreachable, since (absent a catastrophic bug) there are no sequences of transactions from the genesis state that would result in such a state. This is fine, since such unreachable states are of no interest.</p><p>(1) Bennet Yee, Oasis Labs;</p><p>(2) Dawn Song, Oasis Labs;</p><p>(3) Patrick McCorry, Infura;</p><p>(4) Chris Buckland, Infura.</p><p>[1] This is just one way to model Ethereum state; other models, e.g., as a set of mappings one for each key type, would be more precise.</p>","contentLength":5199,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Blockchain Defines ‘Truth’","url":"https://hackernoon.com/how-blockchain-defines-truth?source=rss","date":1744649058,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23092,"unread":true,"content":"<p>Ground truth for smart contract / blockchain systems is knowing what the current state is supposed to be. This does not mean, however, that we must have an efficient representation of that state, merely that it is computable—efficiently, and unambiguously. We argue that the most natural definition for blockchain system state is based on consensus agreement on the order of all transactions since the genesis state (or since a checkpoint state, see Section 2.7).</p><p>\\\nOnce a transaction’s parameters are logged (has achieved log finality), its execution order relative to earlier logged transactions is determined. Via a simple inductive argument, since the input state is computable by the execution order finality of earlier transactions, the resultant state from this transaction can, in principle, also be computed. We call this “transaction order finality.”</p><p>\\\nConsensus about the current state is based on states’ natural names, and computing an efficient representation is not necessarily coupled with this decision. Everything else is an optimization.</p><h2>2.6 Efficient Representations of State</h2><p>All blockchain-based systems use an append-only log to record ground truth. From those log entries the system determines the consensus reality on the state of one (or more) virtual machines. However, different blockchains handle state differently.</p><p>\\\nBitcoin only records transactions in the blockchain blocks. The VM is relatively simple and the state is the number of tokens controlled by public keys— the so-called Unspent Transaction Outputs (UTXOs). The logged messages specify how to transfer tokens using the VM rules, but state is implicit. In contrast, Ethereum also records a representation of the new state that results after all the transactions named within the block are applied to the state from the previous block. This state is recorded via a cryptographic commitment—the “stateRoot”, which is the root hash summary of the Merkle Patricia trie representation of the Ethereum Virtual Machine (EVM) state. Hyperledger [1] takes a Bitcoin-like approach and leaves the interpretation of results—the effect on the VM—to clients.</p><p>\\\nNote that Bitcoin miners must also have an efficient representation of state, since in order to verify new blocks double spending checks etc must be performed— it is just that this state does not show up on-chain. Availability is separate from permanence: in either case, miners has to either “catch up” by replaying transactions since a checkpoint (more on that later) or obtain a copy from somebody else. Apart from replaying transactions, there is no way for Bitcoin miners to verify state obtained from an untrusted party; Ethereum miners, on the other hand, can readily verify the Merklized data structure (stateRoot).</p><p>\\\nRollup systems use an existing underlying blockchain as a security anchor to allow “off-chain” execution, where smart contract code executes in a separate VM (“rollup”), so that many transactions can execute there while requiring fewer (or cheaper) transactions at the underlying blockchain. This is an attractive scaling solution, since (presumably) computation on the rollup is cheaper, and a single underlying blockchain can support multiple rollups. Optimistic rollup designs like Arbitrum [8] commit the transaction order to a bridge contract in the underlying blockchain, computes the resultant state in the rollup, and sends that result to the bridge contract in the underlying blockchain to validate. We will discuss various validation schemes later (see Section 2.10); the key observation here is that transaction order can be determined in a separate step from state computation.</p><p>\\\nAnother way to think of this is that the resultant state from the execution of a transaction  is named once we have the order of all transactions starting from the genesis state up to and including . We may not yet have  that state as a data structure that allows the key-value lookup to be performed efficiently, but there is no doubt what that state would be—everyone given its name will arrive at the same abstract mapping, even if its concrete representation— actual choices of data structures—may differ. Bitcoin only names the current state.[3] Ethereum-like systems both name and compute one particular representation of state. Some rollups separate naming from state computation, where the transaction order is committed to the layer 1 blockchain first, and the correct resultant state is computed off-chain, in the layer 2 rollup, and committed to layer 1 at a later time. Other rollups use a mempool design for the rollup, so that the transaction order is determined by rollup nodes rather than in the underlying blockchain, and that order is committed along with the computed state hash. Such a design reduces the number of transactions in the underlying blockchain, trading off reduced transaction processing cost there for tight coupling between transaction order finality and state determination.</p><p>\\\nThe separation of concerns should be explicit. The consensus layer is responsible for making an immutable, append-only log. Its primary purpose is to record the transaction—the calldata—in the order in which they are to be executed. <em>This names the resultant state, and everything else is secondary</em>. Computing and agreeing on this state can come later, as fulfilling a promised value. The result—a correspondence between a named state and the state representation— can be similarly recorded to make state representation sharing easier. That is to say: Bitcoin logs only execution order; Ethereum logs both execution order and an efficient representation of the resultant state in a tightly coupled manner; decoupled layer 2 rollup designs, on the other hand, logs both but separately, so that problems with the validity of the computed state does not necessarily invalidate the committed transaction order.</p><p>\\\nNote that it is important to calculate state and to reach consensus on it, since blockchains are not closed systems: transfers between rollup and underlying blockchain is an example of external actions that depend on state; in general, any contracts that can cause off-chain effects, such as the shipment of goods, require consensus and state value finality.</p><p>\\\nIn our view, obtaining an equivalent but more efficient representation of a given state is an important optimization. Indeed, committing the transaction execution order yields one sense of finality—transaction order finality, allowing us to name a committed state. Computing the stateRoot and reaching agreement on the result yields a second sense of finality—“state value finality”, allowing us to confidently  the state’s value or representation.</p><p>(1) Bennet Yee, Oasis Labs;</p><p>(2) Dawn Song, Oasis Labs;</p><p>(3) Patrick McCorry, Infura;</p><p>(4) Chris Buckland, Infura.</p><p>[3] Though states are realized periodically, when  are created. See Section 2.7 for more details.</p>","contentLength":6940,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What Happens After You Hit ‘Send’ on Blockchain","url":"https://hackernoon.com/what-happens-after-you-hit-send-on-blockchain?source=rss","date":1744649045,"author":"EScholar: Electronic Academic Papers for Scholars","guid":23091,"unread":true,"content":"<p>(1) Bennet Yee, Oasis Labs;</p><p>(2) Dawn Song, Oasis Labs;</p><p>(3) Patrick McCorry, Infura;</p><p>(4) Chris Buckland, Infura.</p><p>Blockchains combine a distributed append-only log with a virtual machine that defines how log entries are interpreted. By viewing transactions as state transformation functions for the virtual machine, we separate the  of a state from the computation of its value and reaching consensus on that value. This distinction allows us to separate the notion of <em>transaction order finality</em> from . Further consideration of how blockchain governance handles catastrophic common-mode failures such as zero day exploits lead us to the notion of .</p><p>\\\nConsensus on the transaction order determines the ground truth. Everything else—computing the value of a state or handling catastrophic failures such as bugs / zero-day based attacks—are just optimizations.</p><p>The core ideas behind smart contracts and blockchain systems are straightforward, based on a distributed, decentralized append-only log and how we interpret the meaning of those log entries using an abstract virtual machine (VM).</p><p>\\\nWhile the basic idea is simple, there are many design choices that need to be made before the full blockchain system is specified, implemented, and becomes usable, e.g., the format of messages that can be logged and their meaning, the VM state machine semantics, etc. These design choices can have important implications on how the resultant system behaves.</p><p>\\\nWhile practitioners understand the nuances, explicating these notions can make it easier for their impact to be discussed and for alternative design choices to be investigated. This paper attempts to use some basic ideas and notation from programming languages, semantics, and group theory to help model smart contract systems as a way to guide how we look at these design choices, the security issues that arise, and their scaling implications.</p><p>\\\nWe introduce the following distinct flavors of finality:</p><p>\\\n• log finality, when an entry has been irrevocably appended to the blockchain log.</p><p>\\\n• transaction order finality, when a transaction’s effect on the VM state is irrevocably determined, without necessarily first computing it.</p><p>\\\n• state value finality, when the computed state value is determined as an efficiently accessed data structure. This is irrevocable except for recovery from critical infrastructure failures (determined by governance), e.g., an adversary exploits a bug in code used by all participants or an adversary was able to violate a security assumption, such as bribing an above-threshold number of committee participants.</p><p>\\\n• checkpoint finality, when the computed state value can no longer be changed by hard forks and thus becomes truly irrevocable.</p><p>\\\nWe argue that transaction order finality, built using log finality, is the key to reasoning about a blockchain system. State value finality and checkpoint finality are nonetheless important optimizations: they respectively enable application for which independent private state determination is too expensive and permit the storage layer to reclaim storage.</p><p>\\\nIn the next section, we present the ideas, notations, and terminologies that we use to analyze blockchain properties and use them to discuss some well-known blockchain systems and their properties. Then, in Section 3, we discuss what we think are “ideal” rollup properties and attempt to sketch what such a system would be like. Finally, we present concluding remarks in Section 4.</p>","contentLength":3471,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple Preparing Major iPadOS 19 Overhaul with Mac-like Features","url":"https://apple.slashdot.org/story/25/04/14/1557247/apple-preparing-major-ipados-19-overhaul-with-mac-like-features?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744648800,"author":"msmash","guid":22962,"unread":true,"content":"Apple is readying a substantial overhaul for iPadOS 19 that will transform the tablet experience to function more like macOS, according to Bloomberg. The update will focus on productivity features, multitasking capabilities, and app window management - areas where iPad power users have long requested improvements. \n\nThe software revamp comes approximately a year after Apple introduced the M4 chip to the iPad Pro lineup and coincides with the expected arrival of new iPad Pro models featuring M5 processors. According to Bloomberg, many users have expressed frustration that iPad hardware capabilities have consistently outpaced software functionality. \n\nWhile the company won't fully port macOS to iPad as some users have wished, the changes will reportedly be substantial enough to satisfy much of the professional user base that has been pushing for more desktop-like functionality. The upcoming changes are expected to be highlighted at Apple's Worldwide Developers Conference in June.","contentLength":992,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google’s newest AI model is designed to help study dolphin ‘speech’","url":"https://techcrunch.com/2025/04/14/googles-newest-ai-model-is-designed-to-help-study-dolphin-speech/","date":1744648015,"author":"Kyle Wiggers","guid":22926,"unread":true,"content":"<article>Google’s AI research lab, Google DeepMind, says that it has created an AI model that can help decipher dolphin vocalizations, supporting research efforts to better understand how dolphins communicate. The model, called DolphinGemma, was trained using data from the Wild Dolphin Project (WDP), a nonprofit that studies Atlantic spotted dolphins and their behaviors. Built on […]</article>","contentLength":381,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Google Classroom gives teachers an AI feature for quiz questions","url":"https://techcrunch.com/2025/04/14/google-classroom-gives-teachers-an-ai-feature-for-quiz-questions/","date":1744647704,"author":"Lauren Forristal","guid":22925,"unread":true,"content":"<article>Google Classroom introduced a new AI-powered feature designed to help teachers generate questions. Launched on Monday, this tool lets educators create a list of questions based on specific text input. Using this text-dependent question-generation tool, which utilizes Gemini, teachers can either upload files from Google Drive or manually enter text for the AI to generate […]</article>","contentLength":378,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The HackerNoon Newsletter: This Detective Game Helps Beginners Master SQL and Database Logic (4/14/2025)","url":"https://hackernoon.com/4-14-2025-newsletter?source=rss","date":1744646729,"author":"Noonification","guid":23090,"unread":true,"content":"<p>🪐 What’s happening in tech today, April 14, 2025?</p><p>By <a href=\"https://hackernoon.com/u/David\">@David</a> [ 4 Min read ] Avi Schiffmann on HackerNoon: It’s mostly millenials+ that try  fuck their robots. It’s mostly GenZ  younger that are able to view AI as a platonic companion. <a href=\"https://hackernoon.com/the-only-real-moat-that-exists-is-consumer-mindshare-says-friendcom-ceo-avi-schiffmann\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/hackernooncontests\">@hackernooncontests</a> [ 2 Min read ] Use this guide to draft your Web3 Development Writing Contest entry on blockchain nodes, their roles, and tools like GetBlock that simplify node management.  <a href=\"https://hackernoon.com/answer-to-win-your-share-of-$5000-what-is-a-blockchain-node-and-how-does-it-work\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/nailyasaf\">@nailyasaf</a> [ 8 Min read ] Learn how color grading works, what color targets are, and build your own palette-based grading tool in React — from scratch and with purpose. <a href=\"https://hackernoon.com/this-simple-app-lets-you-see-how-hollywood-uses-color-to-mess-with-your-emotions\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/hristow\">@hristow</a> [ 2 Min read ] A new way to learn SQL: solve crimes using real SQL queries. Build database logic fast with interactive storytelling and gamified practice. <a href=\"https://hackernoon.com/this-detective-game-helps-beginners-master-sql-and-database-logic\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/haimeng\">@haimeng</a> [ 6 Min read ] Learn how I built a multi-stage Langchain agent for MySQL. This article details my journey, challenges, and key steps in creating an intelligent database intera <a href=\"https://hackernoon.com/langchain-promised-an-easy-ai-interface-for-mysqlheres-what-it-really-took\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>","contentLength":1262,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Librarians in UK Increasingly Asked To Remove Books","url":"https://news.slashdot.org/story/25/04/14/1538206/librarians-in-uk-increasingly-asked-to-remove-books?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744646400,"author":"msmash","guid":22929,"unread":true,"content":"An anonymous reader shares a report: Requests to remove books from library shelves are on the rise in the UK, as the influence of pressure groups behind book bans in the US crosses the Atlantic, according to those working in the sector. Although \"the situation here is nowhere [near] as bad, censorship does happen and there are some deeply worrying examples of library professionals losing their jobs and being trolled online for standing up for intellectual freedom on behalf of their users,\" said Louis Coiffait-Gunn, CEO of the Chartered Institute of Library and Information Professionals (Cilip). \n\nEd Jewell, president of Libraries Connected, an independent charity that represents public libraries, said: \"Anecdotal evidence from our members suggests that requests to remove books are increasing.\" The School Library Association (SLA) said this year has seen an \"increase in member queries about censorship.\" Most of the UK challenges appear to come from individuals or small groups, unlike in the US, where 72% of demands to censor books last year were brought forward by organised groups, according to the American Library Association earlier this week. \n\nHowever, evidence suggests that the work of US action groups is reaching UK libraries too. Alison Hicks, an associate professor in library and information studies at UCL, interviewed 10 UK-based school librarians who had experienced book challenges. One \"spoke of finding propaganda from one of these groups left on her desk,\" while another \"was directly targeted by one of these groups.\" Respondents \"also spoke of being trolled by US pressure groups on social media, for example when responding to free book giveaways.\"","contentLength":1686,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Amid Trump tariff chaos, Nvidia launches AI chip production on US soil","url":"https://arstechnica.com/ai/2025/04/amid-trump-tariff-chaos-nvidia-launches-ai-chip-production-on-us-soil/","date":1744646147,"author":"Benj Edwards","guid":22931,"unread":true,"content":"<p>Nvidia <a href=\"https://blogs.nvidia.com/blog/nvidia-manufacture-american-made-ai-supercomputers-us/\">announced plans</a> today to manufacture AI chips and build complete supercomputers on US soil for the first time, commissioning over one million square feet of manufacturing space across Arizona and Texas. The politically timed move comes amid rising US-China tensions and the Trump administration's push for domestic manufacturing.</p><p>Nvidia's announcement comes less than two weeks after the Trump administration's <a href=\"https://arstechnica.com/tech-policy/2025/04/trump-boosts-china-tariffs-to-125-pauses-tariff-hikes-on-other-countries/\">chaotic rollout</a> of new tariffs and just two days after the administration's contradictory messages on electronic component exemptions.</p><p>On Friday night, the US Customs and Border Protection <a href=\"https://www.npr.org/2025/04/12/nx-s1-5363025/apple-iphone-tariff-exemption-china\">posted a bulletin</a> exempting electronics including smartphones, computers, and semiconductors from Trump's steep reciprocal tariffs. But by Sunday, Trump and his commerce secretary Howard Lutnick contradicted this move, claiming the exemptions <a href=\"https://abcnews.go.com/US/live-updates/trump-tariffs-live-updates-us-stronger-despite-market/?id=120551033\">were only temporary</a> and that electronics would face new \"semiconductor tariffs\" in the <a href=\"https://www.rollingstone.com/politics/politics-news/trump-admin-new-tariffs-electronics-china-1235316601/\">coming months</a>.</p>","contentLength":949,"flags":null,"enclosureUrl":"https://cdn.arstechnica.net/wp-content/uploads/2025/01/chinese_ai_header-1152x648.jpg","enclosureMime":"","commentsUrl":null},{"title":"Inside the System That Optimizes Cross-Border Digital Currency Trading","url":"https://hackernoon.com/inside-the-system-that-optimizes-cross-border-digital-currency-trading?source=rss","date":1744646042,"author":"EScholar: Electronic Academic Papers for Scholars","guid":22975,"unread":true,"content":"<p>This paper proposes a novel approach for facilitating cross-border CBDCs exchange through a rollup (a form of L2 blockchain) on the public Layer-1 network, further enhanced with a Layer-3 (L3), as illustrated in Fig. 3.</p><p>\\\n The system operates as a L2 blockchain on the public L1 network, benefiting from the inherent security and infrastructure of the L1, including consensus mechanisms and miners/validators. Bitcoin, Ethereum or other L1 networks can be the underlying L1. The system also incorporates Virtual Machines (VMs) to execute smart contracts, with the Ethereum Virtual</p><p>\\\nMachine (EVM) being our chosen VM due to its compatibility with most DeFi protocols.</p><p>\\\n<em>L2 and L3s Responsibilities.</em> L2 is the data integration layer and its operations are managed by central institutions like BIS, focusing on interoperability with other CBDC blockchains and facilitating communication between L2 and L3s. The system supports multiple independent L3 blockchains, each with the authority to determine the deployment of decentralized exchanges (DEX) and Automated Market Makers (AMM). Furthermore, the deployment of other DeFi protocols is feasible within this framework. AMM and exchange logic of L3s is moved to the external entities that compete with each other.</p><p>\\\n<em>Transaction Privacy and Compliance.</em> The L2 and L3 blockchains are private (permissioned networks). All participants must undergo KYC [24] procedures before entering the system. This ensures the system can maintain full transaction privacy, e.g. by leveraging zero-knowledge proofs technology [15], while adhering to regulatory requirements.</p><p>\\\n. We propose utilizing proof of storage protocols to enhance the security, instead of bridges. Unlike bridges that often involve trust assumptions and centralization, the system employs a proof-of-storage approach. CBDC tokens are directly minted on L2, and proof-of-storage protocols rely on corresponding token reserves within country-specific CBDC blockchains.</p><p>\\\n<em>Rule-based router to L3s.</em> At the core of the system is a Rule-based router hosted on L2. This router employs rules to select the optimal AMM-DEX and L3 for traders at any given moment. Trading fees are dependent on gas costs and trade expenses, and the router optimizes these parameters for each trade.</p><p>\\\n<em>Integration with DeFi on Ethereum.</em> To ensure compatibility with regulations, the system integrates with DeFi through the privacy pools on the Ethereum blockchain, proposed by Buterin et al.[11]. Only profiles and users validated through these pools are permitted to trade CBDCs, with no additional restrictions or limitations imposed.</p><p>\\\n<em>Comparison to Mariana Project.</em> A key distinction is its flexibility regarding AMMs, allowing external operators to make decisions about the types of AMMs or central limit order books they wish to operate on L3. Operators of L3s retain control over actions and DeFi protocols within their respective layers. Another advantage of the L2-based system with L3 enhancements is cost optimization and resistance to network congestion. The L2 router automatically directs traders to the L3 AMM-DEX with the lowest trade and gas fees.</p><p>(1) Krzysztof Gogol, University of Zurich (gogol@ifi.uzh.ch);</p><p>(2) Johnnatan Messias, Matter Labs;</p><p>(3) Malte Schlosser, University of Zurich;</p><p>(4) Benjamin Kraner, University of Zurich;</p><p>(5) Claudio Tessone, University of Zurich.</p>","contentLength":3355,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"This Study Breaks Down the True Costs of CBDC Exchange","url":"https://hackernoon.com/this-study-breaks-down-the-true-costs-of-cbdc-exchange?source=rss","date":1744646033,"author":"EScholar: Electronic Academic Papers for Scholars","guid":22974,"unread":true,"content":"<p>There is an abundance of literature discussing the implementation of CBDCs in various countries [23], [13], [12], [21], [5], but little research on the exchange between CBDCs in AMMs, except for Project Mariana [4]. Lipton and Sepp[20] study the implicit costs (price impact) for G-10 CBDCs exchange at AMM with Concentrated Liquidity (Uniswap v3).</p><p>\\\nThis work is the first research that takes the holistic approach to analyze the total costs of CBDCs exchange at various AMMs, including Stableswap Invariant (Curve v2), applied in Project Mariana. This study found that a multi-AMM set-up for CBDCs exchange on L2 is more cost-efficient than a single AMM of Project Mariana, despite the fragmentation of liquidity among various AMMs. Such a multi-AMM system on private L2 is further presented, and its behavior is evaluated via simulation based on the historical FX rates, Mariana Project set up as a benchmark.</p><p>\\\nThis work makes the following contributions.</p><p>\\\n– Demonstrating that multi-AMMs set-up for CBDCs exchange is more costefficient than a single AMM.</p><p>\\\n– Designing such multi-AMMs set-up for CBDCs exchange using L2 and L3 blockchains and demonstrating its superior performance for small, medium, and largest transaction volumes and any transaction in case of spikes of gas fees.</p><p>\\\n– Conducting first detailed analysis of the total costs of CBDCs swaps on AMM-DEX—gas fees, swap fees (explicit fees), and price impact (explicit fees), among various AMMs and L1 and L2-based DEXes.</p><p>\\\n– Providing quantitative metrics to evaluate the efficiency of cross-border CBDCs on DEXes for major AMMs. Their implementation is available in the public GitHub repository [17]</p><p>\\\n– Building a framework for simulation based on historical FX rate that can be replicated in other cross-border CBDCs projects or in permission DeFi in the Ethereum ecosystem. For all metrics, the mathematical background and numerical methods with the implementation are provided, such as the Newthon-Raphon method for price impact in Cryptoswap Invariant AMM applied in Project Mariana.</p><p>(1) Krzysztof Gogol, University of Zurich (gogol@ifi.uzh.ch);</p><p>(2) Johnnatan Messias, Matter Labs;</p><p>(3) Malte Schlosser, University of Zurich;</p><p>(4) Benjamin Kraner, University of Zurich;</p><p>(5) Claudio Tessone, University of Zurich.</p>","contentLength":2286,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"What Layer-2 Rollups Mean for CBDC Trading","url":"https://hackernoon.com/what-layer-2-rollups-mean-for-cbdc-trading?source=rss","date":1744646031,"author":"EScholar: Electronic Academic Papers for Scholars","guid":22973,"unread":true,"content":"<p>This section introduces the concept of L2 blockchain scaling, presents the functionalities of Project Mariana, and summarizes this work’s contributions to the research on cross-border CBDCs exchange.</p><p>There are two approaches to tackle the challenges of blockchain scalability and related high gas prices: Layer-1 (L1) and Layer-2 (L2) blockchains. L1 scaling involves creating entirely new blockchains, e.g., with unique consensus mechanisms or block sizes. These chains operate with their own validators and infrastructure, requiring decentralization to win users’ trust. L2 scaling takes a different approach and uses complex computations off-chain (outside of Ethereum), aiming to reduce on-chain data congestion. These off-chain activities include rollups, sidechains, plasma, and state channels. Layer-2 blockchains rely on the security of underlying Layer-1 chains, such as Ethereum, for final settlement.</p><p>\\\nRollups represent a form of L2 scaling that does not custody any data by themselves. Rollups offload complex calculations from the Ethereum mainnet and store the results (along with other transactions) in Ethereum after compressing them. Fig. 1 illustrates rollup architecture with key components—sequencers and verifiers. Sequencers roll up transactions to the Layer-1 chain. By bundling transactions, rollups manage to save on gas fees. Verifiers are smart contracts that operate on Ethereum and verify the transactions stored by the sequencer. They ensure the correctness of the transactions.</p><p>The specific focus of this work is on facilitating cross-border exchanges of CBDCs. One notable proposal for such a solution is Project Mariana on L1 blockchain</p><p>\\\n\\\n(L1-Mariana) [4], initiated by BIS, the Swiss National Bank, the Bank of France, and the Monetary Authority of Singapore.</p><p>\\\nWithin L1-Mariana, a DEX based on AMM is employed to exchange wholesale CBDCs versions of Swiss Franc (CHF), Euro (EUR), and Singaporean Dollar (SGD). The selected AMM is the Stableswap Invariant, first introduced by Curve v2—the second largest DEX in terms of trading volumes in permissionless DeFi on Ethereum [1]. The setup involves bridges that facilitate the transition of wholesale CBDCs from domestic central bank blockchains to the chain where the Cryptoswap Invariant pool operates, as depicted in Fig. 2.</p><p>\\\nWhereas the project proved the feasibility of AMM-DEX for cross-border CBDCs exchange, several questions arise—e.g., the choice of the blockchain (and its scalability and security), the AMM and the pool types (3-token pools vs 2- token pool)—which this research addresses.</p><p>(1) Krzysztof Gogol, University of Zurich (gogol@ifi.uzh.ch);</p><p>(2) Johnnatan Messias, Matter Labs;</p><p>(3) Malte Schlosser, University of Zurich;</p><p>(4) Benjamin Kraner, University of Zurich;</p><p>(5) Claudio Tessone, University of Zurich.</p>","contentLength":2816,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A New Architecture for Cross-Border CBDC Trading","url":"https://hackernoon.com/a-new-architecture-for-cross-border-cbdc-trading?source=rss","date":1744646022,"author":"EScholar: Electronic Academic Papers for Scholars","guid":22972,"unread":true,"content":"<p>(1) Krzysztof Gogol, University of Zurich (gogol@ifi.uzh.ch);</p><p>(2) Johnnatan Messias, Matter Labs;</p><p>(3) Malte Schlosser, University of Zurich;</p><p>(4) Benjamin Kraner, University of Zurich;</p><p>(5) Claudio Tessone, University of Zurich.</p><p>\\\n. This paper proposes a novel multi-layer blockchain architecture for the cross-border trading of CBDCs. The permissioned layer-2, by relying on the public consensus of the underlying network, ensures the security and integrity of the transactions and interoperability with domestic CBDC implementations. Multiple Layer-3s operate various Automated Market Makers (AMMs) and compete with each other for the lowest costs. Simulations of trading costs are conducted based on historical FX rates to provide insights into the practical implications of the system, with Project Mariana as a benchmark. The study shows that a multi-layer and multi-AMM setup is more cost-efficient even with liquidity fragmentation than a single AMM.</p><p>The Bitcoin network, described in a whitepaper by the anonymous individual or group known as Satoshi Nakamoto, launched in 2008 [22]. The fundamental promise of this first cryptocurrency was to establish a peer-to-peer payment system that operates independently of traditional financial intermediaries. In 2014, Vitalik Buterin introduced Ethereum [10], the next-generation blockchain with a virtual machine capable of executing computer programs known as smart contracts. With Ethereum and the Ethereum Virtual Machine (EVM), Decentralized Finance (DeFi) was born. By utilizing smart contracts, DeFi offers sophisticated financial services, such as trading, lending, borrowing, derivatives and asset management [29], [25], [9], [18].</p><p>\\\nIt quickly became apparent that this new blockchain-based financial system required non-volatile tokens, giving the advent to stablecoins—tokens with values pegged to fiat currencies. The success of stablecoins prompted central banks to explore similar solutions, leading to the development of Central Bank Digital Currencies (CBDCs) [28]. While CBDCs do not necessarily have to be implemented on a blockchain, the decentralized approach promises enhanced scalability and security [4], [23], [13], [12]. Various central banks across the globe are already engaged in CBDC initiatives[4], [23], [5]. The collective effort explores ways to integrate these CBDCs into a unified marketplace, potentially transcending borders, as seen in Project Mariana by the Bank for International Settlements (BIS) [4].</p><p>\\\nThis paper introduces a novel architectural framework for cross-border CBDC trading that is based on Layer-2 (L2) blockchain scaling. L2s proved to be an efficient approach for addressing the limitations of Ethereum, especially scalability and privacy [26], [32], [16]. The proposed system is the rollup (non-custodial L2), on the public L1 blockchain that seamlessly integrates additional Layer-3 (L3) blockchains, each operating decentralized exchanges (DEXes), or other DeFi protocols, utilizing CBDCs. The system automatically selects L3 and DEXes with optimal costs. This system architecture is compared to the approach of Project Mariana in a series of simulations based on the historical Foreign Exchange (FX) rates.</p>","contentLength":3213,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"\"The only real moat that exists is consumer mindshare,\" says Friend.com CEO Avi Schiffmann","url":"https://hackernoon.com/the-only-real-moat-that-exists-is-consumer-mindshare-says-friendcom-ceo-avi-schiffmann?source=rss","date":1744645402,"author":"David Smooke","guid":22971,"unread":true,"content":"<p>\\\n<a href=\"https://www.linkedin.com/in/avi-schiffmann/\">Avi Schiffmann</a>: Friend is the first product that can actually be called an AI companion. They are palm-sized, always listening devices you can talk to anytime and bring anywhere. Friends remember everything you say, and each develops a distinct personality.</p><p>\\\nTo me, they’re the world’s first living electronics, and personally it’s a stickier product to me than my iPhone. We’re currently producing a batch of 5,000 friends, which will start shipping July 30th this year (World Friendship Day).</p><p>\\\n\\\n<em>You notably bought the domain for , and have claimed it’s already paid for itself in backlinks and brand reputation. I agree with you. Historically, it’s probably the single word that built Facebook - so I think it will hold internet value regardless. But as I understand it, the majority of your funding went into purchasing the domain - is that true? Could you share more of the process behind the negotiations for such a valuable piece of digital real estate? And what do you plan to spend money on and not spend money on going forward?</em></p><p>\\\nA company is more than a product, and the only real moat that exists is consumer mindshare. I believe in AI companionship for everyone, and there is no major incumbent that openly shares this POV. I think I am a master of getting attention, which will only get more fun as VCs give me more money, and I think I’ll be able to use that to be the dominant voice in digital relationships.</p><p>\\\nThis will be increasingly valuable in the coming years, as I genuinely believe the AI companionship industry will become the most culturally influential consumer category of the next generation. This is what GenA is growing up into and it will be as influential to them as social media was to me.</p><p>\\\n\\\n<em>Do you see your company as more of a hardware company, software company, or another type of company?</em></p><p>\\\nFriend is a digital relationships company. Whatever that means.</p><p>\\\nI launched a little chatbot experiment last year on <a href=\"https://friend.com\">friend.com</a>, where you could chat with these very realistic feeling chatbots. They could block users, for example. My most interesting insight from that is that it’s really mostly millenials+ that try and fuck their robots. It’s mostly GenZ &amp; younger that are able to view AI as a platonic companion. I think for them it’s extremely intuitive, they are growing up with it.</p><p>\\\n\\\n<em>What popular culture is most impactful on your product decision making?</em></p><p>\\\n“I’ll play first, and tell you about it later. Maybe.” - Miles Davis</p><p>\\\n\\\n<em>Mark Zuckerberg, Adam Mosseri, and Linda Yaccarino are all tech executives who have all started wearing gold chains in their public appearances.&nbsp; Do you think this at all relates to normalizing jewelry as a path for ai hardware adoption? Or do they just like the bling bling now?</em></p><p>\\\nI think they just like the bling bling.</p><p>\\\n\\\n<em>What AI models are you using under the hood with Friend? And what types of AI models do you think will see increased usage?</em></p><p>\\\nI find Claude 3.7 to be the best model for Friend right now. That could change by the time we ship, but Claude certainly has the most stable charisma of any model I’ve tried. \\n </p><p>\\\n<em>What future AI breakthroughs have you excited? And what historical AI breakthroughs do you think have been underappreciated by the media?</em></p><p>\\\nI want to see AI memory solved on a foundational model level, rather than the experimental RAG techniques that we have today.</p><p>\\\n\\\n<em>Bad friends can have a massively negative impact on one’s life. How are you preventing or minimizing the potential bad advice that AI could give Friend.com’s users?</em></p><p>\\\nYou haven’t ever had a friend give you bad advice?</p><p>\\\n\\\n<em>When your COVID tracker took the internet by storm, what were some of the strangest inbound messages you received?</em></p><p>\\\nThat will forever be one of the craziest periods of my life. Strangest? I did have the CIA approach me to join some kinda program related to COVID things. I think the government handled COVID awfully. I started <a href=\"https://ncov2019.live/\">ncov2019</a> in January, months before it was even called COVID, so I really watched the world descend into chaos very quickly. I can’t wait to see a smaller government of hyper competent people leveraging AI to more effectively serve its people.</p><p>\\\n\\\n<em>What are a couple programs, apps, books, or technologies you use and love that the general public may not know about?</em></p><p>\\\nVery random but I always try and recommend <a href=\"https://mobbin.com\">mobbin.com</a>. It’s the best resource on modern design practices out there tbh. Great artists steal, copy it all.</p><p>\\\n\\\n<em>What prompt or direction or style can you give to AI to make it more human or friendly?</em></p><p>\\\nJust make it more opinionated, it makes for more entertaining conversation.</p><p>\\\n\\\n<em>Do you dye your own hair?</em></p><p>\\\nMy <a href=\"https://x.com/AviSchiffmann\">X pfp</a> is me with neon green hair, although it was a bit washed out from the ocean, we were at <a href=\"https://en.wikipedia.org/wiki/Nazar%C3%A9,_Portugal\">Nazare</a> in that photo.</p>","contentLength":4784,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Blue Origin’s all-female crew, including Katy Perry, successfully launched","url":"https://techcrunch.com/2025/04/14/blue-origins-all-female-crew-including-katy-perry-successfully-launched/","date":1744644438,"author":"Lauren Forristal","guid":22924,"unread":true,"content":"<article>Jeff Bezos’ space company, Blue Origin, successfully launched its New Shepard rocket at around 9:30 a.m. ET on Monday, as it seeks to challenge Elon Musk’s SpaceX in the space tourism industry.&nbsp; What stands out most about this mission is that it featured the first all-female space crew since 1963, when Soviet astronaut Valentina Tereshkova […]</article>","contentLength":352,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Blue Origin Sends All-Female Crew To Edge of Space in Historic Flight","url":"https://science.slashdot.org/story/25/04/14/1512214/blue-origin-sends-all-female-crew-to-edge-of-space-in-historic-flight?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744644000,"author":"msmash","guid":22928,"unread":true,"content":"Blue Origin's New Shepard completed its 31st mission Monday morning, carrying the first all-female crew to space since Soviet cosmonaut Valentina Tereshkova's 1963 solo flight. The NS-31 mission lifted off from West Texas at 9:30 a.m. EDT, with hundreds of thousands watching via livestream as the autonomous vehicle crossed the Karman line 62 miles above Earth. \n\nThe 10-minute suborbital journey carried six passengers: journalist and Bezos' fiancee Lauren SÃnchez, former NASA scientist Aisha Bowe, bioastronautics researcher Amanda Nguyen, CBS journalist Gayle King, pop star Katy Perry, and film producer Kerianne Flynn. Bowe conducted three research experiments during the flight, while Nguyen became the first Vietnamese and Southeast Asian woman in space. The fully reusable New Shepard system features a pressurized capsule that separates from its booster before returning to Earth with three parachutes.","contentLength":914,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Chipolo’s newest AirTag competitor works with both Apple and Google’s finding networks","url":"https://techcrunch.com/2025/04/14/chipolos-newest-airtag-competitor-works-with-both-apple-and-googles-finding-networks/","date":1744643313,"author":"Sarah Perez","guid":22923,"unread":true,"content":"<article>Chipolo, the maker of AirTag-like devices, on Monday introduced the latest version of its product. Now, instead of offering models that only work with either Apple or Google’s lost-item finding technology, the new Chipolo POP devices work with both companies’ finding networks out of the box. By combining these different functionalities into one device, Chipolo […]</article>","contentLength":372,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meta to start training its AI models on public content in the EU","url":"https://techcrunch.com/2025/04/14/meta-to-start-training-its-ai-models-on-public-content-in-the-eu/","date":1744643037,"author":"Aisha Malik","guid":22922,"unread":true,"content":"<article>Meta announced on Monday that it’s going to train its AI models on public content, such as posts and comments on Facebook and Instagram, in the EU after previously pausing its plans to do so in response to regulatory pressure due to data privacy concerns. The company will start training its AI on users’ content […]</article>","contentLength":322,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Answer to Win Your Share of $5000: What is a Blockchain Node and How Does it Work?","url":"https://hackernoon.com/answer-to-win-your-share-of-$5000-what-is-a-blockchain-node-and-how-does-it-work?source=rss","date":1744642806,"author":"HackerNoon Writing Contests Announcements","guid":22970,"unread":true,"content":"<blockquote><p>For the chance to win from  in the  welcomes submissions from developers, blockchain advocates, and writers who can explore key aspects of Web3 development—like how blockchain nodes work, the best ways to scale dApps, multi-chain interoperability, and more.</p></blockquote><p>:::info\nBelow is a list of questions to help you get started on your draft. You can answer them&nbsp;</p><p><em>This template is a guide, not a constraint If it doesn’t work for you, choose another from our full list of writing prompts .</em></p><h2>Title Question: What Exactly is a Blockchain Node and How Does it Work?</h2><ul><li>What is a ?</li><li>Why are nodes important for blockchain networks?</li><li>How do nodes help secure and maintain a blockchain?</li></ul><h3>2. Types of Blockchain Nodes</h3><ul><li>What are the different types of nodes?</li><li>How does each type function within the network?</li></ul><h3>3. How Blockchain Nodes Process Transactions</h3><ul><li>How do nodes verify and store transactions?</li><li>How does consensus (PoW, PoS, etc.) affect node operations?</li></ul><h3>4. Managing Blockchain Nodes: Challenges and Solutions</h3><ul><li>What are the challenges of running a node?</li><li>How do node providers like GetBlock make it easier?</li></ul><ul><li>Why are nodes essential to blockchain technology?</li><li>How might node infrastructure evolve in the future?</li></ul><p>:::info\nIf you’d like to participate in the Web3 Development Writing Contest but feel this template isn’t right for you, feel free to explore any of the other contest tags:</p>","contentLength":1346,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"BingX Kicks off Its 7th Anniversary With \"Your Voice, Our Story\" Campaign","url":"https://hackernoon.com/bingx-kicks-off-its-7th-anniversary-with-your-voice-our-story-campaign?source=rss","date":1744641658,"author":"BTCWire","guid":22969,"unread":true,"content":"<p>PANAMA CITY, April 14, 2025 – In celebration of its 7th anniversary, the global leading cryptocurrency exchange BingX unveiled a user story campaign titled \"\", inviting users from around the world to share their unique journeys and unforgettable moments with BingX.</p><p>\\\nThis campaign is rooted in BingX's long-standing user-first vision, running from April 14, 2025, 10:00 (UTC) to April 30, 2025, 10:00 (UTC). To thank the community, BingX is offering a 10,000 USDT Early Bird Prize Pool for the first 1,000 participants.</p><p>\\\nExceptional storytellers will have the opportunity to win limited-edition Anniversary Gift Boxes, an iPhone 16 Pro Max, an iPad Pro, and an Apple Watch.</p><p>\\\nSince its establishment in 2018, BingX has grown into one of the top crypto trading platforms globally, thanks to the trust and support of its vibrant community. As part of this year's milestone, BingX is turning the spotlight on the people behind the platform — its users.</p><p>\\\nThe campaign invites its users and community members to submit personal stories, whether it's about their first crypto trade, a life-changing moment, or how BingX has played a role in their crypto journey.</p><p>\\\nSelected stories will be featured across BingX's global social media channels, blog, and video campaign, with exclusive rewards for participants.</p><p>\\\nOutstanding storytellers will not only see their entries turned into a special anniversary video—highlighting the global spirit and diverse backgrounds of BingX users—but will also have an opportunity to participate in a live AMA (Ask Me Anything) session with , Chief Product Officer of BingX.</p><p>\\\nThis interactive session offers storytellers a unique chance to engage directly, share their experiences, and exchange ideas that could shape the future of the platform.</p><blockquote><p>Vivien shared her heartfelt thoughts: \"Every trade tells a story, but behind every trade is a person — full of hope, ambition, and resilience. As we mark our 7th anniversary, it is not just a time to look back at our achievements, but to spotlight the very people who made it possible. This campaign is a chance to celebrate our users — not just as traders, but as visionaries, builders, and dreamers. Through these stories, we gain insights into how BingX has impacted lives globally, and in turn, how our users have shaped us. I am especially excited to meet you during the AMA and hear how we can continue building a platform that evolves with you.\"</p></blockquote><p>This campaign is just the first of many surprises planned for BingX's 7th anniversary. It kicks off a series of initiatives designed to bring users closer to the heart of BingX's journey. By putting the spotlight on real voices, BingX is reaffirming its commitment to transparency, inclusion, and user empowerment. As the celebrations unfold, the community can look forward to more meaningful engagements, rewards, and innovations that reflect the platform's dedication to its users — not just for the past seven years, but for many more to come.</p><p>Founded in 2018, BingX is a leading crypto exchange, serving over 20 million users worldwide. BingX offers diversified products and services, including spot, derivatives, copy trading, and asset management – all designed for the evolving needs of users, from beginners to professionals.</p><p>\\\nBingX is committed to providing a trustworthy platform that empowers users with innovative tools and features to elevate their trading proficiency. In 2024, BingX proudly became the official crypto exchange partner of Chelsea Football Club, marking an exciting debut in the world of sports.</p><p>\\\nFor media inquiries, please contact: </p><p>:::tip\nThis story was distributed as a release by Btcwire under HackerNoon’s Business Blogging Program. Learn more about the program&nbsp;</p>","contentLength":3736,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Facebook Sought To 'Neutralize' Competitive Threats, FTC Argues As Landmark Antitrust Trial Begins","url":"https://tech.slashdot.org/story/25/04/14/1439241/facebook-sought-to-neutralize-competitive-threats-ftc-argues-as-landmark-antitrust-trial-begins?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744641600,"author":"msmash","guid":22927,"unread":true,"content":"An anonymous reader shares a report: An attorney for the Federal Trade Commission told a judge that Facebook, fearing the competitive threat of Instagram posted to their social media network, acquired both as a way to \"neutralize\" the rival. \"They decided that competition was too hard,\" the FTC's attorney, Daniel Matheson, said in his opening statement in the government's antitrust case against the Meta Platforms social media empire. \n\nHe argued that with Meta's monopoly in social media, \"consumers do not have reasonable alternatives they can turn to,\" even as satisfaction has declined. At stake is the potential breakup of Facebook-parent Meta, as the government has zeroed in on the 2012 acquisition of Instagram and 2014 purchase of WhatsApp.","contentLength":752,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Hugging Face buys a humanoid robotics startup","url":"https://techcrunch.com/2025/04/14/hugging-face-buys-a-humanoid-robotics-startup/","date":1744641442,"author":"Kyle Wiggers","guid":22921,"unread":true,"content":"<article>AI dev platform Hugging Face has acquired Pollen Robotics, a robotics startup based in France, for an undisclosed amount. Wired reports that Hugging Face plans to sell Pollen’s humanoid robot, Reachy 2, and let developers download and suggest improvements to its code. Pollen Robotics, which aims to bring affordable humanoid robots to the home, was […]</article>","contentLength":357,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Meet Aptible: HackerNoon Company of the Week","url":"https://hackernoon.com/meet-aptible-hackernoon-company-of-the-week?source=rss","date":1744641004,"author":"Company of the Week","guid":22968,"unread":true,"content":"<p>We are back with another&nbsp;&nbsp;feature! Every week, we share an awesome tech brand from our&nbsp;, making their evergreen mark on the internet. This unique HackerNoon database ranks S&amp;P 500 companies and top startups of the year alike.</p><p>\\\nThis week, we are proud to present , a Platform as a Service (PaaS) that gives startups everything they need to launch and scale apps and databases that are secure, reliable, and compliant.</p><p>\\\nNot only does Aptible support a wide range of languages and frameworks, it also integrates with the tools engineers already love and use. The best part? No manual configuration required!</p><p>\\\nWhat sets Aptible apart from other PaaS solutions is its commitment to scalability, reliability, and security &amp; compliance.</p><h2>Aptible🤝 HackerNoon Writing Contests</h2><p>Aptible was the proud sponsor of the , which ran for a six-month period and had a whopping . The company partnered with HackerNoon to offer technologists with a wide variety of backgrounds, including DevOps managers, developers, or anyone in the QA team or operations team, to showcase their expertise in DevOps for a chance to win big bucks :moneyface:</p><p>\\\nParticipants could write on IaaS, PaaS, PaaS vs. IaaS, Automated Deployment, Containerization and Orchestration, Microservices Architecture, GitOps, DevOps Culture, and more, and got to try out Aptible's hosting platform for free to share their learnings and feedback.</p><p>\\\n\"Aptible's mission is to enable developers to do more with less infrastructure. We also know that when it comes to infrastructure, there are a myriad of opinions, and strong opinions at that. And that’s why we’re excited to partner with HackerNoon, to get more content written, opinions out in the open, and spur active discussion and knowledge sharing of how infrastructure is being built and utilized,\" — Tin Nguyen, Head of Marketing at Aptible, <a href=\"https://www.einpresswire.com/article/649107853/hackernoon-announces-four-new-technology-writing-contests-with-28k-in-prizes-up-for-grabs/\">said</a> at the time.</p><p>\\\nAll in all, the writing contest generated over 260 stories and brought massive brand recall from Aptible’s intended audience with nearly 800k views and generating over 19 days in reading time.</p><p><a href=\"https://hackernoon.com/company/aptible\">Aptible</a> actually has quite an interesting history.</p><p>\\\nAt the time of its founding, the Health Insurance Portability and Accountability Act, or HIPAA, was taking shape with companies scrambling to figure out how to comply with the law. Recognizing this imminent need, Aptible embarked on a mission to simplify HIPAA for developers in healthcare, from solo developers at startups to large-scale development teams who lacked the time/resources to delve into the compliance space.</p><p>\\\nThanks to Aptible, developers had a platform that made HIPAA compliance achievable from day 1.</p><p>\\\nThe rest, as they say, is history.</p><p>\\\nToday, Aptible has expanded its scope to support HITRUST, SOC 2, ISO 27001, and more — establishing themselves as the go-to PaaS not just for digital health companies, but for all dev teams, regardless of industry.</p><p>\\\nHow’s that for awesome? :smirk:</p><p>\\\n\\\nThat's all this week, folks! Stay Creative, Stay Iconic.</p>","contentLength":2983,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Nvidia To Make AI Supercomputers in US for First Time","url":"https://news.slashdot.org/story/25/04/14/1352243/nvidia-to-make-ai-supercomputers-in-us-for-first-time?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744638720,"author":"msmash","guid":22902,"unread":true,"content":"Nvidia has announced plans to manufacture AI supercomputers entirely within the United States, commissioning over 1 million square feet of manufacturing space across Arizona and Texas. Production of Blackwell chips has begun at TSMC's Phoenix facilities, while supercomputer assembly will occur at new Foxconn and Wistron plants in Houston and Dallas respectively. \n\n\"The engines of the world's AI infrastructure are being built in the United States for the first time,\" said Jensen Huang, Nvidia's founder and CEO. \"Adding American manufacturing helps us better meet the incredible and growing demand for AI chips and supercomputers, strengthens our supply chain and boosts our resiliency.\" \n\nThe company will deploy its own AI, robotics, and digital twin technologies in these facilities, using Nvidia Omniverse to create digital twins of factories and Isaac GR00T to build manufacturing automation robots. Nvidia projects an ambitious $500 billion in domestic AI infrastructure production over the next four years, with manufacturing expected to create hundreds of thousands of jobs.","contentLength":1086,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Autonomous trucking startup Kodiak Robotics to go public via SPAC","url":"https://techcrunch.com/2025/04/14/autonomous-trucking-startup-kodiak-robotics-to-go-public-via-spac/","date":1744638340,"author":"Rebecca Bellan","guid":22903,"unread":true,"content":"<article>Self-driving truck startup Kodiak Robotics plans to go public via a merger with special purpose acquisition company Ares Acquisition Corporation II. The transaction values Kodiak, which has raised around $243 million to date, at about $2.5 billion pre-money. New and existing Kodiak institutional investors, like Soros Fund Management, ARK Investments, and Ares, have funded or […]</article>","contentLength":383,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Silicon Valley crosswalk buttons hacked to imitate Musk, Zuckerberg’s voices","url":"https://techcrunch.com/2025/04/14/silicon-valley-crosswalk-buttons-hacked-to-imitate-musk-zuckerberg-voices/","date":1744637740,"author":"Zack Whittaker","guid":22869,"unread":true,"content":"<article>The crosswalk buttons, which include audio alerts, were hacked over the weekend.</article>","contentLength":80,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Nvidia says it plans to manufacture some AI chips in the US","url":"https://techcrunch.com/2025/04/14/nvidia-says-it-plans-to-manufacture-some-ai-chips-in-the-u-s/","date":1744635981,"author":"Kyle Wiggers","guid":22868,"unread":true,"content":"<article>Nvidia said on Monday that it has commissioned more than a million square feet of manufacturing space to build and test AI chips in Arizona and Texas as part of an effort to move a portion of its production to the U.S. The chipmaker said the production of its Blackwell chips has started at TSMC’s […]</article>","contentLength":305,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"This Simple App Lets You See How Hollywood Uses Color to Mess With Your Emotions","url":"https://hackernoon.com/this-simple-app-lets-you-see-how-hollywood-uses-color-to-mess-with-your-emotions?source=rss","date":1744635603,"author":"Nailya Safarova","guid":22967,"unread":true,"content":"<blockquote><p><strong>Why does  feel so unsettlingly green and yellow?</strong></p><p><strong>Why is  soaked in teal and orange?</strong></p><p><strong>Why does film make skin look soft and warm?</strong></p></blockquote><p>\\\n==It’s not magic. It’s color.==</p><p>\\\nAnd whoever controls color — controls the emotional weight of the frame. Color grading is cinema’s visual language — a way to shape atmosphere, guide the viewer’s attention, and set the tone of a story. It can be subtle and almost invisible. Or bold and stylized, like in the work of Wong Kar-Wai, Fincher, Nolan, or Villeneuve. But to speak this language fluently, you first need to understand its grammar.</p><p>\\\nWhere does color work actually begin? How do we know what the “right” color even is? And how do you translate creative intent into technical action?</p><p>\\\nSpoiler: it doesn’t start with LUTs or filters. ==It starts with color targets, calibration, and carefully chosen palettes==.</p><p>\\\nIn this series, we’ll explore:</p><ul><li>what color grading is on the most fundamental level;</li><li>why limiting your palette is a feature, not a bug;</li><li>how color charts work (and why they matter);</li><li>and how to build your own grading tool in the browser — with React and some simple math. \\n </li></ul><p>==We won’t just explain it. We’ll show it.== And you’ll be able to experiment, tinker, and maybe for the first time actually  what color grading is made of.</p><h2><strong>What is Color Grading, and Why Start with Color Targets?</strong></h2><p>Color grading is the process of adjusting and stylizing an image to achieve a specific visual tone, emotional effect, or technical standard. Whether in film, photography, or digital production, grading usually includes:</p><ul><li>balancing exposure and white point;</li><li>correcting technical color shifts;</li><li>crafting a visual style with contrast, tones, and color curves.</li></ul><p>\\\nBut grading isn’t just about “making it pretty.” It’s about control — of the mood, of the viewer’s focus, of the visual language of the entire narrative.</p><p>\\\nBefore you apply any creative look, you need to bring the image to a , which means:</p><ul><li><p>correcting unwanted color casts (color correction);</p></li><li><p>normalizing the footage to a standard color space (like Rec.709 or sRGB);</p></li><li><p>matching material from different cameras into a consistent baseline.</p></li></ul><p>A color target is a chart of color patches with ==precisely measured values==. These values aren’t arbitrary — they’re obtained through spectrophotometric measurements in controlled environments using professional equipment like X-Rite or </p><p>\\\nOne of the first widely adopted targets was the  — a strip of neutral gray tones used for exposure control. Later came more advanced charts with full-color patches — like the , introduced in 1976 (now known as the ). It features 24 color swatches designed to represent common real-world colors: human skin, blue sky, green foliage, and more.</p><p>\\\nWith the rise of digital photography and digital cinema, color targets became even more critical. They are now essential tools for calibrating not just cameras, but also monitors, printers, scanners — and any device that handles color. They’re used in color matching, profiling, and neutral balancing workflows — from film production to scientific imaging.</p><p>\\\nTake X-Rite’s ColorChecker, for example. Each patch is measured under standardized lighting (usually  or ), with results recorded in  — a device-independent color model. Those coordinates are then converted into , depending on your working color space (like , , or ).</p><p>\\\nSo the RGB arrays we use in our app aren’t guesswork — they’re precise digital representations of standardized, physically measured patches.</p><p>\\\nIf the skin tone patch in the ColorChecker Classic is defined as [194, 150, 130] in RGB, that’s how it should look under correct conditions. If your footage shows something different, that’s a sign of a color cast — and a starting point for correction.</p><h3><strong>The Catch: Color Charts Are Just the Beginning</strong></h3><p>Color targets are essential for calibration — but that’s all they are. ==A beginning.== They don’t account for:</p><ul><li>how colors behave in highlights or shadows;</li><li>the unique characteristics of film stock or lenses;</li><li>or the creative intent behind a particular look.</li></ul><p>\\\nIn professional tools like  or , color charts are just step one in a long pipeline. From there, you move into advanced processes like film emulation, tone mapping, grain, halation, bloom, and other stylistic transformations. So it’s critical to understand: <strong>a chart is a calibration tool — not a style.</strong></p><p>To show how choosing a palette affects an image, we built  — a simple web app that visualizes what happens when you restrict your color space (a process known as ).</p><p>\\\n<strong>What You Can Do with CinePalette:</strong></p><ul><li>pick a palette (ColorChecker, Portra, Sepia, etc.);</li><li>remap every pixel to the closest color in that palette;</li><li>compare before &amp; after with an interactive slider;</li><li>or build your own palette from scratch.</li></ul><p>Our app runs entirely in the browser using  and the . The project — called  — will be open-sourced and available on GitHub (link at the end of the series).</p><p>\\\nWe start with a set of predefined palettes, but users can also build and save their own. Palettes are defined as arrays of RGB values — for example, here’s what the  palette looks like:</p><pre><code>\"Portra 400\": [\n  [75, 60, 50],     // shadows\n  [160, 130, 110],  // skin tones\n  [220, 200, 180],  // highlights\n  [60, 100, 80],    // foliage\n  [180, 150, 100]   // neutral\n],\n</code></pre><p>\\\nThe selected palette defines which colors are “allowed” to appear in the final image. These become the visual language of the frame — the base tones that set its mood and style.</p><p>\\\nWhen a user uploads an image and chooses a palette, here’s what happens under the hood:</p><ol><li><strong>The image is rendered to a hidden </strong> — this gives us pixel-level access to manipulate the data.</li><li><strong>We extract the ImageData object</strong>, which contains an array where each pixel is represented by four values: [R, G, B, A].</li><li><strong>We loop through every pixel</strong>, extract its RGB color.</li><li><strong>For each pixel, we find the closest matching color from the selected palette</strong>, using Euclidean distance in RGB space — and replace it.</li></ol><p>\\\nLet’s load up a Shirley card and try applying different palettes — you’ll see immediately how the palette choice shapes the image.</p><p>\\\nThe core of the magic lies in a function that analyzes  and finds the  from the selected palette:</p><pre><code>const findClosestColor = (r, g, b) =&gt; {\n  let minDist = Infinity;\n  let closest = [r, g, b];\n  for (let [pr, pg, pb] of palette) {\n    const dist = Math.sqrt((r - pr) ** 2 + (g - pg) ** 2 + (b - pb) ** 2);\n    if (dist &lt; minDist) {\n      minDist = dist;\n      closest = [pr, pg, pb];\n    }\n  }\n  return closest;\n};\n</code></pre><p>\\\nThen, we replace the pixel’s original color in the ImageData with the closest match from the palette. And we repeat this —  in the image.</p><pre><code>for (let i = 0; i &lt; data.length; i += 4) {\n  const [r, g, b] = [data[i], data[i + 1], data[i + 2]];\n  const [nr, ng, nb] = findClosestColor(r, g, b);\n  data[i] = nr;\n  data[i + 1] = ng;\n  data[i + 2] = nb;\n}\n</code></pre><p>\\\nOnce all pixels have been processed, we render the result back onto the </p><pre><code>ctx.putImageData(imageData, 0, 0);\nsetFilteredImage(canvas.toDataURL());\n</code></pre><p>\\\nHere, we use <strong>Euclidean distance in RGB space</strong> — a classic method to measure how “close” two colors are:</p><pre><code>const dist = Math.sqrt((r - pr) ** 2 + (g - pg) ** 2 + (b - pb) ** 2);\n</code></pre><p>\\\nHere, (r, g, b) is the color of the current pixel, and (pr, pg, pb) is one of the colors in the palette. Out of all the distances calculated, we choose the smallest one — the  within the selected palette.</p><p>\\\nThis approach is intuitive and easy to implement, but it has limitations: ==RGB space doesn’t account for how humans actually perceive color== — for instance, we’re more sensitive to green than to blue, and brightness differences can be misleading.</p><p>We use this approach in  as a simple and accessible way to demonstrate the basic principle of color mapping. However, even in its current form, you might notice that some colors get replaced in ways that feel unexpected or “off.”</p><p>\\\nIn future versions, we plan to add a toggle between  color spaces — allowing users to compare how different models affect the accuracy of color matching.</p><p>CinePalette showcases a basic but fundamental step in color grading: . This is where every visual style begins — with the question: <strong>“What if we only used these colors?”.</strong></p><p>\\\nA Portra palette brings warm, nostalgic tones. Pro 400 feels cool and subdued. Teal &amp; Orange delivers high-contrast cinematic punch. Unlike tools like Dehancer or Resolve, CinePalette doesn’t simulate the physics of film. But it captures the essence: ==color is a tool for style and storytelling.==</p><p>This is just the beginning. In the next parts of the series:</p><ul><li>we’ll expand  with the ability to pick a palette from a reference image;</li><li>add automatic extraction of color schemes from any frame or photo;</li><li>introduce a toggle between  for more perceptually accurate matching;</li><li>and break down how  works — and how you can use it in real-world grading.</li></ul><p>\\\n==Stay tuned — and get ready to not just learn color, but truly  it.==</p>","contentLength":8978,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Conifer locks down $20M seed round for its ‘drop-in’ electric hub motor","url":"https://techcrunch.com/2025/04/14/conifer-locks-down-20m-seed-round-for-its-drop-in-electric-hub-motor/","date":1744635600,"author":"Sean O'Kane","guid":22867,"unread":true,"content":"<article>A handful of engineers who worked at Lucid Motors and on Apple’s electric car project have launched a new startup that puts a fresh spin on electric hub motors. The new startup, called Conifer, has developed its motor to be free of rare earth elements by using more abundant ferrite magnets, which the company says […]</article>","contentLength":322,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intel to sell controlling stake in Altera chip business to Silver Lake","url":"https://techcrunch.com/2025/04/14/intel-agrees-to-sell-controlling-stake-in-altera-chip-business/","date":1744634366,"author":"Kyle Wiggers","guid":22848,"unread":true,"content":"<article>Intel on Monday said it has agreed to sell 51% of its Altera semiconductor business to Silver Lake, a private equity firm. The deal, which values Altera at $8.75 billion, will make the division “operationally independent,” Intel said in a press release. The chipmaker will retain a 49% stake in Altera, which will be led […]</article>","contentLength":330,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"This Detective Game Helps Beginners Master SQL and Database Logic","url":"https://hackernoon.com/this-detective-game-helps-beginners-master-sql-and-database-logic?source=rss","date":1744632031,"author":"Hristo Bogoev","guid":22966,"unread":true,"content":"<p>Like many developers, I've always found traditional SQL tutorials to be tedious. Abstract examples, and little motivation made it hard to stay engaged. As someone who appreciates storytelling, I wondered if there was a better way. Could gamification make learning SQL genuinely enjoyable?</p><p>\\\nThis thought inspired my recent project: , a web-based detective game where solving crimes means mastering SQL queries.</p><h2>From Frustration to Innovation</h2><p>I realized that the biggest obstacle in learning SQL wasn't complexity.. it was boredom. People learn best when they're curious, motivated, and having fun. Games naturally provide all three!</p><p>\\\nWith , players assume the role of a detective solving crimes. Each crime comes with its own database full of tables, suspects, evidence, and clues. To progress, players have to write real SQL queries, uncovering vital pieces of the puzzle.</p><p>\\\nTurning SQL into a detective mystery taught me several things:</p><h3>1. Storytelling Enhances Learning</h3><p>When there's a compelling narrative, users don't even realize they're learning. Players eagerly write queries to see \"what happens next\" in the story. This motivation keeps them going, query after query.</p><p>SQL Noir provides instant results. Each correct query reveals a hidden clue. This approach encourages experimentation and creativity in the player.</p><h3>3. Practical Experience Speeds Up Learning</h3><p>Abstract concepts become concrete when players use SQL to track down a suspect or validate an alibi. Players don't just memorize syntax.. they understand the logic behind it, applying knowledge immediately.</p><h2>Launch Results and User Feedback</h2><p>When I initially launched SQL Noir on <a href=\"https://www.reddit.com/r/SQL/comments/1ioutr3/sql_noir_learn_sql_by_solving_crimes/\">Reddit</a> and <a href=\"https://news.ycombinator.com/item?id=43041827\">Hacker News</a>, I wasn't prepared for the incredible response. Over 30,000 people visited the first day!</p><p>\\\nUser feedback has validated my initial hypothesis:</p><ul><li>Beginners enjoy learning SQL through interactive, goal-oriented scenarios.</li><li>Experienced users appreciate the refreshing way to practice SQL skills.</li><li>Many have shared how it helped them gain confidence in writing SQL queries.</li></ul><p>SQL Noir remains free and open source. If you love storytelling and want to help others learn SQL, contributions are always welcome.</p><p>\\\nI'm eager to hear your feedback, ideas for new cases, or your experiences learning SQL through gamification.</p><p>\\\nThanks for reading, and happy querying!</p>","contentLength":2302,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Can AI Help Manage Nuclear Reactors?","url":"https://hardware.slashdot.org/story/25/04/14/0154240/can-ai-help-manage-nuclear-reactors?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744630440,"author":"EditorDavid","guid":22847,"unread":true,"content":"America's Department of Energy launched a federally funded R&amp;D center in 1946 called the Argonne National Laboratory, and its research became the basis for all of the world's commercial nuclear reactors. \n\nBut it's now developed an AI-based tool that can \"help operators run nuclear plants,\" reports the Wall Street Journal, citing comments from a senior nuclear engineer in the lab's nuclear science and engineering division:\nArgonne's plan is to offer the Parameter-Free Reasoning Operator for Automated Identification and Diagnosis, or PRO-AID, to new, tech-forward nuclear builds, but it's also eyeing the so-called dinosaurs, some of which are being resurrected by companies like Amazon and Microsoft to help power their AI data centers. The global push for AI is poised to fuel a sharp rise in electricity demand, with consumption from data centers expected to more than double by the end of the decade, the International Energy Agency said Thursday. The owners of roughly a third of U.S. nuclear plants are in talks with tech companies to provide electricity for those data centers, the Wall Street Journal has reported. \n\nPRO-AID performs real-time monitoring and diagnostics using generative AI combined with large language models that notify and explain to staff when something seems amiss at a plant. It also uses a form of automated reasoning — which uses mathematical logic to encode knowledge in AI systems — to mimic the way a human operator asks questions and comes to understand how the plant is operating [according to Richard Vilim, a senior nuclear engineer within the lab's nuclear science and engineering division]. \nThe tool can also help improve the efficiency of the personnel needed to operate a nuclear plant, Vilim said. That's especially important as older employees leave the workforce. \"If we can hand off some of these lower-level capabilities to a machine, when someone retires, you don't need to replace him or her,\" he said... Part of the efficiency in updating technology will come from consolidating the monitoring staff at a utility's nuclear plants at a single, centralized location — much as gas-powered plants already do. \n\n\nIt hasn't found its way into a commercial nuclear plant yet, the article acknowledges. But the senior nuclear engineer points out that America's newer gas-powered plants ended up being more automated with digital monitoring tools. Meanwhile the average age of America's 94 operating nuclear reactors is 42 years old, and \"nearly all\" of them have had their licenses extended, according to the article. (Those nuclear plants still provide almost 20% of America's electricity.)","contentLength":2647,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How Blockchain Nodes Keep Your Money and Data Safe","url":"https://hackernoon.com/how-blockchain-nodes-keep-your-money-and-data-safe?source=rss","date":1744624830,"author":"Christopher Iroaganachi","guid":22965,"unread":true,"content":"<p>:::info\n<em>Parts of this article are purely fictional. ZBlockBuilders Inc., its CEO, and all accompanying scenarios are made up to help explain complex blockchain concepts in a fun, relatable way. Any resemblance to real companies or people is purely coincidental.</em></p><blockquote><p><em>Don’t lose the farm. Every CEO and their team needs to understand how blockchain nodes work to keep their revenues and respect secure.</em></p></blockquote><p>Congratulations, Reader. You have just been invited to join the team, as Chief Executive Officer, at ZBlockBuilders Inc., a Web3 technology company looking to extend financial coverage for 1.5 billion financially underserved people across the globe. There are several targets on your mind and, of course, a few concerns about how you’ll accomplish your company’s immediate objective of bringing these into the fold. In other words, you want to democratize the financial system by first educating your potential market.  You’ve been offered a fat paycheck and a tall order so you’ve hired me as your adviser to help with this task.</p><p>Our first marketing campaign is to introduce the idea of nodes to our target market. I’ve come up with an interesting idea: let’s show them how dangerous the current fintech system could get. Bands of bad actors roam the internet, empowered by sophisticated hacking software, snooping on customers, hijacking entire banking apps, and carting off troves of customer data. We develop an ad that shows how we can prevent this cataclysmic conclusion by sharing that our technology depends on independent decentralized computers (known as nodes), all functioning as “checkers-and-balancers” on each other. No transaction is added to the blockchain unless and until all nodes approve that it is valid: <strong><em>a parliament of protocols</em></strong> if you like. So, if they’re out on a beach in Mexico chilling, half-drunk, with a Piña Colada in hand, they can be sure that no unauthorized transactions are added to the blockchain (or approved) until they give the word. This strikes you as really important because you recall that when you were CFO at LibertyWonk Inc., a Web-2 based fintech, some sleazy fellow with passable tech credentials capered away with $ 30 million through a Business Email Compromise scheme, ruining lives and LibertyWonk Inc. itself. You laugh, telling me about a certain ==<a href=\"https://www.bbc.com/news/world-africa-58553109\">Hushpuppi</a>,== who commandeered atleast $24 million from his mastery of BEC and other cybercrimes.</p><p>Now, you’re ensconced in your aubergine-colored leather armchair grinning at me. You’re starting to like this. “Tell me more,” you say. I go on sharing that we’ll introduce a series of social media posts reiterating that each of our nodes stores a copy of the entire node system, allowing anybody to verify the provenance of every transaction. In other words, there’s no hiding behind forged records. I flash a web page from my mobile device in front of you, taking you back on memory lane to remind you of the lessons learned from the investigations of the ==<a href=\"https://www.theguardian.com/business/2012/may/17/files-close-bcci-banking-scandal\">Bank of Credit and Commerce International (BCCI)</a>.== Investigations which commenced in 1992 and concluded in 2012, cost $656 million paid to firms of lawyers and accountants and resulted in innumerable heartbreaks in victims of the humongous heist.</p><p>Nodes (computers, remember?) are linguistic linkers. In other words, they like to communicate with each other just as humans do. Beneath the humming sounds of their hardware, they are asking each other questions about the state of the blockchain just the same way you, as the CEO, would ring the CFO to make yet another inquiry about the financial health of ZBlockBuilders Inc., on a Friday afternoon as you’re getting set to proceed on vacation. While nodes may not go on holiday, they’re still super concerned about how well records are being kept, and believe me, they’ll ask. Something like “hey, are there any new transactions and blocks on our chain, and what are their details?” They constantly check on each other to see how things are going and this involves a process called the consensus mechanism. This simply means that they use a special mode of confirmation to check the state of the blockchain. I’ll share two types of consensus mechanisms.</p><h2>How do Consensus Mechanisms Function?</h2><p>This is native to the Bitcoin core and what it does is require a block miner to solve some truly complex piece of math to create a new block. Once the enterprising mathematician unlocks a new block, it immediately is broadcast to the entire blockchain (just like when Rafiki proudly held the newborn lion cub for all the jungle to see in The Lion King). It more or less says “A new block is born” but without the drama of lions and other animals involved.</p><p>Now, this is native to Ethereum and is somewhat different from how things play out in the Bitcoin core. With the proof of stake mechanism, you’re a validator and not a miner (note the distinction). So you’re not actively mining as such. Instead, you’re expected to stake 32 ETH (thirty-two Ethereum) and have a validator software ready and running in the hopes that you’re selected to propose new blocks to be added to the blockchain. If you act right, you’ll get some rewards for it. If you’re considered irresponsible (acting badly or staying offline for too long: slashing) you’re punished by having to lose some of your ETH (Ethereum).</p><h3>Decentralized and Defended</h3><p>The overwhelming beauty of nodes in the blockchain is that each node is a separate entity of its own, acting independently by itself but unanimously with its peers.  Nodes cannot be compelled to approve transactions or fooled by the witty disguises of questing cybercriminals with suggestive emails, until certain rules are collectively adhered to. There is no central system, as we have in current fintech configurations, that can be manipulated or harassed to relinquish value. Nodes function in a trustless environment. That does not mean that they abhor trust, rather they do not rely on trust or goodwill to function. They are ruthless and reliable executors.</p><p>Essentially, nodes are the librarians, accountants and security guards of the blockchain. They communicate with each other to keep records of the particulars of the blockchain, ensuring that all transactions are properly accounted for and blocking (no pun intended) any unauthorized interactions.</p><p>I see that we’re getting somewhere with my marketing campaign proposals because you’re handing me a glass of orange juice. I’m getting quite hungry too. So, if you like, I’ll come back to offer some more advice after the break.</p>","contentLength":6574,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"LangChain Promised an Easy AI Interface for MySQL—Here’s What It Really Took","url":"https://hackernoon.com/langchain-promised-an-easy-ai-interface-for-mysqlheres-what-it-really-took?source=rss","date":1744619843,"author":"Haimeng Zhou","guid":22821,"unread":true,"content":"<p>LangChain has rapidly become a go-to framework for building powerful applications leveraging Large Language Models (LLMs). While LLMs excel at understanding human language, accessing the vast amounts of structured data locked away in SQL databases typically requires specialized query knowledge. This raises a key question: how can we empower more users to interact with databases, such as MySQL, using simple, natural language?</p><p>\\\nThis article chronicles my practical journey using LangChain to build exactly that — a natural language interface capable of querying a MySQL database. I’ll share the steps involved in setting up the system using Docker, the inevitable hurdles encountered (including managing LLM token limits, ensuring sensitive data privacy, and handling ambiguous prompts), and the multi-step, multi-LLM solutions I developed. Follow along to explore the challenges and successes of bringing conversational AI to relational databases.</p><p>\\\nThe entirety of the Python code implementing the natural language querying tool discussed here was generated with the assistance of AI models, primarily ChatGPT and Gemini. My role involved defining the requirements, structuring the prompts, reviewing and evaluating the generated code for functionality and potential issues, guiding the AI through necessary revisions, integrating the various components, and performing the crucial testing and debugging phases.</p><p>\\\n<strong>Step 1: Establishing the Foundation with Docker</strong></p><ul><li><p>&nbsp;Create a stable, isolated multi-container environment.</p></li><li><p>&nbsp;My first practical step was to create a reliable and reproducible environment using Docker. The architecture involved&nbsp;<strong>three distinct containers</strong>: one running the&nbsp;<strong>Frontend application (React/Node.js)</strong>, one for the&nbsp;<strong>Backend service (Python with LangChain)</strong>, and another dedicated to the&nbsp;. This containerized approach became necessary after encountering frustrating difficulties installing the required Python libraries locally due to dependency conflicts and platform incompatibilities.</p></li><li><p>&nbsp;Using Docker provided a clean slate. Leveraging AI assistance helped accelerate the creation of the&nbsp;s and&nbsp;&nbsp;needed to define these three services and their dependencies (like Python, LangChain, Node.js, MySQL connector). Critical configuration included setting up Docker networking for necessary inter-container communication (e.g., allowing the Frontend to talk to the Backend) and securely handling database credentials using environment variables.</p></li><li><p>&nbsp;Once running, the containers could communicate appropriately, providing the necessary infrastructure. With this foundation established, the following steps will&nbsp;<strong>zoom in specifically on the architecture design and challenges encountered within the Backend Python service</strong>, as this is where the core LangChain logic, LLM orchestration, and data processing pipeline were implemented.</p></li></ul><p>\\\n<strong>Step 2: First Queries and the Schema Size Challenge</strong></p><ul><li><p>&nbsp;The containerized setup worked, enabling successful natural language queries against the database. Simple requests yielded correct query logic and data via LangChain and the primary LLM.</p></li><li><p><strong>The Challenge: Token Limits:</strong>&nbsp;However, a major bottleneck quickly emerged: API errors due to exceeding token limits. This happened because the context provided to the LLM often includes database schema details (table/column names, types), and with hundreds of tables, this schema information made the prompts too large for the LLM’s limits.</p></li><li><p><strong>The Workaround: Subsetting:</strong>&nbsp;My immediate solution was to restrict the schema information provided to the LLM, perhaps by only considering a small, manually defined&nbsp;<strong>subset of the database tables</strong>&nbsp;or using parameters like&nbsp;&nbsp;if applicable to the LangChain component handling schema representation. This significantly reduced prompt size and avoided the errors for queries within that subset.</p></li><li><p>&nbsp;While functional, this is a brittle fix. The LLM remains unaware of tables outside this limited view, preventing more complex queries and requiring manual updates. This clearly indicated that handling large database schemas efficiently requires a more advanced approach.</p></li></ul><p>\\\n<strong>Step 3: Implementing PII/PHI Filtering via a Dedicated LLM Prompt</strong></p><ul><li><p><strong>The Critical Need for Compliance:</strong>&nbsp;After enabling basic queries, the next priority was data privacy compliance. For companies, particularly in regulated sectors like&nbsp;, filtering sensitive PII/PHI is often a&nbsp;&nbsp;(e.g., due to HIPAA or financial regulations) needed to avoid&nbsp;. Exposing raw data also breaks&nbsp;, harms&nbsp;, and violates internal security and&nbsp;. Robust filtering before displaying results was therefore essential to meet these compliance needs, especially for wider team access.</p></li><li><p><strong>The Solution: A “Data Security Bot”:</strong>&nbsp;My approach involved adding a dedicated data sanitization layer…&nbsp;<em>(the rest of the paragraph describing the LLM filter implementation remains the same)</em></p></li><li><p>&nbsp;Inside, a detailed prompt () instructed this second LLM to act as a&nbsp;&nbsp;Its primary task was to review the raw text response and redact identified PHI and PII.</p></li><li><p>&nbsp;A result like&nbsp;<code>{'member_id': 12345, 'member_name': 'Jane Doe', 'address': '123 Main Street, Mercy City'}</code>&nbsp;would be transformed by the filter LLM to&nbsp;<code>{'member_id': 12345, 'member_name': '[REDACTED]', 'address': '[REDACTED]'}</code>.</p></li></ul><p>Here is the entire diagram after the change</p><p>\\\n<strong>Step 4: Refining Prompts for Raw SQL Generation</strong></p><ul><li><p><strong>The Challenge: Misinterpretation:</strong>&nbsp;After implementing the PII filter, I tackled the challenge of ensuring the main NL-to-SQL LLM () accurately understood the user's intent&nbsp;&nbsp;executing potentially complex or ambiguous queries against the database. Vague prompts could lead&nbsp;&nbsp;to execute incorrect SQL, retrieve irrelevant data, or fail.</p></li><li><p><strong>The Solution: A “Prompt Refinement Bot”:</strong>&nbsp;To improve execution reliability, I introduced a preliminary&nbsp;<strong>“Prompt Refinement Bot” — a third LLM call</strong>. This bot acted as an “expert prompt engineer,” taking the original user query and database schema to rewrite the request into a highly explicit and unambiguous instruction&nbsp;.</p></li><li><p>&nbsp;The goal was to formulate a prompt that clearly guided&nbsp;&nbsp;on what tables, columns, and conditions were needed, maximizing the chance it would&nbsp;<strong>execute the correct query</strong>&nbsp;against the database and retrieve the intended data.</p></li><li><p>&nbsp;This pre-processing step significantly improved the consistency and accuracy of the data retrieved by&nbsp;.</p></li></ul><p>\\\n<strong>Step 5: Enhancing Context with Conversation Memory</strong></p><ul><li>&nbsp;To elevate the user experience beyond single queries and enable more natural dialogue, remembering the conversation context was crucial for handling follow-up questions.</li><li>&nbsp;I integrated LangChain’s memory capabilities using&nbsp;<code>ConversationSummaryMemory</code>. This approach uses an LLM (&nbsp;in this case) to progressively summarize the conversation, keeping key context accessible while managing token usage (configured with&nbsp;).</li><li>&nbsp;This summarized&nbsp;&nbsp;was then incorporated directly into the prompt template used when interacting with the&nbsp;&nbsp;(the NL-to-SQL + Executor), alongside the user's current (potentially refined)&nbsp;.</li><li>&nbsp;Adding this memory layer allowed the system to consider the ongoing dialogue, significantly improving usability for more coherent and context-aware conversations about the database contents.</li></ul><p>\\\n<strong>Conclusion: Lessons from Building a Multi-LLM SQL Interface</strong></p><p>\\\nBuilding this natural language interface to MySQL using LangChain was a revealing journey into the power and complexities of modern AI development. What started as a goal to query a database using plain English evolved into a multi-stage pipeline involving three distinct LLM calls: one for refining user prompts, one for translating natural language to SQL and executing it directly against the database, and a critical third one for filtering sensitive PII/PHI from the results. Integrating conversation memory further enhanced the usability, allowing for more natural, context-aware interactions.</p><p>Key challenges like managing LLM token limits with large schemas, ensuring data privacy through filtering, and improving prompt understanding required iterative solutions. While leveraging AI for code generation accelerated parts of the process, designing the overall architecture, implementing specific logic like the PII filter exceptions, integrating components, and rigorous testing remained crucial human-driven tasks.</p><p>\\\n<strong>Next Steps: Exploring Retrieval-Augmented Generation (RAG)</strong></p><p>\\\nThe success rate, especially for more complex or ambiguous queries, indicates clear opportunities for improvement beyond the current prompt engineering and filtering techniques.</p><p>\\\nOne promising avenue I plan to explore next to further boost accuracy is&nbsp;<strong>Retrieval-Augmented Generation (RAG)</strong>. Instead of solely relying on the LLM’s internal knowledge or a static view of the schema, RAG introduces a dynamic retrieval step. Before generating the SQL, a RAG system would search a specialized knowledge base for information highly relevant to the user’s current query.</p><p>\\\nIn this NL-to-SQL context, this could involve retrieving:</p><ul><li>Detailed descriptions or documentation for the specific database tables and columns deemed most relevant to the query.</li><li>Examples of similar natural language questions previously mapped to their correct SQL counterparts.</li><li>Relevant business rules or definitions pertaining to the data requested.</li></ul><p>\\\nThis retrieved, targeted information would then be added (“augmented”) to the prompt sent to the main NL-to-SQL LLM (), providing it with richer, just-in-time context. The hypothesis is that this dynamic context will significantly enhance the LLM's understanding and ability to generate accurate SQL, potentially offering substantial improvements without the extensive dataset requirements of fine-tuning. Implementing and evaluating an effective RAG strategy represents the next exciting phase in enhancing this conversational database interface.</p>","contentLength":9793,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"This CFO Wrecked His Mercedes Trying to Kill the CEO & 3 Other Entrepreneurial War Stories","url":"https://hackernoon.com/this-cfo-wrecked-his-mercedes-trying-to-kill-the-ceo-and-3-other-entrepreneurial-war-stories?source=rss","date":1744618723,"author":"Jonathan Roseland","guid":22820,"unread":true,"content":"<p>The word&nbsp;&nbsp;is drastically overused for everything from mild moodiness and irritability to emotional changes. That's not what this article is about; these are four stories of times I did business with people who were deeply unwell psychologically.</p><p>\\\nSometimes, I ask myself whether it's a degree of insanity within myself that has attracted these people and circumstances or whether it's just a matter of dumb luck that I've been quite intimately ensconced in business four separate times with people varying from unstable addicts to genuinely demented.&nbsp;I'm leaning more toward the former than the latter.</p><p>\\\nIn addition to being entertaining,&nbsp;<strong>I hope that these stories can educate you on how to identify the tale-tale signs of insanity</strong>&nbsp;in the charming, persuasive people you are considering doing business with.</p><p><img src=\"https://cdn.hackernoon.com/images/1nOf3C3xXvNO2p1OYW96H4Kbel33-2025-04-14T08:18:29.287Z-duupmv8ph5bv26vy3gbtl64a\" alt=\"\"> \\n David was my best friend for four years, towards the end of that time it became increasingly evident that he was a non-violent, high-functioning psychopath.</p><p>\\\nDavid was on the path to become a doctor, he was incredibly hard-working and more devoted to his studies than any other college student I've ever known. David, at any given time, had at least one woman intensely in love with him. He had to pay for abortions at least three times, he told me. To this day, he remains the most charming person I have ever met.</p><p>\\\nDavid partied; he loved nightclubs, bottle service, cocaine, and occasionally smoking crystal meth. He had a contagious ability to energize any room. David had a disturbing amount of confidence in his ability to drive drunk -&nbsp;he would, barely able to walk, drive his truck aggressively all the way across town. I remember watching David getting caught with cocaine in a nightclub bathroom and then proceeding to successfully convince the police&nbsp;that it was not his. He had an uncanny talent for getting drugs for free from gay guys. I remember several nights, going to hang out in seedy apartments so he could score drugs for free.</p><p>\\\n<strong>The only other passion that matched his appetite for intoxicants was his religiosity</strong>. He came from an intensely religious Mormon family (who I knew well; they were some of the classiest, most generous people I've ever known). Sometimes, in a drunken fervor, he would explain to me how he was one day going to become&nbsp;&nbsp;(<a href=\"https://www.limitlessmindset.com/podcast/931-lincoln-cannon\">this is part of the Mormon religion</a>).</p><p>When I decided to enter the entertainment business at age 21 by organizing my first concert, David was my partner. The last time I saw David, he actually walked in on me having sex with a woman I had just met who had been admiring the brand-new Maserati I was driving.</p><p>David once stole and took on a joyride a tuner&nbsp;&nbsp;sports car during a house party. When he returned, the car's owner, drunk on tequila, ripped him out of the driver's seat and beat him up. David then hid in a room in the house with some girls while I tried to convince the car's owner not to kill him.</p><p><img src=\"https://cdn.hackernoon.com/images/1nOf3C3xXvNO2p1OYW96H4Kbel33-2025-04-14T08:18:29.291Z-kd1mynq4pfvg6i89ixlje0vx\" alt=\"\">A former banker, supposedly&nbsp;, diagnosed with&nbsp;*dissociative identity disorder (*aka&nbsp;<em>multiple personality syndrome</em>), was the financier of an entertainment start-up I worked for. Early in my career in the entertainment business, a friend called me and told me excitedly that he had an investor who would finance whatever we wanted to do: concerts, nightclubs, clothing lines, football stadium events, etc.</p><p>\\\nThey hired me as the second employee of the company and paid me $35/hourly to organize event marketing strategies and&nbsp;&nbsp;with potential strategic partners (aka&nbsp;).&nbsp;<strong>Ed had an ugly codependent relationship with my friend, the CEO of the start-up, who gave Ed's darker sides continuous excuses to blow his money frivolously</strong>&nbsp;One week, they showed up with an Escalade (on 22-inch chrome rims). The next week, a brand new Mercedes-Benz SLK350, and then a new Maserati GranTurismo from Ferrari of Denver. They also sent me on all-expense-paid trips to Scottsdale and Cancun, Mexico.</p><p>\\\nEd took medication and saw a shrink to deal with his demons.&nbsp;<strong>What seemed to trigger Ed's other personalities most consistently was drinking alcohol</strong>. One was a woman, one was gay, and one was a reckless young man who just wanted to get drunk and laid. His personalities had a clever method for communicating with each other; they would call his cell phone's voicemail and leave messages.</p><p>\\\nAfter several months of this spending, in an uncommon display of maturity and sobriety for a 22-year-old living like a rockstar, I wrote a formal letter to Ed and the CEO stating my serious concern with the spending before the business had made a cent of profit. Their response was a demotion, eventually, we ended up throwing a single event at the Denver Broncos football stadium, it lost probably $15,000 and I resigned.</p><p>After a night of drinking, Ed's most malignant personality emerged while he was driving the company car, a black 2-seater Mercedes convertible, with the CEO. The personality announced to the CEO that he was going to kill him. He then proceeded to run a red light doing +50 miles-per-hour and t-boned a sedan. Amazingly, he didn't kill anyone that day, but he did destroy an almost $70,000 car.</p><p><strong>A mild-mannered tech start-up founder client of mine with a dark past</strong>. Early in my career operating a&nbsp;<a href=\"https://roselanddigital.com/\">web strategy firm</a>, I met a man with a great idea for an eCommerce marketplace. I agreed to develop his online platform in exchange for a four-figure payment and a piece of equity in his start-up.</p><p>\\\n<strong>In the beginning, he came across as smart and easy to deal with.</strong>&nbsp;He told me he had recently gone through a tough divorce. As is common in the start-up development world, we ran into all kinds of technical challenges and delays. We actually ended up having to sue a 3rd party vendor. I remember picking William up at his dad's place for a long, awkward ride to the courthouse. About a year into the partnership, William had significantly changed the project scope of what he wanted the website to do, so he released me from my development responsibilities and had me focus on business development of future customers of the service, which I did, building a list of over 100 potential customers.</p><p>\\\nI had a base of small business clients ready to use the service, but William was lost in a perpetual cycle of second-guessing and redesigning the technical side of things. I urged William to simplify the development side so we could begin serving the clients and generating cash flow.&nbsp;<strong>He started making me all kinds of promises</strong>&nbsp;about increasing my equity, infusions of investment capital, licensing the business model in other countries, etc.</p><p>\\\n<strong>He was kind of a weird guy</strong>; he never went out to socialize or date, he lived with his dad, and he was singularly focused on his start-up. Out of the blue, one day, a woman on Facebook wrote to me, informing me of his history of domestic violence. Apparently, they had a kid together a long time ago, and he had done a bunch of weird stuff to her mother. She provided me with police and court records to verify everything. Then I did something I hadn't yet done up to this point: I Google searched my client, William. The top result for his name was a news story identifying him as the&nbsp;\"<em>Craigslist Stalker of Boulder,\"</em>&nbsp;and there were other news stories about his weird and sometimes violent past.</p><p>\\\nFour years later, his website isn't even up; no investment capital ever arrived, and the customers I gathered were never served. In business, William wasted a huge amount of my time, but I'm mostly just disappointed that this smart guy, with such a good idea, worked so hard and never made it happen. From this episode,&nbsp;<strong>I learned that a great idea counts for nothing; even a great idea plus hard work is pretty useless without a clear way to scale into cash flow</strong>. I also learned to Google search the people I'm considering doing business with. Finally and probably most importantly, I learned that the kind of character that mistreats women is the kind of broken person who will never produce consistent results in business.</p><p>\\\n<strong>My business partner of a few years displayed frequent psychopathic tendencies</strong>. Patrick should have had&nbsp;&nbsp;installed on his bedroom; he was a classic womanizer. As opposed to embracing polyamory, he always had a girlfriend who was committed to him that he would cheat on at every opportunity. Patrick&nbsp;had&nbsp;; he was passionate about fast, performance cars, and he always had some kind of tuned-up car that he drove like a demon.</p><p>\\\n<strong>Patrick had many redeeming qualities that made him a good partner</strong>. Any business I introduced him to, he would learn fast and do better than me. He was a master networker; he would find ways to catch the attention of people more successful than us and land them as clients. He had high standards for the business and the quality of the products and services we sold. As partners, he always made more money for the business than I did.</p><p>\\\nTowards the end of our business partnership, we became roommates for a short time, and he was abusive to me, his girlfriend, and our pets. I was astounded by his ability to not understand how his insanity affected those closest to him.&nbsp;The last time I saw him, we took a brand new BMW on a wild test drive through the foothills of Colorado. Patrick's&nbsp;&nbsp;and vices eventually caught up with him, and&nbsp;<a href=\"https://www.limitlessmindset.com/blog/limitless-characters/1398-live-fast-die-young\">he died in 2016</a>.</p><p>Late one night, after seeing one of our favorite DJs at a nightclub,&nbsp;we got into an extended high-speed car chase. Patrick was drunk, driving his racecar of a Honda Accord. He pulled into a restricted parking lot near the nightclub, and security guards approached the car. But as opposed to apologizing, he screeched out of the parking lot, as he did the security guards bashed out two of the windows of the car with their batons. He clipped the fender of another car as he tore out of the parking lot, attracting the attention of two vigilantes in a white Jeep, who took up hot pursuit of us. We raced around the downtown area, running red lights, and eventually got on the highway. Usually, one of Patrick's cars could easily outrun a Jeep, but the transmission of his Accord was going out as a result of his high-speed habits. The guys in the Jeep kept trying to run us off the road. They were not cops; they were people (probably friends of the driver of the car we had hit and run) who wanted to do bad things to us. About 20 miles north of Denver, we finally lost them by taking an offramp and killing our lights simultaneously.</p><h2><strong>The entrepreneur must dance with risk.</strong></h2><p>That's the game we signed up for. And \"in the light of risk, all Earthly colors meet heavenly flame\" (to paraphrase my favorite line from my favorite novel), but as I would learn, doing business with insane people or those lacking in character was not a risk worth taking. There are all sorts of interesting risks you can take in business, but dealing with those who exhibit a bunch of mental health red flags should not be one of them.</p>","contentLength":10842,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"HIKMICRO Showcases Advanced Digital Ecosystem for Hunters at IWA 2025","url":"https://hackernoon.com/hikmicro-showcases-advanced-digital-ecosystem-for-hunters-at-iwa-2025?source=rss","date":1744618606,"author":"Miss Investigate","guid":22819,"unread":true,"content":"<p><em>Photo Courtesy of HIKMICRO</em></p><p>HIKMICRO showcased its game-changing \"digital system\" concept at the IWA Outdoor Classics 2025 in Nuremberg. The company, known for its cutting-edge digital optics, has introduced an integrated technological ecosystem that enhances every aspect of the hunting experience.</p><p>\\\nThe advanced shutterless technology lies central to HIKMICRO's new strategy, featured in the latest FALCON 2.0 and CONDOR LRF 2.0 thermal monoculars. This breakthrough eliminates image freezing, a common issue that has long plagued thermal imaging devices. The HIKMICRO Shutterless Image System (HSIS) provides continuous viewing without distracting pauses, allowing hunters to capture every crucial moment in the field.</p><p>\\\nThe FALCON 2.0 and CONDOR LRF 2.0 feature a premium 15mK thermal detector, capable of capturing subtle temperature variations for exceptional detail. Both devices include laser rangefinder capabilities with an accuracy of up to 1000 meters (±1m), improving precision in distance measurement. The monoculars also deliver extended battery life, operating for over six hours on a single charge.</p><h2><strong>Advanced Daytime Optics and Integrated Digital Solutions</strong></h2><p>The digital ecosystem from HIKMICRO extends beyond thermal imaging to daytime hunting as well. Hunters have embraced the HABROK 4K binoculars, particularly for deer stalking. These optics excel in low-light conditions, delivering superior performance compared to traditional 10x56 binoculars with 95% light transmission. The HABROK 4K includes a 60mm ED lens that adjusts to different light wavelengths, allowing for clear image capture even in challenging lighting situations.</p><p>\\\nThe SIGHT APP serves as the hub for HIKMICRO's ecosystem, enabling hunters to capture, store, and share their experiences. Through the app's Hunt Ground feature, users can chart hunting grounds, map detected animals, plan trails, and mark high seats and feeders. This information remains quickly accessible via smartphone and can be shared in real-time, boosting safety and collaboration during hunts.</p><p>\\\nFurthermore, the SIGHT APP calculates ballistics and offers laser rangefinding capabilities, adding a new level of precision to the hunting process. Additionally, it connects users to customer support services, extended warranties, and real-time repair status updates, creating a comprehensive digital service experience for hunters.</p><p>HIKMICRO sells products while simultaneously fostering a community of hunters. Its connected ecosystem encourages knowledge sharing and collaboration, promoting camaraderie within the hunting community while enhancing safety. This focus on community building, combined with user-friendly design and technological advancement, makes hunting more accessible and enjoyable for both seasoned professionals and newcomers alike.</p><p>\\\nWhile preparing to showcase its forward-thinking concepts at IWA 2025, HIKMICRO demonstrates that the digital hunting revolution progresses steadily. The company shows dedication to exploring infinite possibilities through its product lineup and integrated solutions.</p><p>\\\nThe strategies revealed at the IWA show reinforce and extend HIKMICRO's brand vision of infinite exploration. Through user-friendly advanced technology and fully integrated solutions, it aims to take digital and thermal hunting devices from niche to mass markets.</p><p>\\\nIn a world where digital and thermal optics rapidly evolve, HIKMICRO leads the way into a future where hunters can easily use the most advanced technology. The company's digital system concept represents a pioneering first step into a new and totally immersive hunting experience, where thermal and digital viewing provide the most effective choice for daytime and nighttime hunting.</p><p>\\\nThe hunting industry continues to evolve with HIKMICRO's digital system concept standing at the forefront of this transformation. It offers hunters a comprehensive suite of tools to enhance their skills, safety, and enjoyment in the field. HIKMICRO redefines the future of the sport itself rather than simply changing how we hunt.</p>","contentLength":4057,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Break Into Cybersecurity Without a Degree or a Million-Dollar Lab","url":"https://hackernoon.com/how-to-break-into-cybersecurity-without-a-degree-or-a-million-dollar-lab?source=rss","date":1744618600,"author":"Pawan Jaiswal","guid":22818,"unread":true,"content":"<p>Cybersecurity is one of the most rapidly growing industries in the technology space. With an increase in cyber attacks, businesses in every sector are seeking talented professionals to safeguard their digital properties. But how do you transition from being an inexperienced student to being a successful, well-compensated cybersecurity expert? In this blog, we will outline the step-by-step journey to establish a successful cybersecurity career—from the fundamentals to becoming an expert.</p><blockquote><p><strong>Prefer watching instead of reading? Here’s a quick video guide</strong></p></blockquote><h3>Step 1: Know What Cybersecurity Is</h3><p>It's crucial to know what cybersecurity actually is before pursuing the career path.</p><p>Cybersecurity is about safeguarding systems, networks, and data against digital attacks. The attacks may be in numerous forms—malware, phishing, DDoS attacks, or insider threats. Cybersecurity experts assist in detecting, preventing, and reacting to these attacks.</p><p>\\\nSome of the main areas in cybersecurity are:</p><ul><li>Network Security: Protecting networks and data from breaches.</li><li>Application Security: Making apps secure from vulnerabilities.</li><li>Cloud Security: Securing data in cloud services.</li><li>Incident Response: Responding and recovering from cyber attacks.</li><li>Penetration Testing: Identifying vulnerabilities before hackers do.</li></ul><h3>Step 2: Build a Strong Foundation</h3><p>As a student, begin with the fundamentals of computer science and networking. These fundamentals are essential for grasping system functionality and how systems may be attacked or defended.</p><p>\\\nRecommended Topics to Study:</p><ul><li>Operating Systems (Linux and Windows)</li><li>Computer Networks (TCP/IP, DNS, VPN)</li><li>Programming/Scripting (Python, Bash, JavaScript)</li><li>Web Technologies (HTML, CSS, JavaScript, HTTP)</li></ul><p>\\\nFree Resources to Start:</p><ul><li>[YouTube Channels like NetworkChuck, John Hammond, The Cyber Mentor]</li></ul><h3>Step 3: Get Familiar with Cybersecurity Concepts</h3><p>Once you’ve got the basics down, start exploring cybersecurity-specific concepts:</p><ul><li>Firewalls and Intrusion Detection Systems (IDS/IPS)</li><li>Encryption and Cryptography</li><li>Social Engineering and Phishing</li><li>Cyber Kill Chain and MITRE ATT&amp;CK framework</li><li>Common Vulnerabilities (OWASP Top 10)</li></ul><p>\\\nBegin to read security blogs, view tutorials, and keep abreast of cybersecurity news to remain current with trends.</p><h3>Step 4: Select Your Cybersecurity Specialization</h3><p>Cybersecurity has numerous specializations.</p><h3>Step 5: Learn by Doing (Hands-On Practice)</h3><p>Theory is great, but practice is greater. Use hands-on platforms to put what you've learned into practice:</p><ul><li>TryHackMe (Beginner-friendly labs)</li><li>Hack The Box (Real-world CTFs and hacking labs)</li><li>PortSwigger Web Security Academy (Web app security)</li><li>OverTheWire (Linux and CTF practice)</li><li>Blue Team Labs Online (For defensive skills)</li></ul><p>\\\nCreate your own Home Lab:</p><ul><li>Create Virtual Machines with VirtualBox or VMware.</li><li>Install Kali Linux, Metasploitable, or vulnerable apps.</li><li>Scan, exploit, and patch, practice.</li></ul><h3>Step 6: Earn Certifications (Optional but Valuable)</h3><p>Certifications demonstrate to employers that you're serious and proficient. You don't have to get them, but they can open doors for you.</p><p>\\\nBeginner-Friendly Certifications:</p><ul><li>CompTIA Security+ – An excellent starting point.</li><li>Certified Ethical Hacker (CEH)</li></ul><p>\\\nIntermediate to Advanced:</p><ul><li>CompTIA CySA+ or PenTest+</li><li>eJPT (by INE) – Excellent for beginner PenTesting</li><li>OSCP (Offensive Security Certified Professional) – Very well known</li></ul><p>\\\nSelect according to your career choice. Penetration testers can opt for OSCP, while SOC analysts might go for Security+ or CySA+.</p><h3>Step 7: Build Your Portfolio</h3><p>Employers would love to see evidence of your skills.</p><p>\\\nCreate a portfolio with:</p><ul><li>Projects: Write blogs, scripts, or automation tools.</li><li>CTF Writeups: Explain that you solved security problems.</li><li>GitHub Repo: Post code, tools, or practice labs.</li><li>Personal Blog or Website: Document your learning process.</li><li>LinkedIn Profile: Maintain it with your projects and accomplishments.</li></ul><p>\\\nThat demonstrates initiative, passion, and hands-on skills—precisely what companies want.</p><h3>Step 8: Apply for Internships or Entry-Level Positions</h3><p>Once you have some projects and skills behind you, begin applying. Even internships or freelance work are a good starting point.</p><p>\\\nEntry-Level Positions to Search for:</p><ul><li>SOC Analyst (Security Operations Center)</li><li>IT Help Desk (usually a gateway to security positions)</li><li>Vulnerability Management Intern</li><li>Don't wait to be \"100% ready.\" The best way to learn is on the job.</li></ul><h3>Step 9: Keep Learning and Networking</h3><p>Cybersecurity is a daily evolving field. Stay ahead by continuing to learn.</p><ul><li>Site follow cybersecurity news sites (KrebsOnSecurity, ThreatPost)</li><li>Site subscribe YouTube channels and newsletters</li><li>Participate in communities: Reddit (r/netsec), Discord, Twitter/X, LinkedIn groups</li></ul><ul><li>Go to local or remote security meetups (BSides, DEFCON groups)</li><li>Participate in Capture the Flag (CTF) tournaments</li><li>Get involved in open-source security initiatives</li></ul><p>\\\nNetworking generally results in getting a job or being mentored.</p><p>Becoming a cybersecurity professional takes time, patience, and commitment—but it's entirely within reach for anyone with interest and motivation. You don't require a costly degree or specialized equipment. You just need a laptop, internet, and the desire to learn.</p><p>\\\nHere's a brief rundown of your journey:</p><ul><li>Learn the Fundamentals – Systems, networks, and programming</li><li>Delve into Cybersecurity Concepts</li><li>Apply for Jobs or Internships</li><li>Continuously Learn and Network</li></ul><p>\\\nCybersecurity is not a career—it's a calling. If you enjoy fixing puzzles, safeguarding individuals, and combating cyber threats, this career is meant for you.</p><p>\\\nSo begin now. The earlier you get started, the sooner you'll be an expert.</p>","contentLength":5585,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Think Your System’s Safe? These Free Tools Will Prove You Wrong","url":"https://hackernoon.com/think-your-systems-safe-these-free-tools-will-prove-you-wrong?source=rss","date":1744618357,"author":"Pawan Jaiswal","guid":22817,"unread":true,"content":"<p>In the constantly changing landscape of cybersecurity, vulnerability scanning is one of the easiest yet most effective methods of keeping ahead of the game. Whether you're running a website, an IT professional, or simply learning the basics of ethical hacking, knowing how to conduct a basic vulnerability scan is a skill that can take you far.</p><p>\\\nIn this blog, we’ll break down what vulnerability scanning is, why it’s important, and how to perform one using simple tools—even if you’re just starting out.</p><blockquote><p>Prefer watching instead of reading? Here’s a quick video guide</p></blockquote><h2>What is a Vulnerability Scan?</h2><p>A vulnerability scan is an automated process that searches your systems, networks, or applications for known security weaknesses.</p><p>\\\nThese weaknesses can be things like:</p><ul><li>Outdated software versions</li><li>Unpatched vulnerabilities</li></ul><p>\\\nThink of it as a digital security check-up for your system.</p><h2>Why Do You Need to Conduct a Vulnerability Scan?</h2><p>A vulnerability scan allows you to:</p><ul><li>Identify risks early before an attacker can target them.</li><li>Patch vulnerabilities to bolster your defenses.</li><li>Become compliant for standards such as PCI-DSS, HIPAA, etc.</li><li>Achieve good cybersecurity hygiene within your process.</li></ul><p>\\\nWhether you operate a personal site or host servers for a business, vulnerability scans are necessary.</p><p>There are numerous tools, both free and paid. For starters, some free and easy-to-use tools are:</p><ul><li>Nmap – Excellent for network scanning and detecting open ports and services.</li><li>Nikto – Good for scanning web servers for known vulnerabilities.</li><li>OpenVAS – A robust open-source vulnerability scanner for full scans.</li><li>OWASP ZAP – Excellent for scanning web applications and detecting security vulnerabilities.</li><li>Vulners Nmap Scripts – Nmap + Vulners script identifies known CVEs within services.</li></ul><p>\\\nLet's go through an example with Nmap and Nikto, which are simple to use and don't need a powerful machine.</p><h3>Step 1: Set Up Your Environment</h3><p>Before you begin scanning, ensure that you have:</p><ul><li>A target to scan – either your own local machine, a test server, or a virtual machine (e.g., Metasploitable or DVWA).</li><li>A Linux VM or system (such as Kali Linux or Ubuntu).</li><li>Nmap: sudo apt install nmap</li><li>Nikto: sudo apt install nikto</li></ul><p>\\\nImportant Note: Always have permission before scanning any target. Unauthorized scanning is illegal and unethical.</p><h3>Step 2: Discover the Target with Nmap</h3><p>Suppose you wish to scan a website or a local server to know what services are running.</p><p>This will return open ports and services running on the target.</p><p>This adds service version detection. You’ll see versions of services like Apache, SSH, FTP, etc.</p><p>\\\nScan for known vulnerabilities (with Vulners script):</p><pre><code>nmap -sV --script vulners example.com\n</code></pre><p>This scan uses the Vulners database to identify known CVEs (Common Vulnerabilities and Exposures) based on service versions.</p><h3>Step 3: Scan Web Server with Nikto</h3><p>If your target is a web application, Nikto is a good place to begin.</p><pre><code>nikto -h http://example.com\n</code></pre><ul><li>Known file paths (such as /admin, /phpinfo.php)</li><li>Potential vulnerabilities</li></ul><p>\\\nIt's not stealthy, but it provides you with a fast snapshot of web server security.</p><h3>Step 4: Analyze the Results</h3><p>After the scans, you'll have outputs such as:</p><ul><li>Open ports (e.g., 22, 80, 443)</li><li>Services running (e.g., SSH, Apache)</li><li>Known CVEs related to those services</li><li>Insecure configurations or exposed files</li></ul><ul><li>Are there any outdated versions? (e.g., Apache 2.2 is outdated)</li><li>Are there any unnecessary open ports?</li><li>Are there known vulnerabilities with published exploits?</li></ul><p>Based on your scan results:</p><ul><li>Harden configurations (e.g., turn off directory listing, secure headers)</li><li>Patch vulnerabilities with vendor advisories</li><li>Re-scan to verify issues are resolved</li></ul><p>\\\nRegular scanning ensures you're not leaving out-of-date vulnerabilities open to attackers.</p><h2>How Often Should You Scan?</h2><ul><li>For personal projects: Monthly or after significant changes</li><li>For organizations: Weekly or as part of continuous monitoring</li><li>After updates: Always scan after system updates or patching</li></ul><p>\\\nThe secret is consistency.</p><h2>Bonus: Practice on Safe Targets</h2><p>Here are some safe and legal places to practice vulnerability scanning:</p><ul><li>Metasploitable 2 – A vulnerable VM to test tools.</li><li>DVWA (Damn Vulnerable Web Application) – Practice web app testing.</li><li>TryHackMe and Hack The Box – Provide labs with real-world scenarios.</li></ul><p>\\\nPracticing in these places teaches you about vulnerabilities and how they're exploited without violating the law.</p><ul><li>Start small – Learn the basics before jumping into advanced tools.</li><li>Stay ethical – Scanners are meant to scan only systems that belong to you or for which you have a test permission.</li><li>Keep learning – Vulnerabilities change, hence keep learning.</li><li>Document your scans – Record what you scan and what you do.</li></ul><p>Performing a basic vulnerability scan doesn’t require deep technical knowledge—it just takes the right tools and a cautious approach. Over time, you’ll learn how to dig deeper, identify risks faster, and strengthen your systems against potential attacks.</p><p>\\\nSo fire up your terminal, pick a target you’re allowed to scan, and start exploring the world of ethical hacking—one vulnerability at a time.</p>","contentLength":5091,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Over 500 Million Searches on iAsk AI—They’re Clearly Doing Something Right","url":"https://hackernoon.com/over-500-million-searches-on-iask-aitheyre-clearly-doing-something-right?source=rss","date":1744617960,"author":"Miss Investigate","guid":22816,"unread":true,"content":"<p>\\\nThe numbers are in—and they’re massive.  just passed  searches. That’s not a typo. 500,000,000+ questions asked, problems solved, papers summarized, and headaches avoided.</p><p>\\\nFor a tool that didn’t exist a few years ago, this kind of growth is wild. But if you’ve used iAsk, you get it. It’s not just another AI chatbot—it’s the fastest way to go from “I’m stuck” to “I got this.”</p><h2><strong>Why Everyone’s Using iAsk</strong></h2><p>Students are swearing by it. Professionals are sneaking it into their workflows. And Gen Z? They're making it go viral on TikTok.</p><p>\\\nWhether it’s breaking down calculus step-by-step, summarizing a 10-page article in seconds, or helping you write a killer essay—iAsk just gets it. No fluff, no distractions, just straight-to-the-point answers that actually help.</p><p>\\\nOne user put it perfectly, “<em>It’s not really just answering questions, you know. iAsk AI solves problems.</em>”</p><h2><strong>What Makes iAsk Different</strong></h2><p>Speed is one thing. Accuracy is another. But iAsk shines because it actually thinks.</p><p>\\\nBehind the scenes, it’s using something called Chain of Thought (CoT) reasoning. That means it doesn’t just spit out answers—it walks through them step-by-step, like a really smart friend who also happens to be an AI.</p><p>Sure, it’s a game-changer for students on tight deadlines. But creatives, researchers, and busy professionals are jumping on board too.</p><p>\\\nNeed to analyze a dense report? Done. Brainstorm content ideas? Easy. Polish a rough draft into something publish-ready? Say hello to .</p><p>\\\n“<em>More than just getting answers, it’s about understanding them</em>,” said one student who used iAsk to prep for finals and crushed it.</p><h2><strong>The Best Part? It’s Still Free for Students</strong></h2><p>To celebrate the milestone, iAsk is making —giving anyone with a .edu email access to premium features like live tutoring, ad-free browsing, and more. For free. For a year.</p><p>Half a billion searches is just the beginning. iAsk is building fast, listening to users, and leveling up what AI search can do.</p><p>\\\nAnd if you’re still using regular search engines that give you a wall of links instead of real answers? Might be time to give iAsk a try.</p><p>\\\nBecause clearly… they’re doing something right.</p>","contentLength":2196,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Bill Gates-backed Arnergy to expand solar access in Nigeria with $18M as demand surges","url":"https://techcrunch.com/2025/04/14/arnergy-to-expand-solar-access-in-nigeria-with-18m-series-b/","date":1744617900,"author":"Tage Kene-Okafor","guid":22771,"unread":true,"content":"<article>Demand for solar energy in power-starved Nigeria has soared in the last decade thanks to worsening grid reliability and rising fuel costs. That’s drawn investor interest to Arnergy, a clean tech startup meeting that need. The company just raised a $15 million Series B extension (on top of a $3 million B1 round last year), […]</article>","contentLength":331,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Tonga’s Government Still Runs on Gmail. Here’s Why That’s a Big Problem.","url":"https://hackernoon.com/tongas-government-still-runs-on-gmail-heres-why-thats-a-big-problem?source=rss","date":1744617825,"author":"Edwin Liava'a","guid":22815,"unread":true,"content":"<p>This morning, I visited the Immigration Department to collect my passport. According to their standard processing timeframe, new applications should be completed within one week. Instead, I discovered my application was on hold, not due to any complex issue, but because I was requested by an immigration officer to sent requested information to her personal gmail address, but she was absent from work today.</p><p>\\\nMore concerning was when I was told to resend my documents to \"<a href=\"mailto:tongaimmigration@gmail.com\">tongaimmigration@gmail.com</a>\" a Gmail address being used as the official email address for the entire Immigration Department. This vital government department doesn't even have a professional government email domain. Even worse, at the time of writing this blog, I still have not received any feedback regarding my document submission. I have no idea if my documents were received or are being processed. Somehow, ordinary citizens are left completely in the dark with no feedback whatsoever. This represents an extremely poor level of service to citizens who pay the taxes that fund civil servants' paychecks.</p><p>\\\nThis experience inspired me to write this blog addressing the fundamental ICT challenges facing our government and proposing straightforward solutions that could dramatically improve services for all Tongan tax paying citizens.</p><h2>The Current State of ICT in Tonga's Government</h2><p>The Kingdom of Tonga's government information and communication technology (ICT) infrastructure is fundamentally broken and disconnected. Despite various attempts at establishing e-Governance initiatives with donor funding, most efforts have failed to deliver cohesive, sustainable results.</p><p>\\\nThese failures manifest in several ways:</p><ol><li>: Government ministries operate independent websites with inconsistent designs, user experiences, and functionality.</li><li>: Most government websites lack basic security measures like SSL certificates, leaving citizen data vulnerable.</li><li>: Rather than using a unified government domain structure, departments often use commercial email providers for official communications.</li><li>: Previous ICT projects have become fragmented, with little coordination between ministries.</li><li>: The lack of integrated digital systems directly impacts citizens, causing delays in essential services.</li></ol><p>\\\nYou don't need to be a rocket scientist to diagnose these problems or develop solutions. However, the persistent issues suggest potential competency challenges within the government's ICT leadership.</p><h2>The Solution: A Standardized Domain Structure and Digital Infrastructure</h2><p>Fixing Tonga's government web presence doesn't require complex technology or massive budgets. It begins with implementing basic standards that governments worldwide have adopted:</p><h3>1. Unified Domain Structure Examples</h3><p>The Tongan government should establish a standardized domain structure using \"gov.to\" as the primary domain, with consistent subdomains for each ministry:</p><ul><li>Ministry of Foreign Affairs: mfa.gov.to</li><li>Prime Minister's Office: pmo.gov.to</li><li>Ministry of Finance: mof.gov.to</li><li>Ministry of Public Enterprises: mpe.gov.to</li><li>Ministry of Education: moe.gov.to</li><li>Ministry of Health: moh.gov.to</li><li>Ministry of Justice: moj.gov.to</li><li>Ministry of Lands: mol.gov.to</li><li>Ministry of Tourism: mot.gov.to</li><li>Ministry of Infrastructure: moi.gov.to</li></ul><p>\\\nThis approach creates a professional, cohesive digital identity for the government while making it easier for citizens to find and trust official websites and communications.</p><h3>2. Implement Basic Security Standards</h3><p>All government websites should implement SSL certificates (HTTPS), which are now standard practice and often free to implement. This basic security measure protects data in transit and establishes trust with users.</p><h3>3. Standardized Email Addresses</h3><p>All government officials should use email addresses on their respective ministry domains (e.g., <a href=\"mailto:immigration@mfa.gov.to\">immigration@mfa.gov.to</a>) rather than personal accounts on commercial providers. This maintains professionalism and data sovereignty.</p><h3>4. Centralized ICT Governance</h3><p>Establish a central ICT authority with the mandate to enforce standards across all ministries, providing technical support and ensuring consistency.</p><h2>Process Map for Implementation</h2><p>The following process map outlines the key steps needed to standardize Tonga's government ICT infrastructure:</p><p>To turn this vision into reality, here's a proposed timeline for implementing the standardized ICT infrastructure:</p><h2>Benefits of Implementation</h2><p>Implementing these recommendations would deliver numerous benefits:</p><ul><li>: Professional, secure websites increase public confidence in government services.</li><li>: SSL certificates and standardized infrastructure reduce vulnerability to cyber threats.</li><li>: Standardized contact points reduce confusion and improve efficiency.</li><li>: A unified approach reduces redundancy and makes maintenance more efficient.</li><li><strong>Preparation for e-government</strong>: These basic steps lay the foundation for more advanced digital services.</li></ul><p>My frustrating experience at the Immigration Department this morning is just one symptom of a larger problem affecting government services across Tonga. The good news is that solutions are readily available and well established.</p><p>\\\nBy implementing basic standards for domain structure, security, and email communications, the Tongan government can significantly improve service delivery and prepare for more advanced digital transformation. These changes don't require massive budgets or cutting edge technology, just proper planning, leadership, and implementation of widely used standards.</p><p>\\\nAs tax paying citizens, we deserve a government that embraces these basic digital standards. The recommendations outlined above represent not just best practices but minimum requirements for a modern public administration in the digital age.</p><p>\\\nI hope this blog inspires action and contributes to a better digital future for Tonga's government and the citizens it serves.</p>","contentLength":5817,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"JavaScript Becomes More Powerful Than Ever","url":"https://hackernoon.com/javascript-becomes-more-powerful-than-ever?source=rss","date":1744617546,"author":"This Week in JavaScript","guid":22814,"unread":true,"content":"<p>Hello JavaScript Enthusiasts!</p><p>\\\nWelcome to a new edition of “”!</p><p>\\\nFrom Google's ambitious new AI workspace to Microsoft clamping down on VS Code forks, plus serious upgrades to JavaScript itself, there's a lot to unpack.</p><h3><strong>JavaScript in 2025: New Features You Should Know</strong></h3><p>JavaScript in 2025 is more powerful, expressive, and efficient than ever.</p><ul><li> give you map, filter, and flatMap on iterables—great for transforming large streams or datasets efficiently</li><li> offers native deep-copying for objects with circular references or complex types</li><li>s lets you create externally controlled promises, making async flow less clunky</li><li> makes grabbing the last element easier and cleaner</li><li> now support union, intersection, and difference natively—no more third-party libs</li><li> let you intercept and manipulate strings dynamically, useful for sanitization or internationalization</li></ul><p>\\\nIf you're still relying on old patterns, now’s the time to upgrade.</p><h3><strong>Google Launches Firebase Studio</strong></h3><ul><li>Import projects from GitHub, GitLab, Bitbucket, or local machines</li><li>Prototyping agents convert sketches and plain English into runnable code</li><li>Real-time previews, Android emulators, and one-click deploys to Firebase or Cloud Run</li></ul><p>\\\nThink of it as Google’s answer to Cursor or v0, but natively integrated into the Firebase ecosystem.</p><h3><strong>Battle-Tested Node.js Testing Playbook</strong></h3><ul><li>Reliable patterns for mocking, Dockerized databases, flaky queue simulations, and message brokers</li><li>Test structures built around API routes and behavior-driven outcomes</li><li>A showcase Node.js app with 40+ tests (yes, including the DB) that all run in under five seconds</li></ul><p>\\\nIf you're tired of flaky test suites and want a setup that runs fast and scales cleanly, this guide is gold.</p><h3><strong>Microsoft's Lockdown on VS Code Forks</strong></h3><ul><li>Extensions are now restricted to official environments (VS Code, Visual Studio, Azure DevOps)</li><li>Cursor is pivoting to Open VSX and OSS alternatives</li><li>Comes amid Microsoft’s expansion of Agent Mode and MCP in VS Code</li></ul><p>\\\nThe developer ecosystem is splintering. This move might redefine the editor landscape in the age of AI-first tooling.</p><p>Let's speed-run through some of the other big tool updates this week!</p><ul><li> Design your API once, and TypeSpec generates OpenAPI specs, JSON Schema, server code, and client libraries across languages. It's a language for API contracts, letting you build API-first with less drift, more consistency, and scalable architecture baked in from day one.</li><li>: Adds ESM support via a new client generator, Early Access migrations for Cloudflare D1 and Turso, and a new MCP server that connects to AI tools. Developers can now spin up Postgres workflows via AI prompts like \"make a DB for a habit tracker.\"</li><li> Boosts Android startup by avoiding JS bundle compression and brings major Metro bundler improvements. Swift-native module registration on iOS is now possible, and Remote JS Debugging has officially been removed for good.</li><li> Text-shadow utilities finally arrive, along with powerful new masking features, pointer-aware variants, and legacy browser fallbacks. The update makes layouts more expressive while improving accessibility and responsiveness across devices.</li><li> Turbopack enters alpha for production builds, offering up to 83% faster performance. Adds new routing hooks, instrumentation APIs, and support for Rspack as a community bundler, pushing forward Next.js as the go-to meta-framework.</li></ul><p>And that's it for the thirtieth issue of \"\"</p><p>\\\nFeel free to share this newsletter with a fellow developer, and follow for more weekly updates.</p><p>\\\nUntil next time, happy coding!</p>","contentLength":3505,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"You Don’t Own Your Data, But AI Does—and That’s the Problem","url":"https://hackernoon.com/you-dont-own-your-data-but-ai-doesand-thats-the-problem?source=rss","date":1744617535,"author":"Laszlo Fazekas","guid":22813,"unread":true,"content":"<p>Few people truly understand the revolutionary shift unfolding before their eyes when it comes to AI. It’s not just that our tools and software have become smarter — it’s that we’ve started developing software in an entirely new way.</p><p>\\\nThis is understandable, of course, since there hasn’t been any dramatic change in either hardware or software. Our programs still run on digital CPUs and GPUs, and they’re still written in traditional programming languages like Python. So, where exactly is the revolutionary change?</p><p>\\\nIt’s worth taking a look at the source code of large language models like <a href=\"https://github.com/openai/gpt-2\">GPT-2</a>, <a href=\"https://github.com/xai-org/grok-1\">Grok</a>, or Meta’s <a href=\"https://github.com/meta-llama/llama\">LLaMA</a>. Even to a layperson, one striking thing is how short and relatively simple this code is — which is surprising, considering the vast knowledge and problem-solving intelligence these models possess. This is when we begin to truly grasp why this is a real revolution, and why we can say that the way we develop software has fundamentally changed.</p><blockquote><p>In an artificial intelligence system, the runtime code is just a marginal part of the system — the real knowledge and intelligence come from the dataset used for training. <strong>Data is the new source code!</strong></p></blockquote><p>\\\nThat’s precisely why this new form of software has been called  by Andrej Karpathy — and I think that’s a very fitting name.</p><h2>Open weight ≠ open source</h2><p>There are several freely available open-source models that anyone can download, run, or even modify. Examples include LLaMA, Grok, and the recently much-discussed Chinese model DeepSeek.</p><p>\\\nThese models typically consist of a few Python files and several massive weight matrices (each several gigabytes in size). While it's true that these models can be further developed — fine-tuned, quantized, distilled, and so on — they still can’t truly be considered open-source in the classical sense. This is because we don’t have access to the datasets used to train them.</p><p>\\\nIt’s more accurate to call these  rather than open-source models, since the truly valuable component — the training data — remains in the hands of the publishing companies (Meta, xAI, etc.).</p><blockquote><p>True open-source AI is built on open data.</p></blockquote><p>Large language models are typically built by first creating a , which is then fine-tuned for a specific purpose (e.g., chatting, as with ChatGPT). This foundation model is trained on data produced by humanity and made publicly available — through websites, books, YouTube videos, and social media. Since this data wealth is the result of our collective work, it would be logical to treat these datasets as public domain resources, freely accessible to everyone.</p><p>\\\nFor this reason, many services have explicitly decided to prohibit AI model developers from using their content.</p><p>\\\nPersonally, I don’t fully agree with this approach, as I believe it hinders progress. I would much prefer a  that allows publicly available data to be used for AI training — on the condition that the resulting dataset and model must be made freely accessible in return.</p><p>\\\nSince no legal framework like this currently exists, and there’s no incentive for AI companies to develop truly open-source models, this responsibility falls to the community.</p><h2>Decentralized storage — the ideal home for open datasets</h2><p>But what would an open dataset built by a global community actually look like? That’s far from a trivial question, as there are significant ideological and cultural differences between people across different regions of the world. For this reason, it's impossible to create a single dataset from publicly available global knowledge that everyone would agree on. Beyond that, it’s crucial that such a dataset is not owned by anyone, that access cannot be restricted, that data cannot be retroactively modified, and that no one has the power to censor it.</p><p>\\\nGiven these criteria, the best choice is an immutable decentralized storage system, such as  or . These solutions use content-addressing (where the address of the data is a hash generated from its content), making unauthorized content modification virtually impossible. Storage is distributed across multiple nodes, ensuring secure and censorship-resistant access where data availability cannot be restricted.</p><p>\\\nThese systems have another extremely useful feature: they store content in blocks. Since the address of a piece of content is derived from its hash, if the same block appears in multiple files, it only needs to be stored once. In this way, both IPFS and Swarm function similarly to a , where versioning is automatic, and forking is cheap. This is ideal in cases where we want to store multiple datasets that differ only slightly (e.g., by less than 1%). If someone disagrees with the content of a dataset, they can create a new version without needing to make a full copy — just the changes are stored. Exactly like when we fork a project on GitHub to modify something.</p><h2>How blockchain can support the creation of open datasets</h2><p>Blockchain and decentralized storage complement each other well. On one hand, decentralized storage makes it possible to store large amounts of data with a level of security comparable to blockchain storage. On the other hand, the blockchain can provide the incentive system and governance layer for decentralized storage. A good example is Ethereum Swarm, which could not function without a blockchain, since its incentive system — essential for the network’s optimal operation — is implemented through smart contracts running on the blockchain.</p><p>\\\nIn the case of open datasets, blockchain-based DAOs could decide what gets included in a dataset. The system could function similarly to Wikipedia, where administrators ensure that false information doesn't make it into the encyclopedia. Of course, it’s often not clear-cut what counts as false information. Wikipedia has no real solution for this issue — but in a decentralized, blockchain-based system, forks come into play.</p><p>\\\nIf someone disagrees with the content of a dataset, they can create their own fork and launch a new DAO to manage the alternative version.</p><p>If data is the new source code, then in the case of Software 2.0 (artificial intelligence), training is the equivalent of compiling the program. In traditional software development, this compilation is done locally by developers on their own machines. In AI systems, however, training is an extremely energy- and computation-intensive task. Training a large language model can cost millions of dollars and requires massive computer clusters — a major challenge for community-driven models.</p><p>\\\nOne option is for the community to raise funds and rent computing power from a cloud provider for centralized training. Another possibility is decentralized training, where members donate computing capacity either for free (as a public good) or in exchange for compensation.</p><p>\\\nHowever, decentralized training is far from a trivial task. One challenge is that large models cannot be trained on a single node — multi-node training is required, which demands high-volume communication between nodes. This communication must be optimized for training to be efficient. Fortunately, several startups are working on this issue. One notable example is <a href=\"https://exolabs.net/\">Exo Labs</a>, which has developed a protocol called <a href=\"https://blog.exolabs.net/day-5/\">DiLoCo</a>, designed to enable training over an internet-connected network of nodes.</p><p>\\\nAnother challenge — common to all open decentralized systems (blockchains, decentralized storage, etc.) — is the issue of . Since anyone can freely contribute their own devices to the system, there’s no guarantee they will act honestly. A malicious actor, for instance, could use unauthorized data instead of the DAO-approved dataset, thereby “contaminating” the model.</p><p>\\\nIn these systems, trust is replaced by computational guarantees. The more security we want in an untrusted network of nodes, the more computational power is required. A good example of this is blockchain, where each node publishing a new block also validates all computations in the chain leading up to it.</p><p>\\\nThis approach, however, doesn’t work for AI training, so we must explore other solutions. Here are three potential approaches:</p><h3>Consensus-based Validation</h3><p>One approach is to have each computation performed by multiple (e.g., three) randomly selected nodes. If the results don’t match, the dishonest node loses its staked deposit. The advantage of this method is that it provides relatively high security. The downside is that it triples the required computing power.</p><p>With zero-knowledge proof (ZKP) technology, one can prove that a computation was performed — and do so in a way that the proof itself is cheap to verify. This technique is used in systems like zkRollups, where a zkSNARK proves that valid transactions were executed on a Layer 2 chain. The drawback is that generating the proof is computationally expensive, especially as the number of multiplications in the computation increases. This means that with current ZKP technology, training AI models this way would require drastically more computing power. Still, ZKPs are an actively researched area, and in the future, they may become efficient enough for distributed training.</p><h3>Optimistic Decentralized Machine Learning</h3><p>Optimistic decentralized machine learning works similarly to optimistic rollups. Computation is assumed to be correct unless someone submits a fraud-proof to show otherwise. In practice, the training node logs each step of the process — including the initial weight matrix, training data, and resulting weight matrix. If the log also records the random seeds, the entire computation becomes deterministic and reproducible.</p><p>\\\nValidator nodes can then randomly sample segments of the training log and verify them. If any inconsistencies are found, the training node loses its stake. This method has the lowest computational cost: it doesn’t require expensive zero-knowledge proof generation, and unlike consensus-based validation, only randomly selected parts of the computation need to be re-verified. This makes it the most efficient of the three approaches.</p><p>\\\nFinally, decentralized training requires a “node marketplace” — a platform where available computing resources can be discovered and utilized. An example is <a href=\"https://aleph.im/#solutions\">Aleph Cloud</a>, which, like other cloud providers, offers computational capacity — but it is a decentralized platform designed to provide scalable storage, computing, and database services through a network of distributed nodes. It uses an ERC20 token to pay for the services, so it can be easily integrated with other blockchain-based solutions. Aleph nodes use trusted execution environments, so validation is less relevant in this case.</p><p>For large-scale models, not only is training non-trivial due to the high computational demands but running the model (inference) is also challenging. This is especially true for reasoning models, where results emerge only after multiple consecutive forward passes — meaning the total computational power required for inference can far exceed that of training.</p><p>\\\nSince running a neural network works the same way as during training (inference is forward phases, whereas training involves many forward and backward phases), optimistic decentralized machine learning can also be applied here.</p><p>\\\nThe main challenge in this context is privacy. Technologies like Homomorphic Encryption and Multiparty Computation (MPC) can help protect private data. At the same time, hardware performance continues to grow exponentially, and new techniques — such as 1.5-bit neural networks and distilled Mixture-of-Experts (MoE) models like DeepSeek — are increasingly making it possible to run these networks locally.</p><p>\\\nI believe that in the long run, we will be able to run such models locally — or at the very least, within privately rented trusted environments.</p><p>By now, it’s clear to most people that AI is going to bring about revolutionary changes. It will reshape our world in ways we can hardly imagine — and that’s without even mentioning the impact of humanoid robots. What’s absolutely crucial is who holds the power over AI. Will it remain centralized in the hands of a few large corporations, or will it become a shared public good that benefits all of humanity?</p><p>\\\nThis makes one question central to our future: Will truly decentralized AI emerge?</p><p>\\\nBuilding such a system requires more than just technical innovation — it demands open datasets, decentralized storage, blockchain-based governance, and incentive mechanisms that allow communities to contribute and collaborate freely. It also needs sustainable solutions for decentralized training and inference, ensuring both efficiency and privacy.</p><p>\\\nIf we succeed, we won't just democratize AI — we’ll lay the groundwork for a new digital commons, where intelligence itself is co-created, transparent, and open to all.</p>","contentLength":12847,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Ethereum Is More Than Crypto. It’s a Machine for Making Worlds","url":"https://hackernoon.com/ethereum-is-more-than-crypto-its-a-machine-for-making-worlds?source=rss","date":1744617492,"author":"sshshln","guid":22812,"unread":true,"content":"<p>This article argues that Ethereum, far beyond being a mere technical protocol or financial instrument, constitutes a philosophical infrastructure: a machinic system that encodes, performs, and experiments with foundational categories of thought—being, time, knowledge, ethics, aesthetics, and subjectivity. Drawing from a wide range of philosophical traditions—from ancient metaphysics to posthumanism, from Stoicism to Deleuzean assemblage theory—we interpret Ethereum as a “pluriversal machine” that generates new forms of ontological and political reality through protocol design, cryptographic consensus, and distributed coordination. We explore how Ethereum recasts ontology as procedural and composable; time as synthetic and programmable; knowledge as trustless and collectively verified; and ethics as embedded in code, shaped by DAO governance and smart contract execution. We argue that Ethereum’s aesthetics emerge not from representation but from protocol poetics and rhizomatic design, producing emergent forms of ritual, art, and decentralized meaning-making. In anthropology, Ethereum gives rise to a new kind of networked subject—the Eterean—defined less by identity than by composable agency, interaction, and on-chain presence. Ethereum’s teleology, we contend, is not utopian but infrastructural: it enables new forms of collective imagination and coordination without prescribing their ends. It embodies a recursive, self-modifying philosophy—an open system where critique becomes code and where theory is enacted through participation. As such, Ethereum becomes not merely an object of philosophical inquiry but a platform for philosophy itself.</p><h2>Introduction: Ethereum as Thinking Infrastructure</h2><p>In the 21st century, the blockchain is not merely a technological breakthrough—it is a conceptual rupture. Ethereum, the most expressive of blockchain infrastructures, invites us not only to program transactions but to reprogram the categories through which we understand existence, coordination, and value. This article proposes that Ethereum operates not merely within philosophy but as philosophy: a medium that formalizes metaphysical, epistemological, ethical, aesthetic, and anthropological transformations in code. Ethereum is a thinking infrastructure—a system that does not only enable computation but computes categories. It modulates being, time, agency, trust, and collectivity. In doing so, Ethereum mirrors the way previous philosophical epochs anchored their thought in material form. Classical Greek philosophy was co-constituted by the polis, where democratic deliberation and ontological speculation emerged hand in hand (Arendt, 1958). Medieval philosophy was bound to ecclesiastical order, while Enlightenment thought unfolded through the print medium, shaping the public sphere and abstract reason (Habermas, 1989).</p><p>\\\nToday, Ethereum and similar protocols serve as platforms for what Yuk Hui (2016) calls “technodiversity”—a plurality of techno-cultural worldings. To think Ethereum philosophically is thus to consider it an apparatus of metaphysical inscription. It defines what counts as presence (the block), what constitutes agency (the address, the DAO), and what form knowledge must take to be accepted as truth (hashes, signatures, finality). Like law, money, and ritual before it, Ethereum is a synthetic a priori—a structure that enables worlds. Moreover, Ethereum challenges the conventional subject-object split. It is not a neutral medium for human intentions, but a generative force that entangles humans, machines, and contracts into new forms of relationality. Its smart contracts are not instruments but infrastructural performatives (Suchman, 2007): they bring into being what they declare.</p><p>\\\nThus, Ethereum is less a tool we use, and more a logic we inhabit. This paper advances the thesis that Ethereum is a pluriversal philosophical machine (Escobar, 2020). Drawing on speculative realism, post-structuralism, ancient epistemologies, and techno-political movements from cyberpunk to solarpunk, we argue that Ethereum constitutes a site where philosophy is encoded, contested, and enacted—not in texts, but in protocols.</p><p>\\\nEach section of this paper explores a distinct philosophical register through which Ethereum operates:</p><ul><li>Ontology, where being is procedural, temporal, and distributed;</li><li>Epistemology, where knowledge emerges not through trust, but through cryptographic proof and consensus;</li><li>Ethics, where justice is reconfigured through automation and coordination;</li><li>Aesthetics, where poetics emerge through code, ritual, and recursion;</li><li>Anthropology, where the human is remade as a node in a digital pluriverse;</li><li>And teleology, where the end is not an end-state, but an open architecture for collective becoming.</li></ul><p>\\\nEthereum, we suggest, is not merely used. It is inhabited. And through this inhabitation, it reveals itself as one of the most compelling philosophical objects—and subjects—of our time.</p><h2>Ontology: Procedural Being and the Cosmology of Code</h2><p>Ontology, classically understood, concerns the fundamental nature of being—what exists, how it persists, and in what ways entities relate to each other. Within Ethereum, being is neither substance nor essence, but procedure. An entity—be it a smart contract, a token, or a DAO—does not merely exist; it is instantiated, activated, and maintained through formalized operations. This marks a decisive shift: from metaphysics of presence to an ontology of execution. In traditional Western ontology, being has often been understood as what is—an entity’s quiddity, a stable identity independent of context (Aristotle’s ousia). Ethereum destabilizes this notion. It offers a computational paradigm where existence is contingent upon validation—what exists is that which has been inscribed into the ledger through consensus and cryptographic proof. To exist on Ethereum is to be verifiable, to persist through decentralized computation and replicated state. This aligns with a process-relational ontology (Whitehead, 1929; DeLanda, 2006), where entities are defined not by static essence but by dynamic relations. In Ethereum, identity is performative and composable: an address, a contract, a DAO is what it does, when it does it, and how it does it within the broader network of protocol-defined interactions. Smart contracts are paradigmatic here. They are not objects but executable intentions—codified logics that become through invocation. Their being is evental, akin to Alain Badiou’s conception of the event as something that breaks into the world, reconfiguring its structure (Badiou, 2005). The Ethereum Virtual Machine (EVM) serves as a metaphysical substrate in which these contracts unfold, echoing Heidegger’s Gestell—a technological enframing that brings forth a world through code. Importantly, Ethereum encodes a temporal ontology. Each block is a discrete unit of protocol time: timestamped, finalized, and sequentially anchored. Time here is not the Newtonian absolute nor the Bergsonian lived durée—but a hybrid: it is both machine-precise and subjectively elastic. For the validator, block time is rhythm; for the user, it is latency, anticipation, and finality.</p><p>\\\nThus, Ethereum generates a dual temporality: Kantian a priori time (structured, protocolized) and Bergsonian experiential time (qualitative, anticipatory).</p><p>\\\nEthereum’s ontology is plural and layered:</p><ul><li>Procedural: Existence is determined by process—being is becoming through transaction and execution.</li><li>Temporal: Time is constructed as cryptographic succession—non-linear, synthetic, and protocol-dependent.</li><li>Compositional: Contracts and DAOs are assemblages—modular systems that interoperate, mutate, and fork.</li><li>Machinic: Agency is distributed across code, human, and infrastructure—non-human actors are not extensions but ontological co-creators.</li></ul><p>\\\nWe might also frame Ethereum as a space of ontological design (Escobar, 2018; Willis, 2006). It is not just a technical system, but a site where new ontologies are crafted and lived. Through coding, deploying, and transacting, users author realities. Each smart contract creates a mini-world with its own laws, affordances, and modes of being-together. In this sense, Ethereum is not one ontology but a metaphysical multiplicity—a pluriverse of instantiated, programmable ontic regimes. At its philosophical limit, Ethereum performs what Gilles Deleuze might call an “immanent metaphysics”: a system where the divine is not transcendent, but embedded in operations. The hash becomes a sacred trace; the block, a unit of ontic ritual. Ethereum is not simply decentralized infrastructure—it is a procedural cosmology, one in which every contract and consensus round is an enactment of ontological choice.</p><h2>Epistemology: Trustless Knowledge and Protocol Consensus</h2><p>Epistemology, the philosophical study of knowledge, has historically revolved around a triad: belief, truth, and justification. In classical Western thought—Plato’s Theaetetus, Descartes’ Meditations, or Kant’s Critique of Pure Reason—knowledge was anchored in the authority of the subject, in the capacity of reason to access, verify, or deduce truths about the world. Ethereum presents a rupture in this schema: knowledge on-chain is trustless, collective, and procedural—anchored not in belief or human testimony, but in protocol-mediated verification.</p><p>\\\nAt the heart of Ethereum’s epistemology is consensus. This is not consensus in the Habermasian or democratic sense, where dialogue and mutual understanding yield legitimacy. Nor is it consensus as expert agreement in the scientific tradition. Instead, it is protocol consensus: a computationally bounded procedure in which a distributed network of validators agrees on the validity of state transitions. Truth is not discovered or debated—it is finalized. This truth is mechanical but not arbitrary. Like Peirce’s pragmatic theory of truth—where beliefs are validated through practical consequences—Ethereum’s truths are meaningful because they settle state, because they affect action. The ledger, in this context, becomes an epistemic apparatus: a trace-generating machine whose “knowledge” is the sum of finalized interactions. Once inscribed, a transaction becomes an ontological and epistemic fact. Ethereum thus operates as what Foucault would call a regime of veridiction—a system that does not merely reflect truth but produces it through institutionalized mechanisms (Foucault, 1977). In Ethereum, this mechanism is not juridical but cryptographic. Blocks are “truth events” in Badiou’s sense: emergent moments that redefine what counts as real, registered within a formal system.</p><p>\\\nSeveral components of Ethereum construct a new epistemic ecology:</p><ul><li>Validators serve as decentralized witnesses, akin to Latour’s “inscription devices”—they observe, verify, and commit.</li><li>Oracles function as hybrid epistemic agents, bridging off-chain phenomena with on-chain representation. They raise ontological and epistemological issues: what is the status of a temperature reading or election result once mediated through an oracle contract?</li><li>Zero-knowledge proofs (ZKPs) introduce a radical form of epistemology: proof without revelation. This challenges the dominant Enlightenment model where knowledge is tied to visibility and transparency. ZKPs enact an epistemology of opacity, echoing Édouard Glissant’s call for the right to not be fully knowable (Glissant, 1997).</li></ul><p>\\\nEthereum also undermines the epistemic centrality of the subject. It does not require intention, belief, or interpretation to establish truth. Instead, it offers a post-representational epistemology—where truth emerges through execution, rather than representation. No single actor “knows” the state; rather, the state is collectively maintained and cryptographically secured. In this sense, Ethereum recalls Buddhist epistemology’s suspicion of permanence and ego-centric knowledge—suggesting instead that truth is emergent, interdependent, and provisional. There is an implicit critique of ideology embedded in this model. Ethereum assumes that authority corrupts and that trust, when centralized, becomes a vector of coercion. By operationalizing “trustlessness,” Ethereum epistemically displaces institutions—banks, states, notaries—and replaces them with code, hashes, and consensus rules. This is both emancipatory and problematic: it liberates verification from human intermediaries, but also reifies the authority of machines.</p><p>\\\nStill, Ethereum is not anti-human. Rather, it is trans-human in its epistemology: knowledge is distributed, automated, and procedural, but humans still write the contracts, run the nodes, and interpret the chain. Ethereum does not replace epistemology—it expands it. It adds new modalities of knowing that are non-discursive, non-propositional, and non-representational.</p><p>\\\nTo summarize, Ethereum’s epistemology is:</p><ul><li>Trustless (truth without institutional authority);</li><li>Procedural (truth via protocol execution);</li><li>Post-representational (knowledge without a knowing subject);</li><li>Multiperspectival (validators, oracles, and other agents of distributed knowledge);</li><li>Foucauldian in its power-knowledge structure;</li><li>Peircean in its pragmatic finalization of belief through consequence.</li></ul><p>\\\nEthereum, in this light, becomes a new kind of epistemic engine—not one that reflects the world, but one that produces reality through consensus, computation, and code.</p><h2>Ethics: Smart Contracts, Determinism, and Algorithmic Justice</h2><p>If traditional ethics asks, How should we live?, Ethereum poses a new question: How should we live when decisions are encoded in code? In Ethereum, ethics is neither purely deontological (duty-based) nor consequentialist (outcome-based); rather, it is procedural, embedded in the deterministic execution of smart contracts and consensus algorithms. This procedurality shifts ethical responsibility from human discretion to encoded logic—a development both liberating and fraught with philosophical tension.</p><h3>Code as Law, Law as Ritual</h3><p>Law has long served as the formal instantiation of moral reasoning. But whereas legal systems historically evolved through debate, interpretation, and revision, Ethereum’s smart contracts are self-executing and immutable once deployed. They resemble lex cryptographia, a concept explored by legal scholar Primavera De Filippi, where “law” is not debated but run. This recalls natural law theory, where justice is inscribed into the fabric of the universe—but here, the \"natural\" order is authored by developers, not divinity. It also echoes Hobbesian sovereignty, where rules are enforced without appeal. In Ethereum, the Leviathan is the EVM, and its will is final upon execution. But this mechanical clarity comes at a cost. Without interpretative elasticity, smart contracts risk what legal theorists call rule-based injustice: the precise application of a rule in a context where mercy or nuance is warranted. A contract may execute flawlessly but fail ethically. As Lawrence Lessig famously observed, code is law—but it is a law without judges.</p><h3>Stoicism, Kant, and the Ethics of Necessity</h3><p>The ethical logic of Ethereum recalls Stoic philosophy, which emphasized aligning one's will with the rational order of the cosmos. In this view, virtue lies in accepting necessity. Smart contracts embody a similar ethic: they demand that users accept outcomes predetermined by logic, not intention. Yet, unlike Stoicism, which allowed for internal moral deliberation, Ethereum forecloses such spaces. There is no inner appeal once the contract is triggered. This risks collapsing moral agency into mechanical compliance. In Kantian terms, while Ethereum offers a categorical imperative—execute as promised—it lacks the moral reasoning behind the act. Some protocols attempt to mitigate this. DAOs and governance layers introduce democratic discretion—rules can be changed, proposals debated. This resembles Habermas' discourse ethics, where legitimacy arises through communicative rationality. Here, Ethereum serves as a forum rather than a judge, where norms evolve through participation.</p><p>Following Judith Butler, we can frame Ethereum’s ethical logic not as a set of pre-given rules but as performative. A DAO is not a static moral entity but an evolving scene of ethics—a platform where moral decisions are enacted iteratively. This connects with practice theory in anthropology and sociology, where meaning and normativity emerge through repetition and use. The DAO becomes a moral laboratory, where communities test different mechanisms of decision-making: quadratic voting, conviction voting, futarchy. Each is an experiment in encoding fairness. These are not merely technical parameters but moral architectures, structuring who gets to decide, on what terms, and with what weight. We may call this a procedural ethics: not ethics as doctrine, but as programmable process. It is closer to Aristotle’s phronesis—practical wisdom—than to codified law. In this view, ethics in Ethereum is emergent: it must be learned, adjusted, iterated.</p><h3><strong>Critiques: Exclusion, Bias, and Algorithmic Harm</strong></h3><p>However, this ethical turn toward code must contend with the critique of algorithmic harm. Scholars such as Cathy O’Neil (2016) and Ruha Benjamin (2019) warn that automated systems often reproduce existing inequalities under the guise of neutrality. In Ethereum, access to protocols is theoretically universal, but in practice constrained by literacy, capital, and bandwidth. The absence of intermediaries does not guarantee the absence of power. Moreover, protocol design itself can encode bias. Gas fees disproportionately affect low-volume users; token distributions replicate financial inequality; smart contract bugs can devastate users with no legal recourse. Ethereum thus risks becoming an ethics of exclusion: a system that privileges code as truth, but forgets the uneven terrain of access and participation. This demands a shift toward reflexive ethics—an ethics not only encoded in contracts but debated in forums, surfaced in audits, and tested through lived experience. Projects like Gitcoin’s “Quadratic Funding” or MetaGov’s deliberative tooling illustrate how Ethereum can evolve into a normative medium, not just a transactional one.</p><p>\\\nThus, Ethereum’s ethical architecture challenges us to rethink foundational moral categories:</p><ul><li>Autonomy becomes composable and executable;</li><li>Responsibility is redistributed across code and user;</li><li>Justice is procedural and programmable;</li><li>Virtue is iterated through governance.</li></ul><p>\\\nEthereum does not merely enforce rules; it reshapes the very grammar of moral action. Its ethics are not static but recursive—emerging not from lawgivers or codes of conduct, but from interaction, iteration, and communal governance. It is not a final form of justice, but an unfolding praxis of ethical experimentation.</p><h2>Aesthetics: Rhizomes, Rituals, and Protocol Poetics</h2><p>Beyond logic and utility, Ethereum unfolds as an aesthetic phenomenon. Its architecture—recursive, composable, and networked—is not only functional but expressive. To understand Ethereum aesthetically is to see it not merely as infrastructure but as an aesthetic regime: a field where form, perception, and affect are governed by code.</p><p>Ethereum’s composability invites us to consider Gilles Deleuze and Félix Guattari’s concept of the rhizome. A rhizome is a structure without a beginning or end, without hierarchy or binary opposition. It connects “any point to any other,” forming a mesh of relations rather than a tree of causes. Ethereum mirrors this logic. Smart contracts, dApps, and protocols can fork, recombine, and iterate endlessly. There is no central scaffold; instead, a modular landscape emerges—a horizontal web of aesthetic production. This rhizomatic structure opposes the cathedral-like architecture of Web2 platforms, replacing vertical design with decentralized growth. NFTs, generative art platforms (like Art Blocks), and autonomous worlds do not exist as isolated works but as aesthetic ecosystems. They spawn endless derivatives, callbacks, and recursive visual and narrative logics. Art here is not about final form, but about procedural expansion.</p><h3>Protocol as Ritual: The Liturgical Chain</h3><p>While Ethereum disenchants trust (removing gods, banks, and judges), it re-enchants protocol. Every transaction is a ritual: a gesture inscribed permanently into a shared ledger, witnessed by validators, sealed by cryptographic consensus. This is not far from the liturgical structure of religious traditions: symbolic action, performed before a witnessing structure, producing binding change. In this sense, Ethereum revives the sacred under the logic of computation. Validators perform rites of verification. Blocks become ritual intervals—discrete pulses in the cosmic rhythm of the chain. Repetition, permanence, and public legibility generate a ritual aesthetics of code. This resonates with media theorist Yuk Hui’s concept of cosmotechnics—the idea that every technology encodes a cosmology. Ethereum encodes a computational cosmology: a worldview where truth is formal, public, and irreversible. It replaces divine law with cryptographic order, yet retains the performative gravitas of sacred ritual.</p><h3>The Poetics of Solidity: Code as Literary Device</h3><p>Solidity—the programming language of Ethereum—is not only technical; it is aesthetic material. Like poetry, it is terse, formal, and prone to ambiguity. A single misplaced line can rupture meaning. In this, smart contracts resemble Oulipo experiments in constrained writing: meaning generated through formal restriction. Simon de la Rouvière, Sarah Friend, and Rhea Myers explore the poetic affordances of Solidity, crafting works that are not merely on-chain but of-chain: that use logic to produce ambiguity, indeterminacy, and affect. Here, Ethereum becomes a platform for procedural poetics: not art that tells, but art that runs. Just as McKenzie Wark argues for “games as the new allegories,” we might say Ethereum is a platform where poems are protocols. A DAO can be an epic; a contract, a haiku; a token, a metaphor. Art is no longer consumed—it is executed, transacted, become-machine.</p><h3>From Aura to Address: The Aesthetic Politics of NFTs</h3><p>Walter Benjamin famously lamented the loss of the aura in mechanical reproduction. Ethereum, in a paradoxical twist, reintroduces aura through reproducibility. NFTs are infinitely copyable, yet uniquely indexed. Their aura lies not in scarcity but in traceability. NFTs reframe questions of authorship, ownership, and exhibition. Who owns an artwork? The minter? The wallet holder? The community that curates it? What counts as an original in a world of remixes, airdrops, and derivatives? This aesthetic field opens space for posthuman creativity. AI-generated works, DAOs as curators, autonomous agents as artists—Ethereum displaces the Romantic artist with a decentralized assemblage. The artwork becomes an event, not a product: a ritual of minting, trading, remixing, and remembering.</p><p>\\\nThus, Ethereum’s aesthetics are not ornamental—they are ontological. They reveal a world where code becomes symbol, transaction becomes rite, and community becomes form. Ethereum is not just infrastructure for aesthetic production—it is itself an aesthetic medium: recursive, ritualistic, rhizomatic. To think Ethereum aesthetically is to witness the birth of a protocol poetics—an art form where logic, ritual, and symbol converge in a new kind of digital beauty.</p><h2>Anthropology: The Eterean Archetype and the Networked Self</h2><p>Philosophical anthropology asks: What is the human? In the age of decentralized protocols, biometric identities, pseudonymous wallets, and machine legibility, Ethereum answers not with essence but with function, not with substance but with address. Ethereum gives rise to a new anthropological figure—the Eterean. Neither a traditional citizen nor a passive user, the Eterean is a hybrid entity: simultaneously sovereign and collective, traceable and anonymous, embodied and abstract. This emergent archetype signals a shift in the very structure of identity and subjectivity under conditions of decentralization.</p><h3>From Subject to Address: Identity After Humanism</h3><p>The Eterean is not defined by name, birth, or nation-state. Instead, they are constituted by:</p><ul><li>a sequence of interactions,</li></ul><p>\\\nIdentity is no longer narrative—it is relational, modular, and computable. As Gilles Deleuze foresaw in his “Postscript on the Societies of Control,” we are moving from the era of enclosed individuals to that of dividuals—splittable, reconfigurable units of data and behavior. Ethereum embraces this dividual logic. A single person may operate through multiple wallets, ENS names, and roles across protocols. Identity becomes multi-scalar, transactional, and composable. It is not unified, but distributed—stitched together across layers of pseudonymity, governance participation, liquidity provision, and artistic curation. The Eterean, then, is a posthuman subject. Like Donna Haraway’s cyborg, the Eterean is a boundary-breaker, blurring the line between human, machine, and collective. Ethereum is not only a digital environment—it is an anthropotechnical matrix that reconditions what it means to be a social being.</p><h3>The Social Fabric of Protocols: DAOs as Institutions</h3><p>Ethnographers have long studied institutions—churches, families, states—as primary organizers of human life. In Ethereum, these roles are played by DAOs. But DAOs are not mere governance platforms; they are ritualized collectivities that mediate identity, belonging, and responsibility. DAOs introduce:</p><ul><li>new forms of collective action (e.g., proposal voting, working groups),</li><li>new concepts of membership (token-gated access, soulbound credentials),</li><li>new rituals of legitimacy (on-chain participation, quadratic voting, reputation-based roles).</li></ul><p>\\\nIn this sense, DAOs are post-institutional institutions—emergent normative systems encoded in code, guided not by tradition but by composable logic. They enable modular personhood: you are a steward here, a delegate there, a lurker elsewhere. This reflects Édouard Glissant’s concept of the Relation-subject: identity formed not in isolation, but through ongoing interaction, opacity, and negotiation. Ethereum does not prescribe who the Eterean is—it provides the grammar to be plural.</p><h3>The Eterean as Myth and Meme</h3><p>Every political epoch has its mythic figure:</p><ul><li>The Citizen (of the Republic),</li><li>The Bourgeois (of Capitalism),</li><li>The Worker (of Socialism),</li><li>The Cyborg (of Technofeminism),</li><li>The Hacker (of the Early Internet).</li></ul><p>\\\nEthereum offers the Eterean: an archetype born of composability, sovereignty, and ritual. The Eterean does not simply obey protocols—they compose them. They do not merely own their data—they orchestrate their presence across multiple symbolic registers: economic (via tokens), social (via DAOs), aesthetic (via NFTs), and epistemic (via governance). In this sense, the Eterean is both subject and substrate—a being whose existence is constantly enacted through interaction with code. And like all archetypes, the Eterean is also a meme: a replicable cultural unit. The idea of the sovereign, self-sovereign, post-national citizen—traversing discords, multisigs, and testnets—is not just an identity. It’s an imaginary.</p><p>What happens when personhood becomes programmable? When agency is fragmented, recombined, and routed through logic gates? Ethereum’s anthropology raises fundamental questions for political theory and rights discourse:</p><ul><li>Who is the subject of rights in a DAO?</li><li>What counts as representation in a pseudonymous network?</li><li>Can a multisig wallet hold moral responsibility?</li></ul><p>\\\nThese are not speculative puzzles—they are practical design challenges. Ethereum's ecosystem is building new legible selves: entities that can act, vote, be held accountable—without defaulting to traditional identifiers. This opens a new chapter in the philosophy of the person, where agency is no longer exclusively human, but shared with and extended by systems. In conclusion, Ethereum inaugurates a novel anthropology. The Eterean is not a utopian figure—it is a pragmatic abstraction, one that emerges from the mesh of contracts, rituals, and protocols. Ethereum does not answer the anthropological question of \"What is the human?\" but reframes it: What can a cryptographic subject do? How does one become many across a chain?</p><h2>Teleology: Toward Digital Liberation and Collective Coordination</h2><p>Teleology concerns ends, purposes, and the aims of systems. While many technologies disguise or obscure their ends, Ethereum places its aspirations in plain sight: autonomy, decentralization, transparency, and programmable coordination. Yet these values do not resolve into a single utopia. Rather, Ethereum presents an open teleology—a framework that enables communities to define and pursue their own collective goals.</p><h3>Coordination as Telos: From Market to Mechanism</h3><p>Ethereum is often described as a general-purpose computational layer or “world computer,” but at its heart, it is a machine for coordination. It operationalizes a vision shared by thinkers like Elinor Ostrom and Friedrich Hayek: that decentralized decision-making can outperform central planning, provided there are transparent rules and credible commitment mechanisms.</p><p>\\\nThrough smart contracts, token economies, and DAOs, Ethereum creates a substrate where:</p><ul><li>cooperation does not require trust,</li><li>incentives can be transparently aligned,</li><li>and governance can be encoded and upgraded iteratively.</li></ul><p>\\\nThe telos, then, is not a fixed outcome (e.g., equality, growth, utopia), but a condition: collective self-governance at scale. This aligns Ethereum with prefigurative politics—movements that build the future by enacting its values in the present. Rather than lobbying for better institutions, Ethereum makes them: composable, forkable, auditable. It is not a roadmap—it is a toolkit.</p><h3>Digital Liberation: A Post-Nation Political Imagination</h3><p>Ethereum’s vision of digital sovereignty echoes the emancipatory projects of libertarian socialism, crypto-anarchism, and cyberfeminism. It proposes a world where the rights to transact, organize, and express are not granted by states but guaranteed by protocols. But Ethereum goes further: it redefines political subjectivity. Citizenship is no longer tied to geography or birth. Instead, one can be a governor in a DAO, a steward in a protocol, or a citizen in a network state. This is a post-national teleology—a model of governance based not on borders, but on participation, alignment, and code. Ethereum does not yet replace the nation-state, but it introduces rival logics of legitimacy, grounded in participation rather than paternalism. As Vitalik Buterin notes in The Most Important Scarce Resource is Legitimacy, Ethereum’s governance—and by extension, its future—is bound to legitimacy production: the capacity of communities to sustain norms, coordinate upgrades, and enact change without coercion.</p><h3>Futurisms: Infinite Garden and Beyond</h3><p>The Ethereum Foundation has embraced a poetic metaphor to express its long-term vision: the Infinite Garden. Unlike a fortress or a corporation, the garden is: open-ended, non-linear, cultivated rather than commanded.</p><p>\\\nThis metaphor marks a subtle but powerful shift in teleological thinking. Ethereum is not a pipeline to a specific end-state. It is a generative ecology, where experimentation, diversity, and resilience emerge not through top-down design, but through continuous tending. The Infinite Garden reflects a Deleuzian telos: not the realization of an ideal form, but the proliferation of differences, capacities, and intensities.</p><p>\\\nIn this view, Ethereum’s “goal” is not achievement but becoming.</p><p>\\\nAt the same time, other visions—Solarpunk, Lunarpunk, Defensive Accelerationism—sketch alternate teleologies:</p><ul><li>Solarpunk sees Ethereum as the infrastructure for sustainable, regenerative, and cooperative futures.</li><li>Lunarpunk emphasizes resistance, privacy, and crypto as refuge in hostile environments.</li><li>d/acc advocates for measured acceleration—a world where technology is developed with care, anticipating collapse and cultivating robustness.</li></ul><p>\\\nEach of these visions orients Ethereum toward a different future, reflecting the system’s deep pluriversal character: one protocol, many trajectories.</p><p>No teleology is immune to contradiction. Ethereum’s dreams of liberation coexist with: plutocratic risks in Proof-of-Stake systems, extractive tokenomics, governance capture. These tensions do not invalidate its telos, but they complicate it. Ethereum is not a perfected system—it is a site of philosophical struggle between autonomy and regulation, openness and constraint, plurality and coherence. The promise of Ethereum lies not in its claims, but in its capacity to hold competing futures. It offers a space where anarchism and institutionalism, openness and privacy, freedom and safety, can be prototyped, tested, and refined. In this sense, Ethereum’s teleology is not a destiny—it is an invitation.</p><h2>Conclusion: Ethereum as Philosophical Machine</h2><p>Ethereum is often portrayed as a technical infrastructure—a decentralized computational substrate for finance, identity, and organization. But beneath this utilitarian description lies something more profound: Ethereum is a philosophical machine. It does not simply implement ideology; it modulates the very conditions under which ideology, ethics, and knowledge are possible.</p><h3>Beyond Instrumentality: Ethereum as Ontological Generator</h3><p>Ethereum’s architecture—the blockchain, smart contracts, consensus mechanisms—does more than perform tasks. It enacts a mode of being, one that aligns with what Martin Heidegger might have called world disclosure: it reveals a world in which things appear, relate, and endure differently.</p><ul><li>Time becomes block-time: discrete, measurable, programmable, yet experienced in latency and anticipation.</li><li>Truth is no longer representational but procedural—produced by consensus, inscribed in hash.</li><li>Agency dissolves into assemblages—contracts, tokens, DAOs—all capable of action without identity.</li></ul><p>\\\nThese are not metaphors—they are ontological realities encoded in protocols. Ethereum is not about “what is”—it is about how being is structured in a world governed by cryptographic trust.</p><p>Philosophy has long sought unity: a single truth, a coherent subject, a rational system. Ethereum refuses these closures. It hosts not one ontology, but many; not one ethics, but evolving norms; not one community, but multitudes. This makes Ethereum pluriversal: a platform that holds and coordinates incompatible logics without resolving them into sameness.</p><p>\\\nLike Édouard Glissant’s poetics of relation, Ethereum embraces opacity, multiplicity, and irreducible difference.</p><ul><li><p>A DAO practicing mutual aid can co-exist with a DeFi protocol optimizing yield.</p></li><li><p>A privacy-focused Lunarpunk enclave can share infrastructure with a Solarpunk regenerative community.</p></li><li><p>Code written in the same language—Solidity—can express radically divergent political imaginations.</p></li></ul><p>Ethereum thus functions as what Deleuze would call a desiring-machine: not a fixed ideology, but a system that enables flows of subjectivity, value, and relation to form, dissolve, and recombine.</p><h3>From Critique to Participation</h3><p>To think Ethereum philosophically is not simply to critique it. It is to participate in its becoming. Every governance vote, protocol upgrade, and dApp deployment contributes to the shape of its ethics, epistemology, and ontology. Ethereum doesn’t just allow new political forms—it necessitates philosophical agency from its users. To use Ethereum is to enter into a relation with code, community, and consequence. One becomes not just a consumer or citizen, but a co-architect of the digital real. This is perhaps Ethereum’s most radical proposition: that philosophy is no longer something one reads—it is something one does, in the act of coding, validating, coordinating, and caring for shared infrastructure.</p><h3>Toward a Praxis of Protocol</h3><p>The future of Ethereum—as of philosophy—depends on our capacity to hold contradictions, to navigate the tensions between automation and care, anonymity and community, scalability and sovereignty. Ethereum offers no easy answers. But it provides something better: a canvas for philosophical experimentation. It is, in the end, a living system of recursive design and recursive critique. Each block is a gesture; each smart contract a fragment of ethical intention made executable. Ethereum is not a philosophy of the past. It is not even a philosophy of the future. It is a philosophy in motion—an open composition of code, thought, and collective imagination. To philosophize Ethereum is to garden the protocol, to care for the commons, to accept the paradox of autonomy and dependence, and to embrace the infinite recursion of decentralization itself.</p><ul><li>Aristotle. (1984). Politics (C. Lord, Trans.). University of Chicago Press.</li><li>Aristotle. (2004). Rhetoric (W. Rhys Roberts, Trans.). Dover Publications.</li><li>Benjamin, R. (2019). <em>Race after technology: Abolitionist tools for the new Jim code</em>. Polity Press.</li><li>Bergson, H. (1913). Time and free will: An essay on the immediate data of consciousness.</li><li>Butler, J. (1990). Gender trouble: Feminism and the subversion of identity. Routledge.</li><li>Davis, J. B. (2015). The blockchain as a narrative technology: Investigating the social ontology and normative configurations of cryptocurrencies. Philosophy &amp; Technology, 28(1), 107–132.</li><li>DeLanda, M. (2006). A new philosophy of society: Assemblage theory and social complexity. Continuum.</li><li>Deleuze, G., &amp; Guattari, F. (1987). A thousand plateaus: Capitalism and schizophrenia. University of Minnesota Press.</li><li>Escobar, Arturo (2020),&nbsp;<em>Pluriversal Politics: The Real and the Possible</em>. Durham, N.C.: Duke University Press, 232 pp.&nbsp;Translation by David Frye.</li><li>Floridi, L. (2013). The ethics of information. Oxford University Press.</li><li>Foucault, M. (1969). The archaeology of knowledge. Pantheon Books. Foucault, M. (1977). Discipline and punish: The birth of the prison. Pantheon Books.</li><li>Galloway, A. R. (2018). Blockchain as philosophy. In J. Geiger &amp; M. Schneider (Eds.), Blockchain and philosophy: New prospects for an old tradition (pp. 1–14). Routledge.</li><li>Glissant, É. (1997). Poetics of relation (B. Wing, Trans.). University of Michigan Press.</li><li>Haraway, D. (1991). Simians, cyborgs, and women: The reinvention of nature. Routledge.</li><li>Harman, G. (2005). Guerrilla metaphysics: Phenomenology and the carpentry of things. Open Court.</li><li>Harman, G. (2018). Object-oriented ontology: A new theory of everything. Pelican.</li><li>Jonas, H. (1984). The imperative of responsibility: In search of an ethics for the technological age. University of Chicago Press.</li><li>Kant, I. (1781/1998). Critique of pure reason (P. Guyer &amp; A. Wood, Trans.). Cambridge University Press.</li><li>Latour, B. (2005). Reassembling the social: An introduction to actor-network theory. Oxford University Press.</li><li>O'Neil, C. (2016). <em>Weapons of math destruction: How big data increases inequality and threatens democracy</em>. Crown Publishing Group.</li><li>Meillassoux, Q. (2008). After finitude: An essay on the necessity of contingency. Continuum. Stiegler, B. (2010). Taking care of youth and the generations (D. Ross, Trans.). Stanford University Press.</li><li>Tiqqun. (2001). The cybernetic hypothesis. Ill Will Editions.</li><li>Virilio, P. (2000). The information bomb (C. Turner, Trans.). Verso.</li><li>Zuboff, S. (2019). The age of surveillance capitalism: The fight for a human future at the new frontier of power. PublicAffairs.</li></ul>","contentLength":39726,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"An Electric Racecar Drives Upside Down","url":"https://tech.slashdot.org/story/25/04/14/0542240/an-electric-racecar-drives-upside-down?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744616040,"author":"EditorDavid","guid":22772,"unread":true,"content":"Formula One cars, the world's fastest racecars, need to grip the track for speed and safety on the curves — leading engineers to design cars that create downforce. And racing fans are even told that \"a Formula 1 racecar generates enough downforce above a certain speed that it could theoretically drive upside down,\" writes the automotive site Jalopnik. \n\n\"McMurtry Automotive turned this theory into reality after having its Spéirling hypercar complete the impressive feat...\"\n\n\nAdmittedly, the Spéirling's success can be solely attributed to its proprietary 'Downforce-on-Demand' fan system that produces 4,400 pounds of downforce at the push of a button... For those looking to do the math, Spéirling weighs 2,200 pounds. With the stopped car's fan whirling at 23,000 rpm, the rig was rotated to invert the road deck... Then, the hypercar rolled forward a few feet before stopping while inverted. The rig rotated the road deck back down, and the Spéirling drove off like nothing happened. \nThe McMurtry Spéirling, as a 1,000-hp twin-motor electric hypercar, didn't have to clear the other hurdles that an F1 car would have clear to drive upside down. Dry-sump combustion engines aren't designed to run inverted and would eventually fail catastrophically. Oil wouldn't be able to cycle through and keep the engine lubricated. \nThe car is \"an electric monster purpose-built to destroy track records,\" Jalopnik wrote in 2022 when the car shaved more than two seconds off a long-standing record. The \"Downforce-on-Demand\" feature gives it tremendous acceleration — in nine seconds it can go from 0 to 186.4 mph (300 km/h), according to Jalopnik. \n\n\"McMurtry is working towards finalizing a production version of its hypercar, called the Spéirling PURE. Only 100 will be produced.\"","contentLength":1789,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How to Prepare for the Next Crypto Catastrophe (Because It’s Probably Coming)","url":"https://hackernoon.com/how-to-prepare-for-the-next-crypto-catastrophe-because-its-probably-coming?source=rss","date":1744615677,"author":"Obyte","guid":22811,"unread":true,"content":"<p>Have you ever seen a black swan? Probably not. They’re not common (unless you’re in Australia), and we’re more accustomed to white swans worldwide. That’s why, since 2001, the writer and mathematician Nassim Nicholas Taleb has used this rare animal to describe outlier events, often negative, very impactful, and almost impossible to predict. That’s the ‘Black Swan Theory’.</p><p>\\\nThe term doesn’t differ that much in the cryptocurrency realm. <strong>A Black Swan Event in crypto is an unexpected and rare event that has a huge impact on the market, often causing extreme price crashes or major disruptions.</strong> As we’ve said before, these events are usually unpredictable, but they may seem obvious only in hindsight. Examples include major exchange collapses, sudden regulatory crackdowns, or yes, a global pandemic.</p><p>\\\nBesides the price volatility, a sudden event like this can spread fear and uncertainty, causing many to sell their holdings, reducing liquidity. Governments might respond with stricter regulations, affecting businesses and users. If trust in the market weakens, adoption could slow down, making it harder for cryptocurrencies to reach widespread use. However, Black Swan Events don’t tend to repeat themselves – that’s why they are difficult to predict.</p><h2>Previous Black Swans in Crypto</h2><p><strong>The COVID-19 pandemic was a major Black Swan Event that impacted global markets, including crypto.</strong> In March 2020, as fear spread, investors rushed to sell risky assets,  and other cryptocurrencies to crash by over 50% in just a few days. However, as governments introduced stimulus measures and interest in digital assets grew, crypto markets rebounded and reached new all-time highs in the following years. This event highlighted both the volatility and resilience of cryptocurrencies.</p><p> in 2014 was another major Black Swan Event. Mt. Gox was considered, by many sources, the biggest Bitcoin exchange at the time. However, due to mismanagement and hacks, it lost around 850,000 BTC, leading to its bankruptcy. The collapse shook investor confidence and caused Bitcoin’s price to drop significantly. It also exposed the need for better security and regulation in crypto exchanges, shaping the industry’s approach to risk management.</p><p>\\\n<strong>In 2022, the Terra (LUNA) crash and FTX bankruptcy were two of the most devastating Black Swan Events.</strong> Terra’s algorithmic stablecoin, UST, lost its peg (it wasn’t stable anymore), wiping out billions of dollars and collapsing the entire ecosystem. Later that year, FTX, one of the largest exchanges, went bankrupt due to fraud and mismanagement (and likely as a side effect of Terra, too), further damaging trust in the industry. Both events led to stricter regulations and made investors more cautious.</p><p>\\\nThat’s the thing with Black Swan Events. They’re often devastating enough to make everyone learn from previous mistakes and make efforts (and laws) so that they don’t happen ever again. The European Union, for instance,  after the Terra episode.</p><h2>Future Black Swans in Crypto?</h2><p>While price predictions are never fully reliable, Black Swan events are even more unpredictable. Analysts can study markets and news, forming their own theories and guesses, but nothing is certain—no one can truly see the future. However, some preventive measures are always available.</p><p><strong>To protect themselves from Black Swan Events, crypto investors should diversify their portfolios and avoid putting all their funds into one asset.</strong> Holding a mix of cryptocurrencies, , and even traditional assets can reduce risks during market crashes. Choosing coins that have survived past crises and proven their resilience is also crucial. Long-established projects with strong fundamentals and active development are more likely to withstand unexpected downturns.</p><p>\\\nAdditionally, investors should practice risk management by setting stop-loss orders while engaging in speculative trading, and only investing what they can afford to lose. Keeping funds in secure non-custodial wallets instead of exchanges can also prevent losses  or bankruptcies. Staying informed about market trends and regulatory changes can help users react quickly and make better financial decisions.</p><p>\\\n<strong>It’s also important to remember that cryptocurrencies weren’t created just for speculation. The real value lies in their utility and autonomy.</strong> Instead of chasing price movements, users should focus on projects that offer them some real-world benefits. For example,  has provided a resilient and fully decentralized crypto ecosystem since 2016. Its DAG-based platform eliminates middlemen like miners and “validators” while enabling smart contracts, conditional payments, , self-sovereign ID, textcoins, chatbots, and more, making it a strong choice for those looking for the most resilient crypto ecosystems.</p>","contentLength":4818,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Writing Code Is Easy Now. Reviewing It? That’s Where the Real Work Begins","url":"https://hackernoon.com/writing-code-is-easy-now-reviewing-it-thats-where-the-real-work-begins?source=rss","date":1744614131,"author":"Guy Eisenkot","guid":22810,"unread":true,"content":"<p>\\\nAI code generation has taken off, making it easier than ever to produce functional code. Tools like Cursor, Lovable, Bolt, v0 (etc and etc) can generate entire functions, classes, and even full applications in seconds. But while AI has been racing ahead in code creation, investment in AI-driven code review has lagged behind.</p><p>\\\nAnd that’s a problem—because writing code is only half the battle.</p><p>\\\nIn real-world codebases, success isn’t about how quickly you can generate working code. It’s about whether that code integrates cleanly, remains maintainable, and doesn’t introduce bugs that will haunt the team later. The real bottleneck in software development isn’t typing speed—it’s ensuring that code is correct, scalable, and sustainable over time. The perfect future state is to delegate a task to AI where we have the confidence that it’s actually good enough. And that’s why AI-assisted code review is the next frontier that actually matters.</p><h3><strong>The Illusion of \"Working\" Code</strong></h3><p>It’s easy to fall into the trap of thinking that if code compiles and runs, it’s good enough. AI code generation tools make this even more tempting, providing instant, seemingly functional solutions. But experienced developers know that \"it works\" is just the beginning. Poorly structured, unclear, or overly complex code can turn into technical debt overnight.</p><p>\\\nCode review is what separates code that merely functions from code that endures. The best reviewers don’t just check for correctness; they evaluate whether a change is clear, maintainable, and safe in the broader system. They ask:</p><ul><li>Is this the simplest way to solve the problem?</li><li>Will this be understandable six months from now?</li><li>How does this change interact with the rest of the system?</li><li>Are we introducing unnecessary risk or hidden dependencies?</li></ul><p>\\\nThese are the kinds of questions that code generation tools don’t ask—and that’s why the lack of investment in AI-assisted code review is a glaring gap in today’s development workflows.</p><p>Reviewing code is a completely different skill from writing it. It requires not just technical knowledge, but also architectural thinking and an awareness of long-term consequences. It’s about catching subtle issues that could cause cascading failures later. It’s about recognizing when something is  but <em>practically unmaintainable</em>.</p><p>\\\nGreat code reviewers develop an instinct for complexity. They recognize when a function does too much, when an abstraction hides more than it helps, or when a small change has unintended side effects. And crucially, they know how to communicate these concerns effectively—so that the entire team improves, not just the code.</p><h3><strong>Why AI-Assisted Code Review Is the Missing Piece</strong></h3><p>As codebases grow in size and complexity, even the best human reviewers struggle to keep up. Manually tracing dependencies across multiple services, languages, and APIs is an enormous cognitive load. And with AI tools generating more code than ever, we need AI-powered review tools just as urgently.</p><ul><li>Analyze code changes holistically, recognizing patterns across the entire repository.</li><li>Identify potential breaking changes, security risks, and inefficiencies before they become problems.</li><li>Free up developers from repetitive, tedious checks—so they can focus on design, architecture, and real innovation.</li></ul><h3><strong>Code Review as the True Measure of a Development Team</strong></h3><p>A team’s ability to review code effectively is one of the strongest indicators of long-term success. It determines how quickly new developers ramp up, how well the team handles technical debt, and how resilient the software is to future changes. A strong code review culture doesn’t just produce better code; it produces better engineers.</p><p>\\\nAI code generation is useful, but it’s only part of the equation. If we want to build software that lasts, we need to invest just as much in AI-driven code review. Because in the end, success isn’t about how fast you can push changes—it’s about whether those changes make your codebase stronger or weaker over time.</p>","contentLength":4035,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"99.98% of Tokens Are 'Average' or Worse – Here's What You're Missing On Token Reputation Index","url":"https://hackernoon.com/9998percent-of-tokens-are-average-or-worse-heres-what-youre-missing-on-token-reputation-index?source=rss","date":1744614078,"author":"Elsa","guid":22809,"unread":true,"content":"<p>\\\nAs the crypto market continues its downward spiral, many tokens have plummeted 80-90% from their all-time highs. But this isn’t just a macro trend—there are deeper structural issues at play. A groundbreaking report by bitsCrunch, which analyzed 2 million tokens across 16 weighted metrics using AI-powered algorithms, reveals a harsh truth: 94% of tokens are mediocre at best, and only 14 earned a top-tier “Excellent” rating. Let’s unpack the data and what it means for investors navigating this turbulent market.</p><h2>A Market Flooded with Low-Quality Tokens</h2><p>bitsCrunch’s Token Reputation Index exposes a stark reality: the crypto ecosystem resembles a precarious pyramid. At the top, a mere 14 tokens (0.0007% of the total) achieved an “Excellent” rating, while roughly 317 (0.016%) scored “Good.” The remaining 99.98%—over 1.9 million tokens—fall into the “Average” or worse categories.</p><p>\\\nEthereum remains the dominant blockchain, hosting 54.56% of all tokens (1.1 million+). However, quality varies wildly. For example, according to bitsCrunch data, 573,739 Ethereum tokens scored “Fair”, while only 7 Ethereum tokens earned the “Excellent” designation. Emerging chains like Polygon and Base, which rank second and third in token volume, face similar challenges. On Polygon, 96.7% of its 451,000 tokens are classified as “Fair” or “Terrible,” while Base’s 336,000 tokens see 75.6% stuck in the “Fair” tier.</p><p>\\\nAvalanche offers a glimmer of contrast. Though its token count is just 10.7% of Ethereum’s, 4.03% of its tokens score “Average” compared to Ethereum’s 0.34%.</p><h2>Why Most Tokens Fail: Three Fatal Flaws</h2><p>The report identifies three critical red flags plaguing low-scoring tokens. First, liquidity ghost towns dominate. On Ethereum, tokens in the “Fair” tier have liquidity pools five times smaller than top-rated ones. Thin liquidity amplifies volatility, triggering panic sells and trapping investors in illiquid positions.</p><p>\\\nSecond, centralized ownership runs rampant. In Ethereum’s “Terrible” tier, the top 10 holders often control disproportionate shares, raising risks of market manipulation. By contrast, “Excellent” tokens exhibit healthier decentralization, distributing ownership more evenly to mitigate systemic risks.</p><p>\\\nThird, abysmal trading activity plagues low-rated tokens. They suffer from negligible trading volumes and fewer profitable traders, creating a vicious cycle of disinterest. High-rated tokens, however, attract long-term holders through consistent volume and positive ROI narratives.</p><h2>Chain Wars: Ethereum’s Double-Edged Dominance</h2><p>Ethereum’s first-mover advantage comes with a paradox. On one hand, its robust DeFi infrastructure, developer tools, and massive user base make it the go-to platform for token launches. On the other, gas fees and network congestion have driven many projects to cheaper alternatives like Polygon and Base. These chains, however, struggle to match Ethereum’s liquidity depth, leaving their ecosystems fragmented and volatile.</p><p>\\\nBase, Coinbase’s Ethereum Layer 2 chain, exemplifies this tension. Its token count has surged to nearly three times Avalanche’s, but most projects there remain in their experimental “teenage phase”—high on hype but unproven in sustainability. Meanwhile, chains like Avalanche and Linea are carving niches through technical differentiation, though limited user bases continue to stifle growth.</p><p>The data delivers a brutal reality check: token quantity does not equal quality. As regulators sharpen their focus and investors grow savvier, projects must prioritize three pillars to survive: liquidity resilience, decentralized holder distribution, and sustainable trading activity.</p><p>\\\nThe next bull run will separate crypto’s “MAG-7” contenders from the rubble. API tools like the Token Reputation Index will become critical for cutting through the noise, helping investors identify projects built for longevity—not just viral pumps.</p>","contentLength":4001,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Chaos on Earth: Wars, Crises, Disasters... What if We Just Move to Mars?","url":"https://hackernoon.com/chaos-on-earth-wars-crises-disasters-what-if-we-just-move-to-mars?source=rss","date":1744614044,"author":"Daria Leonova","guid":22808,"unread":true,"content":"<p>\\\nAs kids, many of us dreamed of becoming astronauts. But these days, it seems that just flying into space isn’t enough. Now, humanity dreams of something bigger — <strong>colonizing another planet</strong>. But is that possible today?</p><p>\\\nUnfortunately, the short answer is no. The most promising candidate for terraforming is Mars, but turning it into a livable world would require massive transformations — and right now, our technologies just aren’t there yet.</p><p>\\\nBut that hasn’t stopped the world’s brightest minds. In fact, there's already a growing list of bold, fascinating ideas — some of which are . Space agencies and private companies are working hard on technologies that may not terraform Mars tomorrow, but they’re laying the foundation to one day make it possible.</p><p>One of the things humanity is already capable of building is a base on the Moon. In fact, NASA’s  aims to establish the first long-term human presence on the lunar surface.</p><p>Because it would teach us an essential set of skills for further space exploration and even terraforming:</p><ul><li><p>How to live in extreme environments;</p></li><li><p>How to grow food in closed systems;</p></li><li><p>How to recycle water and air;</p></li><li><p>How to mine local materials for fuel or construction.&nbsp;</p></li></ul><p>In other words, how to live and work on another world - something we’ve only simulated in labs or thought about theoretically. Now, it is time to test it with real-life experience.&nbsp;</p><p>:::tip\n<em>The average temperature on the Moon is -</em>25°C (-13&nbsp;°F)<em>. However, according to the latest calculations, the constant temperature in caves on the Moon is +17</em>°C(+63&nbsp;°F)<em>, which is super comfortable for people and sensitive equipment.</em></p><h2>ISRU (In-Situ Resource Utilization)</h2><p>We’ve all travelled at least once in our lives, so we know — you can’t take everything with you. But in space, the stakes are much higher. You can’t just pay $50 for an extra kilo like you would with airline baggage. Every gram counts.</p><p>That’s why , or <em>In-Situ Resource Utilization</em>, is a game-changing concept. It’s all about using resources available at your destination — like extracting oxygen from carbon dioxide on Mars or mining lunar soil for water and fuel. \\n </p><p>NASA is actively developing and testing  technologies right here on Earth, Hawaii, where volcanic terrain closely resembles the surface of the Moon and Mars. These experiments help refine the hardware and processes that could one day support astronauts far from home.</p><p>:::tip\nSpaceX’s Starship is designed to be ultra-efficient, with delivery costs of exactly $50 per kilogram — but only to Low Earth Orbit (LEO). Beyond that, costs and complexity rise sharply, so ISRU becomes even more essential for distant space missions.&nbsp; </p><h2>Nuclear fuel for rockets and power for colonies</h2><p>The search for an alternative source of energy is not only a problem faced by earthlings when buying an electric car. Space corporations are looking for more efficient fuel for their rockets too.&nbsp;Rocket propellant presents a classic paradox: the more fuel you carry, the heavier your spacecraft becomes. And the heavier it is, the more fuel you need.</p><p>On top of that, space travel demands extremely precise calculations with a lot of input variables. This includes the weight of the rocket, which changes constantly due to the burning of the fuel.&nbsp;</p><p>\\\nThese issues have pushed scientists to look for an alternative approach. Like nuclear energy. It is obvious that such fuel is harmless for our planet, so it looks impossible to use it for space ships launching. However, we can use it safely outside Earth’s atmosphere.  \\n   \\n Currently, NASA is exploring two propulsion systems – nuclear thermal and nuclear electric. Both systems could drastically reduce travel times to distant planets and may one day serve as power sources for other planets' colonies.</p><p>:::tip\n With nuclear thermal propulsion (NTP), a spacecraft could reach Mars in around 3–4 months, compared to 6–9 months with current chemical rockets.</p><p>To increase the efficiency of launching ships and travelling through the Earth's atmosphere, there are some hypothetical concepts. And Skyhook is among them. The idea is simple and beautiful. Imagine a giant rotating cable orbiting Earth, dipping into the upper atmosphere and “catching” a spacecraft launched from the ground. It would then use its momentum to fling the spacecraft into a higher orbit — dramatically reducing the fuel needed. In other words, you can transfer the energy from the tether and get a massive boost when releasing the ship.&nbsp;</p><p>You may have heard about space elevators, another concept that solves the same problem. However, elevators remain sci-fi for today because no suitable material exists for their construction. At the same time, Skyhook seems to be able to be implemented with existing carbon nanotubes or graphene composites.&nbsp;</p><p>:::tip\nA space elevator would need a cable 35,786 km long — almost three Earth diameters. However, the Japanese construction company Obayashi Corp has proposed building a space elevator by 2050.&nbsp;</p><p>Today, another technology relates directly to the colonisation of Mars - Synthetic Biology. Theoretically, it could even let us skip the massive 200-year process of warming the planet with giant orbital mirrors. In a nutshell, the idea is to engineer microbes to speed up the process of making Mars habitable.&nbsp;</p><p>Among tasks that engineered microbes and plants can do:</p><ul><li> from CO₂ (on Mars, for example)</li><li> in Martian or lunar soil to help grow plants</li><li>, where microbes extract useful metals or materials from rocks</li><li><strong>Breaking down toxic substances</strong> (like perchlorates in Martian soil)</li><li>Creating food, fuel, and medicine in space from simple inputs</li></ul><p>\\\nDetailed ideas of how this can work out you can find in this .</p><p>:::tip\nNASA is already trying to use microorganisms to produce nutrients—off Earth and on demand—that will be critical for human health in space. The experiment is called .</p><p>\\\nAlthough terraforming Mars or any other planet in the near future is impossible, preparatory steps can be taken. We are not ready to reshape other planets and make them more Earth-like. The scale is vast, the challenges are immense, and the timelines stretch across centuries. But we have technologies, materials, and ideas for “smaller” technologies that will make space colonization possible.</p><p>\\\nWe’re still learning to crawl before we can fly. But it turns out you can’t fly in Space if you don’t know how to crawl :)</p>","contentLength":6412,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The TechBeat: The Internet Is Rigged, Only Decentralization Can Fix It (4/14/2025)","url":"https://hackernoon.com/4-14-2025-techbeat?source=rss","date":1744611058,"author":"Techbeat","guid":22807,"unread":true,"content":"<p>By <a href=\"https://hackernoon.com/u/rsystems\">@rsystems</a> [ 4 Min read ] \n In this winning article by Preeti Verma from R Systems Blogbook Ch. 1, discover how GitHub Copilot boosts developer productivity through automation and learning <a href=\"https://hackernoon.com/how-github-copilot-enhances-developer-productivity-by-preeti-verma\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/clapper\">@clapper</a> [ 4 Min read ] \n Clapper, a rapidly growing social media platform, announces its partnership with TruBit, the leading digital asset payment solutions platform in Latin America. <a href=\"https://hackernoon.com/trubit-and-clapper-bring-us-latam-payment-solutions-to-maximize-earnings-for-content-creators\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/dineshbesiahgari\">@dineshbesiahgari</a> [ 17 Min read ] \n AutoResponder AI automates email replies using AWS &amp; AI. Streamline inbox management, boost productivity, and stay responsive with this serverless Gmail assista <a href=\"https://hackernoon.com/autoresponder-ai-the-smart-way-to-manage-your-gmail-inbox\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/andrewproton\">@andrewproton</a> [ 6 Min read ] \n Would you want your chatbot to start discussing Taylor Swift lyrics instead of providing tech support? Well.. that’s what our chatbot did. Here's why. <a href=\"https://hackernoon.com/this-is-what-happens-when-you-store-your-ai-prompts-in-the-wrong-place\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/dineshbesiahgari\">@dineshbesiahgari</a> [ 4 Min read ] \n Explore the AI Knowledge Ark, a visionary initiative to safeguard humanity’s intellectual and cultural legacy. Learn how AI ensures knowledge survival, inspired <a href=\"https://hackernoon.com/an-ai-ark-could-save-human-knowledgeif-we-dont-screw-it-up-first\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/andrewproton\">@andrewproton</a> [ 7 Min read ] \n LLM prompt modularization allows you to safely introduce changes to your system over time. <a href=\"https://hackernoon.com/this-one-practice-makes-llms-easier-to-build-test-and-scale\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/plantfaceash\">@plantfaceash</a> [ 4 Min read ] \n What started as a hedgehog-led love story is now a global community powerhouse, and these murals are its loudest statement yet. <a href=\"https://hackernoon.com/hegecoin-$hege-paints-the-crypto-world-with-murals-across-9-countries\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/janinegrainger\">@janinegrainger</a> [ 3 Min read ] \n This past month, hackers stole a staggering $1.5 billion from the crypto exchange Bybit in what the market dubbed “The biggest digital heist ever” <a href=\"https://hackernoon.com/bybits-$15-billion-hack-proves-cryptos-biggest-flaw-isnt-the-blockchain\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/alexsvetkin\">@alexsvetkin</a> [ 9 Min read ] \n Large-scale LLMs test (o1, o3-mini; Gemini 2.0 Flash, 2.0 Pro, 2.5 Pro; DeepSeek V3, R1; xAI Grok 2; Claude 3.7 Sonnet) on solving Leetcode algorithmic problems <a href=\"https://hackernoon.com/testing-llms-on-solving-leetcode-problems-in-2025\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/hackercm8rb8yho00003d73roo9e3hg\">@hackercm8rb8yho00003d73roo9e3hg</a> [ 3 Min read ] \n The experience turned out to be nearly 100% “vibe coding.” In just 12 minutes, I laid down the initial gameplay by simply instructing Cursor on my goals.\n <a href=\"https://hackernoon.com/how-i-built-a-retro-game-in-an-hour-my-experience-with-gemini-25-pro-and-vibe-coding\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/hackernooncontests\">@hackernooncontests</a> [ 2 Min read ] \n HackerNoon’s #blockchain Writing Contest offers a $2,000 prize pool, including $300 for the best DePIN story. <a href=\"https://hackernoon.com/want-to-win-your-share-of-$2000-tell-us-how-your-hardware-can-power-aleph-clouds-depin\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/bigmao\">@bigmao</a> [ 7 Min read ] \n A protocol for trash pickers, not token traders. Blockchain’s most underrated use case is waste—and Web3 might just find redemption in the rubbish. <a href=\"https://hackernoon.com/proof-of-waste-the-blockchain-belongs-in-the-dumpster\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ckp\">@ckp</a> [ 3 Min read ] \n Nova Act has a 94% success rate interacting with finicky calendar widgets. The toolkit is Amazon’s first public step toward artificial general intelligence. <a href=\"https://hackernoon.com/forget-chatbots-meet-actionbots-why-amazons-nova-act-could-reshape-web-interaction\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/albertlieyeongdok\">@albertlieyeongdok</a> [ 4 Min read ] \n Discover hands-on AI projects focused on voice interfaces—build with Whisper, GPT, and TTS to create transcription tools, voice assistants and more. <a href=\"https://hackernoon.com/these-voice-first-ai-projects-make-you-productive-without-typing-and-theyre-open-source\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/jonathanpullinger\">@jonathanpullinger</a> [ 6 Min read ] \n The GameBoy changed my life and the lives of many of my peers, and I believe that context chains will do the same for web3 gaming. <a href=\"https://hackernoon.com/my-gameboy-taught-me-the-future-of-web3-gaming\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/thesavvyben_\">@thesavvyben_</a> [ 6 Min read ] \n  Discover how the decentralized internet can restore internet freedom, privacy, and security.  Learn about the future of this shift in internet control. <a href=\"https://hackernoon.com/the-internet-is-rigged-only-decentralization-can-fix-it\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/jay-thakur\">@jay-thakur</a> [ 4 Min read ] \n Edge AI agents—autonomous systems operating directly on endpoint devices—are fundamentally reshaping how we deploy intelligence.  <a href=\"https://hackernoon.com/edge-ai-agents-are-apparently-a-thing-now\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/bigmao\">@bigmao</a> [ 9 Min read ] \n Muddy’s short only works if no one understands the stack. This is the line-by-line dismantling that makes their whole bet fall apart. <a href=\"https://hackernoon.com/muddy-waters-didnt-short-applovin-they-shorted-you\">Read More.</a></p>","contentLength":3421,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The EFF's 'Certbot' Now Supports Six-Day Certs","url":"https://it.slashdot.org/story/25/04/14/0356212/the-effs-certbot-now-supports-six-day-certs?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744605240,"author":"EditorDavid","guid":22756,"unread":true,"content":"10 years ago \"certificate authorities normally issued certificate lifetimes lasting a year or more,\" remembers a new blog post Thursday by the EFF's engineering director. So in 2015 when the free cert authority Let's Encrypt first started issuing 90-day TLS certificates for websites, \"it was considered a bold move, that helped push the ecosystem towards shorter certificate life times.\"\n\n \nAnd then this January Let's Encrypt announced new six-day certificates... \n\nThis week saw a related announcement from the EFF engineering director. More than 31 million web sites maintain their HTTPS certificates using the EFF's Certbot tool (which automatically fetches free HTTPS certificates forever) — and Certbot is now supporting Let's Encrypt's six-day certificates. (It's accomplished through ACME profiles with dynamic renewal at 1/3rd of lifetime left or 1/2 of lifetime left, if the lifetime is shorter than 10 days):\n \nThere is debate on how short these lifetimes should be, but with ACME profiles you can have the default or \"classic\" Let's Encrypt experience (90 days) or start actively using other profile types through Certbot with the --preferred-profile and --required-profile flags. For six day certificates, you can choose the \"shortlived\" profile.\n \nWhy shorter lifetimes are better (according to the EFF's engineering director):\n\n If a certificate's private key is compromised, that compromise can't last as long.\n With shorter life spans for the certificates, automation is encouraged. Which facilitates robust security of web servers. \n Certificate revocation is historically flaky. Lifetimes 10 days and under prevent the need to invoke the revocation process and deal with continued usage of a compromised key.","contentLength":1730,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Trump Denies Tariff 'Exception' for Electronics, Promises New Electronics Tariffs Soon","url":"https://news.slashdot.org/story/25/04/14/0038246/trump-denies-tariff-exception-for-electronics-promises-new-electronics-tariffs-soon?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744594440,"author":"EditorDavid","guid":22741,"unread":true,"content":"Late Friday news broke that U.S. President Trump's new tariffs included exemptions for smartphones, computer monitors, semiconductors, and other electronics. But Sunday morning America's commerce secretary insisted \"a special-focus type of tariff\" was coming for those products, reports ABC News. President Trump \"is saying they're exempt from the reciprocal tariffs,\" the commerce secretary told an interviewer, \"but they're included in the semiconductor tariffs, which are coming in probably a month or two.... This is not like a permanent sort of exemption.\" \n\nThe Wall Street Journal notes that Sunday the president himself posted on social media that \"NOBODY is getting 'off the hook' for the unfair Trade Balances, and Non Monetary Tariff Barriers... There was no Tariff 'exception' announced on Friday. These products are subject to the existing 20% Fentanyl Tariffs, and they are just moving to a different Tariff 'bucket.'\" \n\n\"The administration is expected to take the first step toward enacting the new tariffs as soon as next week,\" reports the New York Times, \"opening an investigation to determine the effects of semiconductor imports on national security.\" \n\nMore from ABC News:\n\nCommerce Secretary Howard Lutnick said Sunday that the administration's decision Friday night to exempt a range of electronic devices from tariffs implemented earlier this month was only a temporary reprieve.. Lutnick said on \"This Week\" that the White House will implement \"a tariff model in order to encourage\" the semiconductor industry, as well as the pharmaceutical industry, to move its business to the United States. \"We can't be beholden and rely upon foreign countries for fundamental things that we need,\" he said.... \"These are things that are national security that we need to be made in America.\"\n","contentLength":1805,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Palantir's 'Meritocracy Fellowship' Urges High School Grads to Skip College's 'Indoctrination' and Debt","url":"https://news.slashdot.org/story/25/04/13/2342232/palantirs-meritocracy-fellowship-urges-high-school-grads-to-skip-colleges-indoctrination-and-debt?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744587840,"author":"EditorDavid","guid":22740,"unread":true,"content":"Stanford law school graduate Peter Thiel later co-founded Facebook, PayPal, and Palantir. But in 2010 Thiel also created the Thiel Fellowship, which annually gives 20 to 30 people under the age of 23 $100,000 \"to encourage students to not stick around college.\" (College students must drop out in order to accept the fellowship.) \n\nAnd now Palantir \"is taking a similar approach as it maneuvers to attract new talent,\" reports financial news site The Street:\n\n\nThe company has launched what it refers to as the \"Meritocracy Fellowship,\" a four-month internship program for recent high school graduates who have not enrolled in college. The position pays roughly $5,400 per month, more than plenty of post-college internship programs. Palantir's job posting suggests that the company is especially interested in candidates with experience in programming and statistical analysis. \nPalantir's job listing specifically says they launched their four-month fellowship \"in response to the shortcomings of university admissions,\" promising it would be based \"solely on merit and academic excellence\" (requiring an SAT score over 1459 or an ACT score above 32.) \"Opaque admissions standards at many American universities have displaced meritocracy and excellence...\"\n\nAs a result, qualified students are being denied an education based on subjective and shallow criteria. Absent meritocracy, campuses have become breeding grounds for extremism and chaos... Skip the debt. Skip the indoctrination. Get the Palantir Degree... \n\nUpon successful completion of the Meritocracy Fellowship, fellows that have excelled during their time at Palantir will be given the opportunity to interview for full-time employment at Palantir.","contentLength":1713,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"UK founders grow frustrated over dearth of funding: ‘the problem is getting worse’","url":"https://techcrunch.com/2025/04/13/uk-founders-grow-frustrated-over-dearth-of-funding-the-problem-is-getting-worse/","date":1744587828,"author":"Connie Loizos","guid":22736,"unread":true,"content":"<article>According to Dealroom data cited by the Financial Times, British startups raised just £16.2 billion last year, far less than the more than £65 billion raised by their counterparts in Silicon Valley during the same period. In fact, the U.S. appears to be pulling further ahead each year. In 2024, 57% of global venture capital […]</article>","contentLength":333,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"After Meta Cheating Allegations, 'Unmodified' Llama 4 Maverick Model Tested - Ranks #32","url":"https://tech.slashdot.org/story/25/04/13/2226203/after-meta-cheating-allegations-unmodified-llama-4-maverick-model-tested---ranks-32?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744583280,"author":"EditorDavid","guid":22712,"unread":true,"content":"Remember how last weekend Meta claimed its \"Maverick\" AI model (in the newly-released Llama-4 series) beat GPT-4o and Gemini Flash 2 \"on all benchmarks... This thing is a beast.\" \nAnd then how within a day several AI researchers pointed out that even Meta's own announcement admitted the Maverick tested on LM Arena was an \"experimental chat version,\" as TechCrunch pointed out. (\"As we've written about before, for various reasons, LM Arena has never been the most reliable measure of an AI model's performance. But AI companies generally haven't customized or otherwise fine-tuned their models to score better on LM Arena — or haven't admitted to doing so, at least.\") \n\nFriday TechCrunch on what happened when LMArena tested the unmodified release version of Maverick (Llama-4-Maverick-17B-128E-Instruct). \n\nIt ranked 32nd. \n\"For the record, older models like Claude 3.5 Sonnet, released last June, and Gemini-1.5-Pro-002, released last September, rank higher,\" notes the tech site Neowin.","contentLength":994,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Access to future AI models in OpenAI’s API may require a verified ID","url":"https://techcrunch.com/2025/04/13/access-to-future-ai-models-in-openais-api-may-require-a-verified-id/","date":1744578272,"author":"Kyle Wiggers","guid":22693,"unread":true,"content":"<article>OpenAI may soon require organizations to complete an ID verification process in order to access certain future AI models, according to a support page published to the company’s website last week. The verification process, called Verified Organization, is “a new way for developers to unlock access to the most advanced models and capabilities on the […]</article>","contentLength":359,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Three Million Child Deaths Linked To Drug Resistance, Study Shows","url":"https://science.slashdot.org/story/25/04/13/210217/three-million-child-deaths-linked-to-drug-resistance-study-shows?utm_source=rss1.0mainlinkanon&utm_medium=feed","date":1744578120,"author":"EditorDavid","guid":22691,"unread":true,"content":"\"More than three million children around the world are thought to have died in 2022 as a result of infections that are resistant to antibiotics,\" reports the BBC, citing a study by two leading experts in child health that used data from sources including the World Health Organization and the World Bank:\n\nExperts say this new study highlights a more than tenfold increase in AMR-related infections in children in just three years. The number could have been made worse by the impact of the Covid pandemic... \n\nThe report's lead authors, Doctor Yanhong Jessika Hu of Murdoch Children's Research Institute in Australia and Professor Herb Harwell of the Clinton Health Access Initiative, point to a significant growth in the use of antibiotics that are meant to only be held back for the most serious infections. Between 2019 and 2021 the use of \"watch antibiotics\", drugs with a high risk of resistance, increased by 160% in South East Asia and 126% in Africa. Over the same period, \"reserve antibiotics\" — last-resort treatments for severe, multidrug-resistant infections — rose by 45% in South East Asia and 125% in Africa. \nThe authors warn that if bacteria develop resistance to these antibiotics, there will be few, if any, alternatives for treating multidrug-resistant infections.\n \n\"Antibiotics are ubiquitous around us,\" Professor Harwell warns in the article. \"They end up in our food and the environment and so coming up with a single solution is not easy.\" The article also quotes a senior lecturer in microbiology at King's College London, who says the new study \"marks a significant and alarming increase compared to previous data\". \n\n\"These findings should serve as a wake-up call for global health leaders. Without decisive action, AMR could undermine decades of progress in child health, particularly in the world's most vulnerable regions.\" \n\nThanks to Slashdot reader Bruce66423 for sharing the article.","contentLength":1924,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Apple reportedly working on a Vision Pro that plugs into your Mac","url":"https://techcrunch.com/2025/04/13/apple-reportedly-working-on-a-vision-pro-that-plugs-into-your-mac/","date":1744576161,"author":"Anthony Ha","guid":22692,"unread":true,"content":"<article>Apple isn’t giving up on its mixed reality headset the Vision Pro, according to Bloomberg’s Mark Gurman. The company has been debating the best direction forward for the product after disappointing sales, Gurman says, but is now moving forward with two different models. One would address probably the two biggest complaints about the initial product […]</article>","contentLength":360,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Why Global Digital Ambitions Will Fail Without Connectivity and Power","url":"https://hackernoon.com/why-global-digital-ambitions-will-fail-without-connectivity-and-power?source=rss","date":1744575937,"author":"The Sociable","guid":22711,"unread":true,"content":"<h2>Once the digital control grid is in place, the crackdowns on dissent can begin: perspective</h2><p>Discussions at the World Bank Global Digital Summit conclude that everybody needs electricity and internet connectivity in order to install Digital Public Infrastructure (DPI).</p><p>\\\nIn what was basically a regurgitation of last year’s UN&nbsp;, the&nbsp;<a href=\"https://live.worldbank.org/en/event/2025/global-digital-summit\">opening day</a>&nbsp;of the World Bank Global Digital Summit 2025 included many of the same players echoing the same talking points about digital ID being central to DPI and overall digital transformation.</p><p>\\\nGiving the opening remarks, World Bank Vice President for Digital Transformation Sangbu Kim said that the World Bank Group was investing in constructing DPI (digital ID, fast payment systems, and data exchanges) all around the world, especially in developing countries.</p><blockquote><p><strong><em>“We’re strongly focusing on building Digital Public Infrastructure, so billions of people without access to digital ID, digital payments, and secure data sharing can fully participate in the digital economy”</em></strong></p><p>Sangbu Kim, World Bank Global Digital Summit, March 2025</p></blockquote><p>\\\nJust like at the UN Summit of the Future last September, the world World Bank summit placed heavy emphasis on the desire to bring internet to the 2.6 billion people who are currently without it.</p><p>\\\nWithout internet connectivity, there can be no DPI. But first, there can be no internet connectivity without electricity.</p><p>World Bank Group president Ajay Banga spoke on the issue.</p><blockquote><p><strong><em>“None of this [Digital Public Infrastructure] works without access to the internet […] Internet doesn’t happen without access to electricity”</em></strong></p><p>Ajay Banga, World Bank Global Digital Summit, March 2025</p></blockquote><p>\\\nBanga’s words echo those of Microsoft president Brad Smith, who opined at last year’s UN Summit of the Future.</p><blockquote><p><strong><em>“The electricity divide, I believe, is the fundamental cause in so many ways of the great North-South divide”</em></strong></p><p>Brad Smith, UN Summit of the Future, September 2024</p></blockquote><p>\\\nMoving on from electricity to connectivity at the World Bank Global Digital Summit, International Telecommunications Union (ITU) secretary general Doreen Bogdan-Martin said that connecting 2.6 billion people to the internet would have an estimated cost of $1.6 trillion.</p><blockquote><p><strong><em>“We have 2.6 Billion people that have never ever connected to the internet. To close that gap our latest estimate shows that we’re going to need about $1.6 trillion US dollars”</em></strong></p><p>Doreen Bogdan-Martin, World Bank Global Digital Summit, March 2025</p></blockquote><p>\\\nAnother talking point from the UN Summit of the Future that the ITU secretary general brought up was one of the affordability of handheld devices in developing countries because that’s what’s needed in order to access the internet that is already available.</p><p>“<strong><em>We also have challenges linked to affordability</em></strong>,” said Bogdan-Martin.</p><p>\\\n“<strong><em>We might get the network there, but the device is far too expensive […] We have our Device Affordability Coalition, and we have to do more to bring the cost of those devices down</em></strong>,” she added.</p><p>\\\nLast year at the UN Summit of the Future,&nbsp;Mats Granryd, the director general at the Global System for Mobile Communications Agency (GSMA), also said that getting the remaining 2.6 billion people connected to the internet was a matter of handset affordability.</p><blockquote><p><strong><em>“2.6 billion people […] are not connected to the internet and predominately to mobile internet […] The biggest barrier is handset affordability”</em></strong></p><p>Mats Granryd, UN Summit of the Future Action Day 2, September 2024 \\n </p></blockquote><p>\\\n<strong><em>These 2.6 billion people, the vast majority — 95+ percent live beneath a mobile broadband coverage</em></strong>,” said Granryd.</p><p>\\\n“<strong><em>We don’t need more stuff, we don’t need more base stations, we don’t need anything in the sky either — it is just there to use, but they can’t use it</em></strong>.”</p><p>\\\nGranryd’s solution was to make mobile handsets more affordable, with around $20 being the “sweet spot.”</p><p>\\\nOnce everyone has electricity and is connected to the internet, that is where Digital Public Infrastructure kicks in.</p><p>\\\nIt all starts with digital identity, which links to programmable fast payment systems like Central Bank Digital Currencies (CBDCs), stablecoins, and tokenized deposits.</p><p>\\\nProponents of DPI say that it will be fundamental for all citizens in order to participate in the digital economy and access governments services.</p><p>\\\nMorocco’s Minister Delegate to the Head of Government in charge of Digital Transition and Administrative Reform Amal El Fallah Seghrouchni said that in her country there were 2,700 government services available and that a single portal was needed to unify them all.</p><blockquote><p><strong><em>“There is some attention made to national digital locker. This means that Morocco is developing an interoperable and secure e-wallet”</em></strong></p><p>Amal El Fallah Seghrouchni, World Bank Global Digital Summit, March 2025</p></blockquote><p>\\\n“Today, we have like 2,700 services, so when it comes to normal people they need help to navigate,” she said.</p><p>\\\n“<strong><em>This is why this portal is very important, and it provides a good entry for each event of life</em></strong>&nbsp;— not for services.</p><p>\\\n“<strong><em>And also there is some attention made to national digital locker. This means that Morocco is developing an interoperable and secure e-wallet that will ensure compliance with international security and data protection standards</em></strong>.”</p><p>\\\nSpeaking of “each event of life,” earlier this month,&nbsp;<a href=\"https://sociable.co/government-and-policy/nigeria-cradle-to-grave-dpi-digital-id-scheme-citizen-life-events/\">Nigeria announced</a>&nbsp;it was doing something similar with regards to digital services being crucial to all “life events.”</p><p>\\\nNigeria’s Federal Ministry of Communications, Innovation, and Digital Economy, published a&nbsp;<a href=\"https://drive.google.com/file/d/1MWUm1SvRXJka3oDK8bQBJBWCzg_uughu/view\">document</a>&nbsp;called, “<strong>Supporting Life Events: The Nigeria Digital Public Infrastructure Framework</strong>,” outlining the country’s agenda to use digital ID to track and trace “key life events” of every citizen from the cradle to the grave.</p><blockquote><p><strong><em>“The Federal Government of Nigeria is on a mission to appropriately deploy digital technology to support Nigerians through these significant and profound moments so they can integrate into the state and enjoy the benefits of citizenhood from cradle to old age”</em></strong></p><p>Supporting Life Events: The Nigeria Digital Public Infrastructure Framework*, March 2025*</p></blockquote><blockquote><p><strong><em>“The Nigerian DPI will support significant landmarks such as registration of births, primary healthcare, vaccinations, student scholarships, marriages, mortgages, pensions, retirement and so on”</em></strong></p><p>Supporting Life Events: The Nigeria Digital Public Infrastructure Framework*, March 2025*</p></blockquote><p>\\\nAnd by now, you’ve probably heard of a digital wallet, but that concept is being expanded to a digital locker that can store even more personal information for public and private entities to access.</p><p>\\\nThe notion of a digital locker that the Moroccan minister mentioned was also a hot topic at the&nbsp;<a href=\"https://sociable.co/government-and-policy/digital-id-dpi-govt-tracking-individual-finances-vaccine-passports/\">Sri Lanka DPI Summit</a>&nbsp;last month.</p><p>There, one of India’s digital identity architects, Aadhaar founder CTO Srikanth Nadhamuni touted India’s “<a href=\"https://www.digilocker.gov.in/\">DigiLocker</a>” as an example for other nations to follow.</p><blockquote><p><strong><em>“Mandatory linking of Aadhaar [digital ID system] and PAN [income tax system] allowed the government to better track individuals’ financial activities”</em></strong></p><p>Srikanth Nadhamuni, Sri Lanka DPI Summit [slide], February 2025</p></blockquote><p>\\\nWith the DigiLocker, there have been “<strong><em>five point two billion digitally verified records in India. One hundred and fifty million people are using these lockers</em></strong>,” said Nadhamuni while listing the various types of records that were stored in these digital lockers.</p><p>\\\nThese records and credentials included&nbsp;<a href=\"https://sociable.co/tag/digital-id/\">digital ID</a>&nbsp;cards, educational records, caste certificates, and&nbsp;<a href=\"https://sociable.co/?s=vaccine+passports\">vaccine passports</a>, the latter of which Nadhamuni said were “super important.”</p><p>The first day of the World Bank Global Digital Summit 2025 echoed many of the same talking points as the UN Summit of the Future and other globalist meetings like the Sri Lanka DPI Summit, the UN and Gates Foundation-backed&nbsp;<a href=\"https://sociable.co/government-and-policy/50-in-5-dpi-launches-digital-id-payments-data-sharing/\">50-in-5 campaign</a>, the&nbsp;<a href=\"https://sociable.co/?s=world+government+summit\">World Governments Summits</a>, the World Economic Forum (<a href=\"https://sociable.co/?s=wef\">WEF</a>), and many, many more.</p><p>\\\nThe road to Digital Public Infrastructure is pretty straightforward:</p><ul><li>: People can’t access the internet or use devices without electricity, and AI data centers require massive amounts of energy to run</li><li><strong>Internet connectivity for all</strong>: You can’t build a digital control grid without having everybody connected to the internet</li><li><strong>Install Digital Public Infrastructure</strong>&nbsp;(DPI): Once everyone has electricity and is connected to the internet, then the digital control grid can be built through DPI (digital ID, fast payments systems like programmable digital currencies, and massive data sharing)</li></ul><p>\\\nOne topic missing from the World Bank summit was the idea of narrative control under the guise of fighting misinformation, disinformation, and hate speech.</p><p>\\\nOnce the digital control grid is fully realized, the plan is to then crackdown on any dissent to the Sustainable Development Goals.</p><p>\\\nAt last year’s UN Summit of the Future, a side event took place on September 22 entitled “” which was dedicated to attacking anyone who disagreed with UN Agenda 2030 and the Sustainable Development Goals (SDGs).</p><p>\\\nUN Under-Secretary-General for Global Communications&nbsp;Melissa Fleming, who two years prior declared, “” while admitting to partnering with Google to manipulate search results on COVID and climate narratives, said that the UN was exhausted going after disinformation and hate speech.</p><blockquote><p><strong><em>“We discovered along the way that UN content was being downranked on the very platforms that we thought were big opportunities to reach people far and wide”</em></strong></p><p>UN Communications Director Melissa Fleming, The Future of Information Integrity and the SDGs, September 2024</p><p>\\\n  \\\n  <strong><em>“We now have to communicate in a way that is going to not just break through the noise but also navigate through the disinformation and the hate”</em></strong></p><p>UN Communications Director Melissa Fleming, The Future of Information Integrity and the SDGs, September 2024 \\n </p></blockquote><p>Fleming lamented that people weren’t buying what she was selling, even to the extent that big tech platforms were downranking UN narratives, which she attributed to disinformation and hate speech.</p><p>\\\n“<strong><em>In a way we just became so exhausted by it. Why are we doing this? We even discovered along the way that UN content was being downranked on the very platforms that we thought were big opportunities to reach people far and wide</em></strong>,” she added.</p><p>\\\nFor Fleming, if you don’t agree with the UN, then you are participating in disinformation and hate speech — a common theme throughout the session.</p><blockquote><p><strong><em>“What are the tools of the New World? Everybody should have a digital ID; everybody should have a bank account; everybody should have a smartphone. Then, anything can be done. Everything else is built on that”</em></strong></p><p>Infosys Co-Founder Nandan Nilekani, IMF Spring Meetings, April 2023</p></blockquote><p>\\\nOur digital future is one where they must first get everyone electricity in order to get everyone connected to the internet.</p><p>\\\nThen, once everyone is connected, the digital gulag of Digital Public Infrastructure, which consists of digital ID, programmable digital currencies, and massive, cross-border data sharing, can begin.</p><p>\\\nFrom there, it’s mass censorship, de-platforming, de-monetizing, and downranking for anyone who doesn’t fall in line with&nbsp;<a href=\"https://sociable.co/government-and-policy/un-platforms-quash-narratives-threaten-sdgs/\">UN narratives</a>, especially as they relate to Agenda 2030 and the SDGs.</p><p>\\\nAt last year’s inaugural World Bank Global Digital Summit, World Bank president Ajay Banga said that digital identity should be embraced worldwide and that governments should be the owners, so they can guarantee privacy and security for their citizens.</p><p>\\\nThis year’s World Bank Global Digital Summit 2025 runs from March 18-19 under the theme “Digital Pathways for All.”</p>","contentLength":11624,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"AI is a Dangerous Weapon in the Age of Misinformation","url":"https://hackernoon.com/ai-is-a-dangerous-weapon-in-the-age-of-misinformation?source=rss","date":1744575909,"author":"The Tech Panda","guid":22709,"unread":true,"content":"<p>\\\nAI’s capacity to spread misinformation is reaching disturbing new heights—perhaps the most alarming form being its weaponization through deepfakes. Recently, Scarlett Johansson called for a ban on deepfake technology after a video surfaced online featuring an AI-generated version of her. The video also included other Jewish actors like Jerry Seinfeld and Mila Kunis, all wearing t-shirts with the word “Kanye” and an image of a middle finger bearing a Star of David at its center.</p><blockquote><p>“… I also firmly believe that the potential for hate speech multiplied by A.I. is a far greater threat than any one person who takes accountability for it. We must call out the misuse of A.I., no matter its messaging, or we risk losing a hold on reality,” the actress&nbsp;<a href=\"https://people.com/scarlett-johansson-artificial-intelligence-limited-ai-video-goes-viral-11305926\">told</a>.</p></blockquote><p>\\\nPeople are frequently turning to AI to speed things up, or create sensation, especially in the media industry. Last year, a Wyoming reporter&nbsp;<a href=\"https://www.theguardian.com/technology/article/2024/aug/14/wyoming-reporter-ai-cody-enterprise?utm_source=Iterable&amp;utm_medium=email&amp;utm_campaign=newsletter-20240815\">was caught</a>&nbsp;using AI to create fake quotes and stories. Creating sensational stories with the help of AI has already proven dangerous. The anti-migrant violence in UK&nbsp;<a href=\"https://time.com/7007925/misinformation-violence-riots-britain/\">was born from</a>&nbsp;online misinformation.</p><p>\\\nAfter the incident of three girls being tragically stabbed in the UK, rioters created AI-generated images that incited hatred and spread harmful stereotypes. As per&nbsp;, far-right groups also made use of AI music generators to create songs with xenophobic content. This content spread across online apps like TikTok via efficient recommendation algorithms.</p><p>\\\nLast October, according to&nbsp;,&nbsp;AI-powered search engines like Google, Microsoft, and Perplexity were found promoting scientific racism in search results.</p><p>\\\nDeepfakes of Taylor Swift, female politicians, and children that went viral last year are forcing tech companies to sit up and take notice. Henry Ajder, a generative AI expert who has studied deepfakes for nearly a decade told&nbsp;, “We are at an inflection point where the pressure from lawmakers and awareness among consumers is so great that tech companies can’t ignore the problem anymore.”</p><blockquote><p><strong>==<em>“We are at an inflection point where the pressure from lawmakers and awareness among consumers is so great that tech companies can’t ignore the problem anymore.”</em>==</strong>&nbsp;— Henry Ajder, Gen AI expert.</p></blockquote><p>\\\nFor example, Google said it is&nbsp;<a href=\"https://technologyreview.us11.list-manage.com/track/click?u=47c1a9cec9749a8f8cbc83e78&amp;id=87d8dd16cf&amp;e=25729e09dd\">taking steps to keep explicit deepfakes</a>&nbsp;from appearing in search results. Watermarks and protective shields haven’t actually worked so far. But regulation is being upped. For example, the UK banned both creation and distribution of nonconsensual explicit deepfakes. The EU has its AI Act and the US has been pushing for the Defiance Act.</p><h2><strong>AI is Aiding in Financial Fraud</strong></h2><p>AI-generated fake news spread on social media is&nbsp;<a href=\"https://newslink.reuters.com/click/38615556.78610/aHR0cHM6Ly93d3cucmV1dGVycy5jb20vdGVjaG5vbG9neS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9haS1nZW5lcmF0ZWQtY29udGVudC1yYWlzZXMtcmlza3MtbW9yZS1iYW5rLXJ1bnMtdWstc3R1ZHktc2hvd3MtMjAyNS0wMi0xNC8_dXRtX3NvdXJjZT1TYWlsdGhydSZ1dG1fbWVkaXVtPU5ld3NsZXR0ZXImdXRtX2NhbXBhaWduPURhaWx5LUJyaWVmaW5nJnV0bV90ZXJtPTAyMTQyNSZsY3RnPTYxNGRjZjJjNGEyN2FiNDVkMzY3YzFlZA/614dcf2c4a27ab45d367c1edBe8445ae6\">heightening the risks of bank runs</a>, according to a new British study that says lenders must improve monitoring to detect when disinformation risks impact customer behavior. Other kinds of fraud are also rampant.</p><p>\\\nAlso, Juniper Research&nbsp;<a href=\"https://www.juniperresearch.com/research/fintech-payments/fraud-security/merchant-fraud-prevention-research-report/\">predicts</a>&nbsp;that the value of eCommerce fraud will rise from US$44.3 B in 2024 to US$107 B in 2029, a growth of 141%.</p><p>\\\nAll thanks to AI, which is fueling the sophistication of attacks across the eCommerce ecosystem, with the use of deepfakes created using AI to defeat verification systems being a key threat. This threat, combined with rising levels of ‘friendly fraud’, where fraud is committed by the customer themselves, such as refund fraud, is increasingly threatening merchant profitability.</p><p>\\\nAI is helping fraudsters stay ahead of security measures and commit sophisticated attacks on a larger scale. AI is also making higher-quality attacks possible at an unprecedented frequency by creating credible messages and synthetic identities.</p><h2><strong>Should AI be as open as the internet?</strong></h2><p>Meta’s AI chief, Yann LeCun, has&nbsp;<a href=\"https://www.youtube.com/watch?v=Z6X6OZODzMU\">urged</a>&nbsp;that AI should be as open as the internet since eventually, all our interactions with the digital world are going to be mediated by AI assistants. LeCun explained that platforms like ChatGPT and Llama will constitute a repository of all human knowledge and culture, creating a shared infrastructure like the internet today.</p><p>He&nbsp;<a href=\"https://cbybs-zc1.maillist-manage.in/click/1127b885308d15d4/1127b885308bd1ef\">said</a>&nbsp;that we cannot have a small number of AI assistants (OpenAI’s ChatGPT and alike) controlling the digital diet of every citizen across the world. “This will be extremely dangerous for diversity of thought, for democracy, for just about everything,” he added.</p><p>\\\nAs AI becomes more and more human-like, we must remember that it is still not human. As Microsoft’s Satya Nadella told&nbsp;, AI is software and it doesn’t display human intelligence.</p><p>\\\n“It has got intelligence if you want to give it that moniker, but it’s not the same intelligence that I have,” he says.</p><p>:::info\n<strong>Navanwita Bora Sachdev, Editor, The Tech Panda</strong></p>","contentLength":4715,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Many Workers Still Feel Unprepared to Navigate AI in the Workplace","url":"https://hackernoon.com/many-workers-still-feel-unprepared-to-navigate-ai-in-the-workplace?source=rss","date":1744575902,"author":"The Tech Panda","guid":22710,"unread":true,"content":"<p>\\\nArtificial Intelligence is everywhere now. It’s safe to say that organizations have either fully adopted or are in the process of fully adopting AI in almost every department. But is every department of these organizations welcoming AI with open arms? Is every employee comfortable with AI integration in their organizations?</p><p>A joint&nbsp;<a href=\"https://web-assets.bcg.com/a0/96/9d90d6464a4aade697c3414f1b26/indias-hr-revolution-ficci-bcg-2024.pdf\">report</a>&nbsp;by the Federation of Indian Chambers of Commerce &amp; Industry (FICCI) and Boston Consulting Group (BCG) says the integration of generative AI in HR functions is creating bionic organizations that blend human creativity with technological precision. In fact, 45% of Indian companies have already implemented or are piloting GenAI in their HR processes, with 93% reporting improved process efficiency and productivity as one of the key benefits.</p><p>\\\nFinally, the report highlights the growing use of predictive analytics to enhance decision-making across the HR value chain with a third of CXOs surveyed sharing that their organization has centralized workforce planning with analytics incorporated.</p><p>As per&nbsp;<a href=\"https://www.f5.com/go/report/digital-enterprise-maturity-index-report\">F5’s 2024 Digital Enterprise Maturity Index</a>, enterprises are pushing ahead on digital transformation efforts with 29% of companies (called “doers”) now leading, up from 4% last year. 82% of “doers” operate hybrid applications, indicating advanced digital readiness and effective AI integration.</p><p>\\\nGenerative AI is fundamentally changing digital operations, significantly enhancing automation and data management. In fact, 97% of digitally mature organizations have adopted or plan to adopt Site Reliability Engineering (SRE) practices, essential for scaling AI-driven operations and maintaining performance. Also, with the increasing reliance on AI, 92% of mature organizations have adopted zero trust principles, reflecting a higher confidence level in their security frameworks.</p><p>\\\nOrganizations whose automation maturity is “automated” saw the biggest benefits: 53% enjoy greater consistency, 71% saw cost savings, and 80% report greater operational efficiencies. Advanced organizations manage an average of 468 APIs, showcasing a sophisticated digital infrastructure prepared for AI integration.</p><p>Different departments of organizations are responding in different ways as AI gets integrated into them. For example, 60% of respondents to ISACA’s recent&nbsp;<a href=\"https://www.isaca.org/resources/infographics/2024-ai-pulse-poll?utm_source=isaca&amp;utm_medium=other&amp;utm_campaign=pr_both_training_artificial-intelligence_ai_q324_ai-courses-part-2&amp;utm_content=ai_ai-courses-part-2&amp;cid=pr_4000151&amp;appeal=pr\">2024 AI Pulse Poll</a>&nbsp;believe AI will have a positive impact on audit/assurance in the next year—the highest number compared to other domains like risk, compliance, security, IT strategy/governance, and privacy.</p><p>\\\nAI has certainly made things uncertain in the IT workplace though. 39% believe that AI will have a negative impact on privacy as a professional domain in the next year. Additionally, 20% of respondents indicated they are not at all confident in their ability to detect AI-powered misinformation; the same percentage echoed this lack of confidence in their organizations’ abilities. When asked who is responsible for overseeing the usage of AI within their organization, one in five said they are not sure.</p><p>\\\nHowever, with 23% of respondents saying their organization is considering increasing those AI jobs and 5% saying they will need AI training within two years to help them retain their roles or advance their careers, education,n and training will be essential for professionals to keep pace.</p><p>\\\n“As AI continues to impact professions across many fields in a rapid and unprecedented way, those from auditors and cybersecurity managers, to risk analysts and privacy professionals will need to understand the technology, as well as its applications and impact as it pertains to their work,” said Shannon Donahue, ISACA Chief Content and Publishing Officer. “Digital trust professionals at all career stages should explore the range of tools at their disposal to stay informed and relevant when it comes to emerging technologies, to both expand their knowledge and futureproof their careers.”</p><p>\\\nGenerative AI is transforming quality engineering, HR, and digital operations, accelerating productivity and automation. While AI fluency is in high demand, upskilling remains crucial. As businesses navigate AI integration, addressing security concerns and knowledge gaps will be essential. Organizations that invest in AI-driven tools and training will stay competitive in this evolving landscape. Still, there are kinks that need to be worked out. Not all employees feel ready to flow with AI at the workplace.</p>","contentLength":4442,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"New Tech Is Changing Hiring, Fast","url":"https://hackernoon.com/new-tech-is-changing-hiring-fast?source=rss","date":1744575887,"author":"The Tech Panda","guid":22708,"unread":true,"content":"<p>\\\n<strong>The one constant in life is change, and the job market is the perfect example. Only 20 years ago, job seekers walked into physical businesses, clutching printed resumes hoping for an interview. Today, the hiring landscape is completely reliant on new technology.</strong></p><p>\\\nThe development of AI and automation is causing big shifts in the job market, making some jobs obsolete—take data entry and manufacturing roles, for example. At the same time, ongoing labor shortages receive widespread media attention. There are  job openings in the US, but only 6.8 million job seekers, emphasizing an increasing mismatch between job openings and worker qualifications.</p><p>\\\nBusinesses are under immense pressure to fill positions quickly to keep operations unaffected while ensuring they’re finding the most qualified person for the job. To balance this hiring conundrum, companies need to switch up their hiring practices and benefit from new technologies like AI-driven recruitment tools, skills-based hiring platforms, and blockchain to find and hire top industry professionals before their competition does.</p><p>\\\nLet's explore technology that’s changing the way businesses and job seekers connect.</p><h2>Smarter Candidate Matching</h2><p>Applicant tracking systems (ATS) have already improved HR processes, helping companies track applications and automate messaging. But with AI integration, hiring is taken to the next level as ATS can now analyze and filter resumes, searching for specific keywords like job titles, relevant skills, and industry experience. For example, if a company is hiring a data analyst, the HR manager can set the parameters so the AI-powered ATS can prioritize resumes that include keywords like SQL, Python, and Tableau.</p><p>\\\nBy offloading manual tasks to AI platforms, HR managers can spend their time on building a happier, more productive workforce, such as enhancing their employer branding, developing their talent strategy, and developing employee retention techniques. Plus, since top candidates are typically only in the job market for around , being able to filter through masses of applications quickly is essential.</p><p>\\\nHowever, when using AI in hiring, decision-makers must take action to avoid bias. Previously,  used an AI algorithm to review 10 years’ worth of resumes to understand how to find the best candidates. Unfortunately, due to the lower number of female employees, the AI algorithm thought male dominance in the workplace was a factor for success.</p><p>\\\nAlthough most businesses don’t design the AI models they use, ultimately they must take responsibility for ensuring ethical and unbiased implementation. Therefore, company AI models need to be trained on varied and equal datasets and require regular human oversight to check for patterns is a must to ensure that hiring aligns with the business diversity goals. This can be done in-house if the expertise is available, or AI consulting firms can be brought in to assess the model and its data sets.</p><p>\\\nBut AI isn't only for businesses. AI-powered platforms are now also available for job seekers, which can optimize resumes, cover letters, and LinkedIn profiles. It’s only fair for candidates to be able to use the technology they’re up against in the application process, allowing them to meet the requirements of the AI-powered ATS systems. This includes adding the right keywords at the right density, excluding unnecessary information, and checking that the layout is ATS-approved. Platforms can also help candidates quickly update their resume for each job application and ensure resumes, cover letters, and LinkedIn profiles all tell a cohesive story.</p><p>There's been a growing shift toward skills-based hiring over degree-based credentials, and the US is leading the way in this HR revolution. The Boston Consulting Group found that job postings requiring a bachelor's degree declined by  between 2017 and 2022 for college-level vacancies. This is likely linked to the revelation that skills-based hires are more loyal to their employers and have a 9% lengthier tenure at their organizations compared with traditional hires.</p><p>\\\nWhile testing candidates isn’t a new concept, for instance back in 2017  started using online recruiting games, analyzing candidates’ risk assessment skills and fairness during the application process. However, new AI-powered platforms offer hundreds of online tests assessing technical skills like an AWS Kubernetes test to soft skills and tests on emotional intelligence and brainstorming.</p><p>\\\nThese platforms offer pre-made evaluations, so businesses can test and go, or HR managers can design customizable tests and assessments tailored to specific job roles. The AI algorithms can also adjust the difficulty of the tests based on a candidate’s responses, meaning businesses get a true measure of a candidate's skills, and eliminate the need for hiring managers to manually review test scores. Regarding test integrity, many platforms offer features like video monitoring and screen recording and restrict access to other websites.</p><p>\\\nBusinesses spend around  to source and hire each new candidate, so this extra level of testing can save a substantial amount of money, especially if in a high-turnover industry.</p><p>\\\nThese platforms can integrate easily with existing ATS and HR tools through API integrations, which allow for the exchange of secure data. This real-time data synchronization automatically transfers candidate information, test results, and evaluation metrics, helping to optimize the testing routine and increasing the hiring speed.</p><h2>Transparent Credential Verification</h2><p>As its name indicates, blockchain holds \"blocks\" of records, in an immutable \"chain,\" creating a secure and trustworthy way to share information. This is becoming considerably useful for HR managers looking to filter out candidates who embellish resumes with extra skills and additional years of experience. Plus,  of HR practitioners are so busy that they cannot verify every candidate's qualifications and background.</p><p>\\\nSince blockchains are decentralized and act as distributed ledgers, this means once information is uploaded, it’s very difficult to alter or delete. Therefore, hiring managers who have found their top candidates can verify their degrees or work credentials on the blockchain that would have been issued and uploaded by their university and previous employers.</p><p>\\\nIn the case of background checks—which usually take around —candidates with blockchain records could control who views their verified credentials and grant permission to potential employers immediately, streamlining the hiring process while maintaining privacy.</p><p>\\\nThe job market will continue to evolve in tandem with new technology and societal shifts. So for businesses to stay competitive and effectively match talent with opportunities they need to incorporate new technologies into the recruitment process. As AI and blockchain develop, they continue to play a vital role in shaping the future of work—one where hiring is faster, fairer, and more reliable than ever.</p>","contentLength":7049,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["tech"]}