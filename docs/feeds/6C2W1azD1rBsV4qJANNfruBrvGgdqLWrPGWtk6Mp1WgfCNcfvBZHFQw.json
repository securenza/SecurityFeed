{"id":"6C2W1azD1rBsV4qJANNfruBrvGgdqLWrPGWtk6Mp1WgfCNcfvBZHFQw","title":"The System Design Newsletter","displayTitle":"Dev - System Design Newsletter","url":"https://newsletter.systemdesign.one/feed","feedLink":"https://newsletter.systemdesign.one/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":3,"items":[{"title":"Your YouTube Channel to Learn System Design üî•","url":"https://newsletter.systemdesign.one/p/system-design-youtube-channel","date":1738928139,"author":"Neo Kim","guid":65,"unread":true,"content":"<p>I created a YouTube channel to help you learn system design.</p><p>‚Ä¢ System design fundamentals.</p><p>‚Ä¢ System design interview preparation tips.</p><p>‚Ä¢ Simplified engineering case studies with visuals.</p><p>‚Ä¢ System design deep dives with real-world software architecture.</p><p>You'll receive a new video every 10 days.</p><p>I'll make it your main video channel for system design over time.</p><p>And I want to help you become good at work + ace system design interviews:</p><p>Please show your support,</p>","contentLength":461,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/83516d21-e16e-4561-861e-e83b9bf60224_1280x720.gif","enclosureMime":"","commentsUrl":null},{"title":"1 Simple Technique to Scale Microservices Architecture üöÄ","url":"https://newsletter.systemdesign.one/p/how-to-scale-microservices","date":1738677848,"author":"Neo Kim","guid":64,"unread":true,"content":"<p>Get the powerful template to approach system design for FREE on newsletter sign-up:</p><p><em>You will find references at the bottom of this page if you want to go deeper.</em></p><p>Once upon a time, there was a tech startup.</p><p>They tracked food deliveries in real-time.</p><p>Yet they had only a few customers; so, a simple monolith architecture was enough.</p><p>Until one day, an influencer with a massive following shared their app, and traffic skyrocketed.</p><p>So they moved to microservices architecture for scale.</p><p>Although it temporarily solved their scalability issues, there were newer problems.</p><ol><li><p>Implementing new features became difficult because of the dependencies between microservices.</p></li><li><p>The operational complexity increased due to different programming languages across microservices.</p></li></ol><p>Authorization can make or break your application‚Äôs security and scalability. From managing dynamic permissions to implementing fine-grained access controls, the challenges grow as your requirements and users scale.</p><p>This eBook will guide you through the 6 key requirements all authorization layers should include to avoid technical debt:</p><ul><li><p>Architectural and design considerations for building a scalable and secure authorization layer.</p></li><li><p>20+ technologies, approaches, and standards to consider for your permission management systems.</p></li><li><p>Practical insights, based on 500+ interviews with engineers, architects, and IAM professionals.</p></li></ul><p>Learn how to create an authorization solution that evolves with your business needs, while avoiding technical debt.</p><h2>How to Scale Microservices</h2><p>They wanted to reduce the maintenance effort and scale microservices quickly.</p><p>So they relied on automation.</p><p>A microservice must be scaled to handle changing traffic.</p><p>Yet scaling manually is slow and causes errors.</p><p>So they use <a href=\"https://en.wikipedia.org/wiki/Infrastructure_as_code\">infrastructure as code</a> to keep things simple; it‚Äôs used to deploy new instances based on demand.  means managing and provisioning infrastructure using code.</p><p>Ready for the next technique?</p><p>It‚Äôs difficult to understand and maintain APIs without a proper naming convention.</p><p>Yet maintaining consistent naming for APIs across microservices is hard. </p><p><em>So they generate APIs using code and store API definitions as JSON in a separate Git repository.</em></p><p>Here are the benefits of code-generated APIs:</p><ul><li><p>API paths can be validated using <a href=\"https://www.sonarsource.com/learn/linter/\">linters</a>.</p></li><li><p>API naming conventions and request-response structures are standardized.</p></li><li><p>API version changes can be tracked through tagging.</p></li><li><p>It ensures API operations are defined.</p></li><li><p>User-friendly API paths can be set up as default.</p></li></ul><p>Also it standardizes APIs built using different programming languages. Put simply, code generation makes it look like a single person wrote APIs across the system.</p><p>Besides code generation ensures health checks are included in each microservice.</p><ul><li><p>A health check URL is included in the API specification of the microservice.</p></li></ul><p>An unhealthy service is removed from production to avoid service interruptions.</p><p>A change to database schema shouldn‚Äôt break microservices depending on it. </p><p>Yet sharing a single database across microservices introduces tight coupling and failure risk.</p><p>So they set up separate databases for each microservice.</p><p>But maintaining many databases is a huge effort; so, they create databases and tables using code.</p><p>Here are its main benefits:</p><ul><li><p>Consistent database names.</p></li><li><p>Ensure proper database indexes exist from the start.</p></li><li><p>Easy to maintain and operate the database.</p></li></ul><p>Besides a microservice shouldn't talk to a database owned by another microservice. Instead, communication happens only via the microservice‚Äôs API owning the database. Otherwise, the data changes aren't safe as they bypass business logic.</p><p>: use code generation and automation to scale microservices quickly. It reduces maintenance efforts and helps with version control.</p><p>üëã  -Do you want to level up at work and better understand technical discussions?</p><p>My mission is to help you go from 0 to 1 in system design by spending less than 37 minutes a month.</p><ul><li><p>I launched the newsletter deep dives last month.</p></li></ul><ul><li><p>Yet future deep dives, starting this month, are available only to paid subscribers.</p></li><li><p>And subscription fees will be higher than the current fees.</p></li></ul><p>So<strong> pledge now to get access at a very low price.</strong></p><p><em>‚ÄúThis newsletter is an amazing resource for learning system design.‚Äù </em>Alex</p><p>Subscribe to get simplified case studies delivered straight to your inbox:</p><p><strong>Want to advertise in this newsletter? </strong>üì∞</p><p>Thank you for supporting this newsletter.</p><p>You are now 123,001+ readers strong, very close to 124k. Let‚Äôs try to reach 124k readers by 10 February. Consider sharing this post with your friends and get rewards.</p>","contentLength":4531,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/84c96d29-cf27-47f0-9e1c-78ca1fa5f461_1280x720.gif","enclosureMime":"","commentsUrl":null},{"title":"How Bluesky Works ü¶ã","url":"https://newsletter.systemdesign.one/p/how-does-bluesky-work","date":1737551587,"author":"Neo Kim","guid":63,"unread":true,"content":"<p>Get the powerful template to approach system design for FREE on newsletter sign-up:</p><p><em>This post outlines Bluesky architecture; you will find references at the bottom of this page if you want to go deeper.</em></p><p><em>Note: I wrote this post after reading their engineering blog and documentation.</em></p><p>Once upon a time, Twitter had only a few million users.</p><p>And each user interaction went through their centralized servers.</p><p>So content moderation was easy.</p><p>Yet their growth rate was explosive and became one of the most visited sites in the world.</p><p>So they added automation and human reviewers to scale moderation.</p><p>Although it temporarily solved their content moderation issues, there were newer problems. Here are some of them:</p><ul><li><p>The risk of error increases if a single authority decides the moderation policies.</p></li><li><p>There‚Äôs a risk of bias when a single authority makes moderation decisions.</p></li><li><p>Managing moderation at scale needs a lot of effort; it becomes a bottleneck.</p></li></ul><p>So they set up <a href=\"https://bsky.app/\">Bluesky</a>: a research initiative to build a decentralized social network.</p><p>A decentralized architecture distributes control across many servers.</p><p>Here are 3 popular decentralized architectures in distributed systems:</p><ul><li><p>Federated architecture: client-server model; but different people run parts of the system and parts communicate with each other.</p></li><li><p>Peer-to-Peer architecture: there‚Äôs no difference between client and server; each device acts as both.</p></li><li><p>Blockchain architecture: distributed ledger for consensus and trustless interactions between servers.</p></li></ul><p><em>Bluesky uses a federated architecture</em><em>for its familiar client-server model, reliability, and convenience.</em> So each server could be run by different people and servers communicate with each other over HTTP.</p><p>Think of the federated network as email; a person with Gmail can communicate with someone using Protonmail.</p><p>Yet building a decentralized social network at scale is difficult.</p><p>So smart engineers at Bluesky used simple ideas to solve this hard problem.</p><p><em>I wrote a summary of this post (save it for later):</em></p><p>They created a decentralized open-source framework to build social networking apps, called Authenticated Transfer Protocol (), and built Bluesky on top of it.</p><p>Put simply, Bluesky doesn‚Äôt run separate servers; instead, ATProto servers distribute messages to each other.</p><p>A user‚Äôs data is shared across apps built on ATProto; Bluesky is one of the apps. So if a user switches between apps on ATProto, such as a photo-sharing app or blogging app, they don‚Äôt lose their followers (<a href=\"https://en.wikipedia.org/wiki/Social_graph\">social graph)</a>.</p><p>Imagine ATProto as Disneyland Park and Bluesky as one of its attractions. A single ticket is enough to visit all the attractions in the park. And if you don‚Äôt like one of the attractions, try another one in the park.</p><p>Here‚Äôs how Bluesky works:</p><p>A <a href=\"https://docs.bsky.app/docs/tutorials/creating-a-post\">post</a> is a short status update by a user; it includes text and images. </p><p>The text content and timestamp of the post are stored in a . <em>Think of the repository as a collection of data published by a single user.</em><a href=\"https://www.sqlite.org/\">SQLite</a> is used as its data layer for simplicity; each repository gets a separate SQLite database.</p><p>The data records are encoded in <a href=\"https://cbor.io/\">CBOR</a>, a compact binary format, before storing it in SQLite for low costs.</p><p>Repositories of different users are stored on a ; they set up many data servers for scale.</p><p><em>A data server exposes HTTP to handle client requests. </em>Put simply, the data server acts as a proxy for all client interactions. Also it manages user authentication and authorization. The data server includes tooling to automatically apply updates in the federated architecture.</p><p>They run 6 million user repositories on a single data server at 150 USD per month.</p><p>Think of the user repository as a Git repo and the data server as GitHub. It‚Äôs easy to move a Git repo from GitHub to GitLab. Similarly, a user repository is movable from one data server to another.</p><p>Besides it‚Äôs possible to use <a href=\"https://docs.bsky.app/showcase?tags=client\">alternative clients</a> for Bluesky. Yet it‚Äôs necessary to maintain a standard data schema for interactions. So separate  and API endpoints are defined for each app on ATProto, including Bluesky.</p><p>A user's repository doesn‚Äôt store information about actions performed by their followers such as comments or likes on their post. Instead, it‚Äôs stored only in the repository of the follower who took the action.</p><p>A post is shown to the user‚Äôs followers.</p><p>Yet it‚Äôs expensive to push updates to each follower‚Äôs repository. So information is collected from every data server using the .</p><p>The crawler doesn‚Äôt index data but forwards it.</p><ul><li><p>The crawler subscribes for updates on the data server: new posts, likes, or comments.</p></li><li><p>The data server notifies the crawler about updates in real time over <a href=\"https://en.wikipedia.org/wiki/WebSocket\">websockets</a>.</p></li><li><p>The crawler collects information from data servers and generates a .</p></li></ul><p>Consider the generated stream as a log over websockets; put simply, the crawler combines each user‚Äôs actions into a single TCP connection.</p><p>A user's post is shown to followers only after counting the likes, comments, and reposts on it.</p><p>Yet the stream doesn‚Äôt contain this information. So the stream‚Äôs data is aggregated using the ; it transforms raw data into a consumable form by processing it. Imagine the index server as a data presentation layer.</p><p>The index server is built using the <a href=\"https://go.dev/\">Go</a> language for concurrency. A NoSQL database, <a href=\"https://www.scylladb.com/\">ScyllaDB</a>, is used as its data layer for horizontal scalability.</p><p>A reference to the user's post ID is added to the follower‚Äôs repository when they like or repost a post. So the total number of likes and reposts is calculated by crawling every user repository and adding the numbers.</p><p>Here‚Äôs the workflow for displaying a post:</p><ul><li><p>A user‚Äôs request is routed via their data server to the index server.</p></li><li><p>The data server finds the people a user follows by looking at their repository.</p></li><li><p>The index server creates a list of post IDs in reverse chronological order.</p></li><li><p>The index server expands the list of post IDs to full posts with content.</p></li></ul><p>The index server then responds to the client.</p><p>In short, a user repository stores primary data, while the index server stores derived data from repositories.</p><p>The index server is the most read-heavy service; so, its results are cached using <a href=\"https://en.wikipedia.org/wiki/Redis\">Redis</a>, an in-memory storage, for performance.</p><p>JSON Web Token () is used for authentication between Bluesky services.</p><p>Media files, such as images and videos, are stored on the data server‚Äôs disk for simplicity. A cryptographic ID () is used to reference the media files in the repository. The index server fetches the media files from the data server on user request and caches them on the content delivery network () for efficiency.</p><p>A user updates only their repository when they follow someone. </p><p>Their repository adds a reference to the user‚Äôs unique decentralized identifier () to indicate follow.</p><p>The number of followers for a user is found by indexing every repository. This is similar to how Google finds inbound links to a web page; all documents on the web are crawled.</p><p>A user account includes a handle based on the domain name (); it keeps things simple.</p><p>And each user automatically gets a handle from the ‚Äòbsky.social‚Äô subdomain upon account creation. Yet posts are stored using DID, and the user handle is displayed along with the posts. So changes to a user's handle don‚Äôt affect their previous posts.</p><p>A user‚Äôs DID is immutable, but the handle is mutable; put simply, a user‚Äôs handle is reassignable to a custom domain name.</p><p>Here‚Äôs how a user handle with a custom domain name is verified on Bluesky:</p><ul><li><p>The user enters their custom domain name in the Bluesky account settings.</p></li><li><p>Bluesky generates a unique text value for the user: public key.</p></li><li><p>The user stores this value in the <a href=\"https://www.cloudflare.com/en-gb/learning/dns/dns-records/dns-txt-record/\">DNS TXT record</a> of the custom domain name.</p></li></ul><p>The index server then periodically checks the DNS TXT record and validates the user handle. Imagine  as a text data field for domain name settings.</p><h3>3. User Timeline and Feed</h3><p>A user‚Äôs timeline is created by arranging their posts in reverse chronological order.</p><p>Yet a user‚Äôs repository doesn‚Äôt contain information about likes and comments received on a post. So the request is sent to the index server; it returns the user‚Äôs timeline with aggregated data.</p><p>A feed is created from posts by people a user follows.</p><p>Bluesky supports <a href=\"https://bsky.app/feeds\">feeds</a> with custom logic, and there are 50K+ custom feeds available. </p><p>Consider the  as a filter for a specific list of keywords or users.</p><ul><li><p>The crawler generates a stream from data servers.</p></li><li><p>The feed generator filters, sorts, and ranks the content based on custom logic.</p></li><li><p>The feed generator creates a list of post IDs.</p></li></ul><p>The index server then populates the feed‚Äôs content on a user request.</p><p> is used to fetch the feed; it offers better performance. </p><p>It includes an extra parameter in API requests and responses. The cursor parameter points to a specific item in the dataset; for example, the post‚Äôs timestamp to fetch feed until a specific post.</p><ul><li><p>A sequential unique column, such as the post's timestamp, is chosen for pagination.</p></li><li><p>The user requests include the cursor parameter to indicate the result‚Äôs offset.</p></li><li><p>The index server uses the cursor parameter to paginate the result dataset.</p></li><li><p>The index server responds with the cursor parameter for future requests.</p></li></ul><p>The client decides the cursor parameter‚Äôs window size based on its viewport. The cursor-based pagination scales well as it prevents a full table scan in the index server.</p><p>Imagine a  as metadata to categorize content. Besides it‚Äôs possible to apply a label manually. A user chooses to hide or show a warning for posts with a specific label.</p><p>This preference is stored on their data server.</p><p>Here‚Äôs how Bluesky moderation works:</p><ul><li><p>The moderation service consumes the stream from the crawler.</p></li><li><p>The moderation service analyzes the content and assigns a label to it.</p></li><li><p>The index server stores the content along with its label.</p></li><li><p>The user requests are routed via the data server to the index server.</p></li><li><p>The data server includes label IDs in HTTP request headers before forwarding them.</p></li><li><p>The index server applies the label setting in the response.</p></li></ul><p>Also a data server operator does basic moderation. </p><p>The data server filters out the muted users before responding to the client.</p><p>Put simply, a user can post about anything, but the content is moderated before being shown to the public.</p><p>Bluesky allows a user to see how many people they follow also follow a specific user: <a href=\"https://www.ernberck.com/social-proof-explained/\">social proof</a>.</p><p>For example, when I visit <a href=\"https://bsky.app/profile/jay.bsky.team\">Jay‚Äôs</a> Bluesky profile, it shows how many people I follow also follow her.</p><p><em>Let‚Äôs dive into the different approaches they used to build this feature.</em></p><ul><li><p>Find the people I follow by querying the database.</p></li><li><p>Do separate parallel queries for each user to find the people they follow.</p></li><li><p>Check if any of them also follow Jay.</p></li></ul><p>But this approach won‚Äôt scale as the number of parallel queries increases with the number of people a user follows.</p><p>A scalable approach is to convert it into a set intersection problem:</p><ul><li><p>Set 1 tracks the people I follow.</p></li><li><p>Set 2 tracks the people who follow Jay.</p></li></ul><p>The intersection of these sets gives the expected result.</p><p>An in-memory graph service prevents expensive database queries and performs intersections quickly. Yet <a href=\"https://redis.io/docs/latest/develop/data-types/sets/\">Redis Sets</a> don‚Äôt use different CPU cores at once. So here‚Äôs how they implemented a minimum viable product:</p><ul><li><p>Each user has a 32-character DID.</p></li><li><p>The DID values are <a href=\"https://en.wikipedia.org/wiki/String_interning\">converted</a> into uint64 to reduce memory usage.</p></li><li><p>Each user‚Äôs DID maintains 2 sets: people they follow and people who follow them.</p></li></ul><p>But it still consumes a lot of memory and takes extra time to start.</p><p>So they optimized the graph service by implementing it using <a href=\"https://vikramoberoi.com/posts/a-primer-on-roaring-bitmaps-what-they-are-and-how-they-work/\">Roaring Bitmaps</a>.</p><p><em>Yet let‚Äôs take a step back and learn Bitmaps to better understand Roaring Bitmaps.</em></p><p>A  represents binary states using bit arrays.</p><p>Imagine Bluesky has only 100 users.</p><p>The index value of the people I follow is set to 1 on the Bitmap; the people I follow are then found by walking the Bitmap and recording the index of non-zero bits. A constant time lookup tells whether I follow a specific user. Although Bitmaps do faster bitwise operations, it‚Äôs inefficient for sparse data. </p><p>A 100-bit long Bitmap is needed even if I follow only a single user; so, it won‚Äôt scale for Bluesky‚Äôs needs.</p><p>It turns consecutive 0s and 1s into a number for reduced storage. For example, if I follow the last 10 users, only the last 10 indices are marked by 1. With Run-Length Encoding, it‚Äôs stored as 90 0s and 10 1s, thus low storage costs.</p><p>But this approach won‚Äôt scale for randomly populated data, and a lookup walks the entire Bitset to find an index.</p><p>Ready for the best technique? .</p><p>Think of it as compressed Bitmaps, but 100 times faster. <em>A Roaring Bitmap splits data into containers and each container uses a different storage mechanism.</em></p><ul><li><p>The dense data is stored in a container using Bitmap; it uses a fixed-size bit array.</p></li><li><p>The data with a large contiguous range of integers are stored in a container using run-length encoding; which reduces storage costs.</p></li><li><p>The sparse data is stored in a container as integers in a sorted array; it reduces storage needs.</p></li></ul><p>Put simply, Roaring Bitmaps use different containers based on data sparsity.</p><p>The set intersection is done in parallel and a container is converted into a different format for the set intersection. Also the graph data is stored and transferred over the network in Roaring Bitmap‚Äôs <a href=\"https://github.com/dgraph-io/sroar\">serialization format</a>.</p><p>Many instances of graph service are run for high availability and <a href=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/\">rolling updates</a>.</p><p>Bluesky supports short videos up to 90 seconds long.</p><p>The video is streamed through HTTP Live Streaming (). Think of HLS as a group of text files; it‚Äôs a standard for adaptive bitrate video streaming.</p><p>A client dynamically changes video quality based on network conditions.</p><ul><li><p>A video is encoded into different quality levels: 480p, 720p, 1080p, and so on.</p></li><li><p>Each encoded video is split into small segments of 5 seconds long.</p></li></ul><p>The client checks the network conditions and requests video segments of the right quality.</p><p>HLS uses Playlist files to manage encoded video segments. </p><p>Imagine the  as a text file, and there are 2 types of Playlists:</p><ul><li><p>Master playlist: list of all video quality levels available.</p></li><li><p>Media playlist: list of all video segments for a specific video quality.</p></li></ul><p>First, the client downloads the Master playlist to find available quality levels. Second, it selects a Media playlist based on network conditions. Third, it downloads the video segments in the sequence defined on the Media playlist.</p><p>The videos and playlists are cached in CDN to reduce costs and handle bandwidth needs. The stream requests are routed to CDN via <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/302\">302 HTTP redirects</a>.</p><p>The video views are tracked by <a href=\"https://systemdesign.one/distributed-counter-system-design/\">counting</a> requests to its Master playlist file.</p><p>And the response for the Master playlist includes a Session ID; it‚Äôs included in future requests for Media playlists to track the user session.</p><p>Besides the video seconds watched by a user are found by checking the last fetched video segment.</p><p>A video subtitle is stored in text format and has a separate Media playlist file.</p><p>The Master playlist includes a reference to subtitles; here‚Äôs how it works:</p><ul><li><p>The client finds the available subtitles by querying the Master playlist.</p></li><li><p>The client downloads a specific subtitle's Media playlist based on the language selected by the user.</p></li></ul><p>The client then downloads the subtitle segments defined in the Media Playlist.</p><p>Subscribe to get simplified system design case studies delivered to your inbox:</p><h3>Bluesky Quality Attributes</h3><p>A user‚Äôs data is cryptographically signed before saving it in the data server; it shows data authorship.</p><p>The <a href=\"https://www.baeldung.com/cs/merkle-trees\">Merkle search tree</a> is used to check the integrity of data, such as posts, transferred over the network.</p><p>Think of the  as an efficient data structure to check data integrity. It doesn‚Äôt store original data; instead, it has only cryptographic hashes representing data.</p><p>Besides the crawler keeps a copy of each user‚Äôs repository; it verifies the Merkle search tree signatures on data updates.</p><p>The crawler generates a stream to update the index server.</p><p>Yet the stream increases bandwidth and infrastructure costs. So the events are validated on the crawler and services, such as the feed generator, are connected to a trusted crawler. Besides Merkle search tree blocks are <a href=\"https://github.com/bluesky-social/jetstream\">converted</a> to JSON objects, which lack verifiability and signatures, to reduce stream size.</p><p>Put simply, Merkle search tree verification overhead is avoided by consuming the stream from a trustable crawler.</p><p>The crawler transfers the stream to the index server over websockets; <a href=\"https://facebook.github.io/zstd/\">zstd</a> compresses websocket traffic for performance.</p><p>A user, with a massive following, needs a data server with only tiny computing resources as the index server displays aggregated data.</p><p>Every change to a user's profile is propagated via the index server; which, means <a href=\"https://systemdesign.one/consistency-patterns/#eventual-consistency\">eventual consistency</a>.</p><p>Yet a user viewing their profile right after an update should see the latest changes. So Bluesky offers <em>read-after-write consistency for profile updates</em>; here‚Äôs how:</p><ul><li><p>All client requests are routed via the data server to the index server.</p></li><li><p>The response headers from the index server are compared against the data server. </p></li><li><p>The response is updated to include missing records before returning it to the client.</p></li></ul><p>This read-after-write behavior applies only to a user viewing their profile; others see the changes eventually.</p><p>A popular user's post notifies many users, which results in many requests to view the post at once.</p><p>The results from the index server are cached to reduce the database load. Yet a popular user's post creates a <a href=\"https://en.wikipedia.org/wiki/Thundering_herd_problem\">thundering herd problem</a>.</p><ul><li><p>A view request, the first one, from a follower reaches the cache server.</p></li><li><p>The cache server queries the database for post content.</p></li><li><p>Requests from others reach the database while the cache waits for the first response.</p></li></ul><p>It groups requests for the same data within a short period. Then forwards only a single request to the database; thus, preventing the thundering herd problem.</p><p>The data server notifies the crawler about data changes in repositories over websockets.</p><p>Yet network interruptions occur, so the crawler periodically checks repositories. It then compares the data against its local replica to find data changes.</p><p>Also requests are rate-limited to keep the system operational.</p><p><a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\">HTTP 429 (Too Many Requests)</a> is returned in response headers when the rate limit threshold is exceeded. Interactions between servers are also rate-limited to avoid abuse in the decentralized architecture. A new data server‚Äôs request limit capacity is increased over time, based on trust, to keep the crawler running smoothly.</p><p>Besides a user is only allowed up to 1,666 requests an hour to reduce bot activity.</p><p>Bluesky has more than <a href=\"https://blueskyusercount.com/\">28 million users</a>; it became an independent company in 2021.</p><p>Although anybody can host a server on ATProto, most Bluesky services are now run by a single company.</p><p>ATProto and Bluesky look like an interesting new approach to social networks.</p><p>üëã  -Do you want to level up at work and better understand technical discussions?</p><p>My mission is to help you go from 0 to 1 in system design by spending less than 37 minutes a month.</p><p>This is the first deep dive article in this newsletter; it's a free preview.</p><ul><li><p>Yet future deep dives, starting this February, are available only to paid subscribers.</p></li><li><p>And subscription fees will be way higher than the current fees.</p></li></ul><p>So<strong> pledge now to get access at a very low price.</strong></p><p><em>\"This newsletter gave me ideas on how to build scalable systems.\"</em> Aditya, Google.</p><p>Subscribe to get simplified case studies delivered straight to your inbox:</p><p>Thank you for supporting this newsletter. Consider sharing this post with your friends and get rewards. Y‚Äôall are the best.</p>","contentLength":19389,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/449c6406-d812-4547-bc2a-8e55c325ce3c_1280x720.gif","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}